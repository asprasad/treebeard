\section{Conclusions}
\label{sec:conclusion}
Two trends motivate the need for systems that provide portable 
performance for ML inference -- machine learning 
is becoming more ubiquitous and hardware is getting more diverse.
This paper discusses the challenges in targeting decision tree models
to run at peak performance on CPUs and GPUs. To address these, we 
design \Treebeard{}, a schedule-guided, retargetable compiler for
decision tree inference. We demonstrate that code generated 
by \Treebeard{} is significantly faster than existing systems like XGBoost, 
RAPIDS FIL and Tahoe. This is because our scheduling language is able 
express more combinations of optimization strategies and our 
schedule exploration technique is able to quickly find high-performance schedules.
