\section{Conclusions}
\label{sec:conclusion}
Two trends motivate the need for systems that provide portable performance for
ML inference -- machine learning is becoming more ubiquitous and hardware is
getting more diverse.  This paper discussed the challenges in targeting decision
tree models to run at peak performance on CPUs and GPUs. To address these, we
designed \Treebeard{}, a schedule-guided, retargetable compiler for decision
tree inference. We demonstrated that code generated by \Treebeard{} is
significantly faster than existing systems like XGBoost, RAPIDS FIL and Tahoe.
We obtained such improvements because our scheduling language was able express
more combinations of optimization strategies, and our schedule exploration
technique was able to quickly find high-performance schedules.
