Q1: How does SilvanForge’s decision-forest-based ‘schedule space’ and scheduling language differ from prior languages for other domains, e.g., TVM’s? For instance, what operators are new to SilvanForge?

Unlike other domains where scheduling languages are used, SilvanForge targets an irregular application, one that involves traversing multiple decision trees. One of the paper's key contributions lies in recognizing the existence of a scheduling space for a domain as diverse as ours and demonstrating the significant performance variations across different schedules. The proposed scheduling language suitably enhances a loop centric scheduling language to target SilvanForge specific operators and perform tree traversal specific optimizations like walk interleaving, walk unrolling, reductions etc. These cannot be supported with existing scheduling languages. {Can we show an example.}
This has parallels to how TVM extends Halide to tensor specific primitives like tensorization and cooperative data loading. Despite the fact that TVM and Halide operate on similar domains (deep learning vs. image processing), such extensions were necessary for TVM to perform optimizations that were not expressible in Halide.

We believe that the design of SilvanForge's scheduling language is conceptually satisfying because it shows that by extending a core set of loop transformation primitives with a few domain specific primitives can capture the optimization space of a complex application like decision tree inference. Prior work has proposed a small fixed set of optimization techniques and as discussed in the paper, the language is powerful enough to express all these optimizations and more. 


Q2: Which SilvanForge optimizations are least likely to be supported by PyTorch (in the context of a decision forest compiled by modern Hummingbird), and why?
* HB only exposes limited parallelism in all its algorithms currently. This is a very small subset of the SilvanForge schedule space and as discussed in Section 2 of the paper, this amount of parallelism is likely insufficient to fully utilize the GPU. Further, the algorithms rely on gathering individual features as and when required and it is very unlikely that the underlying tensor compiler will decide to read input rows into shared memory as SilvanForge does. The analysis of memory access and reuse is complicated due to the indirect accesses of trees and rows. SF gets around this with domain specific abstractions and knowledge. 
* We find that in some cases, padding trees is very detrimental to performance (almost 2x in some cases). HB currently always pads trees to the same depth. SilvanForge can generate code that does not pad trees. Additionally, even when trees are padded, HB forces all trees in the model to have the same depth while this is not the case with SilvanForge.
* Even if one were to expose all forms of parallelism to the tensor compiler, flattening out this parallelism correctly into high-performance kernels is non-trivial and likely beyond the ability of current tensor compilers. As concrete examples, it would be nearly impossible (without domain specific knowledge) to restructure the computation to correctly determine the optimal number of threads to use for tree and row parallelism, or to determine whether or not to interleave walks and to what depth. 

* Systems challenges 
    -- no access to lower level details like shared memory, thread synchronization, etc at the tensor abstraction
    -- kernels are generated dynamically from the tensor graph and there is no scope for controlling how these kernels are optimized at the level of the tensor graph. TVM scheduling language is lower level. 

Hummingbird represents the decision tree inference computation as a PyTorch graph using tensor operations in order to take advantage of systems like PyTorch and TVM. While this enables GPU compilation and re-targetability, the tensor abstraction is not sufficient to express rewrites that SilvanForge performs. 
It is very difficult (or even impossible) to express many of our optimizations including tree walk interleaving , tree walk unrolling (especially when trees have different depths), caching trees/rows and reductions in shared memory, using tensor operations.
 \TODO{THis sounds too dismissive. Can we add a line saying what can be done with tensors. What would nail this is to show the tensor computation from HB and argue why its not possible to generate code corresponding to interleaved walk (or another optimization for which we show code) }
This is partially validated by prior experiments on CPUs where a direct comparison between Treebeard (that performs optimizations like unrolling and interleaving) and Hummingbird reveals a massive performance gap. 
It is also not possible to express the various GPU specific configurations that SilvanForge can express, like parallelism on both tree and row, caching and reduction, with just tensor abstractions. 

Additionally, representing tree traversals through tensor operations obscures the underlying computation's semantics, rendering it unfeasible for the tensor compiler to perform these optimizations. We expect that the tensor representation will necessitate multiple kernel calls (at least one for the tree walk and then subsequently for the reduction) which will be inefficient compared to the single kernel call that SilvanForge can generate not only because of the kernel call overhead, but also because intermediate results will need to be written to memory. 

The translation described in the Hummingbird paper uses one tensor element to represent the current node of each walk. This corresponds to the SilvanForge schedule where one thread walks one tree, and is only one of the many possible schedules that SilvanForge can generate (TODO check this). Another aspect where SilvanForge and Hummingbird differ is support for different representations of the model. SilvanForge can generate code for different representations of the model (array, sparse, reorg) while Hummingbird only supports a single representation. As noted in the paper, different representations can have different performance characteristics and SilvanForge can tune the code to use the representation that is best suited for the model being compiled. 

RB Q: You claim that SilvanForge decouples schedule from the backend architecture  but it seems both of these would change substantially with CPU? What fraction of your compiler changes are 'portable' across platforms, and how well does the CPU search heuristic work?
A: The scheduling language, high-level IR and mid-level IR are fully shared.
As described in the paper, except for a few target specific primitives, the scheduling language is common for both target processors. The same scheduling language is used to specify the structure of inference code on the CPU. When a schedule doesn't mark any loops as targetting a GPU dimension, CPU code is generated. The high-level and mid-level IR and optimizations on them are fully shared between the CPU and GPU compilation pipelines. The inference computation is represented as loops in both these IRs and therefore the, the representations and transformations on them are common. The compilation pipelines diverge starting starting at the lowering of MIR to low-level IR (as described in the paper). Even so, we are able to share significant amount of code between the CPU and GPU lowering due to how in-memory representations are abstracted in SilvanForge (Section 6). We found that a search heuristic is not needed on the CPU. Exploring only a few configurations is sufficient to find the best schedule. For the CPUs we tested on, we found that applying all optimizations is always beneficial and only a few configurations of the loop-nest needs to be explored.

RC Q: Although I wonder if at least some of the explanation is that so many people have moved on from decision tree models to the hot new generative thing.
A: As we establish in Section 1, decision trees are still widely used in practice and are likely to remain so for the foreseeable future. Also, the fact that their popularity has not declined over the last few years is evident from the last few Kaggle surveys. We believe that the retargetable performance that SilvanForge provides will be valuable to the large number of practitioners who use decision trees.

RC Q: It's really surprising to me that MLIR doesn't support reductions well -- they seem pretty fundamental to many kernels that other compilers targeting MLIR would see. But this section doesn't really explain if there's anything specific to the decision tree world here, or if this is just a general-purpose "add reductions to MLIR" thing. Either is probably interesting, but I didn't get enough context from the paper to know the answer.
A: As mentioned in the paper, the parallel reduction support in MLIR currently is either for value types (scf.reduce) or for tensors (linalg). Both of these do not fit the requirements of generating code for decision tree inference. With scf.reduce, every accumulation creates a logical copy and eliminating these copies correctly is a non-trivial problem. Additionally, MLIR does not have a lowering path from scf.reduce to a GPU implementation. With linalg, the entire tensor of values that are to be reduced need to be written to memory first thus making it impossible to fuse the reduction into the inner-most loops.

The reduction support we implement in SilvanForge is fairly general. Only the process of identifying reduction loops (Section 5) is specific to decision tree inference (tree loops are identified as reduction loops). All lowering of the ops in the reduction dialect are general and can be used for any other application that requires reductions. \TODO{Should we say that we can replace the reduction loop identification with a more general mechanism?}

RE Q: There might be other metrics besides kernel time speedup. For instance, the memory footprint of the resulting model.
A: While we did not evaluate such metrics, it should not be difficult to optimize for them using SilvanForge. We believe that the generality of the scheduling language encapsulates a vast enough space and finding variants that are optimized for other metrics should be possible.

-------------------------------------------------------------------------

RE Q: How much do different optimizations contribute to overall performance of code generated by SILVANFORGE?
A: TODO Mention what we've said about perf improvements due to shared reduction and row caching?
RD Q: ...speedup diminishes on large batch sizes.

RC Q:  It would be helpful to see results at batch size 1, for example, even if they're not great.
TODO: Should we say that we would use CPUs for such small batch sizes?

Reviewer A

* [Done] There is very little conceptual novelty; similar approaches are widely used for neural network optimization and graphics code (Halide).
* Very limited evaluation (only 8 real-world benchmarks), comparison to important related work appears to be missing.
* Past work has focused on throughput as opposed to latency, and I think this paper seems to conflate them somewhat. I think the evaluation would be stronger if it separately looked at throughput and latency; it may be possible that optimizations in the scheduling space optimize one at the cost of the other.
* [Done] The main issue, in my view, is that the paper is missing a comparison against Hummingbird

Reviewer B
* [Done] Table 5 (scheduler search space) and Algorithm 1 (search heuristic) seem rather GPU specific. You claim that SilvanForge decouples schedule from the backend architecture  but it seems both of these would change substantially with CPU? What fraction of your compiler changes are 'portable' across platforms, and how well does the CPU search heuristic work?

Reviewer C
* [Done] Not clear about novelty over other scheduling languages
* Autotuning is ad hoc

Reviewer D
* Evaluated only on benchmarks. Unclear how well it will work in a practical setup. Specifically, its speedup diminishes on large batch sizes.
* Can you show the absolute time? All the numbers are shown as relative speedups. But if the absolute time is already fast enough, how much do practitioners care about the improved inference performance?

Reviewer E
* [Done] Unclear how the ideas here are different from ideas presented in other programmer-directed scheduling systems like Halide.
* [Done] There might be other metrics besides kernel time speedup. For instance, the memory footprint of the resulting model. In particular, the choice of representation (in Section 6) might affect this footprint. I would have liked to see an evaluation of this.
* [Done] How much do different optimizations contribute to overall performance of code generated by SILVANFORGE?
* [Done] Could you comment on the main decision-tree-specific insights in the scheduling language here in comparison to prior scheduling languages for other domains?
