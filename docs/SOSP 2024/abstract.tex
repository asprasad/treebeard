\begin{abstract}
  The proliferation of machine learning together with the rapid evolution of 
  the hardware ecosystem has led to a surge in the demand for model inference on a variety
  of hardware. 
  Decision tree based models are the most popular models on tabular data.
  This paper is motivated by the problems encountered when targeting 
  inference of these models to run at peak performance on CPU and GPU targets.
  Existing solutions are neither
  portable nor achieve the best possible performance for the specific hardware they 
  target. This is because they do not explore and customize optimization 
  configurations to the model being used. 
    
  We present \Treebeard{}, a \emph{schedule-guided},
  \emph{retargetable} compiler for decision tree based models
  that searches over several optimization choices and automatically generates 
  high-performance inference routines for CPUs and GPUs.  
  \Treebeard{} has two core components. The first is a scheduling language 
  that encapsulates the optimization space, and techniques to efficiently
  explore this space. The second is an optimizing retargetable compiler that 
  can generate code for any specified schedule. \Treebeard{}'s ability to use different data layouts, 
  loop structures and caching strategies enables it to achieve portable performance
  across a range of targets.   
  % To accomplish this level of configurability, we re-architect 
  % and significantly extend the open-source \TreebeardOLD{} CPU compiler
  % to support (i) schedule-guided compilation, (ii) retargetable GPU code
  % generation, and (iii) GPU-specific optimizations. 
  %The scheduler and retargetable code generator components work hand-in-glove, synergizing and mutually benefiting from each other.
  
  We evaluate \Treebeard{} on several hundred decision tree models across different batch sizes
  and target architectures. We find that our schedule exploration strategy is able to quickly
  find near-optimal schedules.
  In terms of performance, \Treebeard{} generated code is an order of magnitude faster than XGBoost and
  about 2-5$\times$ faster on average than RAPIDS FIL and Tahoe over several batch sizes.
  While these systems only target NVIDIA GPUs, \Treebeard{} achieves competent performance on AMD GPUs as well. 
  On CPUs, \Treebeard{} is able to outperform \TreebeardOLD{} by up to $5\times$ by utilizing 
  additional sources of parallelism at small batch sizes.
\end{abstract}
