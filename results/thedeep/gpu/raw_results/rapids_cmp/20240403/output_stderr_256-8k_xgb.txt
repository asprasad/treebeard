abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.401724,0.246032
gpu_array,256,8,1,20,2,true,false,true,false,0.291652,0.165536
gpu_array,256,8,1,20,4,true,false,true,false,0.28916,0.160254
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.392821,0.260008
gpu_sparse,256,8,1,20,2,true,false,true,false,0.264464,0.14058
gpu_sparse,256,8,1,20,4,true,false,true,false,0.295806,0.170806
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.458683,0.321964
gpu_reorg,256,8,1,20,2,true,false,true,false,0.320898,0.171345
gpu_reorg,256,8,1,20,4,true,false,true,false,0.267023,0.131978
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.268666,0.13139
gpu_array,256,8,1,50,2,true,false,true,false,0.236789,0.0995117
gpu_array,256,8,1,50,4,true,false,true,false,0.228758,0.0931557
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.267048,0.130887
gpu_sparse,256,8,1,50,2,true,false,true,false,0.238382,0.104453
gpu_sparse,256,8,1,50,4,true,false,true,false,0.238742,0.107603
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.31115,0.170525
gpu_reorg,256,8,1,50,2,true,false,true,false,0.244612,0.102871
gpu_reorg,256,8,1,50,4,true,false,true,false,0.236113,0.0887919
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.368251,0.247715
gpu_array,256,32,1,20,2,true,false,true,false,0.301582,0.17156
gpu_array,256,32,1,20,4,true,false,true,false,0.294367,0.164902
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.368652,0.245884
gpu_sparse,256,32,1,20,2,true,false,true,false,0.271024,0.156069
gpu_sparse,256,32,1,20,4,true,false,true,false,0.292299,0.171205
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.442433,0.303482
gpu_reorg,256,32,1,20,2,true,false,true,false,0.311052,0.168195
gpu_reorg,256,32,1,20,4,true,false,true,false,0.293278,0.149863
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,50,4,true,false,true,true,0.201716,0.0822963
0.0822963
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,50,4,false,false,true,true,0.215151,0.0879185
0.0879185
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,20,4,true,false,true,true,0.24829,0.12329
0.12329
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,20,4,false,false,true,true,0.282221,0.151083
0.151083
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,32,1,20,4,true,false,true,true,0.294219,0.16029
0.16029
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,32,1,20,4,false,false,true,true,0.296872,0.16964
0.16964
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0822963
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.273976 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.359255,0.244858
gpu_array,256,8,1,20,2,true,false,true,false,0.28642,0.164768
gpu_array,256,8,1,20,4,true,false,true,false,0.279146,0.153588
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.403136,0.240748
gpu_sparse,256,8,1,20,2,true,false,true,false,0.253499,0.130731
gpu_sparse,256,8,1,20,4,true,false,true,false,0.279194,0.159216
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.44132,0.297905
gpu_reorg,256,8,1,20,2,true,false,true,false,0.295751,0.159032
gpu_reorg,256,8,1,20,4,true,false,true,false,0.258315,0.12327
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.252394,0.12293
gpu_array,256,8,1,50,2,true,false,true,false,0.224358,0.0932199
gpu_array,256,8,1,50,4,true,false,true,false,0.209408,0.0871987
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.262441,0.131303
gpu_sparse,256,8,1,50,2,true,false,true,false,0.24416,0.104651
gpu_sparse,256,8,1,50,4,true,false,true,false,0.235142,0.106794
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.314057,0.171758
gpu_reorg,256,8,1,50,2,true,false,true,false,0.252299,0.102188
gpu_reorg,256,8,1,50,4,true,false,true,false,0.243507,0.0883733
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.373362,0.247804
gpu_array,256,32,1,20,2,true,false,true,false,0.302084,0.172062
gpu_array,256,32,1,20,4,true,false,true,false,0.282782,0.165036
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.374707,0.245801
gpu_sparse,256,32,1,20,2,true,false,true,false,0.287112,0.155416
gpu_sparse,256,32,1,20,4,true,false,true,false,0.30522,0.171292
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.443588,0.303521
gpu_reorg,256,32,1,20,2,true,false,true,false,0.324807,0.169116
gpu_reorg,256,32,1,20,4,true,false,true,false,0.280056,0.150033
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.187612,0.0821429
0.0821429
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.214682,0.0924721
0.0924721
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.277843,0.169026
0.169026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.286872,0.174149
0.174149
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.287997,0.181412
0.181412
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.286208,0.174601
0.174601
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0821429
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.273224 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.201244,0.0595033
gpu_array,256,8,1,20,2,true,false,true,false,0.192268,0.0538756
gpu_array,256,8,1,20,4,true,false,true,false,0.183984,0.0455915
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.207204,0.0593248
gpu_sparse,256,8,1,20,2,true,false,true,false,0.183783,0.0481808
gpu_sparse,256,8,1,20,4,true,false,true,false,0.178217,0.0459626
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.222366,0.0728125
gpu_reorg,256,8,1,20,2,true,false,true,false,0.221758,0.0565792
gpu_reorg,256,8,1,20,4,true,false,true,false,0.20887,0.0542941
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.193739,0.0514397
gpu_array,256,8,1,50,2,true,false,true,false,0.192121,0.0475893
gpu_array,256,8,1,50,4,true,false,true,false,0.186443,0.0474916
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.206359,0.0512249
gpu_sparse,256,8,1,50,2,true,false,true,false,0.179233,0.0486523
gpu_sparse,256,8,1,50,4,true,false,true,false,0.184874,0.0481557
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.219685,0.0600865
gpu_reorg,256,8,1,50,2,true,false,true,false,0.204975,0.0531892
gpu_reorg,256,8,1,50,4,true,false,true,false,0.205438,0.0530943
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.20505,0.061635
gpu_array,256,32,1,20,2,true,false,true,false,0.20659,0.0570368
gpu_array,256,32,1,20,4,true,false,true,false,0.175449,0.047659
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.195603,0.06
gpu_sparse,256,32,1,20,2,true,false,true,false,0.185187,0.0490262
gpu_sparse,256,32,1,20,4,true,false,true,false,0.176537,0.0481892
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.235343,0.076861
gpu_reorg,256,32,1,20,2,true,false,true,false,0.222294,0.0565569
gpu_reorg,256,32,1,20,4,true,false,true,false,0.219247,0.052394
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.168055,0.0458454
0.0458454
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.16514,0.047394
0.047394
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.16339,0.0445285
0.0445285
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.159933,0.0444196
0.0444196
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.169202,0.0458761
0.0458761
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.161498,0.047659
0.047659
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0444196
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.089197 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.194967,0.062154
gpu_array,256,8,1,20,2,true,false,true,false,0.194515,0.0561217
gpu_array,256,8,1,20,4,true,false,true,false,0.178064,0.0474833
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.204794,0.0624944
gpu_sparse,256,8,1,20,2,true,false,true,false,0.182196,0.0504994
gpu_sparse,256,8,1,20,4,true,false,true,false,0.183438,0.0478348
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.22923,0.0774442
gpu_reorg,256,8,1,20,2,true,false,true,false,0.220625,0.0565625
gpu_reorg,256,8,1,20,4,true,false,true,false,0.218502,0.0538811
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.199283,0.0514035
gpu_array,256,8,1,50,2,true,false,true,false,0.194911,0.0475893
gpu_array,256,8,1,50,4,true,false,true,false,0.187422,0.0473549
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.1963,0.0506529
gpu_sparse,256,8,1,50,2,true,false,true,false,0.179947,0.0476925
gpu_sparse,256,8,1,50,4,true,false,true,false,0.176069,0.0477204
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.224908,0.0591713
gpu_reorg,256,8,1,50,2,true,false,true,false,0.206032,0.0520145
gpu_reorg,256,8,1,50,4,true,false,true,false,0.210142,0.0527762
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.195544,0.0610575
gpu_array,256,32,1,20,2,true,false,true,false,0.187712,0.0548996
gpu_array,256,32,1,20,4,true,false,true,false,0.182201,0.0471568
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.192263,0.0600084
gpu_sparse,256,32,1,20,2,true,false,true,false,0.182793,0.0488644
gpu_sparse,256,32,1,20,4,true,false,true,false,0.173555,0.0479967
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.226275,0.0783956
gpu_reorg,256,32,1,20,2,true,false,true,false,0.207492,0.056264
gpu_reorg,256,32,1,20,4,true,false,true,false,0.204626,0.0522824
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.155042,0.0456669
0.0456669
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.167397,0.0474191
0.0474191
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.16829,0.0444057
0.0444057
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.15406,0.0441267
0.0441267
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.170633,0.0461914
0.0461914
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.161521,0.0476814
0.0476814
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0441267
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0897673 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.787838,0.315181
gpu_array,256,8,1,20,2,true,false,true,false,0.763429,0.241108
gpu_array,256,8,1,20,4,true,false,true,false,0.685273,0.224336
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.80034,0.33159
gpu_sparse,256,8,1,20,2,true,false,true,false,0.638814,0.16002
gpu_sparse,256,8,1,20,4,true,false,true,false,0.701289,0.216356
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.27709,0.432224
gpu_reorg,256,8,1,20,2,true,false,true,false,1.05225,0.217427
gpu_reorg,256,8,1,20,4,true,false,true,false,1.09097,0.205924
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.666339,0.186429
gpu_array,256,8,1,50,2,true,false,true,false,0.627963,0.142472
gpu_array,256,8,1,50,4,true,false,true,false,0.598795,0.12279
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.667662,0.185519
gpu_sparse,256,8,1,50,2,true,false,true,false,0.608585,0.131465
gpu_sparse,256,8,1,50,4,true,false,true,false,0.611311,0.134749
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.08679,0.220156
gpu_reorg,256,8,1,50,2,true,false,true,false,0.970706,0.127514
gpu_reorg,256,8,1,50,4,true,false,true,false,0.972068,0.124969
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.564562,0.105857
0.105857
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.597238,0.144113
0.144113
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.710491,0.254576
0.254576
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.731624,0.281847
0.281847
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.105857
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.230739 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.784777,0.313237
gpu_array,256,8,1,20,2,true,false,true,false,0.705725,0.240882
gpu_array,256,8,1,20,4,true,false,true,false,0.701275,0.224155
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.81238,0.331353
gpu_sparse,256,8,1,20,2,true,false,true,false,0.74764,0.15947
gpu_sparse,256,8,1,20,4,true,false,true,false,0.775979,0.21627
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.29603,0.431632
gpu_reorg,256,8,1,20,2,true,false,true,false,1.06761,0.216602
gpu_reorg,256,8,1,20,4,true,false,true,false,1.05095,0.20553
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.654732,0.18654
gpu_array,256,8,1,50,2,true,false,true,false,0.613468,0.142486
gpu_array,256,8,1,50,4,true,false,true,false,0.66161,0.121989
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.656602,0.185619
gpu_sparse,256,8,1,50,2,true,false,true,false,0.605444,0.131113
gpu_sparse,256,8,1,50,4,true,false,true,false,0.609018,0.134687
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.0871,0.220469
gpu_reorg,256,8,1,50,2,true,false,true,false,0.983415,0.127388
gpu_reorg,256,8,1,50,4,true,false,true,false,0.983407,0.12459
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.555868,0.105533
0.105533
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.591401,0.143856
0.143856
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.704071,0.254294
0.254294
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.714367,0.267938
0.267938
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.105533
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.229664 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.412391,0.26507
gpu_array,256,8,1,20,2,true,false,true,false,0.323209,0.164727
gpu_array,256,8,1,20,4,true,false,true,false,0.346749,0.142508
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.402517,0.254079
gpu_sparse,256,8,1,20,2,true,false,true,false,0.306897,0.167946
gpu_sparse,256,8,1,20,4,true,false,true,false,0.320826,0.16067
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.483418,0.334422
gpu_reorg,256,8,1,20,2,true,false,true,false,0.36351,0.202238
gpu_reorg,256,8,1,20,4,true,false,true,false,0.347003,0.192427
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.595725,0.186685
gpu_array,256,8,1,50,2,true,false,true,false,0.576618,0.171484
gpu_array,256,8,1,50,4,true,false,true,false,0.597148,0.177506
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.353052,0.193454
gpu_sparse,256,8,1,50,2,true,false,true,false,0.604422,0.184222
gpu_sparse,256,8,1,50,4,true,false,true,false,0.61685,0.181024
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.380776,0.226758
gpu_reorg,256,8,1,50,2,true,false,true,false,0.35226,0.192104
gpu_reorg,256,8,1,50,4,true,false,true,false,0.339503,0.184369
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.430611,0.275477
gpu_array,256,32,1,20,2,true,false,true,false,0.313281,0.169308
gpu_array,256,32,1,20,4,true,false,true,false,0.30577,0.157891
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.395011,0.243225
gpu_sparse,256,32,1,20,2,true,false,true,false,0.330929,0.190304
gpu_sparse,256,32,1,20,4,true,false,true,false,0.337483,0.186814
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.470921,0.324157
gpu_reorg,256,32,1,20,2,true,false,true,false,0.386384,0.234598
gpu_reorg,256,32,1,20,4,true,false,true,false,0.393027,0.226733
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.300257,0.16856
0.16856
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.310508,0.178811
0.178811
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.31683,0.173973
0.173973
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.355332,0.22531
0.22531
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.259866,0.123705
0.123705
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.2882,0.152598
0.152598
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.123705
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.338594 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.422665,0.264182
gpu_array,256,8,1,20,2,true,false,true,false,0.311747,0.163867
gpu_array,256,8,1,20,4,true,false,true,false,0.284294,0.141995
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.404037,0.25281
gpu_sparse,256,8,1,20,2,true,false,true,false,0.32231,0.180569
gpu_sparse,256,8,1,20,4,true,false,true,false,0.319955,0.172076
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.503725,0.360868
gpu_reorg,256,8,1,20,2,true,false,true,false,0.373039,0.216789
gpu_reorg,256,8,1,20,4,true,false,true,false,0.355332,0.206336
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.609051,0.200569
gpu_array,256,8,1,50,2,true,false,true,false,0.578683,0.171317
gpu_array,256,8,1,50,4,true,false,true,false,0.610879,0.177285
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.336183,0.193326
gpu_sparse,256,8,1,50,2,true,false,true,false,0.599328,0.183591
gpu_sparse,256,8,1,50,4,true,false,true,false,0.60245,0.181133
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.378214,0.226429
gpu_reorg,256,8,1,50,2,true,false,true,false,0.348859,0.192051
gpu_reorg,256,8,1,50,4,true,false,true,false,0.34714,0.183636
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.419085,0.27567
gpu_array,256,32,1,20,2,true,false,true,false,0.30897,0.169461
gpu_array,256,32,1,20,4,true,false,true,false,0.30209,0.157559
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.385991,0.244249
gpu_sparse,256,32,1,20,2,true,false,true,false,0.352394,0.191122
gpu_sparse,256,32,1,20,4,true,false,true,false,0.331364,0.187391
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.485519,0.324247
gpu_reorg,256,32,1,20,2,true,false,true,false,0.379222,0.218507
gpu_reorg,256,32,1,20,4,true,false,true,false,0.373719,0.211889
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.303831,0.158184
0.158184
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.324766,0.180234
0.180234
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.322896,0.174459
0.174459
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.369076,0.231242
0.231242
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.269035,0.124503
0.124503
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.286325,0.152955
0.152955
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.124503
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.34153 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.39194,0.0783203
gpu_array,256,8,1,20,2,false,false,true,false,1.38434,0.0718387
gpu_array,256,8,1,20,4,false,false,true,false,1.36082,0.0578041
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.39783,0.0780804
gpu_sparse,256,8,1,20,2,false,false,true,false,1.37221,0.0714314
gpu_sparse,256,8,1,20,4,false,false,true,false,1.37975,0.0627902
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.40605,0.0851786
gpu_reorg,256,8,1,20,2,false,false,true,false,1.424,0.0768973
gpu_reorg,256,8,1,20,4,false,false,true,false,1.38661,0.0679687
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.39813,0.0644196
gpu_array,256,8,1,50,2,false,false,true,false,1.39594,0.06
gpu_array,256,8,1,50,4,false,false,true,false,1.37124,0.0598549
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.38169,0.0652846
gpu_sparse,256,8,1,50,2,false,false,true,false,1.40629,0.074255
gpu_sparse,256,8,1,50,4,false,false,true,false,1.40227,0.0741406
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.38638,0.0699749
gpu_reorg,256,8,1,50,2,false,false,true,false,1.39383,0.066822
gpu_reorg,256,8,1,50,4,false,false,true,false,1.39908,0.0664927
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.40701,0.0850279
gpu_array,256,32,1,20,2,false,false,true,false,1.41119,0.0802734
gpu_array,256,32,1,20,4,false,false,true,false,1.51754,0.0727902
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.41985,0.0844754
gpu_sparse,256,32,1,20,2,false,false,true,false,1.41741,0.0798019
gpu_sparse,256,32,1,20,4,false,false,true,false,1.4083,0.0751479
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.46058,0.0900446
gpu_reorg,256,32,1,20,2,false,false,true,false,1.54066,0.0819531
gpu_reorg,256,32,1,20,4,false,false,true,false,1.4458,0.0774916
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.3757,0.0581752
0.0581752
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.37907,0.0565206
0.0565206
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.37283,0.0709291
0.0709291
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0565206
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.110806 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.39653,0.0778878
gpu_array,256,8,1,20,2,false,false,true,false,1.39123,0.0720313
gpu_array,256,8,1,20,4,false,false,true,false,1.36504,0.0575614
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.53773,0.0773521
gpu_sparse,256,8,1,20,2,false,false,true,false,1.41384,0.071769
gpu_sparse,256,8,1,20,4,false,false,true,false,1.38076,0.0621177
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.45777,0.0861217
gpu_reorg,256,8,1,20,2,false,false,true,false,1.42427,0.0771735
gpu_reorg,256,8,1,20,4,false,false,true,false,1.39864,0.0677288
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.39003,0.0646987
gpu_array,256,8,1,50,2,false,false,true,false,1.39923,0.059947
gpu_array,256,8,1,50,4,false,false,true,false,1.39227,0.0596763
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.40859,0.0654018
gpu_sparse,256,8,1,50,2,false,false,true,false,1.40617,0.0746959
gpu_sparse,256,8,1,50,4,false,false,true,false,1.41926,0.0743973
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.40182,0.070904
gpu_reorg,256,8,1,50,2,false,false,true,false,1.45121,0.0661663
gpu_reorg,256,8,1,50,4,false,false,true,false,1.41269,0.0661523
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.42843,0.0846791
gpu_array,256,32,1,20,2,false,false,true,false,1.41959,0.0808622
gpu_array,256,32,1,20,4,false,false,true,false,1.41274,0.0728962
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.44087,0.084841
gpu_sparse,256,32,1,20,2,false,false,true,false,1.41467,0.0798465
gpu_sparse,256,32,1,20,4,false,false,true,false,1.42112,0.0751395
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.44753,0.0909431
gpu_reorg,256,32,1,20,2,false,false,true,false,1.41637,0.0832199
gpu_reorg,256,32,1,20,4,false,false,true,false,1.40518,0.0764927
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.34483,0.0579967
0.0579967
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.3592,0.0556334
0.0556334
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.36174,0.0710017
0.0710017
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0556334
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.110865 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.199353,0.0604018
gpu_array,256,8,1,20,2,true,false,true,false,0.208111,0.0546512
gpu_array,256,8,1,20,4,true,false,true,false,0.188541,0.0462416
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.211546,0.0603181
gpu_sparse,256,8,1,20,2,true,false,true,false,0.181995,0.0486244
gpu_sparse,256,8,1,20,4,true,false,true,false,0.184261,0.0469838
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.24452,0.0798996
gpu_reorg,256,8,1,20,2,true,false,true,false,0.235776,0.0577623
gpu_reorg,256,8,1,20,4,true,false,true,false,0.229688,0.0561384
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.195608,0.051635
gpu_array,256,8,1,50,2,true,false,true,false,0.184464,0.0477455
gpu_array,256,8,1,50,4,true,false,true,false,0.180991,0.04762
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.192997,0.0512556
gpu_sparse,256,8,1,50,2,true,false,true,false,0.178457,0.0478767
gpu_sparse,256,8,1,50,4,true,false,true,false,0.180714,0.0479018
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.235818,0.0633845
gpu_reorg,256,8,1,50,2,true,false,true,false,0.23043,0.0563225
gpu_reorg,256,8,1,50,4,true,false,true,false,0.261685,0.054654
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.206013,0.0614816
gpu_array,256,32,1,20,2,true,false,true,false,0.199029,0.0556138
gpu_array,256,32,1,20,4,true,false,true,false,0.193161,0.04863
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.208725,0.0614035
gpu_sparse,256,32,1,20,2,true,false,true,false,0.205762,0.0500698
gpu_sparse,256,32,1,20,4,true,false,true,false,0.187637,0.0492439
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.250073,0.0787556
gpu_reorg,256,32,1,20,2,true,false,true,false,0.222771,0.0592662
gpu_reorg,256,32,1,20,4,true,false,true,false,0.230402,0.0540625
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.171819,0.0462612
0.0462612
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.167595,0.0476172
0.0476172
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.175472,0.0448912
0.0448912
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.164247,0.044827
0.044827
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.163368,0.0467383
0.0467383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.172157,0.049947
0.049947
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.044827
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.0910451 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.197109,0.0631808
gpu_array,256,8,1,20,2,true,false,true,false,0.195293,0.0563421
gpu_array,256,8,1,20,4,true,false,true,false,0.18721,0.0477009
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.197852,0.0628069
gpu_sparse,256,8,1,20,2,true,false,true,false,0.191233,0.0506083
gpu_sparse,256,8,1,20,4,true,false,true,false,0.188013,0.0479464
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.259883,0.0785212
gpu_reorg,256,8,1,20,2,true,false,true,false,0.220405,0.0580162
gpu_reorg,256,8,1,20,4,true,false,true,false,0.227701,0.0547098
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.194844,0.0508705
gpu_array,256,8,1,50,2,true,false,true,false,0.176629,0.0477232
gpu_array,256,8,1,50,4,true,false,true,false,0.191535,0.0475614
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.190904,0.0513951
gpu_sparse,256,8,1,50,2,true,false,true,false,0.191124,0.0482673
gpu_sparse,256,8,1,50,4,true,false,true,false,0.185151,0.0484319
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.224598,0.0622098
gpu_reorg,256,8,1,50,2,true,false,true,false,0.226387,0.0545117
gpu_reorg,256,8,1,50,4,true,false,true,false,0.232676,0.0546624
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.208474,0.0622684
gpu_array,256,32,1,20,2,true,false,true,false,0.202324,0.0555608
gpu_array,256,32,1,20,4,true,false,true,false,0.191155,0.048298
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.204863,0.0608901
gpu_sparse,256,32,1,20,2,true,false,true,false,0.184414,0.0499275
gpu_sparse,256,32,1,20,4,true,false,true,false,0.179328,0.0493052
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.24666,0.0798075
gpu_reorg,256,32,1,20,2,true,false,true,false,0.225731,0.0577623
gpu_reorg,256,32,1,20,4,true,false,true,false,0.213903,0.0543052
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.171097,0.0449805
0.0449805
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.175407,0.044827
0.044827
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.165003,0.0466992
0.0466992
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.165424,0.0476786
0.0476786
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.158552,0.0469448
0.0469448
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.170954,0.0498605
0.0498605
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.044827
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0913706 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.90595,6.42269
gpu_array,256,8,1,20,2,true,false,true,false,13.9399,13.4762
gpu_array,256,8,1,20,4,true,false,true,false,13.4937,13.0651
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.42877,6.00411
gpu_sparse,256,8,1,20,2,true,false,true,false,13.5021,13.0669
gpu_sparse,256,8,1,20,4,true,false,true,false,9.62273,9.17463
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.69348,7.25487
gpu_reorg,256,8,1,20,2,true,false,true,false,11.3628,10.8968
gpu_reorg,256,8,1,20,4,true,false,true,false,8.73692,8.26873
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.48403,4.05323
gpu_array,256,8,1,50,2,true,false,true,false,7.63206,7.18787
gpu_array,256,8,1,50,4,true,false,true,false,8.68962,8.25324
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,4.06321,3.64859
gpu_sparse,256,8,1,50,2,true,false,true,false,7.4852,7.02371
gpu_sparse,256,8,1,50,4,true,false,true,false,7.96289,7.52093
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,5.03564,4.58586
gpu_reorg,256,8,1,50,2,true,false,true,false,7.75652,7.30116
gpu_reorg,256,8,1,50,4,true,false,true,false,11.631,11.1662
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,7.05009,6.62375
gpu_array,256,32,1,20,2,true,false,true,false,5.78368,5.3579
gpu_array,256,32,1,20,4,true,false,true,false,6.39903,5.9766
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.51856,6.09055
gpu_sparse,256,32,1,20,2,true,false,true,false,5.96751,5.54954
gpu_sparse,256,32,1,20,4,true,false,true,false,5.87701,5.44509
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.93607,7.49411
gpu_reorg,256,32,1,20,2,true,false,true,false,6.81012,6.37095
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.88753,2.7603
2.7603
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,3.05743,2.94583
2.94583
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.84812,5.73429
5.73429
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.28007,6.15562
6.15562
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.7603
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 165 seconds of which 2.7504 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.94096,6.49621
gpu_array,256,8,1,20,2,true,false,true,false,13.8728,13.413
gpu_array,256,8,1,20,4,true,false,true,false,13.3876,12.9506
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.60595,6.1824
gpu_sparse,256,8,1,20,2,true,false,true,false,13.5479,13.1037
gpu_sparse,256,8,1,20,4,true,false,true,false,9.68131,9.2399
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.71829,7.28135
gpu_reorg,256,8,1,20,2,true,false,true,false,11.3589,10.9036
gpu_reorg,256,8,1,20,4,true,false,true,false,8.82758,8.35102
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.40269,3.97021
gpu_array,256,8,1,50,2,true,false,true,false,7.62483,7.19068
gpu_array,256,8,1,50,4,true,false,true,false,8.74488,8.31519
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,4.09115,3.66258
gpu_sparse,256,8,1,50,2,true,false,true,false,7.41463,6.98662
gpu_sparse,256,8,1,50,4,true,false,true,false,8.01152,7.57179
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,5.03884,4.59911
gpu_reorg,256,8,1,50,2,true,false,true,false,7.83198,7.38499
gpu_reorg,256,8,1,50,4,true,false,true,false,11.5918,11.1387
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,7.14559,6.72483
gpu_array,256,32,1,20,2,true,false,true,false,5.83491,5.41806
gpu_array,256,32,1,20,4,true,false,true,false,6.49992,6.07414
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.42473,6.00509
gpu_sparse,256,32,1,20,2,true,false,true,false,5.96997,5.55367
gpu_sparse,256,32,1,20,4,true,false,true,false,5.80516,5.38775
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.95002,7.52201
gpu_reorg,256,32,1,20,2,true,false,true,false,6.86429,6.40781
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.78006,2.65673
2.65673
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,2.97958,2.86406
2.86406
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.99919,5.88088
5.88088
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.22741,6.12194
6.12194
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.65673
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 164 seconds of which 2.75659 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.281476,0.0588198
gpu_array,256,8,1,20,2,true,false,true,false,0.324113,0.103689
gpu_array,256,8,1,20,4,true,false,true,false,0.295206,0.0714342
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.270943,0.0577734
gpu_sparse,256,8,1,20,2,true,false,true,false,0.302444,0.0920647
gpu_sparse,256,8,1,20,4,true,false,true,false,0.302182,0.0862221
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.293697,0.075505
gpu_reorg,256,8,1,20,2,true,false,true,false,0.344266,0.11603
gpu_reorg,256,8,1,20,4,true,false,true,false,0.315031,0.0934905
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.28966,0.0547266
gpu_array,256,8,1,50,2,true,false,true,false,0.301741,0.0790848
gpu_array,256,8,1,50,4,true,false,true,false,0.275499,0.0796289
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.256219,0.0530943
gpu_sparse,256,8,1,50,2,true,false,true,false,0.275709,0.0798382
gpu_sparse,256,8,1,50,4,true,false,true,false,0.29375,0.0789062
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.283996,0.0641295
gpu_reorg,256,8,1,50,2,true,false,true,false,0.335569,0.0889174
gpu_reorg,256,8,1,50,4,true,false,true,false,0.328253,0.088298
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.246094,0.0608259
gpu_array,256,32,1,20,2,true,false,true,false,0.246752,0.0581362
gpu_array,256,32,1,20,4,true,false,true,false,0.255672,0.0558956
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.295078,0.058471
gpu_sparse,256,32,1,20,2,true,false,true,false,0.245778,0.051024
gpu_sparse,256,32,1,20,4,true,false,true,false,0.248507,0.0543108
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.292079,0.0744448
gpu_reorg,256,32,1,20,2,true,false,true,false,0.303284,0.0610965
gpu_reorg,256,32,1,20,4,true,false,true,false,0.304169,0.0664453
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.222243,0.0486942
0.0486942
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.258446,0.0586691
0.0586691
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.231515,0.0473633
0.0473633
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.237215,0.0480413
0.0480413
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.254403,0.0596484
0.0596484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.260201,0.0615402
0.0615402
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0473633
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.117056 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.260611,0.0619503
gpu_array,256,8,1,20,2,true,false,true,false,0.318973,0.110268
gpu_array,256,8,1,20,4,true,false,true,false,0.28154,0.0767411
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.265555,0.0624302
gpu_sparse,256,8,1,20,2,true,false,true,false,0.310642,0.0918917
gpu_sparse,256,8,1,20,4,true,false,true,false,0.29089,0.086091
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.288915,0.076303
gpu_reorg,256,8,1,20,2,true,false,true,false,0.3399,0.116127
gpu_reorg,256,8,1,20,4,true,false,true,false,0.321819,0.0930246
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.28906,0.0541267
gpu_array,256,8,1,50,2,true,false,true,false,0.296473,0.0788393
gpu_array,256,8,1,50,4,true,false,true,false,0.275098,0.0786691
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.258764,0.0528488
gpu_sparse,256,8,1,50,2,true,false,true,false,0.29531,0.0793499
gpu_sparse,256,8,1,50,4,true,false,true,false,0.275767,0.0787807
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.295067,0.0640402
gpu_reorg,256,8,1,50,2,true,false,true,false,0.308025,0.0898326
gpu_reorg,256,8,1,50,4,true,false,true,false,0.31274,0.0889676
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.257416,0.0615458
gpu_array,256,32,1,20,2,true,false,true,false,0.281401,0.0587444
gpu_array,256,32,1,20,4,true,false,true,false,0.261855,0.0570564
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.295357,0.059308
gpu_sparse,256,32,1,20,2,true,false,true,false,0.247966,0.0515374
gpu_sparse,256,32,1,20,4,true,false,true,false,0.262494,0.0549051
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.293354,0.0746038
gpu_reorg,256,32,1,20,2,true,false,true,false,0.29168,0.061769
gpu_reorg,256,32,1,20,4,true,false,true,false,0.292645,0.0677567
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.234598,0.0493304
0.0493304
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.250751,0.0593443
0.0593443
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.23596,0.0479018
0.0479018
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.246071,0.0485268
0.0485268
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.262168,0.060159
0.060159
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.262673,0.0623382
0.0623382
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0479018
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.118534 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.208815,0.12418
gpu_array,512,8,1,20,2,true,false,true,false,0.169157,0.0838704
gpu_array,512,8,1,20,4,true,false,true,false,0.163633,0.0789974
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.208089,0.122803
gpu_sparse,512,8,1,20,2,true,false,true,false,0.160911,0.076276
gpu_sparse,512,8,1,20,4,true,false,true,false,0.174313,0.0890267
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.268978,0.160254
gpu_reorg,512,8,1,20,2,true,false,true,false,0.191855,0.0870378
gpu_reorg,512,8,1,20,4,true,false,true,false,0.165055,0.0680501
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.151471,0.0700911
gpu_array,512,8,1,50,2,true,false,true,false,0.13901,0.0582812
gpu_array,512,8,1,50,4,true,false,true,false,0.143314,0.0606315
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.154079,0.0726986
gpu_sparse,512,8,1,50,2,true,false,true,false,0.146178,0.0706576
gpu_sparse,512,8,1,50,4,true,false,true,false,0.153597,0.0728678
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.192816,0.087998
gpu_reorg,512,8,1,50,2,true,false,true,false,0.148001,0.0549023
gpu_reorg,512,8,1,50,4,true,false,true,false,0.172064,0.0731055
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.209648,0.124362
gpu_array,512,32,1,20,2,true,false,true,false,0.165443,0.0866667
gpu_array,512,32,1,20,4,true,false,true,false,0.168092,0.083457
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.208421,0.124437
gpu_sparse,512,32,1,20,2,true,false,true,false,0.162412,0.0797298
gpu_sparse,512,32,1,20,4,true,false,true,false,0.170446,0.0871126
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.253828,0.156823
gpu_reorg,512,32,1,20,2,true,false,true,false,0.190176,0.0905664
gpu_reorg,512,32,1,20,4,true,false,true,false,0.184163,0.0806478
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.148311,0.0539095
0.0539095
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.156162,0.0643652
0.0643652
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.156725,0.0675326
0.0675326
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.165762,0.076569
0.076569
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.175247,0.0808464
0.0808464
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.173516,0.084974
0.084974
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0539095
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.292222 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.218753,0.124352
gpu_array,512,8,1,20,2,true,false,true,false,0.176341,0.0838932
gpu_array,512,8,1,20,4,true,false,true,false,0.16402,0.0787337
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.207419,0.123434
gpu_sparse,512,8,1,20,2,true,false,true,false,0.167152,0.0760059
gpu_sparse,512,8,1,20,4,true,false,true,false,0.174899,0.0889616
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.263158,0.160293
gpu_reorg,512,8,1,20,2,true,false,true,false,0.182969,0.0866146
gpu_reorg,512,8,1,20,4,true,false,true,false,0.172412,0.0682454
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.156816,0.0702279
gpu_array,512,8,1,50,2,true,false,true,false,0.14056,0.0585286
gpu_array,512,8,1,50,4,true,false,true,false,0.143402,0.0607194
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.160133,0.0728939
gpu_sparse,512,8,1,50,2,true,false,true,false,0.153187,0.0705046
gpu_sparse,512,8,1,50,4,true,false,true,false,0.15056,0.0730859
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.188698,0.0884375
gpu_reorg,512,8,1,50,2,true,false,true,false,0.154206,0.0552474
gpu_reorg,512,8,1,50,4,true,false,true,false,0.184255,0.0729264
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.21444,0.124596
gpu_array,512,32,1,20,2,true,false,true,false,0.172874,0.0869368
gpu_array,512,32,1,20,4,true,false,true,false,0.163906,0.0838281
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.208555,0.125221
gpu_sparse,512,32,1,20,2,true,false,true,false,0.165778,0.0798405
gpu_sparse,512,32,1,20,4,true,false,true,false,0.179652,0.0878548
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.262806,0.157337
gpu_reorg,512,32,1,20,2,true,false,true,false,0.195407,0.0912402
gpu_reorg,512,32,1,20,4,true,false,true,false,0.184863,0.0813477
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.146761,0.0543132
0.0543132
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.162227,0.0645703
0.0645703
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.16027,0.0678223
0.0678223
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.171774,0.076722
0.076722
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.171836,0.0806901
0.0806901
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.178669,0.0849186
0.0849186
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0543132
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.292899 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.126185,0.0324349
gpu_array,512,8,1,20,2,true,false,true,false,0.126279,0.0299251
gpu_array,512,8,1,20,4,true,false,true,false,0.11487,0.0269792
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.122399,0.0325553
gpu_sparse,512,8,1,20,2,true,false,true,false,0.116608,0.0280664
gpu_sparse,512,8,1,20,4,true,false,true,false,0.12071,0.0276107
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.147686,0.0409147
gpu_reorg,512,8,1,20,2,true,false,true,false,0.140426,0.0317025
gpu_reorg,512,8,1,20,4,true,false,true,false,0.136364,0.0302441
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.117262,0.0287207
gpu_array,512,8,1,50,2,true,false,true,false,0.122415,0.0280143
gpu_array,512,8,1,50,4,true,false,true,false,0.116569,0.0280273
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.11597,0.0287305
gpu_sparse,512,8,1,50,2,true,false,true,false,0.121947,0.034056
gpu_sparse,512,8,1,50,4,true,false,true,false,0.119863,0.0339258
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.15597,0.0348763
gpu_reorg,512,8,1,50,2,true,false,true,false,0.157565,0.0364714
gpu_reorg,512,8,1,50,4,true,false,true,false,0.148379,0.0363997
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.123874,0.0307747
gpu_array,512,32,1,20,2,true,false,true,false,0.119733,0.0279362
gpu_array,512,32,1,20,4,true,false,true,false,0.115752,0.0246061
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.11194,0.0305599
gpu_sparse,512,32,1,20,2,true,false,true,false,0.106989,0.0256087
gpu_sparse,512,32,1,20,4,true,false,true,false,0.108379,0.0250456
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.143424,0.0392578
gpu_reorg,512,32,1,20,2,true,false,true,false,0.147894,0.0300553
gpu_reorg,512,32,1,20,4,true,false,true,false,0.138825,0.0287988
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0903125,0.0239063
0.0239063
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.0893001,0.024847
0.024847
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.097181,0.0255664
0.0255664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.0934635,0.0257552
0.0257552
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.0941439,0.0251335
0.0251335
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.100335,0.0254655
0.0254655
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0239063
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.100656 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.119105,0.0325163
gpu_array,512,8,1,20,2,true,false,true,false,0.117806,0.0299154
gpu_array,512,8,1,20,4,true,false,true,false,0.116719,0.026875
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.120348,0.0324577
gpu_sparse,512,8,1,20,2,true,false,true,false,0.112536,0.0279004
gpu_sparse,512,8,1,20,4,true,false,true,false,0.107454,0.0273763
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.153493,0.0408626
gpu_reorg,512,8,1,20,2,true,false,true,false,0.142878,0.0315495
gpu_reorg,512,8,1,20,4,true,false,true,false,0.160951,0.0300911
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.11528,0.0286914
gpu_array,512,8,1,50,2,true,false,true,false,0.108597,0.0278678
gpu_array,512,8,1,50,4,true,false,true,false,0.111188,0.0278548
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.112637,0.0286523
gpu_sparse,512,8,1,50,2,true,false,true,false,0.11916,0.0338737
gpu_sparse,512,8,1,50,4,true,false,true,false,0.123073,0.0338802
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.146009,0.034681
gpu_reorg,512,8,1,50,2,true,false,true,false,0.151051,0.0364681
gpu_reorg,512,8,1,50,4,true,false,true,false,0.155482,0.0363411
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.114134,0.0308008
gpu_array,512,32,1,20,2,true,false,true,false,0.11248,0.0278451
gpu_array,512,32,1,20,4,true,false,true,false,0.101305,0.0244824
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.119105,0.0305632
gpu_sparse,512,32,1,20,2,true,false,true,false,0.112822,0.0255827
gpu_sparse,512,32,1,20,4,true,false,true,false,0.105667,0.0249382
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.151471,0.0394922
gpu_reorg,512,32,1,20,2,true,false,true,false,0.136501,0.0303809
gpu_reorg,512,32,1,20,4,true,false,true,false,0.144245,0.0290104
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0970085,0.0240918
0.0240918
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.102513,0.0250391
0.0250391
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.103262,0.0257878
0.0257878
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.100212,0.0259928
0.0259928
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.0986003,0.0250326
0.0250326
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.0984733,0.0255566
0.0255566
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0240918
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.100603 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.764395,0.159577
gpu_array,512,8,1,20,2,true,false,true,false,0.738102,0.122217
gpu_array,512,8,1,20,4,true,false,true,false,0.723659,0.122747
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.763682,0.169281
gpu_sparse,512,8,1,20,2,true,false,true,false,0.683444,0.0909961
gpu_sparse,512,8,1,20,4,true,false,true,false,0.696589,0.111302
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.929342,0.22166
gpu_reorg,512,8,1,20,2,true,false,true,false,0.749437,0.118577
gpu_reorg,512,8,1,20,4,true,false,true,false,0.745674,0.113512
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.67695,0.101429
gpu_array,512,8,1,50,2,true,false,true,false,0.660876,0.0768913
gpu_array,512,8,1,50,4,true,false,true,false,0.674342,0.0812435
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.68571,0.105632
gpu_sparse,512,8,1,50,2,true,false,true,false,0.687217,0.103232
gpu_sparse,512,8,1,50,4,true,false,true,false,0.686204,0.102871
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.716956,0.117347
gpu_reorg,512,8,1,50,2,true,false,true,false,0.69778,0.0825456
gpu_reorg,512,8,1,50,4,true,false,true,false,0.720928,0.105042
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.64152,0.0822754
0.0822754
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.652601,0.0998665
0.0998665
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,0.64279,0.0881022
0.0881022
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,0.750534,0.19194
0.19194
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0768913
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.262993 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.754528,0.159476
gpu_array,512,8,1,20,2,true,false,true,false,0.703405,0.122025
gpu_array,512,8,1,20,4,true,false,true,false,0.715117,0.122669
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.761514,0.168415
gpu_sparse,512,8,1,20,2,true,false,true,false,0.670296,0.0902181
gpu_sparse,512,8,1,20,4,true,false,true,false,0.709242,0.110934
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.843376,0.22098
gpu_reorg,512,8,1,20,2,true,false,true,false,0.72762,0.118245
gpu_reorg,512,8,1,20,4,true,false,true,false,0.734987,0.113242
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.685632,0.102298
gpu_array,512,8,1,50,2,true,false,true,false,0.673971,0.0769661
gpu_array,512,8,1,50,4,true,false,true,false,0.656051,0.0818327
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.697389,0.105592
gpu_sparse,512,8,1,50,2,true,false,true,false,0.684375,0.102995
gpu_sparse,512,8,1,50,4,true,false,true,false,0.693548,0.103053
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.732461,0.117878
gpu_reorg,512,8,1,50,2,true,false,true,false,0.713672,0.0828125
gpu_reorg,512,8,1,50,4,true,false,true,false,0.732764,0.10516
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.651966,0.0829557
0.0829557
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.658574,0.0999805
0.0999805
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,0.640091,0.0880078
0.0880078
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,0.748636,0.191995
0.191995
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0769661
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.262936 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.264642,0.140944
gpu_array,512,8,1,20,2,true,false,true,false,0.228958,0.100703
gpu_array,512,8,1,20,4,true,false,true,false,0.214277,0.0977409
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.269818,0.14612
gpu_sparse,512,8,1,20,2,true,false,true,false,0.228805,0.11292
gpu_sparse,512,8,1,20,4,true,false,true,false,0.2446,0.115693
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.315508,0.195716
gpu_reorg,512,8,1,20,2,true,false,true,false,0.26266,0.1318
gpu_reorg,512,8,1,20,4,true,false,true,false,0.249762,0.129971
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.368932,0.122188
gpu_array,512,8,1,50,2,true,false,true,false,0.36568,0.118285
gpu_array,512,8,1,50,4,true,false,true,false,0.375924,0.130482
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.240368,0.119925
gpu_sparse,512,8,1,50,2,true,false,true,false,0.363607,0.124674
gpu_sparse,512,8,1,50,4,true,false,true,false,0.372529,0.134899
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.264043,0.139043
gpu_reorg,512,8,1,50,2,true,false,true,false,0.250918,0.128522
gpu_reorg,512,8,1,50,4,true,false,true,false,0.296995,0.16874
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.275736,0.146178
gpu_array,512,32,1,20,2,true,false,true,false,0.230482,0.110039
gpu_array,512,32,1,20,4,true,false,true,false,0.229961,0.108867
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.258252,0.139111
gpu_sparse,512,32,1,20,2,true,false,true,false,0.248919,0.112852
gpu_sparse,512,32,1,20,4,true,false,true,false,0.246608,0.117051
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.311136,0.174417
gpu_reorg,512,32,1,20,2,true,false,true,false,0.273053,0.137637
gpu_reorg,512,32,1,20,4,true,false,true,false,0.255609,0.13777
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.210482,0.0874349
0.0874349
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.203783,0.0924544
0.0924544
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.196839,0.0874642
0.0874642
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.231273,0.114736
0.114736
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.189521,0.0755892
0.0755892
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.189671,0.0835514
0.0835514
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0755892
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.418152 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.27167,0.140811
gpu_array,512,8,1,20,2,true,false,true,false,0.223649,0.100602
gpu_array,512,8,1,20,4,true,false,true,false,0.220531,0.0974837
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.264626,0.146136
gpu_sparse,512,8,1,20,2,true,false,true,false,0.245039,0.112878
gpu_sparse,512,8,1,20,4,true,false,true,false,0.247357,0.115846
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.31681,0.196367
gpu_reorg,512,8,1,20,2,true,false,true,false,0.260169,0.131263
gpu_reorg,512,8,1,20,4,true,false,true,false,0.250602,0.13016
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.366351,0.12221
gpu_array,512,8,1,50,2,true,false,true,false,0.357738,0.118154
gpu_array,512,8,1,50,4,true,false,true,false,0.378044,0.130648
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.236517,0.11998
gpu_sparse,512,8,1,50,2,true,false,true,false,0.357233,0.124811
gpu_sparse,512,8,1,50,4,true,false,true,false,0.375589,0.134704
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.271976,0.139163
gpu_reorg,512,8,1,50,2,true,false,true,false,0.253184,0.128835
gpu_reorg,512,8,1,50,4,true,false,true,false,0.303265,0.168499
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.271543,0.145892
gpu_array,512,32,1,20,2,true,false,true,false,0.228867,0.109727
gpu_array,512,32,1,20,4,true,false,true,false,0.23151,0.108464
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.27778,0.139759
gpu_sparse,512,32,1,20,2,true,false,true,false,0.252093,0.11277
gpu_sparse,512,32,1,20,4,true,false,true,false,0.247096,0.116888
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.302298,0.174694
gpu_reorg,512,32,1,20,2,true,false,true,false,0.261257,0.137559
gpu_reorg,512,32,1,20,4,true,false,true,false,0.261543,0.137845
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.194518,0.0877474
0.0877474
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.198027,0.0925586
0.0925586
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.202187,0.0876042
0.0876042
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.219616,0.114798
0.114798
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.182061,0.0752897
0.0752897
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.194508,0.0831803
0.0831803
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0752897
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.418133 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.11857,0.0450033
gpu_array,512,8,1,20,2,false,false,true,false,1.11473,0.0431185
gpu_array,512,8,1,20,4,false,false,true,false,1.11075,0.0417415
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.14086,0.0445052
gpu_sparse,512,8,1,20,2,false,false,true,false,1.10263,0.0433887
gpu_sparse,512,8,1,20,4,false,false,true,false,1.12593,0.0425944
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.14907,0.0553158
gpu_reorg,512,8,1,20,2,false,false,true,false,1.17897,0.0507161
gpu_reorg,512,8,1,20,4,false,false,true,false,1.13754,0.0476953
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.14901,0.0461458
gpu_array,512,8,1,50,2,false,false,true,false,1.15304,0.0495247
gpu_array,512,8,1,50,4,false,false,true,false,1.15875,0.0493783
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.12906,0.0470247
gpu_sparse,512,8,1,50,2,false,false,true,false,1.14576,0.0546094
gpu_sparse,512,8,1,50,4,false,false,true,false,1.1508,0.0544499
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.171,0.0492578
gpu_reorg,512,8,1,50,2,false,false,true,false,1.17265,0.0548145
gpu_reorg,512,8,1,50,4,false,false,true,false,1.15436,0.0547493
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.1416,0.046543
gpu_array,512,32,1,20,2,false,false,true,false,1.14562,0.0440592
gpu_array,512,32,1,20,4,false,false,true,false,1.13348,0.042334
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.13175,0.0464648
gpu_sparse,512,32,1,20,2,false,false,true,false,1.14132,0.0443197
gpu_sparse,512,32,1,20,4,false,false,true,false,1.12664,0.0439616
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.16744,0.05611
gpu_reorg,512,32,1,20,2,false,false,true,false,1.1508,0.0518424
gpu_reorg,512,32,1,20,4,false,false,true,false,1.16116,0.0491764
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.10351,0.0423145
0.0423145
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.11943,0.0426107
0.0426107
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.12616,0.0421712
0.0421712
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0417415
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.146016 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.13351,0.0449707
gpu_array,512,8,1,20,2,false,false,true,false,1.12513,0.0431022
gpu_array,512,8,1,20,4,false,false,true,false,1.12775,0.0418132
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.13962,0.0445638
gpu_sparse,512,8,1,20,2,false,false,true,false,1.13376,0.043265
gpu_sparse,512,8,1,20,4,false,false,true,false,1.12401,0.042627
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.15586,0.055599
gpu_reorg,512,8,1,20,2,false,false,true,false,1.14861,0.050957
gpu_reorg,512,8,1,20,4,false,false,true,false,1.15266,0.0478451
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.13403,0.0461361
gpu_array,512,8,1,50,2,false,false,true,false,1.13873,0.0495378
gpu_array,512,8,1,50,4,false,false,true,false,1.15378,0.0496094
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.138,0.0468522
gpu_sparse,512,8,1,50,2,false,false,true,false,1.14501,0.0545117
gpu_sparse,512,8,1,50,4,false,false,true,false,1.1457,0.054554
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.17116,0.0494141
gpu_reorg,512,8,1,50,2,false,false,true,false,1.14847,0.0547168
gpu_reorg,512,8,1,50,4,false,false,true,false,1.15245,0.0547917
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.12858,0.0465462
gpu_array,512,32,1,20,2,false,false,true,false,1.13191,0.0440202
gpu_array,512,32,1,20,4,false,false,true,false,1.14293,0.0426725
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.14342,0.0464193
gpu_sparse,512,32,1,20,2,false,false,true,false,1.14344,0.0444824
gpu_sparse,512,32,1,20,4,false,false,true,false,1.15091,0.0441374
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.16713,0.0564518
gpu_reorg,512,32,1,20,2,false,false,true,false,1.15098,0.0520247
gpu_reorg,512,32,1,20,4,false,false,true,false,1.14566,0.0493099
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.12111,0.0423307
0.0423307
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.13914,0.0427897
0.0427897
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.11239,0.0427311
0.0427311
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0418132
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.146307 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.131891,0.0329329
gpu_array,512,8,1,20,2,true,false,true,false,0.131292,0.0303809
gpu_array,512,8,1,20,4,true,false,true,false,0.125254,0.0269466
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.123408,0.0329134
gpu_sparse,512,8,1,20,2,true,false,true,false,0.120658,0.0282096
gpu_sparse,512,8,1,20,4,true,false,true,false,0.126634,0.0276758
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.164997,0.0419499
gpu_reorg,512,8,1,20,2,true,false,true,false,0.155518,0.0324707
gpu_reorg,512,8,1,20,4,true,false,true,false,0.155563,0.0312142
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.129059,0.0287988
gpu_array,512,8,1,50,2,true,false,true,false,0.126533,0.029528
gpu_array,512,8,1,50,4,true,false,true,false,0.124443,0.0300423
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.122972,0.029222
gpu_sparse,512,8,1,50,2,true,false,true,false,0.137035,0.034821
gpu_sparse,512,8,1,50,4,true,false,true,false,0.129098,0.0346973
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.163177,0.0355729
gpu_reorg,512,8,1,50,2,true,false,true,false,0.15154,0.0382585
gpu_reorg,512,8,1,50,4,true,false,true,false,0.160602,0.0382064
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.126286,0.0312337
gpu_array,512,32,1,20,2,true,false,true,false,0.13012,0.0285579
gpu_array,512,32,1,20,4,true,false,true,false,0.119769,0.0253678
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.130661,0.0310514
gpu_sparse,512,32,1,20,2,true,false,true,false,0.119945,0.0261947
gpu_sparse,512,32,1,20,4,true,false,true,false,0.114258,0.0257161
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.16334,0.040293
gpu_reorg,512,32,1,20,2,true,false,true,false,0.151383,0.0309408
gpu_reorg,512,32,1,20,4,true,false,true,false,0.144687,0.0294531
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.102992,0.0248665
0.0248665
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.110423,0.0264388
0.0264388
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.115322,0.0254785
0.0254785
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.11514,0.0259473
0.0259473
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.11499,0.0264486
0.0264486
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.106901,0.0268229
0.0268229
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0248665
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103286 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.128955,0.033252
gpu_array,512,8,1,20,2,true,false,true,false,0.126865,0.0305111
gpu_array,512,8,1,20,4,true,false,true,false,0.12277,0.0270671
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.114928,0.0328971
gpu_sparse,512,8,1,20,2,true,false,true,false,0.117233,0.0280404
gpu_sparse,512,8,1,20,4,true,false,true,false,0.123955,0.0276009
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.157721,0.0418359
gpu_reorg,512,8,1,20,2,true,false,true,false,0.151354,0.0322135
gpu_reorg,512,8,1,20,4,true,false,true,false,0.15002,0.0308789
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.112663,0.0286784
gpu_array,512,8,1,50,2,true,false,true,false,0.119889,0.0293945
gpu_array,512,8,1,50,4,true,false,true,false,0.121862,0.0294141
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.113597,0.0289616
gpu_sparse,512,8,1,50,2,true,false,true,false,0.124443,0.0345996
gpu_sparse,512,8,1,50,4,true,false,true,false,0.125671,0.0345247
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.154596,0.0354557
gpu_reorg,512,8,1,50,2,true,false,true,false,0.151117,0.0378353
gpu_reorg,512,8,1,50,4,true,false,true,false,0.157777,0.037985
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.127393,0.0310384
gpu_array,512,32,1,20,2,true,false,true,false,0.12194,0.0281901
gpu_array,512,32,1,20,4,true,false,true,false,0.121842,0.0254883
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.13402,0.0311556
gpu_sparse,512,32,1,20,2,true,false,true,false,0.119987,0.026237
gpu_sparse,512,32,1,20,4,true,false,true,false,0.130537,0.0257194
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.16806,0.0404557
gpu_reorg,512,32,1,20,2,true,false,true,false,0.155892,0.0308919
gpu_reorg,512,32,1,20,4,true,false,true,false,0.151836,0.0294401
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.100817,0.0246452
0.0246452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.108359,0.0263281
0.0263281
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.107979,0.0252962
0.0252962
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.109906,0.0259212
0.0259212
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.108652,0.0266211
0.0266211
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.111676,0.027041
0.027041
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0246452
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.102975 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.00365,3.7224
gpu_array,512,8,1,20,2,true,false,true,false,8.00358,7.74837
gpu_array,512,8,1,20,4,true,false,true,false,7.34764,7.08462
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.90178,3.65243
gpu_sparse,512,8,1,20,2,true,false,true,false,7.85764,7.60309
gpu_sparse,512,8,1,20,4,true,false,true,false,5.55536,5.29625
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.57298,4.29824
gpu_reorg,512,8,1,20,2,true,false,true,false,5.86005,5.5749
gpu_reorg,512,8,1,20,4,true,false,true,false,5.40004,5.11488
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.76495,3.47198
gpu_array,512,8,1,50,2,true,false,true,false,4.51324,4.22288
gpu_array,512,8,1,50,4,true,false,true,false,9.08243,8.78882
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.40858,3.13059
gpu_sparse,512,8,1,50,2,true,false,true,false,4.61462,4.321
gpu_sparse,512,8,1,50,4,true,false,true,false,8.15195,7.85182
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.95648,3.63682
gpu_reorg,512,8,1,50,2,true,false,true,false,8.25436,7.93405
gpu_reorg,512,8,1,50,4,true,false,true,false,9.68931,9.35793
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.06898,3.82029
gpu_array,512,32,1,20,2,true,false,true,false,3.61706,3.35339
gpu_array,512,32,1,20,4,true,false,true,false,3.86257,3.60671
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.82008,3.57073
gpu_sparse,512,32,1,20,2,true,false,true,false,3.70973,3.46233
gpu_sparse,512,32,1,20,4,true,false,true,false,3.61279,3.35758
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.54027,4.25121
gpu_reorg,512,32,1,20,2,true,false,true,false,4.43216,4.14766
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.64271,2.54896
2.54896
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.85189,2.75684
2.75684
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.19035,3.09009
3.09009
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.31518,3.23185
3.23185
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.54896
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 158 seconds of which 3.68662 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.04716,3.79326
gpu_array,512,8,1,20,2,true,false,true,false,7.98915,7.73004
gpu_array,512,8,1,20,4,true,false,true,false,7.47501,7.21525
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.70846,3.45651
gpu_sparse,512,8,1,20,2,true,false,true,false,7.88868,7.63673
gpu_sparse,512,8,1,20,4,true,false,true,false,5.51478,5.25892
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.61501,4.32139
gpu_reorg,512,8,1,20,2,true,false,true,false,5.86714,5.57872
gpu_reorg,512,8,1,20,4,true,false,true,false,5.38697,5.09921
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.7731,3.47427
gpu_array,512,8,1,50,2,true,false,true,false,4.5013,4.20768
gpu_array,512,8,1,50,4,true,false,true,false,9.16293,8.8641
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.41974,3.14826
gpu_sparse,512,8,1,50,2,true,false,true,false,4.55753,4.26456
gpu_sparse,512,8,1,50,4,true,false,true,false,8.07919,7.78688
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.97556,3.6598
gpu_reorg,512,8,1,50,2,true,false,true,false,8.41288,8.09061
gpu_reorg,512,8,1,50,4,true,false,true,false,9.56112,9.24862
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.20199,3.95785
gpu_array,512,32,1,20,2,true,false,true,false,3.62698,3.38805
gpu_array,512,32,1,20,4,true,false,true,false,3.83887,3.59798
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.61116,3.37613
gpu_sparse,512,32,1,20,2,true,false,true,false,3.63224,3.3894
gpu_sparse,512,32,1,20,4,true,false,true,false,3.60919,3.36245
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.53342,4.27236
gpu_reorg,512,32,1,20,2,true,false,true,false,4.52181,4.24642
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.62035,2.54027
2.54027
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.75012,2.66092
2.66092
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.19062,3.09818
3.09818
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.23344,3.13513
3.13513
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.54027
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 157 seconds of which 3.68281 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.157409,0.0317578
gpu_array,512,8,1,20,2,true,false,true,false,0.175488,0.0556966
gpu_array,512,8,1,20,4,true,false,true,false,0.170472,0.0396126
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.149414,0.0315755
gpu_sparse,512,8,1,20,2,true,false,true,false,0.17473,0.0471257
gpu_sparse,512,8,1,20,4,true,false,true,false,0.183981,0.0453092
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.197334,0.0397819
gpu_reorg,512,8,1,20,2,true,false,true,false,0.233574,0.0610482
gpu_reorg,512,8,1,20,4,true,false,true,false,0.20806,0.0492057
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.159036,0.0294792
gpu_array,512,8,1,50,2,true,false,true,false,0.182064,0.0427409
gpu_array,512,8,1,50,4,true,false,true,false,0.178594,0.042526
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.163232,0.0291178
gpu_sparse,512,8,1,50,2,true,false,true,false,0.17749,0.0453288
gpu_sparse,512,8,1,50,4,true,false,true,false,0.185003,0.0450293
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.200794,0.0360807
gpu_reorg,512,8,1,50,2,true,false,true,false,0.206406,0.0475521
gpu_reorg,512,8,1,50,4,true,false,true,false,0.201621,0.0473242
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.166364,0.0309473
gpu_array,512,32,1,20,2,true,false,true,false,0.157894,0.0296387
gpu_array,512,32,1,20,4,true,false,true,false,0.157676,0.0307227
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.155618,0.0299674
gpu_sparse,512,32,1,20,2,true,false,true,false,0.152839,0.0265365
gpu_sparse,512,32,1,20,4,true,false,true,false,0.168275,0.0296029
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.19265,0.0383529
gpu_reorg,512,32,1,20,2,true,false,true,false,0.185697,0.035306
gpu_reorg,512,32,1,20,4,true,false,true,false,0.192087,0.0390918
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.144017,0.0255273
0.0255273
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.155107,0.0301074
0.0301074
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.141377,0.0254915
0.0254915
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.154606,0.0263509
0.0263509
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.160426,0.0308691
0.0308691
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.154261,0.0318652
0.0318652
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0254915
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.125611 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.159235,0.0316309
gpu_array,512,8,1,20,2,true,false,true,false,0.187373,0.0558626
gpu_array,512,8,1,20,4,true,false,true,false,0.166592,0.0396387
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.162324,0.0314648
gpu_sparse,512,8,1,20,2,true,false,true,false,0.176003,0.0470964
gpu_sparse,512,8,1,20,4,true,false,true,false,0.183867,0.0451953
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.209525,0.0396029
gpu_reorg,512,8,1,20,2,true,false,true,false,0.215684,0.0607357
gpu_reorg,512,8,1,20,4,true,false,true,false,0.199919,0.048877
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.152298,0.0292513
gpu_array,512,8,1,50,2,true,false,true,false,0.164792,0.0423958
gpu_array,512,8,1,50,4,true,false,true,false,0.163411,0.0423177
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.16165,0.0288379
gpu_sparse,512,8,1,50,2,true,false,true,false,0.174486,0.0449284
gpu_sparse,512,8,1,50,4,true,false,true,false,0.175042,0.044834
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.180807,0.035625
gpu_reorg,512,8,1,50,2,true,false,true,false,0.196947,0.047207
gpu_reorg,512,8,1,50,4,true,false,true,false,0.202692,0.0470931
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.152415,0.0306706
gpu_array,512,32,1,20,2,true,false,true,false,0.154362,0.029362
gpu_array,512,32,1,20,4,true,false,true,false,0.16583,0.0304134
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.161764,0.0296029
gpu_sparse,512,32,1,20,2,true,false,true,false,0.149915,0.0262174
gpu_sparse,512,32,1,20,4,true,false,true,false,0.154925,0.0292741
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.196214,0.0380111
gpu_reorg,512,32,1,20,2,true,false,true,false,0.180195,0.035013
gpu_reorg,512,32,1,20,4,true,false,true,false,0.183864,0.0386816
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.147048,0.0253027
0.0253027
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.152347,0.0299512
0.0299512
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.150889,0.0252376
0.0252376
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.141237,0.0260026
0.0260026
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.154284,0.0305859
0.0305859
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.150752,0.0316113
0.0316113
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0252376
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.124778 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.117559,0.0648242
gpu_array,1024,8,1,20,2,true,false,true,false,0.0995947,0.0468604
gpu_array,1024,8,1,20,4,true,false,true,false,0.0991357,0.0454248
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.115718,0.0659131
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.118232,0.0645215
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.113257,0.0595459
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.168208,0.0812939
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.135054,0.0461865
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.13563,0.0496924
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.110684,0.0608789
gpu_array,1024,8,1,50,2,true,false,true,false,0.100933,0.0501514
gpu_array,1024,8,1,50,4,true,false,true,false,0.10106,0.0502783
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.115176,0.0643945
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.112793,0.0610352
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.111489,0.0616846
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.162866,0.0769287
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.134272,0.0463818
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.137432,0.0514941
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.124883,0.0721484
gpu_array,1024,32,1,20,2,true,false,true,false,0.112524,0.0607666
gpu_array,1024,32,1,20,4,true,false,true,false,0.116211,0.0615234
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.123589,0.0747607
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.120762,0.0680273
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.121157,0.0674463
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.169702,0.0847412
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.154722,0.0658545
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.159604,0.0717139
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.0970312,0.0501562
0.0501562
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.0948633,0.0489648
0.0489648
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.0938232,0.0469482
0.0469482
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.097334,0.0514355
0.0514355
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.107476,0.0606006
0.0606006
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.107852,0.0619531
0.0619531
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0454248
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.40848 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.118423,0.0647119
gpu_array,1024,8,1,20,2,true,false,true,false,0.0995068,0.0467725
gpu_array,1024,8,1,20,4,true,false,true,false,0.0970752,0.0453174
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.118477,0.0657422
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.120195,0.0645312
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.112275,0.059541
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.167236,0.0812988
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.130288,0.0463037
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.138452,0.049585
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.112539,0.0607813
gpu_array,1024,8,1,50,2,true,false,true,false,0.100923,0.0501416
gpu_array,1024,8,1,50,4,true,false,true,false,0.100005,0.0502002
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.108105,0.0641602
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.11165,0.0608691
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.112329,0.0615479
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.162725,0.0767871
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.136226,0.0463818
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.140415,0.0515479
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.124878,0.0721436
gpu_array,1024,32,1,20,2,true,false,true,false,0.115479,0.060791
gpu_array,1024,32,1,20,4,true,false,true,false,0.115078,0.0613672
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.123569,0.0747412
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.122788,0.0681006
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.122007,0.0673193
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.173667,0.0847998
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.171211,0.0657422
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.16063,0.0717627
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.0960107,0.0501123
0.0501123
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.0947314,0.048833
0.048833
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.09271,0.0468115
0.0468115
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.0972656,0.0513672
0.0513672
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.107539,0.0606641
0.0606641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.107842,0.0619434
0.0619434
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0453174
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.408109 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0792383,0.0177148
gpu_array,1024,8,1,20,2,true,false,true,false,0.0785059,0.0169824
gpu_array,1024,8,1,20,4,true,false,true,false,0.0810352,0.0175586
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0806055,0.0181055
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0777393,0.0181689
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0799658,0.0184424
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.124214,0.0226514
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.117749,0.0181396
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.118979,0.0183936
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.153462,0.0206494
gpu_array,1024,8,1,50,2,true,false,true,false,0.15583,0.0210645
gpu_array,1024,8,1,50,4,true,false,true,false,0.155703,0.0209375
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.208804,0.0213037
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.157798,0.0240088
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.157808,0.0240186
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.133682,0.0262598
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.127109,0.0255469
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.126279,0.0256934
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0894482,0.0162061
gpu_array,1024,32,1,20,2,true,false,true,false,0.0805469,0.0151172
gpu_array,1024,32,1,20,4,true,false,true,false,0.0763135,0.01479
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.077832,0.0163086
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0756689,0.0151221
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0772754,0.015752
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.119043,0.0213867
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.119028,0.0174658
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.116948,0.0173389
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0741357,0.0145654
0.0145654
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0673389,0.0155811
0.0155811
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0730908,0.0154736
0.0154736
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0690283,0.0162939
0.0162939
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0709375,0.0191797
0.0191797
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0691992,0.0193945
0.0193945
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0145654
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.128126 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0803467,0.0178467
gpu_array,1024,8,1,20,2,true,false,true,false,0.0782764,0.0167529
gpu_array,1024,8,1,20,4,true,false,true,false,0.0889014,0.0176123
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0777002,0.0181299
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0777148,0.0181445
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0790918,0.0185449
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.121421,0.0227881
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.116685,0.0180518
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.114033,0.0183301
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.153447,0.0206348
gpu_array,1024,8,1,50,2,true,false,true,false,0.158677,0.0209814
gpu_array,1024,8,1,50,4,true,false,true,false,0.156694,0.0209521
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.205952,0.0213818
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.169429,0.0239209
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.159692,0.0239502
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.125854,0.0262451
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.125918,0.025332
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.12623,0.0256445
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0806641,0.0162109
gpu_array,1024,32,1,20,2,true,false,true,false,0.0766504,0.015127
gpu_array,1024,32,1,20,4,true,false,true,false,0.0762402,0.0147168
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0748975,0.0163037
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0745996,0.0150293
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0773047,0.0157813
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.121924,0.0213379
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.117012,0.0174023
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.11604,0.0174072
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0683594,0.0146484
0.0146484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.06521,0.0154053
0.0154053
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0652686,0.0154639
0.0154639
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0670557,0.0162744
0.0162744
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0729492,0.0192383
0.0192383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0701172,0.0193359
0.0193359
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0146484
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.127985 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.594155,0.142983
gpu_array,1024,8,1,20,2,true,false,true,false,0.536387,0.106699
gpu_array,1024,8,1,20,4,true,false,true,false,0.535161,0.107427
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.595151,0.152769
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.518472,0.0897607
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.530347,0.102612
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.675894,0.196401
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.576118,0.105415
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.583018,0.102549
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.519707,0.0929492
gpu_array,1024,8,1,50,2,true,false,true,false,0.487861,0.0669629
gpu_array,1024,8,1,50,4,true,false,true,false,0.521372,0.0741064
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.535273,0.0967969
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.53335,0.0909668
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.524058,0.0894873
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.577095,0.103462
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.521035,0.0708398
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.553706,0.0771436
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.481274,0.0740479
0.0740479
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.505332,0.0912695
0.0912695
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.503989,0.078208
0.078208
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.607231,0.183403
0.183403
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0669629
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.470274 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.564014,0.143115
gpu_array,1024,8,1,20,2,true,false,true,false,0.570562,0.114507
gpu_array,1024,8,1,20,4,true,false,true,false,0.534111,0.107354
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.586509,0.152915
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.516392,0.0896338
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.530454,0.10272
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.671924,0.196338
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.611118,0.105259
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.598604,0.10251
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.530596,0.0930957
gpu_array,1024,8,1,50,2,true,false,true,false,0.506265,0.0668115
gpu_array,1024,8,1,50,4,true,false,true,false,0.519619,0.0743066
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.535444,0.0969678
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.530269,0.0908154
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.548364,0.0893799
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.551582,0.10334
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.521289,0.0710937
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.567119,0.0768848
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.547651,0.0740186
0.0740186
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.502451,0.0913184
0.0913184
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.522451,0.113271
0.113271
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.596992,0.181953
0.181953
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0668115
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.478742 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.22521,0.084585
gpu_array,1024,8,1,20,2,true,false,true,false,0.210718,0.0730225
gpu_array,1024,8,1,20,4,true,false,true,false,0.225527,0.0858789
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.165977,0.0888281
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.224819,0.0890771
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.234028,0.0953564
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.213457,0.11873
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.189727,0.0959766
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.232295,0.136592
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.261221,0.11376
gpu_array,1024,8,1,50,2,true,false,true,false,0.246548,0.105923
gpu_array,1024,8,1,50,4,true,false,true,false,0.258901,0.113394
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.287256,0.110498
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.251997,0.113325
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.263457,0.122832
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.313242,0.128672
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.296558,0.118823
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.312285,0.132598
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.22751,0.0859082
gpu_array,1024,32,1,20,2,true,false,true,false,0.22,0.0803516
gpu_array,1024,32,1,20,4,true,false,true,false,0.224658,0.0850098
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.161851,0.0866553
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.22231,0.0855908
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.229497,0.0888721
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.206045,0.118154
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.202036,0.10438
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.199971,0.121846
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.130615,0.0534668
0.0534668
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.143179,0.0660303
0.0660303
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.134028,0.0559033
0.0559033
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.17209,0.0929883
0.0929883
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.147993,0.067915
0.067915
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.147227,0.0749609
0.0749609
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0534668
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.654521 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.226221,0.0846191
gpu_array,1024,8,1,20,2,true,false,true,false,0.213457,0.072832
gpu_array,1024,8,1,20,4,true,false,true,false,0.223271,0.0855762
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.168384,0.0892822
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.235913,0.0894287
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.233291,0.0955957
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.209727,0.118906
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.173369,0.0962207
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.213867,0.136719
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.251851,0.114155
gpu_array,1024,8,1,50,2,true,false,true,false,0.249575,0.106021
gpu_array,1024,8,1,50,4,true,false,true,false,0.257246,0.113691
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.287725,0.110967
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.276836,0.11375
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.263667,0.123042
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.303813,0.129009
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.300898,0.119258
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.310342,0.132607
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.222783,0.0860645
gpu_array,1024,32,1,20,2,true,false,true,false,0.219248,0.0805762
gpu_array,1024,32,1,20,4,true,false,true,false,0.227178,0.0855762
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.163389,0.0862402
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.233149,0.0856885
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.224941,0.0891992
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.211377,0.118604
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.196577,0.10478
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.215225,0.122451
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.132739,0.0536377
0.0536377
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.145352,0.06625
0.06625
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.127266,0.0559766
0.0559766
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.169302,0.0931299
0.0931299
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.14624,0.0681152
0.0681152
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.151133,0.0749609
0.0749609
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0536377
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.65596 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.873428,0.0374902
gpu_array,1024,8,1,20,2,false,false,true,false,0.864424,0.0362988
gpu_array,1024,8,1,20,4,false,false,true,false,0.871841,0.0446924
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.943691,0.0374414
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.897886,0.0365576
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.891021,0.0453174
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.990469,0.0422266
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.989736,0.0424707
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.973408,0.0486035
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.950557,0.0384473
gpu_array,1024,8,1,50,2,false,false,true,false,0.950391,0.0412109
gpu_array,1024,8,1,50,4,false,false,true,false,1.0724,0.0411475
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,1.11778,0.0396533
gpu_sparse,1024,8,1,50,2,false,false,true,false,1.07339,0.0470264
gpu_sparse,1024,8,1,50,4,false,false,true,false,1.08031,0.0471045
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.963437,0.0425391
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.942622,0.0441846
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.96001,0.0449707
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.893696,0.0362744
gpu_array,1024,32,1,20,2,false,false,true,false,0.884746,0.0351367
gpu_array,1024,32,1,20,4,false,false,true,false,0.878228,0.0383838
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.964082,0.0373242
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.885181,0.0355713
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.879595,0.0387744
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.989097,0.0437842
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.991895,0.0416992
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.991118,0.0418994
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.874209,0.0343652
0.0343652
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.867896,0.0378174
0.0378174
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.887959,0.0354199
0.0354199
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0343652
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.248593 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.884263,0.037583
gpu_array,1024,8,1,20,2,false,false,true,false,0.876084,0.0362402
gpu_array,1024,8,1,20,4,false,false,true,false,0.870737,0.0445654
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.962339,0.0375342
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.885342,0.036709
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.898887,0.0453711
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.960356,0.0423877
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.992715,0.0425195
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.973223,0.048418
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.935864,0.0384033
gpu_array,1024,8,1,50,2,false,false,true,false,1.06362,0.0411572
gpu_array,1024,8,1,50,4,false,false,true,false,1.0538,0.0411035
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,1.00651,0.0397119
gpu_sparse,1024,8,1,50,2,false,false,true,false,1.06753,0.0470215
gpu_sparse,1024,8,1,50,4,false,false,true,false,1.0878,0.0467871
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.964272,0.0423975
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.9377,0.0441455
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.961147,0.0451318
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.896831,0.0364795
gpu_array,1024,32,1,20,2,false,false,true,false,0.876865,0.0350684
gpu_array,1024,32,1,20,4,false,false,true,false,0.855708,0.0383252
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.948359,0.0372266
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.88313,0.0354736
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.88748,0.0388477
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.964692,0.0437939
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.964561,0.041709
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.989321,0.0420557
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.884155,0.0345459
0.0345459
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.872744,0.0377832
0.0377832
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.880366,0.0356396
0.0356396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0345459
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.248655 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.094375,0.0182031
gpu_array,1024,8,1,20,2,true,false,true,false,0.0884229,0.0171338
gpu_array,1024,8,1,20,4,true,false,true,false,0.104956,0.0190186
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.089834,0.0185449
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0854395,0.0190332
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0941504,0.0199316
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.137847,0.0235889
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.132314,0.0190332
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.134243,0.022915
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.162715,0.0211133
gpu_array,1024,8,1,50,2,true,false,true,false,0.170972,0.0215576
gpu_array,1024,8,1,50,4,true,false,true,false,0.174819,0.021499
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.214888,0.0215283
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.164888,0.0242627
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.161909,0.0242139
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.141538,0.0272803
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.142861,0.0286035
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.13519,0.0277686
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0930566,0.0168848
gpu_array,1024,32,1,20,2,true,false,true,false,0.100625,0.0156641
gpu_array,1024,32,1,20,4,true,false,true,false,0.0867578,0.0154687
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0892773,0.0170117
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0844141,0.0160547
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0985693,0.0165381
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.133755,0.0224268
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.129482,0.0191309
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.130107,0.0187793
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.080752,0.0153223
0.0153223
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0837354,0.0173291
0.0173291
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0858789,0.0155664
0.0155664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0780859,0.0165625
0.0165625
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0850439,0.0196143
0.0196143
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0862646,0.0198584
0.0198584
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0153223
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.134644 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0992139,0.0181592
gpu_array,1024,8,1,20,2,true,false,true,false,0.0912793,0.0170605
gpu_array,1024,8,1,20,4,true,false,true,false,0.0961914,0.019043
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0868604,0.018501
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0932031,0.0189844
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0894922,0.0201563
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.138662,0.0234277
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.135537,0.0193262
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.131958,0.022583
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.164736,0.0211816
gpu_array,1024,8,1,50,2,true,false,true,false,0.160332,0.0216602
gpu_array,1024,8,1,50,4,true,false,true,false,0.177905,0.0216553
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.242178,0.0214746
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.160171,0.0244287
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.166753,0.0241748
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.138667,0.0273389
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.137969,0.0276172
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.1429,0.0286426
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.104521,0.0166309
gpu_array,1024,32,1,20,2,true,false,true,false,0.0977197,0.0156885
gpu_array,1024,32,1,20,4,true,false,true,false,0.0926514,0.0155029
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0862793,0.0169434
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0893066,0.0160645
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0888525,0.0165869
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.132725,0.022373
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.132461,0.0191797
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.132803,0.0195215
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0845605,0.0152246
0.0152246
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0866553,0.0173193
0.0173193
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0878174,0.0155518
0.0155518
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0926465,0.0164746
0.0164746
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0890381,0.0197021
0.0197021
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0882129,0.0198535
0.0198535
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0152246
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.134765 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.21709,3.06084
gpu_array,1024,8,1,20,2,true,false,true,false,4.95744,4.77287
gpu_array,1024,8,1,20,4,true,false,true,false,4.69945,4.54516
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.86635,2.72572
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.92734,4.76621
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.86557,4.71029
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.66803,3.48736
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.83277,6.6482
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.36807,5.17959
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.81082,3.65066
gpu_array,1024,8,1,50,2,true,false,true,false,4.53596,4.37482
gpu_array,1024,8,1,50,4,true,false,true,false,6.94734,6.78328
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.36068,3.21225
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.55447,4.39529
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.28146,6.11936
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.10508,3.92344
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.09453,6.89824
gpu_reorg,1024,8,1,50,4,true,false,true,false,9.91676,9.72047
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.3135,3.16311
gpu_array,1024,32,1,20,2,true,false,true,false,3.44613,3.29184
gpu_array,1024,32,1,20,4,true,false,true,false,4.02746,3.87219
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.13232,2.99268
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.41857,3.26525
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.78154,3.61943
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,4.00068,3.82393
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.5308,4.34232
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.96801,2.86156
2.86156
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.07537,2.966
2.966
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.09498,1.99244
1.99244
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.25754,2.14719
2.14719
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99244
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 145 seconds of which 6.51837 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.25965,3.05945
gpu_array,1024,8,1,20,2,true,false,true,false,4.94119,4.76834
gpu_array,1024,8,1,20,4,true,false,true,false,4.59854,4.44326
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.86229,2.72068
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.99412,4.83201
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.90408,4.71756
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.67611,3.48178
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.69727,6.50586
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.22367,5.02445
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.72063,3.54289
gpu_array,1024,8,1,50,2,true,false,true,false,4.57359,4.41051
gpu_array,1024,8,1,50,4,true,false,true,false,6.8452,6.68309
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.35934,3.21578
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.54564,4.37572
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.30131,6.13529
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.12598,3.93848
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.04361,6.84732
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.1396,9.94619
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.31891,3.1607
gpu_array,1024,32,1,20,2,true,false,true,false,3.46381,3.31146
gpu_array,1024,32,1,20,4,true,false,true,false,3.95947,3.80811
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.37199,3.22844
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.48256,3.33119
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.77443,3.61916
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,4.03021,3.84857
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.60855,4.41715
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.96434,2.86766
2.86766
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.07051,2.95723
2.95723
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.11174,1.99748
1.99748
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.24551,2.1332
2.1332
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99748
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 147 seconds of which 6.51925 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.107896,0.0170752
gpu_array,1024,8,1,20,2,true,false,true,false,0.125972,0.029292
gpu_array,1024,8,1,20,4,true,false,true,false,0.119414,0.0266406
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.109033,0.0172363
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.123994,0.0312207
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.121484,0.0326172
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.151665,0.0217822
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.162769,0.0348389
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.166323,0.0325342
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.114116,0.0203662
gpu_array,1024,8,1,50,2,true,false,true,false,0.128755,0.0340283
gpu_array,1024,8,1,50,4,true,false,true,false,0.126787,0.0340137
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.113115,0.0203418
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.134316,0.0356836
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.128306,0.0355322
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.157617,0.0267578
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.172163,0.038374
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.165244,0.038291
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.110586,0.0158594
gpu_array,1024,32,1,20,2,true,false,true,false,0.103667,0.0157764
gpu_array,1024,32,1,20,4,true,false,true,false,0.11145,0.0167236
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.112432,0.015752
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.109043,0.0162695
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.109448,0.0176514
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.146348,0.0203711
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.147671,0.0197412
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.149204,0.0232275
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.105273,0.0154297
0.0154297
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.107744,0.0179004
0.0179004
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.106108,0.0162646
0.0162646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.106899,0.0170557
0.0170557
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.098916,0.0178613
0.0178613
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.114268,0.0185645
0.0185645
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0154297
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.162012 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.107925,0.0161279
gpu_array,1024,8,1,20,2,true,false,true,false,0.121152,0.0274023
gpu_array,1024,8,1,20,4,true,false,true,false,0.117778,0.0250049
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.105898,0.0170313
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.119155,0.0312646
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.12623,0.0324805
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.152578,0.0217187
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.161724,0.0347705
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.158408,0.0324316
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.113091,0.0203174
gpu_array,1024,8,1,50,2,true,false,true,false,0.128696,0.0339697
gpu_array,1024,8,1,50,4,true,false,true,false,0.123716,0.0338721
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.111104,0.0202832
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.124385,0.0355176
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.124316,0.0354492
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.160767,0.0269775
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.166279,0.0383496
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.169077,0.0382178
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.110679,0.0159521
gpu_array,1024,32,1,20,2,true,false,true,false,0.11145,0.0157471
gpu_array,1024,32,1,20,4,true,false,true,false,0.107515,0.0166943
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.111489,0.0157861
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.109014,0.0162402
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.114355,0.0176758
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.147339,0.0203857
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.134907,0.0196729
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.150112,0.0231592
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.103965,0.0141211
0.0141211
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.105898,0.0180078
0.0180078
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,0.104121,0.0162305
0.0162305
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,0.105547,0.0166797
0.0166797
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.107515,0.0176709
0.0176709
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.107739,0.0178955
0.0178955
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0141211
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.16038 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0895239,0.0626685
gpu_array,2048,8,1,20,2,true,false,true,false,0.0770947,0.0512158
gpu_array,2048,8,1,20,4,true,false,true,false,0.0728857,0.0470068
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0974341,0.0710669
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0832275,0.0568604
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0865088,0.0596533
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.119468,0.0716162
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0944873,0.0456592
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.085332,0.038457
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0829126,0.0555688
gpu_array,2048,8,1,50,2,true,false,true,false,0.0715649,0.0451978
gpu_array,2048,8,1,50,4,true,false,true,false,0.0707007,0.0448218
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0860913,0.0592358
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0759741,0.0500952
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0788892,0.052522
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.121475,0.0716699
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0897656,0.0414258
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0936719,0.045332
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0928735,0.0660181
gpu_array,2048,32,1,20,2,true,false,true,false,0.0827588,0.0563916
gpu_array,2048,32,1,20,4,true,false,true,false,0.0833228,0.0569556
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0954907,0.0686353
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0745532,0.048186
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0765576,0.0501904
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.124717,0.076377
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.107681,0.0608057
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.100444,0.0525928
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,true,0.0855249,0.0391382
0.0391382
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,true,0.0952295,0.0493311
0.0493311
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,0.0849707,0.0395605
0.0395605
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,0.0889014,0.0430029
0.0430029
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,true,0.0985254,0.052627
0.052627
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,true,0.102285,0.0554102
0.0554102
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.038457
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.731257 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0889917,0.0626245
gpu_array,2048,8,1,20,2,true,false,true,false,0.0775269,0.0511597
gpu_array,2048,8,1,20,4,true,false,true,false,0.0745972,0.0472534
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0969263,0.0710474
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0830493,0.0566821
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0858838,0.0595166
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.118828,0.0714648
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0934985,0.045647
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0857861,0.0384229
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0819263,0.0555591
gpu_array,2048,8,1,50,2,true,false,true,false,0.0715747,0.0452075
gpu_array,2048,8,1,50,4,true,false,true,false,0.0707886,0.0449097
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0860352,0.0591797
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0765259,0.0501587
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0791235,0.0527563
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.118362,0.0714868
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0892627,0.0414111
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0927271,0.0453638
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0922998,0.0659326
gpu_array,2048,32,1,20,2,true,false,true,false,0.0827393,0.0563721
gpu_array,2048,32,1,20,4,true,false,true,false,0.083833,0.0569775
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0949805,0.0686133
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0745605,0.0481934
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0770703,0.0502148
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.124873,0.0765332
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.109673,0.0608447
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.100464,0.0526123
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,true,0.0850269,0.0391284
0.0391284
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,true,0.0942407,0.0493188
0.0493188
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,0.0849512,0.039541
0.039541
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,0.0883984,0.0429883
0.0429883
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,true,0.0978833,0.0524731
0.0524731
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,true,0.101321,0.0554224
0.0554224
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0384229
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.731143 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0514233,0.014314
gpu_array,2048,8,1,20,2,true,false,true,false,0.0583838,0.0139502
gpu_array,2048,8,1,20,4,true,false,true,false,0.0566919,0.0146997
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0517188,0.0150977
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0502295,0.0140967
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0547974,0.01427
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0775,0.0189062
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0742627,0.0146924
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.07479,0.0166846
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0531519,0.0160425
gpu_array,2048,8,1,50,2,true,false,true,false,0.0530737,0.0164526
gpu_array,2048,8,1,50,4,true,false,true,false,0.0570117,0.0164844
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0621216,0.0171997
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0547266,0.0176172
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0546509,0.0175415
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0819287,0.0208936
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0801099,0.0200513
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0780786,0.0199731
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0550488,0.0120801
gpu_array,2048,32,1,20,2,true,false,true,false,0.049541,0.0109668
gpu_array,2048,32,1,20,4,true,false,true,false,0.052002,0.0114746
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.055354,0.0123853
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.050437,0.0113745
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0507251,0.0116626
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0789673,0.0174438
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0748755,0.0138403
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0774048,0.0158813
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0402612,0.0104761
0.0104761
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0427002,0.0114502
0.0114502
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0460156,0.0133008
0.0133008
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.0451538,0.0139038
0.0139038
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0459546,0.0151929
0.0151929
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0465747,0.0153247
0.0153247
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0104761
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.203049 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.049978,0.0133569
gpu_array,2048,8,1,20,2,true,false,true,false,0.0521118,0.0130493
gpu_array,2048,8,1,20,4,true,false,true,false,0.0538623,0.0138232
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.050708,0.0140869
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0498291,0.013208
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0529443,0.0133936
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0794067,0.0188599
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0756958,0.0146606
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0782275,0.0167041
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0527271,0.016106
gpu_array,2048,8,1,50,2,true,false,true,false,0.0555957,0.0165332
gpu_array,2048,8,1,50,4,true,false,true,false,0.0560693,0.0165186
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0543286,0.0172192
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0581372,0.0176099
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0566528,0.0175903
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0887793,0.0209082
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0815308,0.0200073
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0761597,0.0200073
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0506421,0.0120679
gpu_array,2048,32,1,20,2,true,false,true,false,0.0515356,0.0110083
gpu_array,2048,32,1,20,4,true,false,true,false,0.051543,0.0115039
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0509644,0.0123901
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0509644,0.0114136
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0473022,0.0116577
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0774268,0.0173682
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0703662,0.0137256
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0763232,0.0157764
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0416797,0.0104297
0.0104297
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0407983,0.0115015
0.0115015
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0430396,0.0132544
0.0132544
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.0431738,0.013877
0.013877
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0449854,0.0152002
0.0152002
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0446655,0.0153687
0.0153687
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0104297
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.20078 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.439724,0.109158
gpu_array,2048,8,1,20,2,true,false,true,false,0.411125,0.0810474
gpu_array,2048,8,1,20,4,true,false,true,false,0.409622,0.0814966
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.456592,0.116748
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.39551,0.0659204
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.411858,0.076897
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.495139,0.151877
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.435972,0.0795264
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.430559,0.0770435
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.418655,0.0871118
gpu_array,2048,8,1,50,2,true,false,true,false,0.387996,0.0613354
gpu_array,2048,8,1,50,4,true,false,true,false,0.402014,0.0714478
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.425989,0.0915161
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.413423,0.0809033
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.409788,0.0821509
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.46041,0.0956641
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.418665,0.0646606
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.418521,0.070376
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.394651,0.0723853
0.0723853
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.411858,0.0851978
0.0851978
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.384998,0.0583374
0.0583374
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.62354,0.29688
0.29688
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0583374
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.842826 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.437278,0.109153
gpu_array,2048,8,1,20,2,true,false,true,false,0.422957,0.0875073
gpu_array,2048,8,1,20,4,true,false,true,false,0.410212,0.0815991
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.453132,0.116707
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.40822,0.0659351
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.414902,0.0770117
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.506494,0.152002
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.419971,0.0796387
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.421018,0.0772681
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.422703,0.0872534
gpu_array,2048,8,1,50,2,true,false,true,false,0.394741,0.0617334
gpu_array,2048,8,1,50,4,true,false,true,false,0.409595,0.0712158
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.431042,0.091687
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.409888,0.0807861
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.417683,0.0822339
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.455388,0.0955249
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.419712,0.0647314
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.425918,0.0704492
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.396531,0.072312
0.072312
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.411941,0.0852808
0.0852808
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,0.408501,0.0862354
0.0862354
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,0.59166,0.269395
0.269395
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0617334
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.846094 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.167864,0.0907153
gpu_array,2048,8,1,20,2,true,false,true,false,0.170435,0.0942627
gpu_array,2048,8,1,20,4,true,false,true,false,0.167632,0.0909717
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.188789,0.0974805
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.185664,0.107539
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.17981,0.101196
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.220432,0.125706
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.212319,0.117593
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.203452,0.106284
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.184177,0.106052
gpu_array,2048,8,1,50,2,true,false,true,false,0.187266,0.0983984
gpu_array,2048,8,1,50,4,true,false,true,false,0.186863,0.107273
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.199861,0.108552
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.18582,0.105742
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.197476,0.116909
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.221902,0.12571
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.213799,0.115654
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.22084,0.12416
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.166292,0.0862134
gpu_array,2048,32,1,20,2,true,false,true,false,0.166311,0.0862329
gpu_array,2048,32,1,20,4,true,false,true,false,0.167061,0.0884473
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.174932,0.0841113
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.163118,0.085481
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.169697,0.0905957
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.204478,0.109263
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.20116,0.105457
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.214011,0.0958472
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,0.109421,0.0605933
0.0605933
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,0.124065,0.0762134
0.0762134
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,0.118445,0.0696167
0.0696167
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,0.126736,0.0759546
0.0759546
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,2,true,false,true,true,0.122461,0.0707031
0.0707031
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,2,false,false,true,true,0.136785,0.0864917
0.0864917
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0605933
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.3154 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.168879,0.0907544
gpu_array,2048,8,1,20,2,true,false,true,false,0.17001,0.0933496
gpu_array,2048,8,1,20,4,true,false,true,false,0.16937,0.0902686
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.186331,0.0979517
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.185396,0.107271
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.17989,0.100789
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.221709,0.126006
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.217314,0.117705
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.207747,0.106672
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.186711,0.106145
gpu_array,2048,8,1,50,2,true,false,true,false,0.18147,0.0984619
gpu_array,2048,8,1,50,4,true,false,true,false,0.186895,0.107305
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.199529,0.108708
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.186379,0.105813
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.198645,0.117102
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.224988,0.125378
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.216277,0.115691
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.226873,0.123845
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.165742,0.0866406
gpu_array,2048,32,1,20,2,true,false,true,false,0.163262,0.0861133
gpu_array,2048,32,1,20,4,true,false,true,false,0.165815,0.0881787
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.180178,0.0844751
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.165044,0.0854541
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.16918,0.0905664
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.205232,0.109041
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.201069,0.105366
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.196448,0.0958618
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,0.110388,0.0605835
0.0605835
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,0.126514,0.0762207
0.0762207
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,0.123599,0.0698877
0.0698877
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,0.126794,0.0760132
0.0760132
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,2,true,false,true,true,0.123547,0.070813
0.070813
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,2,false,false,true,true,0.137148,0.0863672
0.0863672
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0605835
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.31514 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,0.838838,0.0497754
gpu_array,2048,8,1,20,2,false,false,true,false,0.857961,0.0488794
gpu_array,2048,8,1,20,4,false,false,true,false,0.847927,0.0490991
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,0.832981,0.0492896
gpu_sparse,2048,8,1,20,2,false,false,true,false,0.850867,0.047644
gpu_sparse,2048,8,1,20,4,false,false,true,false,0.856006,0.0493652
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,0.863191,0.0541089
gpu_reorg,2048,8,1,20,2,false,false,true,false,0.848247,0.0503955
gpu_reorg,2048,8,1,20,4,false,false,true,false,0.844592,0.0574829
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,0.826182,0.0346777
gpu_array,2048,8,1,50,2,false,false,true,false,0.826018,0.0354907
gpu_array,2048,8,1,50,4,false,false,true,false,0.844561,0.0354785
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,0.842061,0.0359082
gpu_sparse,2048,8,1,50,2,false,false,true,false,0.814739,0.040813
gpu_sparse,2048,8,1,50,4,false,false,true,false,0.824536,0.0408447
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,0.845884,0.0392432
gpu_reorg,2048,8,1,50,2,false,false,true,false,0.851619,0.0391187
gpu_reorg,2048,8,1,50,4,false,false,true,false,0.842988,0.0392773
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,0.841938,0.0431104
gpu_array,2048,32,1,20,2,false,false,true,false,0.828743,0.0416333
gpu_array,2048,32,1,20,4,false,false,true,false,0.834548,0.0332788
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,0.841553,0.0432129
gpu_sparse,2048,32,1,20,2,false,false,true,false,0.839807,0.0419556
gpu_sparse,2048,32,1,20,4,false,false,true,false,0.825645,0.0341406
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,0.84627,0.0498828
gpu_reorg,2048,32,1,20,2,false,false,true,false,0.835715,0.0476294
gpu_reorg,2048,32,1,20,4,false,false,true,false,0.831318,0.0388379
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,0.820405,0.0332959
0.0332959
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.816702,0.032522
0.032522
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.807874,0.0466431
0.0466431
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.032522
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.525531 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,0.833796,0.0461987
gpu_array,2048,8,1,20,2,false,false,true,false,0.825876,0.0451147
gpu_array,2048,8,1,20,4,false,false,true,false,0.82967,0.0454907
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,0.83593,0.0454028
gpu_sparse,2048,8,1,20,2,false,false,true,false,0.843103,0.0442749
gpu_sparse,2048,8,1,20,4,false,false,true,false,0.84032,0.0458862
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,0.856389,0.0536548
gpu_reorg,2048,8,1,20,2,false,false,true,false,0.836172,0.0505273
gpu_reorg,2048,8,1,20,4,false,false,true,false,0.878308,0.0575073
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,0.838862,0.0346631
gpu_array,2048,8,1,50,2,false,false,true,false,0.825508,0.0354688
gpu_array,2048,8,1,50,4,false,false,true,false,0.821108,0.0354639
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,0.831362,0.0359521
gpu_sparse,2048,8,1,50,2,false,false,true,false,0.844978,0.0407788
gpu_sparse,2048,8,1,50,4,false,false,true,false,0.830986,0.0409473
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,0.835989,0.0391138
gpu_reorg,2048,8,1,50,2,false,false,true,false,0.836587,0.0392236
gpu_reorg,2048,8,1,50,4,false,false,true,false,0.828257,0.0391943
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,0.845281,0.0430347
gpu_array,2048,32,1,20,2,false,false,true,false,0.839497,0.0416455
gpu_array,2048,32,1,20,4,false,false,true,false,0.842952,0.0333813
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,0.845439,0.0431934
gpu_sparse,2048,32,1,20,2,false,false,true,false,0.840198,0.0418579
gpu_sparse,2048,32,1,20,4,false,false,true,false,0.820195,0.0340625
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,0.89115,0.0498413
gpu_reorg,2048,32,1,20,2,false,false,true,false,0.857131,0.047561
gpu_reorg,2048,32,1,20,4,false,false,true,false,0.85,0.0389648
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,0.816016,0.0333008
0.0333008
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.823462,0.0324463
0.0324463
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.833,0.0468677
0.0468677
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.0324463
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.516514 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0606616,0.0142749
gpu_array,2048,8,1,20,2,true,false,true,false,0.0599756,0.0140771
gpu_array,2048,8,1,20,4,true,false,true,false,0.0608813,0.0149829
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0593701,0.0154248
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0614258,0.0150391
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0641797,0.0153516
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0836621,0.019209
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0804297,0.0164648
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0840796,0.0230444
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.063728,0.0163647
gpu_array,2048,8,1,50,2,true,false,true,false,0.0646387,0.0162988
gpu_array,2048,8,1,50,4,true,false,true,false,0.0626953,0.0163086
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0655493,0.0172095
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.062124,0.0176904
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0665845,0.0177563
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0833887,0.0218652
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0817236,0.0211768
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.082854,0.0213306
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0583813,0.0124829
gpu_array,2048,32,1,20,2,true,false,true,false,0.0623193,0.0115381
gpu_array,2048,32,1,20,4,true,false,true,false,0.0588672,0.0119922
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0592871,0.0129004
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0588184,0.0119434
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0589941,0.0126074
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.084585,0.0181787
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0767285,0.0147168
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0781812,0.017146
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0517285,0.0112012
0.0112012
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0542041,0.0127002
0.0127002
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0554761,0.0134839
0.0134839
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.0528052,0.0137427
0.0137427
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.0540112,0.0144604
0.0144604
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.0536084,0.0135693
0.0135693
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0112012
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.211572 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0635571,0.0137524
gpu_array,2048,8,1,20,2,true,false,true,false,0.0594604,0.013562
gpu_array,2048,8,1,20,4,true,false,true,false,0.060354,0.0144556
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0612817,0.014895
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0593823,0.0144604
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0640479,0.0147314
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0814185,0.0184302
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0829663,0.0165601
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0905469,0.0231641
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0647681,0.0164282
gpu_array,2048,8,1,50,2,true,false,true,false,0.0647217,0.0163818
gpu_array,2048,8,1,50,4,true,false,true,false,0.0642334,0.0163818
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0680396,0.0172583
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0660742,0.0177344
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0631079,0.0176978
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0853345,0.0218579
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0867383,0.0213086
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0848169,0.0213403
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0603223,0.0124707
gpu_array,2048,32,1,20,2,true,false,true,false,0.0618506,0.0115576
gpu_array,2048,32,1,20,4,true,false,true,false,0.0604517,0.0121118
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0593066,0.0129199
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0593311,0.0119678
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0618188,0.0125024
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0820557,0.0180908
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0810278,0.0146216
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0835425,0.0171362
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0512158,0.0111768
0.0111768
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0538599,0.0128442
0.0128442
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0520581,0.0134839
0.0134839
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.053772,0.0137329
0.0137329
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.0530542,0.01448
0.01448
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.0511914,0.0135937
0.0135937
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0111768
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.210162 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,4.18846,4.10984
gpu_array,2048,8,1,20,2,true,false,true,false,5.07478,4.99079
gpu_array,2048,8,1,20,4,true,false,true,false,4.54307,4.46152
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,3.88628,3.80815
gpu_sparse,2048,8,1,20,2,true,false,true,false,5.10013,5.022
gpu_sparse,2048,8,1,20,4,true,false,true,false,3.97838,3.89635
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,4.90421,4.80802
gpu_reorg,2048,8,1,20,2,true,false,true,false,5.32235,5.22323
gpu_reorg,2048,8,1,20,4,true,false,true,false,5.10463,5.00453
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,3.71537,3.62846
gpu_array,2048,8,1,50,2,true,false,true,false,4.41181,4.3244
gpu_array,2048,8,1,50,4,true,false,true,false,6.70637,6.61799
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,3.3752,3.29121
gpu_sparse,2048,8,1,50,2,true,false,true,false,4.42375,4.33732
gpu_sparse,2048,8,1,50,4,true,false,true,false,6.19628,6.10692
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,4.165,4.0693
gpu_reorg,2048,8,1,50,2,true,false,true,false,7.65079,7.54972
gpu_reorg,2048,8,1,50,4,true,false,true,false,10.2595,10.1419
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,3.71506,3.63547
gpu_array,2048,32,1,20,2,true,false,true,false,2.95976,2.88065
gpu_array,2048,32,1,20,4,true,false,true,false,2.98069,2.89915
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,3.19228,3.11513
gpu_sparse,2048,32,1,20,2,true,false,true,false,2.96201,2.88437
gpu_sparse,2048,32,1,20,4,true,false,true,false,2.93828,2.85723
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,4.187,4.08886
gpu_reorg,2048,32,1,20,2,true,false,true,false,3.42192,3.32524
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,1.9537,1.91659
1.91659
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,2.10093,2.06382
2.06382
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,2.22521,2.18859
2.18859
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,2.30686,2.27121
2.27121
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.91659
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 157 seconds of which 12.853 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,4.22991,4.1513
gpu_array,2048,8,1,20,2,true,false,true,false,4.97656,4.89746
gpu_array,2048,8,1,20,4,true,false,true,false,4.55993,4.47692
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,3.87693,3.79783
gpu_sparse,2048,8,1,20,2,true,false,true,false,5.18388,5.1038
gpu_sparse,2048,8,1,20,4,true,false,true,false,3.98272,3.90021
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,4.85471,4.75949
gpu_reorg,2048,8,1,20,2,true,false,true,false,5.33008,5.23047
gpu_reorg,2048,8,1,20,4,true,false,true,false,5.10528,5.00372
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,3.66421,3.55776
gpu_array,2048,8,1,50,2,true,false,true,false,4.39717,4.31025
gpu_array,2048,8,1,50,4,true,false,true,false,6.71073,6.62187
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,3.3935,3.30805
gpu_sparse,2048,8,1,50,2,true,false,true,false,4.45646,4.36711
gpu_sparse,2048,8,1,50,4,true,false,true,false,6.11668,6.02635
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,4.20256,4.09221
gpu_reorg,2048,8,1,50,2,true,false,true,false,7.71345,7.61188
gpu_reorg,2048,8,1,50,4,true,false,true,false,10.2157,10.1146
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,3.72114,3.6396
gpu_array,2048,32,1,20,2,true,false,true,false,3.01063,2.9325
gpu_array,2048,32,1,20,4,true,false,true,false,3.08773,2.98422
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,3.23916,3.16299
gpu_sparse,2048,32,1,20,2,true,false,true,false,3.06527,2.98715
gpu_sparse,2048,32,1,20,4,true,false,true,false,2.91747,2.83446
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,4.20217,4.09523
gpu_reorg,2048,32,1,20,2,true,false,true,false,3.5651,3.44156
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,1.95138,1.91524
1.91524
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,2.08719,2.05008
2.05008
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,2.19812,2.16149
2.16149
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,2.24546,2.20933
2.20933
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.91524
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 158 seconds of which 12.8763 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0899487,0.0132886
gpu_array,2048,8,1,20,2,true,false,true,false,0.0999927,0.0247974
gpu_array,2048,8,1,20,4,true,false,true,false,0.0930762,0.0208105
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0883301,0.0141113
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0995117,0.0243164
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.100044,0.0243604
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0909082,0.017666
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.122068,0.0292944
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.109099,0.0304858
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.125759,0.015896
gpu_array,2048,8,1,50,2,true,false,true,false,0.163179,0.0289014
gpu_array,2048,8,1,50,4,true,false,true,false,0.145071,0.0283716
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.132251,0.01604
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.173542,0.0304761
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.145647,0.0304126
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.136995,0.0222485
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.186191,0.0333594
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.162261,0.0333545
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.083606,0.0118286
gpu_array,2048,32,1,20,2,true,false,true,false,0.0859204,0.0117017
gpu_array,2048,32,1,20,4,true,false,true,false,0.0875098,0.0123145
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0919165,0.0118384
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0859375,0.012207
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.088894,0.0132104
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.118203,0.0161523
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.109868,0.0156299
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.113242,0.0190039
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0801416,0.0103174
0.0103174
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0866895,0.0139355
0.0139355
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,0.0853906,0.0126367
0.0126367
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,0.0848633,0.0135742
0.0135742
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0846997,0.0138989
0.0138989
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0873437,0.0141016
0.0141016
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0103174
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.262366 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0867383,0.0125195
gpu_array,2048,8,1,20,2,true,false,true,false,0.0948267,0.0230493
gpu_array,2048,8,1,20,4,true,false,true,false,0.0952393,0.0195557
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0845581,0.013269
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0991113,0.0244043
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0977515,0.0245093
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0909741,0.0177319
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.108911,0.0293213
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.124587,0.0308374
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.127791,0.0159741
gpu_array,2048,8,1,50,2,true,false,true,false,0.168984,0.0288477
gpu_array,2048,8,1,50,4,true,false,true,false,0.154365,0.028877
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.119124,0.0160962
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.158318,0.0303882
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.14863,0.0304663
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.13999,0.0223145
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.188164,0.0333789
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.157363,0.0333398
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0846802,0.0119263
gpu_array,2048,32,1,20,2,true,false,true,false,0.0869409,0.0117456
gpu_array,2048,32,1,20,4,true,false,true,false,0.0846021,0.0123364
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0865991,0.0118921
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0874023,0.012207
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0883521,0.0131567
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.108948,0.0161743
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.108416,0.0156421
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.113223,0.0189844
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0816699,0.0103809
0.0103809
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0846899,0.0138892
0.0138892
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,0.0849731,0.0127075
0.0127075
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,0.0830786,0.0137427
0.0137427
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0862427,0.0139771
0.0139771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0843896,0.0140771
0.0140771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0103809
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.26121 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.140942,0.12019
gpu_array,4096,32,1,2,2,true,false,true,false,0.10062,0.0801123
gpu_array,4096,32,1,2,4,true,false,true,false,0.0796631,0.0591553
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.146182,0.129336
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0906348,0.0698828
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0970435,0.0762915
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0838086,0.0630566
gpu_array,4096,32,1,10,2,true,false,true,false,0.0722876,0.0532446
gpu_array,4096,32,1,10,4,true,false,true,false,0.0636792,0.0470776
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0861841,0.065188
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.072981,0.0541821
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.071687,0.0528882
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.150283,0.129531
gpu_array,4096,64,1,2,2,true,false,true,false,0.106833,0.0858374
gpu_array,4096,64,1,2,4,true,false,true,false,0.083772,0.0632642
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.148013,0.129214
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0907861,0.06979
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.092478,0.0758765
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0814868,0.0629321
gpu_array,4096,64,1,10,2,true,false,true,false,0.0750439,0.0533154
gpu_array,4096,64,1,10,4,true,false,true,false,0.0627075,0.0419556
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0870483,0.0653198
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0638184,0.0467285
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0634644,0.0468628
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0601343,0.0413354
0.0413354
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.062373,0.0440625
0.0440625
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0623486,0.0445264
0.0445264
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0676025,0.049292
0.049292
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0719434,0.0533887
0.0533887
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.103552,0.0847534
0.0847534
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0413354
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.843199 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.140374,0.119622
gpu_array,4096,32,1,2,2,true,false,true,false,0.0999707,0.079707
gpu_array,4096,32,1,2,4,true,false,true,false,0.0778979,0.058855
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.137283,0.118728
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0903955,0.0698877
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0970093,0.0762573
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0843066,0.0628223
gpu_array,4096,32,1,10,2,true,false,true,false,0.0728857,0.0531104
gpu_array,4096,32,1,10,4,true,false,true,false,0.067019,0.0469995
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0819702,0.0651245
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0749878,0.0542358
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.073728,0.0529761
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.150295,0.129543
gpu_array,4096,64,1,2,2,true,false,true,false,0.104631,0.0858325
gpu_array,4096,64,1,2,4,true,false,true,false,0.0844629,0.0632227
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.149841,0.129089
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0881885,0.0696338
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.092395,0.0757935
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0817529,0.0629541
gpu_array,4096,64,1,10,2,true,false,true,false,0.0740991,0.0533472
gpu_array,4096,64,1,10,4,true,false,true,false,0.0624634,0.0419556
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0837939,0.0652393
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0651489,0.0465942
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0656323,0.0468335
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0605518,0.0412646
0.0412646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.062395,0.0440845
0.0440845
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0632764,0.0444775
0.0444775
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0674072,0.0493408
0.0493408
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0731714,0.053396
0.053396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.103848,0.0848047
0.0848047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0412646
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.837932 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0460425,0.0186987
gpu_array,4096,32,1,2,2,true,false,true,false,0.0406812,0.0150464
gpu_array,4096,32,1,2,4,true,false,true,false,0.043479,0.0141821
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0446606,0.0187817
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0397192,0.0104224
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0421143,0.0128174
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0360962,0.00924072
gpu_array,4096,32,1,10,2,true,false,true,false,0.0372119,0.00791504
gpu_array,4096,32,1,10,4,true,false,true,false,0.0346118,0.00775635
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.034646,0.00974365
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0316553,0.00699707
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0347876,0.00817627
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0476318,0.0185791
gpu_array,4096,64,1,2,2,true,false,true,false,0.0450122,0.0149829
gpu_array,4096,64,1,2,4,true,false,true,false,0.0418774,0.0140454
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0478247,0.0185278
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.04021,0.0104248
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0412695,0.0127051
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0378198,0.00925537
gpu_array,4096,64,1,10,2,true,false,true,false,0.0344702,0.00785889
gpu_array,4096,64,1,10,4,true,false,true,false,0.0339331,0.00781006
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0341626,0.00974854
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0315527,0.00713867
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0336084,0.00748535
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0276318,0.00687988
0.00687988
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0299512,0.00919922
0.00919922
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.027644,0.00713623
0.00713623
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0297681,0.00926025
0.00926025
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0308618,0.010354
0.010354
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.040708,0.0162939
0.0162939
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00687988
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.138225 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0459131,0.0185693
gpu_array,4096,32,1,2,2,true,false,true,false,0.0440088,0.0149561
gpu_array,4096,32,1,2,4,true,false,true,false,0.0382544,0.0140845
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0455273,0.0186719
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0365063,0.0103833
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.037915,0.0127686
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0372852,0.00920898
gpu_array,4096,32,1,10,2,true,false,true,false,0.0327271,0.00782471
gpu_array,4096,32,1,10,4,true,false,true,false,0.0353076,0.00771973
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0384448,0.00963623
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0327808,0.00690186
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0354517,0.00810791
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0468311,0.0185107
gpu_array,4096,64,1,2,2,true,false,true,false,0.0434888,0.0149243
gpu_array,4096,64,1,2,4,true,false,true,false,0.0408545,0.013999
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0434082,0.0185059
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0379761,0.0103882
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0393408,0.0127295
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0353516,0.00922852
gpu_array,4096,64,1,10,2,true,false,true,false,0.0357397,0.00790771
gpu_array,4096,64,1,10,4,true,false,true,false,0.0344165,0.00780518
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0380591,0.00973877
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0344995,0.00715576
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0350952,0.00750732
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0298535,0.0069043
0.0069043
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0309302,0.00920166
0.00920166
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0291284,0.00715576
0.00715576
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0302686,0.00927246
0.00927246
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0327783,0.0103174
0.0103174
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0385034,0.0162866
0.0162866
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00690186
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.137778 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.390854,0.102769
gpu_array,4096,8,1,20,2,true,false,true,false,0.362644,0.0772437
gpu_array,4096,8,1,20,4,true,false,true,false,0.365549,0.0764868
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.400017,0.110466
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.351973,0.062666
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.355964,0.0725171
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.366335,0.0792261
gpu_array,4096,8,1,50,2,true,false,true,false,0.351738,0.0575488
gpu_array,4096,8,1,50,4,true,false,true,false,0.353005,0.0673608
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.379827,0.0846606
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.35835,0.0714844
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.36217,0.0738403
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.354802,0.0667163
0.0667163
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.367051,0.080918
0.080918
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,true,false,true,true,0.368772,0.0809302
0.0809302
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,false,false,true,true,0.558547,0.272659
0.272659
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0575488
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.588797 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.388174,0.103018
gpu_array,4096,8,1,20,2,true,false,true,false,0.371094,0.0820312
gpu_array,4096,8,1,20,4,true,false,true,false,0.366167,0.0763721
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.400808,0.110525
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.34781,0.0624097
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.360127,0.0725293
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.373137,0.0791919
gpu_array,4096,8,1,50,2,true,false,true,false,0.348777,0.0575171
gpu_array,4096,8,1,50,4,true,false,true,false,0.353943,0.0670776
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.37626,0.0845117
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.355195,0.0715039
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.368628,0.0739502
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.348491,0.0665088
0.0665088
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.363645,0.080686
0.080686
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,true,false,true,true,0.364565,0.080874
0.080874
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,false,false,true,true,0.555911,0.272219
0.272219
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0575171
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.590203 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.161172,0.120156
gpu_array,4096,32,1,2,2,true,false,true,false,0.122126,0.083064
gpu_array,4096,32,1,2,4,true,false,true,false,0.105496,0.0639917
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.211816,0.125391
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.125476,0.0829956
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.112202,0.0733838
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.131064,0.0775977
gpu_array,4096,32,1,10,2,true,false,true,false,0.130398,0.0752222
gpu_array,4096,32,1,10,4,true,false,true,false,0.117319,0.0665381
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.180266,0.0752856
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.127341,0.0733862
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.122354,0.0679102
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.173079,0.133284
gpu_array,4096,64,1,2,2,true,false,true,false,0.121929,0.0826221
gpu_array,4096,64,1,2,4,true,false,true,false,0.10625,0.0652344
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.217466,0.127866
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.125442,0.0832056
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.115623,0.0738745
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.133135,0.0786914
gpu_array,4096,64,1,10,2,true,false,true,false,0.127197,0.0751953
gpu_array,4096,64,1,10,4,true,false,true,false,0.116445,0.0629785
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.179663,0.0766357
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.126819,0.0755493
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.116633,0.0658521
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0810034,0.0409644
0.0409644
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.101389,0.0630591
0.0630591
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.115393,0.0785278
0.0785278
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.120239,0.0836182
0.0836182
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.114604,0.0782275
0.0782275
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.120544,0.0839233
0.0839233
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0409644
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.988869 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.160415,0.120132
gpu_array,4096,32,1,2,2,true,false,true,false,0.120884,0.0764502
gpu_array,4096,32,1,2,4,true,false,true,false,0.0985083,0.0592017
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.214541,0.12543
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.122747,0.0829517
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.113704,0.0731763
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.130237,0.0775024
gpu_array,4096,32,1,10,2,true,false,true,false,0.128574,0.0751074
gpu_array,4096,32,1,10,4,true,false,true,false,0.120144,0.0664331
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.177805,0.0752661
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.122915,0.0733545
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.120798,0.0678198
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.171179,0.133337
gpu_array,4096,64,1,2,2,true,false,true,false,0.124265,0.0827612
gpu_array,4096,64,1,2,4,true,false,true,false,0.105588,0.0653052
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.21116,0.127908
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.127454,0.0832642
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.115337,0.073833
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.129282,0.0787451
gpu_array,4096,64,1,10,2,true,false,true,false,0.129314,0.0753589
gpu_array,4096,64,1,10,4,true,false,true,false,0.116472,0.0630054
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.181318,0.076582
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.127681,0.0754346
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.116333,0.0657959
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.116182,0.078584
0.078584
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.121841,0.0837549
0.0837549
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0781738,0.0410645
0.0410645
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.101479,0.0631494
0.0631494
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.116594,0.0782642
0.0782642
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.124043,0.0840039
0.0840039
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0410645
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.984259 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.765696,0.0396216
gpu_array,4096,8,1,20,2,false,false,true,false,0.762825,0.0399243
gpu_array,4096,8,1,20,4,false,false,true,false,0.769348,0.0449829
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.775481,0.0435474
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.780269,0.0434521
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.774744,0.0486694
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.767888,0.0393726
gpu_array,4096,8,1,50,2,false,false,true,false,0.772097,0.0401636
gpu_array,4096,8,1,50,4,false,false,true,false,0.761218,0.0400269
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.766797,0.0402344
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.770881,0.0438306
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.773198,0.0441943
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.765347,0.0351221
gpu_array,4096,32,1,20,2,false,false,true,false,0.76791,0.0345117
gpu_array,4096,32,1,20,4,false,false,true,false,0.761799,0.0357251
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.760295,0.0351978
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.768877,0.0347461
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.761904,0.0363184
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.757256,0.0377734
0.0377734
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.746179,0.0347534
0.0347534
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.760095,0.0411011
0.0411011
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0345117
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.341307 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.767307,0.0397681
gpu_array,4096,8,1,20,2,false,false,true,false,0.768562,0.0398022
gpu_array,4096,8,1,20,4,false,false,true,false,0.76425,0.0450122
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.763057,0.0408887
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.768347,0.0408081
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.77592,0.0486255
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.761748,0.0393359
gpu_array,4096,8,1,50,2,false,false,true,false,0.760701,0.0402417
gpu_array,4096,8,1,50,4,false,false,true,false,0.76989,0.0401538
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.776792,0.0404639
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.774275,0.0440503
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.770581,0.0440186
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.770049,0.0351855
gpu_array,4096,32,1,20,2,false,false,true,false,0.755081,0.0346216
gpu_array,4096,32,1,20,4,false,false,true,false,0.7645,0.0357397
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.766331,0.0353735
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.765552,0.0348389
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.76438,0.0363525
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.765632,0.0378491
0.0378491
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.758516,0.0348828
0.0348828
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.770479,0.0412305
0.0412305
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0346216
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.339658 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0551587,0.0187817
gpu_array,4096,32,1,2,2,true,false,true,false,0.053208,0.0151221
gpu_array,4096,32,1,2,4,true,false,true,false,0.0500635,0.0141748
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0544873,0.0188428
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0457739,0.0106177
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0483008,0.0129004
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0471338,0.00953613
gpu_array,4096,32,1,10,2,true,false,true,false,0.0442969,0.0084082
gpu_array,4096,32,1,10,4,true,false,true,false,0.0439844,0.00833984
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.045,0.0100879
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0436768,0.00852051
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0437183,0.00856201
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0532153,0.0187915
gpu_array,4096,64,1,2,2,true,false,true,false,0.0531885,0.0151025
gpu_array,4096,64,1,2,4,true,false,true,false,0.0491235,0.0142114
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0551733,0.0187964
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0436035,0.0106445
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0485498,0.0129053
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0427832,0.00958008
gpu_array,4096,64,1,10,2,true,false,true,false,0.0454614,0.00835205
gpu_array,4096,64,1,10,4,true,false,true,false,0.0432715,0.00835938
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0458423,0.0101978
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0434277,0.00753906
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0411719,0.00845703
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0366064,0.00755371
0.00755371
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0406787,0.00967285
0.00967285
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0365601,0.00848389
0.00848389
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0372803,0.00993652
0.00993652
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0395996,0.0105469
0.0105469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0459424,0.0168896
0.0168896
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00753906
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.143325 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0536499,0.0175171
gpu_array,4096,32,1,2,2,true,false,true,false,0.0494189,0.0140186
gpu_array,4096,32,1,2,4,true,false,true,false,0.0481396,0.0132275
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0529126,0.0175122
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0464795,0.0098584
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0456885,0.0119971
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.045332,0.00944336
gpu_array,4096,32,1,10,2,true,false,true,false,0.0426147,0.00843506
gpu_array,4096,32,1,10,4,true,false,true,false,0.0442212,0.00833252
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0464941,0.0101172
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0425195,0.00858398
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0437378,0.00858154
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0530176,0.0188379
gpu_array,4096,64,1,2,2,true,false,true,false,0.0529883,0.0151465
gpu_array,4096,64,1,2,4,true,false,true,false,0.0476562,0.014209
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0551929,0.0188159
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0469604,0.0105835
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0460962,0.0128931
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0462646,0.00964355
gpu_array,4096,64,1,10,2,true,false,true,false,0.0421216,0.00843018
gpu_array,4096,64,1,10,4,true,false,true,false,0.0440503,0.00840576
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0461328,0.0102441
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0457593,0.00767334
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0433911,0.008479
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0351123,0.00752441
0.00752441
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0377148,0.00963867
0.00963867
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.0366333,0.00855713
0.00855713
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.0383496,0.00905273
0.00905273
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0410571,0.0105396
0.0105396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0464453,0.0169043
0.0169043
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00752441
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.140576 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.72324,4.6981
gpu_array,4096,32,1,2,2,true,false,true,false,3.31135,3.28571
gpu_array,4096,32,1,2,4,true,false,true,false,3.2194,3.19523
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.47904,4.45634
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.3627,3.33804
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.67553,2.65136
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.66856,3.62364
gpu_array,4096,32,1,10,2,true,false,true,false,2.92538,2.87924
gpu_array,4096,32,1,10,4,true,false,true,false,2.89818,2.84325
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.26561,3.22337
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.91558,2.86162
gpu_sparse,4096,32,1,10,4,true,false,true,false,3.03563,2.99291
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,3.99437,3.96776
gpu_array,4096,64,1,2,2,true,false,true,false,3.07953,3.05292
gpu_array,4096,64,1,2,4,true,false,true,false,3.06348,3.04053
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.89691,3.87421
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.10267,3.07996
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.66432,2.64039
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.65347,3.6105
gpu_array,4096,64,1,10,2,true,false,true,false,2.893,2.84832
gpu_array,4096,64,1,10,4,true,false,true,false,3.11419,3.06463
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.87115,2.83062
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.82026,2.77827
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.74288,2.70016
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,2.0938,2.07158
2.07158
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,1.92508,1.90237
1.90237
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,2.16305,2.1401
2.1401
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,2.00377,1.98106
1.98106
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.90237
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 132 seconds of which 8.76874 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.78086,4.754
gpu_array,4096,32,1,2,2,true,false,true,false,3.32484,3.29701
gpu_array,4096,32,1,2,4,true,false,true,false,3.26539,3.23878
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.64855,4.62438
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.40139,3.37746
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.66675,2.64258
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.65162,3.59938
gpu_array,4096,32,1,10,2,true,false,true,false,2.89924,2.84528
gpu_array,4096,32,1,10,4,true,false,true,false,2.82212,2.77549
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.13331,3.09229
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.90847,2.86647
gpu_sparse,4096,32,1,10,4,true,false,true,false,3.02264,2.97967
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,3.98814,3.96373
gpu_array,4096,64,1,2,2,true,false,true,false,3.12083,3.09568
gpu_array,4096,64,1,2,4,true,false,true,false,2.98081,2.95664
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.75449,3.73179
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.12373,3.0981
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.67539,2.65073
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.66508,3.62138
gpu_array,4096,64,1,10,2,true,false,true,false,2.8211,2.76617
gpu_array,4096,64,1,10,4,true,false,true,false,3.06009,3.01712
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.73515,2.69462
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.91446,2.87101
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.69832,2.65389
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,2.16167,2.13896
2.13896
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,2.00333,1.97843
1.97843
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,2.0951,2.07068
2.07068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,1.97478,1.95207
1.95207
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.95207
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 133 seconds of which 8.74023 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.112747,0.0170435
gpu_array,4096,32,1,2,2,true,false,true,false,0.103689,0.0136011
gpu_array,4096,32,1,2,4,true,false,true,false,0.110828,0.0131714
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.1154,0.0170117
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.109434,0.0105566
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.113757,0.0117065
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.110417,0.00885498
gpu_array,4096,32,1,10,2,true,false,true,false,0.100168,0.00812744
gpu_array,4096,32,1,10,4,true,false,true,false,0.110286,0.00799072
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.110962,0.00915527
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.111772,0.00850098
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.104973,0.00780518
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.111707,0.01698
gpu_array,4096,64,1,2,2,true,false,true,false,0.112307,0.0136743
gpu_array,4096,64,1,2,4,true,false,true,false,0.111243,0.0130981
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.113665,0.0167407
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.109026,0.0103931
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.11387,0.0115747
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.108989,0.0088916
gpu_array,4096,64,1,10,2,true,false,true,false,0.108394,0.0082959
gpu_array,4096,64,1,10,4,true,false,true,false,0.110369,0.00807373
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.104229,0.00925781
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.108682,0.00907227
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.10231,0.00782715
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.108345,0.00702637
0.00702637
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.114805,0.0103125
0.0103125
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,true,0.110178,0.00715088
0.00715088
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,true,0.102095,0.0100537
0.0100537
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,true,0.102698,0.0101685
0.0101685
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,true,0.115269,0.0161475
0.0161475
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00702637
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.134457 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.11572,0.0158667
gpu_array,4096,32,1,2,2,true,false,true,false,0.108784,0.0125928
gpu_array,4096,32,1,2,4,true,false,true,false,0.105662,0.0121558
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.111667,0.0157202
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.107437,0.00978027
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.111238,0.010896
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.100352,0.00879883
gpu_array,4096,32,1,10,2,true,false,true,false,0.103064,0.0083374
gpu_array,4096,32,1,10,4,true,false,true,false,0.107092,0.00797119
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.106868,0.00921143
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.105103,0.00842285
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.108376,0.00779053
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.110923,0.0169287
gpu_array,4096,64,1,2,2,true,false,true,false,0.109985,0.0135498
gpu_array,4096,64,1,2,4,true,false,true,false,0.110991,0.0130908
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.110972,0.0167334
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.109771,0.0104053
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.108049,0.0116138
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.108794,0.00894043
gpu_array,4096,64,1,10,2,true,false,true,false,0.103044,0.00831787
gpu_array,4096,64,1,10,4,true,false,true,false,0.104902,0.00797852
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.110015,0.00918457
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.10957,0.00898437
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.109976,0.00768066
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,true,0.108159,0.00708496
0.00708496
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,true,0.105828,0.0101245
0.0101245
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.108574,0.00701172
0.00701172
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.112412,0.0103613
0.0103613
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.105659,0.0102002
0.0102002
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.117891,0.0173047
0.0173047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00701172
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.132317 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0755725,0.0633655
gpu_array,8192,32,1,2,2,true,false,true,false,0.0549915,0.0427844
gpu_array,8192,32,1,2,4,true,false,true,false,0.0481055,0.0369971
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0878845,0.0655457
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.056897,0.0451782
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.05625,0.0452637
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0578687,0.0472485
gpu_array,8192,32,1,10,2,true,false,true,false,0.0510864,0.0394897
gpu_array,8192,32,1,10,4,true,false,true,false,0.0473572,0.036615
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0713367,0.0489978
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0532153,0.0417407
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0527563,0.0411597
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0812793,0.0694385
gpu_array,8192,64,1,2,2,true,false,true,false,0.0598987,0.0476917
gpu_array,8192,64,1,2,4,true,false,true,false,0.0534558,0.0425916
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0955823,0.0734875
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0600024,0.0481616
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0602905,0.0479614
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0592725,0.0473096
gpu_array,8192,64,1,10,2,true,false,true,false,0.0521338,0.0395605
gpu_array,8192,64,1,10,4,true,false,true,false,0.0512231,0.0397485
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0711938,0.0492212
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0550403,0.0442981
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0561597,0.0444409
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0474268,0.0370508
0.0370508
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0483887,0.0380127
0.0380127
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0542688,0.0438928
0.0438928
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0567053,0.0458411
0.0458411
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0497107,0.0393347
0.0393347
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0514746,0.0406104
0.0406104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.036615
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 1.14118 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0742944,0.063186
gpu_array,8192,32,1,2,2,true,false,true,false,0.0543848,0.0427881
gpu_array,8192,32,1,2,4,true,false,true,false,0.0487451,0.0370264
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0879004,0.0655615
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0575159,0.0451868
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0570764,0.0452356
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0590637,0.0472229
gpu_array,8192,32,1,10,2,true,false,true,false,0.0510718,0.0394751
gpu_array,8192,32,1,10,4,true,false,true,false,0.0484045,0.0365637
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0717847,0.0489575
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0535144,0.0417957
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0534106,0.0412036
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.081394,0.0693091
gpu_array,8192,64,1,2,2,true,false,true,false,0.0599744,0.0475232
gpu_array,8192,64,1,2,4,true,false,true,false,0.0544775,0.0425146
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.097688,0.0732739
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0605627,0.0482336
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0594299,0.0478333
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0595105,0.0473035
gpu_array,8192,64,1,10,2,true,false,true,false,0.0508276,0.0395972
gpu_array,8192,64,1,10,4,true,false,true,false,0.051842,0.0397571
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0717737,0.0491907
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.056012,0.0442932
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0559155,0.0444409
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0482288,0.0371204
0.0371204
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0487341,0.0379919
0.0379919
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.054834,0.0438477
0.0438477
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0565076,0.0457654
0.0457654
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.050177,0.0393127
0.0393127
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0522217,0.040625
0.040625
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0365637
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 1.14044 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0284448,0.00952393
gpu_array,8192,32,1,2,2,true,false,true,false,0.0268848,0.00759766
gpu_array,8192,32,1,2,4,true,false,true,false,0.0256091,0.00717651
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.02995,0.00968628
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.024115,0.00604858
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0257056,0.00678467
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0387659,0.00653931
gpu_array,8192,32,1,10,2,true,false,true,false,0.0377222,0.00549561
gpu_array,8192,32,1,10,4,true,false,true,false,0.0381909,0.005354
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0393811,0.0069104
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0400391,0.00585938
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.037821,0.00583862
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0288062,0.00951904
gpu_array,8192,64,1,2,2,true,false,true,false,0.0279504,0.0075647
gpu_array,8192,64,1,2,4,true,false,true,false,0.025238,0.00717163
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0289111,0.00974609
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0248523,0.00617554
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0246399,0.0069397
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0415015,0.00658936
gpu_array,8192,64,1,10,2,true,false,true,false,0.0367773,0.00552734
gpu_array,8192,64,1,10,4,true,false,true,false,0.036156,0.00539429
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0392407,0.00689209
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0386951,0.00598022
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0400049,0.00606934
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0194958,0.00533569
0.00533569
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0200769,0.00579468
0.00579468
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0198022,0.00539795
0.00539795
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0202686,0.00574219
0.00574219
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.0221509,0.00750244
0.00750244
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.0219763,0.00757202
0.00757202
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00533569
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.166895 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0267578,0.00881348
gpu_array,8192,32,1,2,2,true,false,true,false,0.0248474,0.00702515
gpu_array,8192,32,1,2,4,true,false,true,false,0.0253186,0.00664185
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0277661,0.00896729
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0243213,0.00564453
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0249878,0.00631104
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0362256,0.00607422
gpu_array,8192,32,1,10,2,true,false,true,false,0.036571,0.00544312
gpu_array,8192,32,1,10,4,true,false,true,false,0.0393677,0.00531006
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0408984,0.00684082
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0370337,0.00578369
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0378943,0.00578979
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0272888,0.00946655
gpu_array,8192,64,1,2,2,true,false,true,false,0.0262207,0.00754395
gpu_array,8192,64,1,2,4,true,false,true,false,0.0257019,0.00714722
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0284082,0.00973145
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0252173,0.00617432
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0254956,0.00694092
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0402148,0.00652344
gpu_array,8192,64,1,10,2,true,false,true,false,0.0400293,0.0054834
gpu_array,8192,64,1,10,4,true,false,true,false,0.0368518,0.00535767
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0414185,0.00687256
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.038335,0.00598633
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0381787,0.00607422
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0194861,0.00532593
0.00532593
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0203198,0.00579346
0.00579346
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0199158,0.0053894
0.0053894
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.02125,0.00574707
0.00574707
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0220081,0.00748169
0.00748169
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0223291,0.00755859
0.00755859
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00531006
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.16322 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.371101,0.104622
gpu_array,8192,8,1,20,2,true,false,true,false,0.339922,0.0729541
gpu_array,8192,8,1,20,4,true,false,true,false,0.335441,0.0681067
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.377717,0.109895
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.326444,0.0603308
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.334114,0.0686108
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.398789,0.0764014
gpu_array,8192,8,1,50,2,true,false,true,false,0.379188,0.0548474
gpu_array,8192,8,1,50,4,true,false,true,false,0.341471,0.06547
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.402905,0.0806396
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.394905,0.0742261
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.348073,0.0719495
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.33278,0.0683752
0.0683752
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.341354,0.0765833
0.0765833
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.342937,0.0767017
0.0767017
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.563481,0.298467
0.298467
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0548474
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 1.16997 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.373213,0.10417
gpu_array,8192,8,1,20,2,true,false,true,false,0.342203,0.07255
gpu_array,8192,8,1,20,4,true,false,true,false,0.335699,0.0677551
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.379813,0.109794
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.325829,0.0559314
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.336005,0.0686707
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.39921,0.0765784
gpu_array,8192,8,1,50,2,true,false,true,false,0.335079,0.0548059
gpu_array,8192,8,1,50,4,true,false,true,false,0.387456,0.0654346
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.356869,0.0806238
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.351233,0.0742554
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.350258,0.0719373
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.333723,0.0683423
0.0683423
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.343452,0.0766064
0.0766064
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.336074,0.0766748
0.0766748
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.55584,0.287163
0.287163
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0548059
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 17 seconds of which 1.15613 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.118708,0.0767163
gpu_array,8192,32,1,2,2,true,false,true,false,0.0992712,0.0563025
gpu_array,8192,32,1,2,4,true,false,true,false,0.0952881,0.0543945
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.126753,0.0798779
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.105951,0.0631042
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.105898,0.0645166
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.116462,0.0609204
gpu_array,8192,32,1,10,2,true,false,true,false,0.109771,0.0589893
gpu_array,8192,32,1,10,4,true,false,true,false,0.114163,0.0633813
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.114283,0.0587415
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.116559,0.0605286
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.118097,0.0632874
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.127714,0.0864539
gpu_array,8192,64,1,2,2,true,false,true,false,0.104343,0.062229
gpu_array,8192,64,1,2,4,true,false,true,false,0.0994458,0.0585522
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.131359,0.083385
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.106475,0.0650928
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.104988,0.0645825
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.111609,0.0603394
gpu_array,8192,64,1,10,2,true,false,true,false,0.10803,0.057981
gpu_array,8192,64,1,10,4,true,false,true,false,0.120121,0.0616492
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.1196,0.0584424
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.112286,0.0610168
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.119619,0.0629785
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.114891,0.0737537
0.0737537
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.13981,0.0978174
0.0978174
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0742017,0.0336743
0.0336743
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0996631,0.0576709
0.0576709
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.116052,0.0741821
0.0741821
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.140376,0.0991162
0.0991162
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0336743
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.62175 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.11861,0.0764954
gpu_array,8192,32,1,2,2,true,false,true,false,0.0980383,0.0561682
gpu_array,8192,32,1,2,4,true,false,true,false,0.0963049,0.0532141
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.127117,0.0801196
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.105282,0.0631677
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.106342,0.0644714
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.11072,0.0609155
gpu_array,8192,32,1,10,2,true,false,true,false,0.110129,0.0589819
gpu_array,8192,32,1,10,4,true,false,true,false,0.112953,0.0633923
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.120258,0.0587341
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.110139,0.0605786
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.112919,0.0633582
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.129093,0.0867346
gpu_array,8192,64,1,2,2,true,false,true,false,0.103706,0.0624463
gpu_array,8192,64,1,2,4,true,false,true,false,0.100831,0.0584729
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.12968,0.0840259
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.108386,0.0652954
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.10551,0.0646167
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.109601,0.0601624
gpu_array,8192,64,1,10,2,true,false,true,false,0.113563,0.0577771
gpu_array,8192,64,1,10,4,true,false,true,false,0.111177,0.0617383
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.114645,0.0583704
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.111587,0.0609277
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.113931,0.0630273
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.113361,0.0734436
0.0734436
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.138872,0.0978564
0.0978564
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0744055,0.033634
0.033634
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0994275,0.0575574
0.0575574
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.114324,0.0740405
0.0740405
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.14002,0.0990039
0.0990039
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.033634
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.62097 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.725183,0.0440308
gpu_array,8192,8,1,20,2,false,false,true,false,0.7277,0.0459375
gpu_array,8192,8,1,20,4,false,false,true,false,0.845397,0.0474231
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.845959,0.0467651
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.849272,0.0492236
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.8509,0.0499963
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.837001,0.0391492
gpu_array,8192,8,1,50,2,false,false,true,false,0.720392,0.0411926
gpu_array,8192,8,1,50,4,false,false,true,false,0.842629,0.0411157
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.839485,0.0391919
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.725038,0.0435193
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.72373,0.0435547
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.848374,0.0425879
gpu_array,8192,32,1,20,2,false,false,true,false,0.724207,0.0425659
gpu_array,8192,32,1,20,4,false,false,true,false,0.840138,0.0396008
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.84683,0.0429968
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.843807,0.0424158
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.719341,0.0381885
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.834269,0.0398352
0.0398352
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.710383,0.0330151
0.0330151
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.844021,0.0481226
0.0481226
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0330151
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.737631 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.72442,0.0440002
gpu_array,8192,8,1,20,2,false,false,true,false,0.841946,0.0460474
gpu_array,8192,8,1,20,4,false,false,true,false,0.851544,0.047467
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.844622,0.0468921
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.726908,0.0473425
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.847463,0.049978
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.835409,0.0391443
gpu_array,8192,8,1,50,2,false,false,true,false,0.722156,0.0411255
gpu_array,8192,8,1,50,4,false,false,true,false,0.838131,0.041134
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.836443,0.0392017
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.725111,0.0435925
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.841747,0.0435291
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.725635,0.0426514
gpu_array,8192,32,1,20,2,false,false,true,false,0.846482,0.0425269
gpu_array,8192,32,1,20,4,false,false,true,false,0.720887,0.039613
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.844835,0.0429553
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.722731,0.0424329
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.838508,0.0382153
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.834003,0.0398132
0.0398132
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.827531,0.0329749
0.0329749
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.723309,0.0481384
0.0481384
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0329749
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.736277 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0534668,0.0090332
gpu_array,8192,32,1,2,2,true,false,true,false,0.0526746,0.00775269
gpu_array,8192,32,1,2,4,true,false,true,false,0.0508337,0.00725464
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0570776,0.0099585
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0529797,0.00683716
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0511951,0.00712769
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0536926,0.00681763
gpu_array,8192,32,1,10,2,true,false,true,false,0.0528113,0.00593628
gpu_array,8192,32,1,10,4,true,false,true,false,0.0482959,0.00581543
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0549719,0.00724243
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0538403,0.00611084
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0513452,0.00630127
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0547156,0.0097937
gpu_array,8192,64,1,2,2,true,false,true,false,0.0518713,0.00780396
gpu_array,8192,64,1,2,4,true,false,true,false,0.0517932,0.00735962
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0564502,0.0101855
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0528906,0.00674805
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0531763,0.0073999
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0543774,0.00689209
gpu_array,8192,64,1,10,2,true,false,true,false,0.050719,0.00591919
gpu_array,8192,64,1,10,4,true,false,true,false,0.0500269,0.0058374
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0526648,0.00725464
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0539844,0.00637695
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0513904,0.00646851
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0460779,0.00579468
0.00579468
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0477625,0.0068689
0.0068689
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0462354,0.00583008
0.00583008
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0491956,0.0070813
0.0070813
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.046947,0.00764038
0.00764038
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0502368,0.00800049
0.00800049
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00579468
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.176491 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0530054,0.00906006
gpu_array,8192,32,1,2,2,true,false,true,false,0.0540991,0.00722412
gpu_array,8192,32,1,2,4,true,false,true,false,0.0495117,0.00678711
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0548901,0.00923584
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.049856,0.00639893
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0519287,0.00664062
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0539417,0.00682251
gpu_array,8192,32,1,10,2,true,false,true,false,0.0500122,0.00594482
gpu_array,8192,32,1,10,4,true,false,true,false,0.0486853,0.00583862
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0552185,0.00724487
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0505762,0.00614258
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0500488,0.00622559
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0549377,0.00977173
gpu_array,8192,64,1,2,2,true,false,true,false,0.0560242,0.0078064
gpu_array,8192,64,1,2,4,true,false,true,false,0.0575623,0.00739136
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0574866,0.0101233
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0517419,0.006698
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0513831,0.00731567
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0509473,0.00687988
gpu_array,8192,64,1,10,2,true,false,true,false,0.0475171,0.00589111
gpu_array,8192,64,1,10,4,true,false,true,false,0.05005,0.0058606
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0529224,0.00726807
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0516492,0.00636108
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0503821,0.00643677
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0475134,0.00576538
0.00576538
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0466028,0.00680786
0.00680786
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0495239,0.00582275
0.00582275
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0491492,0.00703491
0.00703491
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0481274,0.00772217
0.00772217
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0473657,0.00805908
0.00805908
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00576538
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.174147 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.40953,3.38255
gpu_array,8192,32,1,2,2,true,false,true,false,2.62659,2.59913
gpu_array,8192,32,1,2,4,true,false,true,false,2.56891,2.54071
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.27952,3.25937
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.68536,2.66437
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.5766,2.55536
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.6989,2.67192
gpu_array,8192,32,1,10,2,true,false,true,false,2.77475,2.74972
gpu_array,8192,32,1,10,4,true,false,true,false,2.79313,2.77116
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.57271,2.55037
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.75878,2.73681
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.72351,2.70068
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.05472,3.03396
gpu_array,8192,64,1,2,2,true,false,true,false,2.64283,2.62208
gpu_array,8192,64,1,2,4,true,false,true,false,2.64753,2.62581
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,3.08725,3.06687
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.67661,2.65537
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.61905,2.59793
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.77309,2.74977
gpu_array,8192,64,1,10,2,true,false,true,false,2.79604,2.77284
gpu_array,8192,64,1,10,4,true,false,true,false,3.05299,3.03102
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.72525,2.70328
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.78058,2.75873
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.62804,2.60558
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,2.24176,2.22833
2.22833
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,2.34631,2.33264
2.33264
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,64,1,2,2,true,false,true,true,2.39736,2.38369
2.38369
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,64,1,2,2,false,false,true,true,2.13477,2.12085
2.12085
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,10,-1,true,false,false,true,1.96758,1.95281
1.95281
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,10,-1,false,false,false,true,2.0763,2.06178
2.06178
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.95281
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 129 seconds of which 16.2786 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.35373,3.33225
gpu_array,8192,32,1,2,2,true,false,true,false,2.55959,2.53811
gpu_array,8192,32,1,2,4,true,false,true,false,2.56571,2.54422
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.28785,3.266
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.67741,2.6569
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.55949,2.53922
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.66901,2.64729
gpu_array,8192,32,1,10,2,true,false,true,false,2.74052,2.71708
gpu_array,8192,32,1,10,4,true,false,true,false,2.81095,2.78849
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.5627,2.54097
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.8068,2.78409
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.68125,2.65977
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.05691,3.03616
gpu_array,8192,64,1,2,2,true,false,true,false,2.6773,2.65655
gpu_array,8192,64,1,2,4,true,false,true,false,2.67414,2.6518
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,3.02674,3.00696
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.67956,2.65917
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.56011,2.53936
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.73604,2.71492
gpu_array,8192,64,1,10,2,true,false,true,false,2.78183,2.75998
gpu_array,8192,64,1,10,4,true,false,true,false,3.05591,3.02784
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.65441,2.63146
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.83781,2.81657
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.62157,2.59984
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,2,2,true,false,true,true,2.48621,2.47266
2.47266
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,2,2,false,false,true,true,2.20147,2.18792
2.18792
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,10,-1,true,false,false,true,1.99625,1.98234
1.98234
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,10,-1,false,false,false,true,2.06229,2.0491
2.0491
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,2.46528,2.45149
2.45149
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,2.08553,2.07222
2.07222
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.98234
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 128 seconds of which 16.2469 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0785071,0.0150305
gpu_array,8192,32,1,2,2,true,false,true,false,0.073197,0.0116736
gpu_array,8192,32,1,2,4,true,false,true,false,0.0741309,0.0111426
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0757947,0.0150037
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0720471,0.00905884
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.07526,0.0100745
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0674158,0.00625854
gpu_array,8192,32,1,10,2,true,false,true,false,0.0697693,0.00568237
gpu_array,8192,32,1,10,4,true,false,true,false,0.0719019,0.00549561
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0691113,0.00636719
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0677881,0.00589844
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0671265,0.0057251
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0805103,0.0149585
gpu_array,8192,64,1,2,2,true,false,true,false,0.0773071,0.0116333
gpu_array,8192,64,1,2,4,true,false,true,false,0.0721985,0.0111633
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0747339,0.0150415
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0717017,0.00907959
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0726929,0.0100708
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0686853,0.00630737
gpu_array,8192,64,1,10,2,true,false,true,false,0.0674683,0.00570068
gpu_array,8192,64,1,10,4,true,false,true,false,0.0693201,0.00547729
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0692175,0.00647339
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0697998,0.00620117
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0714319,0.0060022
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0672876,0.00527588
0.00527588
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0716382,0.00791748
0.00791748
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0621191,0.00523438
0.00523438
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0710278,0.0074292
0.0074292
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0670105,0.00975952
0.00975952
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0773901,0.0155005
0.0155005
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00523438
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.218429 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0763477,0.0139697
gpu_array,8192,32,1,2,2,true,false,true,false,0.0769971,0.010835
gpu_array,8192,32,1,2,4,true,false,true,false,0.0734229,0.0103125
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0774963,0.0138977
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0723547,0.00838989
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0723315,0.00922119
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0680969,0.00620728
gpu_array,8192,32,1,10,2,true,false,true,false,0.072135,0.00560669
gpu_array,8192,32,1,10,4,true,false,true,false,0.0672278,0.00546021
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.067937,0.00641357
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0698975,0.00593262
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0680505,0.00579468
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0761353,0.014978
gpu_array,8192,64,1,2,2,true,false,true,false,0.0754883,0.0116455
gpu_array,8192,64,1,2,4,true,false,true,false,0.0738464,0.0111023
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0753906,0.0149658
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0719946,0.00900635
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0723291,0.0100732
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0674341,0.00627686
gpu_array,8192,64,1,10,2,true,false,true,false,0.0672632,0.00573975
gpu_array,8192,64,1,10,4,true,false,true,false,0.0673352,0.00544556
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0691125,0.00649048
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0702905,0.00620361
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0694714,0.00599487
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0691565,0.00519165
0.00519165
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0666809,0.00784302
0.00784302
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0646997,0.00525146
0.00525146
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.069259,0.00749146
0.00749146
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0702332,0.00980835
0.00980835
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0779138,0.0155359
0.0155359
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00519165
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.213881 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
