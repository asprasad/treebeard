abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.411691,0.250419
gpu_array,256,8,1,20,2,true,false,true,false,0.286451,0.167589
gpu_array,256,8,1,20,4,true,false,true,false,0.283477,0.165731
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.38707,0.265419
gpu_sparse,256,8,1,20,2,true,false,true,false,0.261002,0.144372
gpu_sparse,256,8,1,20,4,true,false,true,false,0.298013,0.174129
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.469473,0.326616
gpu_reorg,256,8,1,20,2,true,false,true,false,0.308133,0.172531
gpu_reorg,256,8,1,20,4,true,false,true,false,0.276816,0.135633
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.279336,0.134247
gpu_array,256,8,1,50,2,true,false,true,false,0.234632,0.105167
gpu_array,256,8,1,50,4,true,false,true,false,0.241378,0.105218
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.268094,0.134724
gpu_sparse,256,8,1,50,2,true,false,true,false,0.245993,0.113739
gpu_sparse,256,8,1,50,4,true,false,true,false,0.248013,0.118549
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.315639,0.17613
gpu_reorg,256,8,1,50,2,true,false,true,false,0.245608,0.111122
gpu_reorg,256,8,1,50,4,true,false,true,false,0.245622,0.106671
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.366783,0.250153
gpu_array,256,32,1,20,2,true,false,true,false,0.284255,0.159813
gpu_array,256,32,1,20,4,true,false,true,false,0.278117,0.154233
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.348206,0.231576
gpu_sparse,256,32,1,20,2,true,false,true,false,0.259791,0.139255
gpu_sparse,256,32,1,20,4,true,false,true,false,0.288039,0.170851
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.463638,0.318549
gpu_reorg,256,32,1,20,2,true,false,true,false,0.306155,0.171669
gpu_reorg,256,32,1,20,4,true,false,true,false,0.282394,0.152372
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.196046,0.0905776
0.0905776
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.222799,0.110075
0.110075
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.274475,0.168449
0.168449
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.285516,0.172793
0.172793
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.299768,0.184813
0.184813
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.296981,0.177003
0.177003
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0905776
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.284682 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.381055,0.249916
gpu_array,256,8,1,20,2,true,false,true,false,0.285622,0.167877
gpu_array,256,8,1,20,4,true,false,true,false,0.274693,0.156948
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.367235,0.247257
gpu_sparse,256,8,1,20,2,true,false,true,false,0.261016,0.134342
gpu_sparse,256,8,1,20,4,true,false,true,false,0.283705,0.162612
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.436864,0.302935
gpu_reorg,256,8,1,20,2,true,false,true,false,0.299819,0.160868
gpu_reorg,256,8,1,20,4,true,false,true,false,0.270929,0.12863
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.247921,0.125711
gpu_array,256,8,1,50,2,true,false,true,false,0.237656,0.0987054
gpu_array,256,8,1,50,4,true,false,true,false,0.236529,0.0986942
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.258711,0.134827
gpu_sparse,256,8,1,50,2,true,false,true,false,0.245396,0.1137
gpu_sparse,256,8,1,50,4,true,false,true,false,0.244009,0.117893
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.321961,0.176872
gpu_reorg,256,8,1,50,2,true,false,true,false,0.25185,0.110667
gpu_reorg,256,8,1,50,4,true,false,true,false,0.253211,0.106448
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.367932,0.250745
gpu_array,256,32,1,20,2,true,false,true,false,0.274459,0.159503
gpu_array,256,32,1,20,4,true,false,true,false,0.268633,0.154235
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.348973,0.231228
gpu_sparse,256,32,1,20,2,true,false,true,false,0.261825,0.139057
gpu_sparse,256,32,1,20,4,true,false,true,false,0.289102,0.170798
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.465251,0.319046
gpu_reorg,256,32,1,20,2,true,false,true,false,0.303672,0.171417
gpu_reorg,256,32,1,20,4,true,false,true,false,0.288435,0.152832
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.194743,0.0915067
0.0915067
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.208382,0.0995647
0.0995647
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.275455,0.168312
0.168312
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.279724,0.173139
0.173139
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.292475,0.184774
0.184774
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.285725,0.177467
0.177467
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0915067
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.278453 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.192087,0.0598326
gpu_array,256,8,1,20,2,true,false,true,false,0.183795,0.0532143
gpu_array,256,8,1,20,4,true,false,true,false,0.170619,0.0450614
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.191758,0.0583873
gpu_sparse,256,8,1,20,2,true,false,true,false,0.177408,0.0485017
gpu_sparse,256,8,1,20,4,true,false,true,false,0.176705,0.0455664
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.210748,0.0717969
gpu_reorg,256,8,1,20,2,true,false,true,false,0.199618,0.0550865
gpu_reorg,256,8,1,20,4,true,false,true,false,0.201897,0.0523438
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.188158,0.0503237
gpu_array,256,8,1,50,2,true,false,true,false,0.181549,0.0465039
gpu_array,256,8,1,50,4,true,false,true,false,0.184852,0.0464593
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.186842,0.0501228
gpu_sparse,256,8,1,50,2,true,false,true,false,0.18627,0.0478767
gpu_sparse,256,8,1,50,4,true,false,true,false,0.186434,0.0480413
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.219121,0.0584068
gpu_reorg,256,8,1,50,2,true,false,true,false,0.210918,0.0502037
gpu_reorg,256,8,1,50,4,true,false,true,false,0.208756,0.0519475
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.200036,0.0605273
gpu_array,256,32,1,20,2,true,false,true,false,0.191523,0.0542467
gpu_array,256,32,1,20,4,true,false,true,false,0.173834,0.0460435
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.200703,0.0595201
gpu_sparse,256,32,1,20,2,true,false,true,false,0.168058,0.0486384
gpu_sparse,256,32,1,20,4,true,false,true,false,0.17892,0.0477818
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.221004,0.0764732
gpu_reorg,256,32,1,20,2,true,false,true,false,0.208248,0.055346
gpu_reorg,256,32,1,20,4,true,false,true,false,0.191925,0.0507422
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.158348,0.045625
0.045625
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.154515,0.0468136
0.0468136
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.158666,0.044827
0.044827
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.156758,0.0468248
0.0468248
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.151063,0.0444782
0.0444782
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.155611,0.0440039
0.0440039
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0440039
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0876323 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.195059,0.0616881
gpu_array,256,8,1,20,2,true,false,true,false,0.185513,0.0554911
gpu_array,256,8,1,20,4,true,false,true,false,0.189116,0.0468164
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.191501,0.0614788
gpu_sparse,256,8,1,20,2,true,false,true,false,0.173521,0.0496373
gpu_sparse,256,8,1,20,4,true,false,true,false,0.174517,0.0472852
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.22495,0.0770703
gpu_reorg,256,8,1,20,2,true,false,true,false,0.216772,0.0571735
gpu_reorg,256,8,1,20,4,true,false,true,false,0.207949,0.0544894
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.192162,0.0509794
gpu_array,256,8,1,50,2,true,false,true,false,0.180184,0.0468136
gpu_array,256,8,1,50,4,true,false,true,false,0.17798,0.0468415
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.186755,0.0505943
gpu_sparse,256,8,1,50,2,true,false,true,false,0.177132,0.0482254
gpu_sparse,256,8,1,50,4,true,false,true,false,0.182776,0.0482896
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.21387,0.058736
gpu_reorg,256,8,1,50,2,true,false,true,false,0.20637,0.050678
gpu_reorg,256,8,1,50,4,true,false,true,false,0.201557,0.0508873
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.195402,0.0609152
gpu_array,256,32,1,20,2,true,false,true,false,0.193987,0.0544782
gpu_array,256,32,1,20,4,true,false,true,false,0.180876,0.0463895
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.199272,0.0603209
gpu_sparse,256,32,1,20,2,true,false,true,false,0.182503,0.0491323
gpu_sparse,256,32,1,20,4,true,false,true,false,0.184258,0.0480971
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.228792,0.0775642
gpu_reorg,256,32,1,20,2,true,false,true,false,0.211214,0.0566378
gpu_reorg,256,32,1,20,4,true,false,true,false,0.203809,0.0514648
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.151172,0.0451451
0.0451451
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.169336,0.0471261
0.0471261
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.15654,0.044933
0.044933
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.15978,0.0442662
0.0442662
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.152598,0.0460128
0.0460128
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.160014,0.0472907
0.0472907
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0442662
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 8 seconds of which 0.089239 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.788577,0.310898
gpu_array,256,8,1,20,2,true,false,true,false,0.729699,0.2576
gpu_array,256,8,1,20,4,true,false,true,false,0.70409,0.225854
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.825965,0.309224
gpu_sparse,256,8,1,20,2,true,false,true,false,0.749261,0.17002
gpu_sparse,256,8,1,20,4,true,false,true,false,0.69579,0.215321
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.21757,0.400047
gpu_reorg,256,8,1,20,2,true,false,true,false,1.03186,0.210988
gpu_reorg,256,8,1,20,4,true,false,true,false,1.0116,0.199096
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.651917,0.182609
gpu_array,256,8,1,50,2,true,false,true,false,0.625996,0.139947
gpu_array,256,8,1,50,4,true,false,true,false,0.60796,0.119121
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.753742,0.181755
gpu_sparse,256,8,1,50,2,true,false,true,false,0.59454,0.122441
gpu_sparse,256,8,1,50,4,true,false,true,false,0.601267,0.130843
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.03193,0.214411
gpu_reorg,256,8,1,50,2,true,false,true,false,0.963636,0.128256
gpu_reorg,256,8,1,50,4,true,false,true,false,0.947824,0.121931
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.564035,0.100307
0.100307
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.611557,0.141133
0.141133
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.70286,0.253083
0.253083
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.721044,0.269593
0.269593
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.100307
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.225509 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.79103,0.311119
gpu_array,256,8,1,20,2,true,false,true,false,0.74031,0.257609
gpu_array,256,8,1,20,4,true,false,true,false,0.698571,0.227589
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.817614,0.310918
gpu_sparse,256,8,1,20,2,true,false,true,false,0.645184,0.170296
gpu_sparse,256,8,1,20,4,true,false,true,false,0.705078,0.215123
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.21518,0.404911
gpu_reorg,256,8,1,20,2,true,false,true,false,1.01992,0.210767
gpu_reorg,256,8,1,20,4,true,false,true,false,1.00369,0.199001
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.655008,0.182352
gpu_array,256,8,1,50,2,true,false,true,false,0.627405,0.139682
gpu_array,256,8,1,50,4,true,false,true,false,0.587165,0.118973
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.671649,0.182252
gpu_sparse,256,8,1,50,2,true,false,true,false,0.609043,0.121878
gpu_sparse,256,8,1,50,4,true,false,true,false,0.598708,0.130516
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.04057,0.215232
gpu_reorg,256,8,1,50,2,true,false,true,false,0.948357,0.128602
gpu_reorg,256,8,1,50,4,true,false,true,false,1.08294,0.120887
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.556367,0.100452
0.100452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.607768,0.14125
0.14125
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.709662,0.254305
0.254305
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.734542,0.280859
0.280859
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.100452
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.226538 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.405513,0.25317
gpu_array,256,8,1,20,2,true,false,true,false,0.305432,0.160901
gpu_array,256,8,1,20,4,true,false,true,false,0.290089,0.138304
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.381509,0.241443
gpu_sparse,256,8,1,20,2,true,false,true,false,0.328465,0.17668
gpu_sparse,256,8,1,20,4,true,false,true,false,0.311102,0.167687
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.481331,0.331777
gpu_reorg,256,8,1,20,2,true,false,true,false,0.337999,0.189004
gpu_reorg,256,8,1,20,4,true,false,true,false,0.3274,0.177846
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.606258,0.176571
gpu_array,256,8,1,50,2,true,false,true,false,0.762902,0.165804
gpu_array,256,8,1,50,4,true,false,true,false,0.597567,0.172344
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.327508,0.181861
gpu_sparse,256,8,1,50,2,true,false,true,false,0.603878,0.178655
gpu_sparse,256,8,1,50,4,true,false,true,false,0.595444,0.172453
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.357455,0.206228
gpu_reorg,256,8,1,50,2,true,false,true,false,0.334096,0.176172
gpu_reorg,256,8,1,50,4,true,false,true,false,0.327985,0.167829
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.411099,0.26322
gpu_array,256,32,1,20,2,true,false,true,false,0.323376,0.168242
gpu_array,256,32,1,20,4,true,false,true,false,0.297506,0.155206
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.384554,0.233326
gpu_sparse,256,32,1,20,2,true,false,true,false,0.338781,0.189785
gpu_sparse,256,32,1,20,4,true,false,true,false,0.324581,0.185073
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.454157,0.291769
gpu_reorg,256,32,1,20,2,true,false,true,false,0.348836,0.201515
gpu_reorg,256,32,1,20,4,true,false,true,false,0.346013,0.200366
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.293267,0.157665
0.157665
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.307687,0.175991
0.175991
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.315815,0.1724
0.1724
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.358019,0.225206
0.225206
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.258948,0.117207
0.117207
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.281437,0.149741
0.149741
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.117207
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.323658 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.400098,0.253334
gpu_array,256,8,1,20,2,true,false,true,false,0.302478,0.160737
gpu_array,256,8,1,20,4,true,false,true,false,0.291239,0.138337
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.404275,0.260301
gpu_sparse,256,8,1,20,2,true,false,true,false,0.316094,0.172679
gpu_sparse,256,8,1,20,4,true,false,true,false,0.306961,0.164662
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.486133,0.32207
gpu_reorg,256,8,1,20,2,true,false,true,false,0.342229,0.188211
gpu_reorg,256,8,1,20,4,true,false,true,false,0.332095,0.176961
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.589378,0.175873
gpu_array,256,8,1,50,2,true,false,true,false,0.579657,0.166152
gpu_array,256,8,1,50,4,true,false,true,false,0.574944,0.171484
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.337115,0.180865
gpu_sparse,256,8,1,50,2,true,false,true,false,0.58673,0.178248
gpu_sparse,256,8,1,50,4,true,false,true,false,0.661702,0.172863
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.368398,0.206568
gpu_reorg,256,8,1,50,2,true,false,true,false,0.332408,0.176716
gpu_reorg,256,8,1,50,4,true,false,true,false,0.321883,0.168424
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.407028,0.263613
gpu_array,256,32,1,20,2,true,false,true,false,0.331936,0.180709
gpu_array,256,32,1,20,4,true,false,true,false,0.365167,0.166507
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.393931,0.251632
gpu_sparse,256,32,1,20,2,true,false,true,false,0.320536,0.177679
gpu_sparse,256,32,1,20,4,true,false,true,false,0.314869,0.173686
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.424685,0.271783
gpu_reorg,256,32,1,20,2,true,false,true,false,0.372439,0.216189
gpu_reorg,256,32,1,20,4,true,false,true,false,0.364623,0.215628
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.303491,0.165656
0.165656
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.315416,0.176465
0.176465
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.248128,0.116989
0.116989
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.28918,0.149671
0.149671
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.307335,0.172291
0.172291
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.361004,0.224844
0.224844
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.116989
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.325521 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.07085,0.0781027
gpu_array,256,8,1,20,2,false,false,true,false,1.06066,0.0723828
gpu_array,256,8,1,20,4,false,false,true,false,1.07993,0.0581696
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.081,0.0776535
gpu_sparse,256,8,1,20,2,false,false,true,false,1.07507,0.0722796
gpu_sparse,256,8,1,20,4,false,false,true,false,1.25322,0.0618164
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.12532,0.0868192
gpu_reorg,256,8,1,20,2,false,false,true,false,1.08271,0.0771289
gpu_reorg,256,8,1,20,4,false,false,true,false,1.09359,0.0673661
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.07158,0.0648884
gpu_array,256,8,1,50,2,false,false,true,false,1.05504,0.0595006
gpu_array,256,8,1,50,4,false,false,true,false,1.06594,0.0598019
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.07951,0.065
gpu_sparse,256,8,1,50,2,false,false,true,false,1.06244,0.0758343
gpu_sparse,256,8,1,50,4,false,false,true,false,1.06807,0.0742132
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.04976,0.0692885
gpu_reorg,256,8,1,50,2,false,false,true,false,1.07593,0.0664453
gpu_reorg,256,8,1,50,4,false,false,true,false,1.06161,0.066077
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.055,0.0845787
gpu_array,256,32,1,20,2,false,false,true,false,1.21355,0.0790597
gpu_array,256,32,1,20,4,false,false,true,false,1.03117,0.0724665
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.06819,0.0838142
gpu_sparse,256,32,1,20,2,false,false,true,false,1.0799,0.0793415
gpu_sparse,256,32,1,20,4,false,false,true,false,1.04437,0.0745033
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.35065,0.0889286
gpu_reorg,256,32,1,20,2,false,false,true,false,1.09849,0.0817467
gpu_reorg,256,32,1,20,4,false,false,true,false,1.09705,0.0758482
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.01474,0.057154
0.057154
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,1.01477,0.054947
0.054947
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.02239,0.0698186
0.0698186
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.054947
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.110335 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.08916,0.0780022
gpu_array,256,8,1,20,2,false,false,true,false,1.06828,0.0721819
gpu_array,256,8,1,20,4,false,false,true,false,1.09063,0.0577093
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.10058,0.0777037
gpu_sparse,256,8,1,20,2,false,false,true,false,1.04563,0.0718583
gpu_sparse,256,8,1,20,4,false,false,true,false,1.04336,0.0623326
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.23758,0.0846735
gpu_reorg,256,8,1,20,2,false,false,true,false,1.12101,0.077486
gpu_reorg,256,8,1,20,4,false,false,true,false,1.08416,0.0685352
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.07253,0.0647182
gpu_array,256,8,1,50,2,false,false,true,false,1.08386,0.0598633
gpu_array,256,8,1,50,4,false,false,true,false,1.06921,0.059721
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.06126,0.0657254
gpu_sparse,256,8,1,50,2,false,false,true,false,1.0639,0.0745061
gpu_sparse,256,8,1,50,4,false,false,true,false,1.0785,0.0745926
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.11203,0.0712891
gpu_reorg,256,8,1,50,2,false,false,true,false,1.09136,0.0673661
gpu_reorg,256,8,1,50,4,false,false,true,false,1.07382,0.0671261
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.0825,0.0858454
gpu_array,256,32,1,20,2,false,false,true,false,1.07275,0.0800056
gpu_array,256,32,1,20,4,false,false,true,false,1.0758,0.0730106
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.09108,0.0843834
gpu_sparse,256,32,1,20,2,false,false,true,false,1.10681,0.0800251
gpu_sparse,256,32,1,20,4,false,false,true,false,1.05697,0.0753823
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.10373,0.0908984
gpu_reorg,256,32,1,20,2,false,false,true,false,1.09294,0.083457
gpu_reorg,256,32,1,20,4,false,false,true,false,1.07747,0.0757924
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.01931,0.0578181
0.0578181
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.02239,0.0558761
0.0558761
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.04913,0.0708956
0.0708956
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0558761
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.111042 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.21067,0.060558
gpu_array,256,8,1,20,2,true,false,true,false,0.200625,0.0544196
gpu_array,256,8,1,20,4,true,false,true,false,0.185887,0.0463783
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.201041,0.0604157
gpu_sparse,256,8,1,20,2,true,false,true,false,0.19714,0.0509347
gpu_sparse,256,8,1,20,4,true,false,true,false,0.187514,0.0485631
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.244741,0.0790039
gpu_reorg,256,8,1,20,2,true,false,true,false,0.225273,0.0573047
gpu_reorg,256,8,1,20,4,true,false,true,false,0.21971,0.0550893
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.194132,0.0523912
gpu_array,256,8,1,50,2,true,false,true,false,0.199601,0.0483733
gpu_array,256,8,1,50,4,true,false,true,false,0.191727,0.0483119
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.195516,0.052101
gpu_sparse,256,8,1,50,2,true,false,true,false,0.189037,0.0495285
gpu_sparse,256,8,1,50,4,true,false,true,false,0.188457,0.0495061
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.225633,0.0604548
gpu_reorg,256,8,1,50,2,true,false,true,false,0.222642,0.0535575
gpu_reorg,256,8,1,50,4,true,false,true,false,0.216763,0.0532589
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.203404,0.062779
gpu_array,256,32,1,20,2,true,false,true,false,0.193719,0.0564425
gpu_array,256,32,1,20,4,true,false,true,false,0.188544,0.0490346
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.210617,0.0616211
gpu_sparse,256,32,1,20,2,true,false,true,false,0.193245,0.0503878
gpu_sparse,256,32,1,20,4,true,false,true,false,0.190377,0.0497517
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.239473,0.0782003
gpu_reorg,256,32,1,20,2,true,false,true,false,0.229316,0.0585575
gpu_reorg,256,32,1,20,4,true,false,true,false,0.216641,0.0548103
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.171423,0.046423
0.046423
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.1757,0.0479102
0.0479102
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.167536,0.0458845
0.0458845
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.173792,0.0454436
0.0454436
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.170848,0.0475223
0.0475223
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.179235,0.0508873
0.0508873
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0454436
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.0914333 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.211763,0.0638839
gpu_array,256,8,1,20,2,true,false,true,false,0.208549,0.0573214
gpu_array,256,8,1,20,4,true,false,true,false,0.191649,0.0482338
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.218284,0.0637081
gpu_sparse,256,8,1,20,2,true,false,true,false,0.196311,0.0512221
gpu_sparse,256,8,1,20,4,true,false,true,false,0.192065,0.0486496
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.250142,0.0804994
gpu_reorg,256,8,1,20,2,true,false,true,false,0.225739,0.0577706
gpu_reorg,256,8,1,20,4,true,false,true,false,0.215427,0.0552706
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.195025,0.052726
gpu_array,256,8,1,50,2,true,false,true,false,0.18603,0.0481948
gpu_array,256,8,1,50,4,true,false,true,false,0.179141,0.0480022
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.191669,0.0516016
gpu_sparse,256,8,1,50,2,true,false,true,false,0.179992,0.0488532
gpu_sparse,256,8,1,50,4,true,false,true,false,0.181136,0.0488811
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.227946,0.0599777
gpu_reorg,256,8,1,50,2,true,false,true,false,0.221423,0.0528962
gpu_reorg,256,8,1,50,4,true,false,true,false,0.209082,0.052832
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.204319,0.0614621
gpu_array,256,32,1,20,2,true,false,true,false,0.206208,0.0555385
gpu_array,256,32,1,20,4,true,false,true,false,0.187681,0.0487305
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.198209,0.0609319
gpu_sparse,256,32,1,20,2,true,false,true,false,0.188479,0.0500865
gpu_sparse,256,32,1,20,4,true,false,true,false,0.18947,0.0494029
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.242001,0.0779381
gpu_reorg,256,32,1,20,2,true,false,true,false,0.221147,0.0582003
gpu_reorg,256,32,1,20,4,true,false,true,false,0.224325,0.05524
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.168859,0.0455329
0.0455329
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.168477,0.0451507
0.0451507
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.16731,0.0467746
0.0467746
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.167626,0.0482059
0.0482059
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.177193,0.0477288
0.0477288
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.180279,0.0508147
0.0508147
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0451507
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0917639 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.62158,6.47873
gpu_array,256,8,1,20,2,true,false,true,false,13.3473,13.1804
gpu_array,256,8,1,20,4,true,false,true,false,12.3203,12.159
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.1427,5.99761
gpu_sparse,256,8,1,20,2,true,false,true,false,12.9279,12.7834
gpu_sparse,256,8,1,20,4,true,false,true,false,8.85778,8.70432
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.39938,7.24368
gpu_reorg,256,8,1,20,2,true,false,true,false,10.7956,10.6477
gpu_reorg,256,8,1,20,4,true,false,true,false,8.29227,8.13323
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.13895,3.98996
gpu_array,256,8,1,50,2,true,false,true,false,7.36551,7.21596
gpu_array,256,8,1,50,4,true,false,true,false,8.52512,8.3605
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,3.81804,3.65397
gpu_sparse,256,8,1,50,2,true,false,true,false,7.22246,7.07123
gpu_sparse,256,8,1,50,4,true,false,true,false,7.5491,7.40345
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,4.77266,4.62031
gpu_reorg,256,8,1,50,2,true,false,true,false,7.69691,7.53898
gpu_reorg,256,8,1,50,4,true,false,true,false,11.4728,11.3271
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,6.75869,6.6097
gpu_array,256,32,1,20,2,true,false,true,false,5.4598,5.30801
gpu_array,256,32,1,20,4,true,false,true,false,6.00087,5.85243
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.09066,5.95115
gpu_sparse,256,32,1,20,2,true,false,true,false,5.62006,5.4878
gpu_sparse,256,32,1,20,4,true,false,true,false,5.48467,5.34906
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.67037,7.52751
gpu_reorg,256,32,1,20,2,true,false,true,false,6.6911,6.54936
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.7906,2.66672
2.66672
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,3.04937,2.92382
2.92382
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.95666,5.8205
5.8205
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.24547,6.10429
6.10429
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.66672
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 165 seconds of which 2.72205 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.61881,6.47874
gpu_array,256,8,1,20,2,true,false,true,false,13.3122,13.1538
gpu_array,256,8,1,20,4,true,false,true,false,12.3845,12.2517
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.13217,5.99768
gpu_sparse,256,8,1,20,2,true,false,true,false,12.9677,12.8132
gpu_sparse,256,8,1,20,4,true,false,true,false,8.92975,8.79359
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.38161,7.24433
gpu_reorg,256,8,1,20,2,true,false,true,false,10.8253,10.6875
gpu_reorg,256,8,1,20,4,true,false,true,false,8.1886,8.03905
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.20119,4.04997
gpu_array,256,8,1,50,2,true,false,true,false,7.33681,7.18502
gpu_array,256,8,1,50,4,true,false,true,false,8.50778,8.36325
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,3.79527,3.65297
gpu_sparse,256,8,1,50,2,true,false,true,false,7.13364,6.98297
gpu_sparse,256,8,1,50,4,true,false,true,false,7.56633,7.42626
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,4.76839,4.62051
gpu_reorg,256,8,1,50,2,true,false,true,false,7.76177,7.61613
gpu_reorg,256,8,1,50,4,true,false,true,false,11.5234,11.376
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,6.78954,6.64836
gpu_array,256,32,1,20,2,true,false,true,false,5.3743,5.23144
gpu_array,256,32,1,20,4,true,false,true,false,6.03359,5.88739
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.0978,5.95048
gpu_sparse,256,32,1,20,2,true,false,true,false,5.54337,5.41614
gpu_sparse,256,32,1,20,4,true,false,true,false,5.54263,5.39643
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.67849,7.52671
gpu_reorg,256,32,1,20,2,true,false,true,false,6.72925,6.59086
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.90304,2.77748
2.77748
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,2.9658,2.84527
2.84527
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.86839,5.73391
5.73391
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.17318,6.04037
6.04037
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.77748
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 164 seconds of which 2.72355 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.247048,0.0584319
gpu_array,256,8,1,20,2,true,false,true,false,0.303831,0.105728
gpu_array,256,8,1,20,4,true,false,true,false,0.253853,0.0730497
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.239219,0.0578571
gpu_sparse,256,8,1,20,2,true,false,true,false,0.278457,0.0920731
gpu_sparse,256,8,1,20,4,true,false,true,false,0.285511,0.087966
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.318306,0.0772349
gpu_reorg,256,8,1,20,2,true,false,true,false,0.352902,0.118527
gpu_reorg,256,8,1,20,4,true,false,true,false,0.348418,0.0956278
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.240276,0.0555664
gpu_array,256,8,1,50,2,true,false,true,false,0.278064,0.080519
gpu_array,256,8,1,50,4,true,false,true,false,0.314414,0.0811551
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.249989,0.0552344
gpu_sparse,256,8,1,50,2,true,false,true,false,0.313719,0.0810184
gpu_sparse,256,8,1,50,4,true,false,true,false,0.290871,0.0804911
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.277294,0.065798
gpu_reorg,256,8,1,50,2,true,false,true,false,0.322447,0.0897461
gpu_reorg,256,8,1,50,4,true,false,true,false,0.329054,0.0902148
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.257229,0.0613588
gpu_array,256,32,1,20,2,true,false,true,false,0.278795,0.0583705
gpu_array,256,32,1,20,4,true,false,true,false,0.259018,0.0564509
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.263189,0.0589481
gpu_sparse,256,32,1,20,2,true,false,true,false,0.274297,0.0516406
gpu_sparse,256,32,1,20,4,true,false,true,false,0.25017,0.0548577
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.288906,0.0757366
gpu_reorg,256,32,1,20,2,true,false,true,false,0.278753,0.0622349
gpu_reorg,256,32,1,20,4,true,false,true,false,0.311046,0.0694169
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.23459,0.04988
0.04988
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.241889,0.0588532
0.0588532
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.222095,0.0479883
0.0479883
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.231602,0.0485658
0.0485658
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.246588,0.0602037
0.0602037
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.235033,0.0620424
0.0620424
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0479883
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.118927 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.295299,0.0620396
gpu_array,256,8,1,20,2,true,false,true,false,0.304473,0.113066
gpu_array,256,8,1,20,4,true,false,true,false,0.292723,0.0778795
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.261272,0.0614955
gpu_sparse,256,8,1,20,2,true,false,true,false,0.284233,0.0933845
gpu_sparse,256,8,1,20,4,true,false,true,false,0.284941,0.0873968
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.295943,0.0777511
gpu_reorg,256,8,1,20,2,true,false,true,false,0.360605,0.11786
gpu_reorg,256,8,1,20,4,true,false,true,false,0.349492,0.096144
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.275583,0.0557171
gpu_array,256,8,1,50,2,true,false,true,false,0.293574,0.0804046
gpu_array,256,8,1,50,4,true,false,true,false,0.282358,0.0803488
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.266833,0.0553376
gpu_sparse,256,8,1,50,2,true,false,true,false,0.297436,0.0798019
gpu_sparse,256,8,1,50,4,true,false,true,false,0.302101,0.0794448
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.279512,0.064668
gpu_reorg,256,8,1,50,2,true,false,true,false,0.324872,0.0910547
gpu_reorg,256,8,1,50,4,true,false,true,false,0.308301,0.0895508
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.265932,0.0622489
gpu_array,256,32,1,20,2,true,false,true,false,0.249925,0.0585184
gpu_array,256,32,1,20,4,true,false,true,false,0.263789,0.0561998
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.265678,0.0586468
gpu_sparse,256,32,1,20,2,true,false,true,false,0.240901,0.0517271
gpu_sparse,256,32,1,20,4,true,false,true,false,0.277056,0.0555162
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.297821,0.0751646
gpu_reorg,256,32,1,20,2,true,false,true,false,0.278943,0.0629827
gpu_reorg,256,32,1,20,4,true,false,true,false,0.287667,0.0694754
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.225533,0.0503097
0.0503097
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.259897,0.0595619
0.0595619
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.236526,0.0484682
0.0484682
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.236987,0.0489286
0.0489286
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.266532,0.0606166
0.0606166
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.245109,0.0626311
0.0626311
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0484682
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.12003 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.210244,0.127562
gpu_array,512,8,1,20,2,true,false,true,false,0.168779,0.085446
gpu_array,512,8,1,20,4,true,false,true,false,0.150957,0.0812956
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.208903,0.126221
gpu_sparse,512,8,1,20,2,true,false,true,false,0.152829,0.0799121
gpu_sparse,512,8,1,20,4,true,false,true,false,0.164287,0.0920215
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.255117,0.165924
gpu_reorg,512,8,1,20,2,true,false,true,false,0.195521,0.08875
gpu_reorg,512,8,1,20,4,true,false,true,false,0.177705,0.0728874
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.152614,0.0731868
gpu_array,512,8,1,50,2,true,false,true,false,0.146527,0.0631934
gpu_array,512,8,1,50,4,true,false,true,false,0.146702,0.0653223
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.157493,0.0761133
gpu_sparse,512,8,1,50,2,true,false,true,false,0.156504,0.0783789
gpu_sparse,512,8,1,50,4,true,false,true,false,0.156406,0.0763281
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.376816,0.0923112
gpu_reorg,512,8,1,50,2,true,false,true,false,0.347734,0.0625781
gpu_reorg,512,8,1,50,4,true,false,true,false,0.36849,0.0885417
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.215837,0.126644
gpu_array,512,32,1,20,2,true,false,true,false,0.16359,0.0867676
gpu_array,512,32,1,20,4,true,false,true,false,0.164001,0.0832715
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.208206,0.125524
gpu_sparse,512,32,1,20,2,true,false,true,false,0.155706,0.0749772
gpu_sparse,512,32,1,20,4,true,false,true,false,0.170228,0.0868945
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.266423,0.160954
gpu_reorg,512,32,1,20,2,true,false,true,false,0.196081,0.0932161
gpu_reorg,512,32,1,20,4,true,false,true,false,0.178122,0.0824186
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.159098,0.0594889
0.0594889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.166855,0.0665951
0.0665951
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.16167,0.0718262
0.0718262
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.174395,0.0806445
0.0806445
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.177002,0.0819499
0.0819499
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.185439,0.0871322
0.0871322
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0594889
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.303542 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.208779,0.127399
gpu_array,512,8,1,20,2,true,false,true,false,0.162952,0.0861296
gpu_array,512,8,1,20,4,true,false,true,false,0.164687,0.0820052
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.215729,0.126536
gpu_sparse,512,8,1,20,2,true,false,true,false,0.161634,0.0802539
gpu_sparse,512,8,1,20,4,true,false,true,false,0.173512,0.0921322
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.269772,0.165605
gpu_reorg,512,8,1,20,2,true,false,true,false,0.187633,0.0886751
gpu_reorg,512,8,1,20,4,true,false,true,false,0.173844,0.0722819
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.152855,0.0727767
gpu_array,512,8,1,50,2,true,false,true,false,0.14972,0.0631315
gpu_array,512,8,1,50,4,true,false,true,false,0.146006,0.0652767
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.158825,0.0761426
gpu_sparse,512,8,1,50,2,true,false,true,false,0.158457,0.0790299
gpu_sparse,512,8,1,50,4,true,false,true,false,0.162383,0.0764453
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.370023,0.0933301
gpu_reorg,512,8,1,50,2,true,false,true,false,0.342458,0.0625098
gpu_reorg,512,8,1,50,4,true,false,true,false,0.37263,0.088125
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.208037,0.126006
gpu_array,512,32,1,20,2,true,false,true,false,0.171439,0.0868034
gpu_array,512,32,1,20,4,true,false,true,false,0.166484,0.083151
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.216989,0.125843
gpu_sparse,512,32,1,20,2,true,false,true,false,0.164229,0.0750358
gpu_sparse,512,32,1,20,4,true,false,true,false,0.170693,0.0860579
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.2746,0.161318
gpu_reorg,512,32,1,20,2,true,false,true,false,0.198066,0.0932487
gpu_reorg,512,32,1,20,4,true,false,true,false,0.185938,0.0824219
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.153385,0.0596354
0.0596354
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.159935,0.0668359
0.0668359
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.170674,0.0717155
0.0717155
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.177884,0.0808789
0.0808789
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.177533,0.0824805
0.0824805
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.182826,0.0871224
0.0871224
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0596354
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.303753 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.126198,0.0324479
gpu_array,512,8,1,20,2,true,false,true,false,0.120179,0.0296842
gpu_array,512,8,1,20,4,true,false,true,false,0.118874,0.0264258
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.12415,0.0323535
gpu_sparse,512,8,1,20,2,true,false,true,false,0.116436,0.0278939
gpu_sparse,512,8,1,20,4,true,false,true,false,0.119004,0.0278581
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.153457,0.0401758
gpu_reorg,512,8,1,20,2,true,false,true,false,0.147051,0.0305143
gpu_reorg,512,8,1,20,4,true,false,true,false,0.133451,0.0292839
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.117956,0.028112
gpu_array,512,8,1,50,2,true,false,true,false,0.120618,0.0268685
gpu_array,512,8,1,50,4,true,false,true,false,0.118646,0.026849
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.121924,0.0288249
gpu_sparse,512,8,1,50,2,true,false,true,false,0.123717,0.0345247
gpu_sparse,512,8,1,50,4,true,false,true,false,0.125072,0.0345768
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.146208,0.0335775
gpu_reorg,512,8,1,50,2,true,false,true,false,0.149574,0.0336882
gpu_reorg,512,8,1,50,4,true,false,true,false,0.148402,0.0338184
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.125452,0.0310514
gpu_array,512,32,1,20,2,true,false,true,false,0.113298,0.0280111
gpu_array,512,32,1,20,4,true,false,true,false,0.116224,0.0244271
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.123743,0.0306445
gpu_sparse,512,32,1,20,2,true,false,true,false,0.119092,0.0253418
gpu_sparse,512,32,1,20,4,true,false,true,false,0.125179,0.0249186
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.152614,0.0386816
gpu_reorg,512,32,1,20,2,true,false,true,false,0.143818,0.029235
gpu_reorg,512,32,1,20,4,true,false,true,false,0.14403,0.0274935
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0998926,0.0237207
0.0237207
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.104085,0.0246582
0.0246582
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.0929134,0.0252051
0.0252051
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.10457,0.0257943
0.0257943
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.101162,0.0249902
0.0249902
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.110378,0.0257422
0.0257422
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0237207
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.099061 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.122542,0.0326986
gpu_array,512,8,1,20,2,true,false,true,false,0.12109,0.0299447
gpu_array,512,8,1,20,4,true,false,true,false,0.118623,0.0268262
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.123265,0.0327702
gpu_sparse,512,8,1,20,2,true,false,true,false,0.127246,0.0282878
gpu_sparse,512,8,1,20,4,true,false,true,false,0.124893,0.0278874
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.154808,0.0402246
gpu_reorg,512,8,1,20,2,true,false,true,false,0.148353,0.0305143
gpu_reorg,512,8,1,20,4,true,false,true,false,0.143841,0.0292578
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.121344,0.0282454
gpu_array,512,8,1,50,2,true,false,true,false,0.123861,0.0268555
gpu_array,512,8,1,50,4,true,false,true,false,0.117308,0.0268132
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.118743,0.0288997
gpu_sparse,512,8,1,50,2,true,false,true,false,0.127594,0.0344954
gpu_sparse,512,8,1,50,4,true,false,true,false,0.121748,0.0345085
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.150706,0.0335189
gpu_reorg,512,8,1,50,2,true,false,true,false,0.141003,0.0335807
gpu_reorg,512,8,1,50,4,true,false,true,false,0.149548,0.0336621
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.130534,0.0309245
gpu_array,512,32,1,20,2,true,false,true,false,0.119766,0.0279688
gpu_array,512,32,1,20,4,true,false,true,false,0.117409,0.0243099
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.121175,0.0306803
gpu_sparse,512,32,1,20,2,true,false,true,false,0.109961,0.0253255
gpu_sparse,512,32,1,20,4,true,false,true,false,0.108564,0.0245801
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.145824,0.0384017
gpu_reorg,512,32,1,20,2,true,false,true,false,0.146699,0.0288607
gpu_reorg,512,32,1,20,4,true,false,true,false,0.1425,0.0272656
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0911035,0.0233952
0.0233952
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.0973438,0.0244271
0.0244271
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.0963542,0.0247396
0.0247396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.0899935,0.0255404
0.0255404
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.103105,0.0249805
0.0249805
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.100312,0.0254427
0.0254427
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0233952
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0989013 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.737923,0.157845
gpu_array,512,8,1,20,2,true,false,true,false,0.696982,0.121462
gpu_array,512,8,1,20,4,true,false,true,false,0.722809,0.121247
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.745508,0.166732
gpu_sparse,512,8,1,20,2,true,false,true,false,0.640514,0.0877799
gpu_sparse,512,8,1,20,4,true,false,true,false,0.66387,0.109834
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.782894,0.191097
gpu_reorg,512,8,1,20,2,true,false,true,false,0.696696,0.112061
gpu_reorg,512,8,1,20,4,true,false,true,false,0.717939,0.107262
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.702311,0.0974935
gpu_array,512,8,1,50,2,true,false,true,false,0.656185,0.0741536
gpu_array,512,8,1,50,4,true,false,true,false,0.616273,0.072653
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.66902,0.0993587
gpu_sparse,512,8,1,50,2,true,false,true,false,0.672334,0.0935579
gpu_sparse,512,8,1,50,4,true,false,true,false,0.686416,0.0887598
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.726774,0.112842
gpu_reorg,512,8,1,50,2,true,false,true,false,0.716572,0.0798535
gpu_reorg,512,8,1,50,4,true,false,true,false,0.715889,0.100654
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.645378,0.0802734
0.0802734
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.667005,0.0999479
0.0999479
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.695306,0.128249
0.128249
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.720667,0.154912
0.154912
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.072653
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.251702 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.742943,0.157656
gpu_array,512,8,1,20,2,true,false,true,false,0.712826,0.12168
gpu_array,512,8,1,20,4,true,false,true,false,0.705905,0.121921
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.761693,0.167292
gpu_sparse,512,8,1,20,2,true,false,true,false,0.669639,0.0889095
gpu_sparse,512,8,1,20,4,true,false,true,false,0.699811,0.109967
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.812793,0.191699
gpu_reorg,512,8,1,20,2,true,false,true,false,0.751621,0.112949
gpu_reorg,512,8,1,20,4,true,false,true,false,0.708138,0.107227
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.70236,0.0981934
gpu_array,512,8,1,50,2,true,false,true,false,0.656882,0.0755013
gpu_array,512,8,1,50,4,true,false,true,false,0.669118,0.0740658
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.68987,0.100677
gpu_sparse,512,8,1,50,2,true,false,true,false,0.699727,0.0936068
gpu_sparse,512,8,1,50,4,true,false,true,false,0.667282,0.0891569
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.746494,0.113031
gpu_reorg,512,8,1,50,2,true,false,true,false,0.713854,0.0803906
gpu_reorg,512,8,1,50,4,true,false,true,false,0.723395,0.100999
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.664043,0.0800586
0.0800586
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.673255,0.10099
0.10099
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,0.6689,0.0875195
0.0875195
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,0.758265,0.190557
0.190557
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0740658
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.252318 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.254987,0.135195
gpu_array,512,8,1,20,2,true,false,true,false,0.219053,0.0973079
gpu_array,512,8,1,20,4,true,false,true,false,0.220439,0.0934863
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.262526,0.139479
gpu_sparse,512,8,1,20,2,true,false,true,false,0.227591,0.108451
gpu_sparse,512,8,1,20,4,true,false,true,false,0.226048,0.110814
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.294896,0.174453
gpu_reorg,512,8,1,20,2,true,false,true,false,0.248796,0.121191
gpu_reorg,512,8,1,20,4,true,false,true,false,0.244388,0.116784
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.351963,0.114984
gpu_array,512,8,1,50,2,true,false,true,false,0.347174,0.112799
gpu_array,512,8,1,50,4,true,false,true,false,0.364255,0.127275
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.230658,0.111517
gpu_sparse,512,8,1,50,2,true,false,true,false,0.351374,0.11765
gpu_sparse,512,8,1,50,4,true,false,true,false,0.440247,0.128398
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.245677,0.121979
gpu_reorg,512,8,1,50,2,true,false,true,false,0.245003,0.11805
gpu_reorg,512,8,1,50,4,true,false,true,false,0.270609,0.153421
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.260452,0.141963
gpu_array,512,32,1,20,2,true,false,true,false,0.231315,0.10957
gpu_array,512,32,1,20,4,true,false,true,false,0.228271,0.107178
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.259326,0.134977
gpu_sparse,512,32,1,20,2,true,false,true,false,0.232074,0.112282
gpu_sparse,512,32,1,20,4,true,false,true,false,0.234502,0.116012
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.280273,0.157227
gpu_reorg,512,32,1,20,2,true,false,true,false,0.253734,0.128734
gpu_reorg,512,32,1,20,4,true,false,true,false,0.263346,0.129232
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.19695,0.0869238
0.0869238
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.196774,0.0913053
0.0913053
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.192282,0.0874642
0.0874642
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.217663,0.112845
0.112845
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.182969,0.0735937
0.0735937
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.185505,0.0819889
0.0819889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0735937
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.396752 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.258942,0.134593
gpu_array,512,8,1,20,2,true,false,true,false,0.225697,0.0967904
gpu_array,512,8,1,20,4,true,false,true,false,0.213493,0.0930501
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.253662,0.138428
gpu_sparse,512,8,1,20,2,true,false,true,false,0.224743,0.108857
gpu_sparse,512,8,1,20,4,true,false,true,false,0.232689,0.109642
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.301504,0.1739
gpu_reorg,512,8,1,20,2,true,false,true,false,0.256712,0.121947
gpu_reorg,512,8,1,20,4,true,false,true,false,0.239251,0.117507
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.356611,0.115075
gpu_array,512,8,1,50,2,true,false,true,false,0.349059,0.113382
gpu_array,512,8,1,50,4,true,false,true,false,0.367516,0.127933
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.229199,0.111361
gpu_sparse,512,8,1,50,2,true,false,true,false,0.360124,0.117936
gpu_sparse,512,8,1,50,4,true,false,true,false,0.368018,0.129085
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.24696,0.122611
gpu_reorg,512,8,1,50,2,true,false,true,false,0.247021,0.118766
gpu_reorg,512,8,1,50,4,true,false,true,false,0.278903,0.153903
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.261071,0.141279
gpu_array,512,32,1,20,2,true,false,true,false,0.229811,0.109368
gpu_array,512,32,1,20,4,true,false,true,false,0.229053,0.107308
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.257246,0.13485
gpu_sparse,512,32,1,20,2,true,false,true,false,0.232217,0.112425
gpu_sparse,512,32,1,20,4,true,false,true,false,0.231263,0.116029
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.277891,0.157448
gpu_reorg,512,32,1,20,2,true,false,true,false,0.233187,0.128369
gpu_reorg,512,32,1,20,4,true,false,true,false,0.237187,0.129115
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.170404,0.0864193
0.0864193
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.194658,0.0911426
0.0911426
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.169154,0.0864714
0.0864714
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.213724,0.112161
0.112161
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.177923,0.0731055
0.0731055
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.186986,0.0815169
0.0815169
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0731055
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.39647 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.114,0.0443392
gpu_array,512,8,1,20,2,false,false,true,false,1.11715,0.0422786
gpu_array,512,8,1,20,4,false,false,true,false,1.11589,0.0416732
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.12001,0.0444857
gpu_sparse,512,8,1,20,2,false,false,true,false,1.11495,0.0426823
gpu_sparse,512,8,1,20,4,false,false,true,false,1.0983,0.0423112
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.12611,0.0557943
gpu_reorg,512,8,1,20,2,false,false,true,false,1.12332,0.0504004
gpu_reorg,512,8,1,20,4,false,false,true,false,1.11882,0.0465592
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.12549,0.0480111
gpu_array,512,8,1,50,2,false,false,true,false,1.12128,0.049668
gpu_array,512,8,1,50,4,false,false,true,false,1.13436,0.0497233
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.13483,0.0456348
gpu_sparse,512,8,1,50,2,false,false,true,false,1.12744,0.0551725
gpu_sparse,512,8,1,50,4,false,false,true,false,1.16588,0.0552051
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.13194,0.0486068
gpu_reorg,512,8,1,50,2,false,false,true,false,1.12153,0.0538249
gpu_reorg,512,8,1,50,4,false,false,true,false,1.12821,0.0539876
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.11453,0.0468229
gpu_array,512,32,1,20,2,false,false,true,false,1.12002,0.0438477
gpu_array,512,32,1,20,4,false,false,true,false,1.11768,0.0428125
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.12806,0.0466797
gpu_sparse,512,32,1,20,2,false,false,true,false,1.1353,0.0441504
gpu_sparse,512,32,1,20,4,false,false,true,false,1.11256,0.0442025
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.15582,0.0562142
gpu_reorg,512,32,1,20,2,false,false,true,false,1.12963,0.0515039
gpu_reorg,512,32,1,20,4,false,false,true,false,1.12849,0.0490625
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.11411,0.0424935
0.0424935
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.10039,0.0424479
0.0424479
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.12867,0.0427311
0.0427311
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0416732
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.145749 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.07165,0.0443034
gpu_array,512,8,1,20,2,false,false,true,false,1.11135,0.0423372
gpu_array,512,8,1,20,4,false,false,true,false,1.04382,0.0412174
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.08776,0.0441406
gpu_sparse,512,8,1,20,2,false,false,true,false,1.06079,0.0419108
gpu_sparse,512,8,1,20,4,false,false,true,false,1.06854,0.0418457
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.08031,0.0523145
gpu_reorg,512,8,1,20,2,false,false,true,false,1.102,0.0499154
gpu_reorg,512,8,1,20,4,false,false,true,false,1.08281,0.0463477
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.13833,0.0478385
gpu_array,512,8,1,50,2,false,false,true,false,1.12497,0.0494531
gpu_array,512,8,1,50,4,false,false,true,false,1.10721,0.0492676
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.08228,0.0451693
gpu_sparse,512,8,1,50,2,false,false,true,false,1.08911,0.0546094
gpu_sparse,512,8,1,50,4,false,false,true,false,1.12987,0.0549967
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.09308,0.0481543
gpu_reorg,512,8,1,50,2,false,false,true,false,1.09717,0.0535482
gpu_reorg,512,8,1,50,4,false,false,true,false,1.09662,0.0536523
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.06659,0.0464063
gpu_array,512,32,1,20,2,false,false,true,false,1.07375,0.0438021
gpu_array,512,32,1,20,4,false,false,true,false,1.05679,0.0424642
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.13015,0.0468197
gpu_sparse,512,32,1,20,2,false,false,true,false,1.11445,0.0441341
gpu_sparse,512,32,1,20,4,false,false,true,false,1.11649,0.0442253
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.14165,0.0563639
gpu_reorg,512,32,1,20,2,false,false,true,false,1.14992,0.0516081
gpu_reorg,512,32,1,20,4,false,false,true,false,1.15921,0.0491829
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.06688,0.0421354
0.0421354
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.1025,0.0426042
0.0426042
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.06773,0.0423405
0.0423405
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0412174
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.144702 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.132419,0.0334603
gpu_array,512,8,1,20,2,true,false,true,false,0.122878,0.0304297
gpu_array,512,8,1,20,4,true,false,true,false,0.125234,0.0275781
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.12835,0.0332975
gpu_sparse,512,8,1,20,2,true,false,true,false,0.124339,0.0286361
gpu_sparse,512,8,1,20,4,true,false,true,false,0.121481,0.0283822
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.161426,0.0416341
gpu_reorg,512,8,1,20,2,true,false,true,false,0.153786,0.032041
gpu_reorg,512,8,1,20,4,true,false,true,false,0.156156,0.0305046
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.120661,0.029515
gpu_array,512,8,1,50,2,true,false,true,false,0.121839,0.0313444
gpu_array,512,8,1,50,4,true,false,true,false,0.122458,0.0313118
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.120228,0.0297331
gpu_sparse,512,8,1,50,2,true,false,true,false,0.125465,0.0349707
gpu_sparse,512,8,1,50,4,true,false,true,false,0.121631,0.0350423
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.161973,0.0356706
gpu_reorg,512,8,1,50,2,true,false,true,false,0.164105,0.0365007
gpu_reorg,512,8,1,50,4,true,false,true,false,0.161032,0.0366829
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.122096,0.0316016
gpu_array,512,32,1,20,2,true,false,true,false,0.116618,0.0287272
gpu_array,512,32,1,20,4,true,false,true,false,0.109456,0.025472
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.129437,0.0311296
gpu_sparse,512,32,1,20,2,true,false,true,false,0.120827,0.0264258
gpu_sparse,512,32,1,20,4,true,false,true,false,0.119792,0.0260417
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.158704,0.0402148
gpu_reorg,512,32,1,20,2,true,false,true,false,0.154681,0.0309831
gpu_reorg,512,32,1,20,4,true,false,true,false,0.149183,0.0293913
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0965592,0.0249447
0.0249447
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.106504,0.0264258
0.0264258
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.106758,0.0260286
0.0260286
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.0946029,0.0262435
0.0262435
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.110404,0.0270703
0.0270703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.111289,0.0273047
0.0273047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0249447
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103909 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.133695,0.0334342
gpu_array,512,8,1,20,2,true,false,true,false,0.133379,0.0305143
gpu_array,512,8,1,20,4,true,false,true,false,0.126016,0.0277083
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.131016,0.0333594
gpu_sparse,512,8,1,20,2,true,false,true,false,0.119261,0.0287663
gpu_sparse,512,8,1,20,4,true,false,true,false,0.125007,0.0286523
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.162731,0.0416374
gpu_reorg,512,8,1,20,2,true,false,true,false,0.147266,0.0320312
gpu_reorg,512,8,1,20,4,true,false,true,false,0.15153,0.0304362
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.119395,0.0295508
gpu_array,512,8,1,50,2,true,false,true,false,0.114701,0.0313672
gpu_array,512,8,1,50,4,true,false,true,false,0.121172,0.0313281
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.114238,0.0296029
gpu_sparse,512,8,1,50,2,true,false,true,false,0.125352,0.0348568
gpu_sparse,512,8,1,50,4,true,false,true,false,0.129248,0.034847
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.15224,0.0350521
gpu_reorg,512,8,1,50,2,true,false,true,false,0.150941,0.0363574
gpu_reorg,512,8,1,50,4,true,false,true,false,0.150247,0.0363151
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.115807,0.0311719
gpu_array,512,32,1,20,2,true,false,true,false,0.121432,0.0283333
gpu_array,512,32,1,20,4,true,false,true,false,0.104886,0.025459
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.122145,0.0309993
gpu_sparse,512,32,1,20,2,true,false,true,false,0.105488,0.0260612
gpu_sparse,512,32,1,20,4,true,false,true,false,0.118076,0.0256283
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.158965,0.0398242
gpu_reorg,512,32,1,20,2,true,false,true,false,0.151172,0.0307292
gpu_reorg,512,32,1,20,4,true,false,true,false,0.149378,0.0289355
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.101331,0.0245085
0.0245085
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.106615,0.0265365
0.0265365
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.110651,0.0260156
0.0260156
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.10515,0.0263737
0.0263737
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.112363,0.0270768
0.0270768
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.110609,0.0272754
0.0272754
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0245085
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.1035 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.10034,3.83406
gpu_array,512,8,1,20,2,true,false,true,false,7.94945,7.67016
gpu_array,512,8,1,20,4,true,false,true,false,7.49525,7.2446
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.68243,3.43829
gpu_sparse,512,8,1,20,2,true,false,true,false,7.76341,7.51146
gpu_sparse,512,8,1,20,4,true,false,true,false,5.57148,5.32799
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.59715,4.32827
gpu_reorg,512,8,1,20,2,true,false,true,false,6.02833,5.73211
gpu_reorg,512,8,1,20,4,true,false,true,false,5.36592,5.09118
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.7688,3.48234
gpu_array,512,8,1,50,2,true,false,true,false,4.55512,4.2654
gpu_array,512,8,1,50,4,true,false,true,false,9.20969,8.92062
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.42891,3.15286
gpu_sparse,512,8,1,50,2,true,false,true,false,4.49118,4.19822
gpu_sparse,512,8,1,50,4,true,false,true,false,8.17324,7.88678
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,4.00947,3.6846
gpu_reorg,512,8,1,50,2,true,false,true,false,8.91822,8.60181
gpu_reorg,512,8,1,50,4,true,false,true,false,9.65182,9.34844
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,3.99837,3.75163
gpu_array,512,32,1,20,2,true,false,true,false,3.55987,3.31638
gpu_array,512,32,1,20,4,true,false,true,false,3.87861,3.63056
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.58336,3.34573
gpu_sparse,512,32,1,20,2,true,false,true,false,3.73603,3.48733
gpu_sparse,512,32,1,20,4,true,false,true,false,3.6707,3.4194
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.56719,4.28919
gpu_reorg,512,32,1,20,2,true,false,true,false,4.4703,4.20077
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.66436,2.57973
2.57973
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.75049,2.66195
2.66195
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.07678,2.9915
2.9915
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.20967,3.12309
3.12309
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.57973
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 151 seconds of which 3.69962 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.11085,3.84717
gpu_array,512,8,1,20,2,true,false,true,false,7.94323,7.66328
gpu_array,512,8,1,20,4,true,false,true,false,7.52865,7.24414
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.77871,3.53262
gpu_sparse,512,8,1,20,2,true,false,true,false,7.77013,7.52273
gpu_sparse,512,8,1,20,4,true,false,true,false,5.6037,5.35695
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.57855,4.31293
gpu_reorg,512,8,1,20,2,true,false,true,false,5.98911,5.71763
gpu_reorg,512,8,1,20,4,true,false,true,false,5.40848,5.15001
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.81341,3.5263
gpu_array,512,8,1,50,2,true,false,true,false,4.52936,4.23184
gpu_array,512,8,1,50,4,true,false,true,false,9.17516,8.88154
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.62615,3.34359
gpu_sparse,512,8,1,50,2,true,false,true,false,4.62458,4.33357
gpu_sparse,512,8,1,50,4,true,false,true,false,8.20882,7.92822
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.98788,3.68449
gpu_reorg,512,8,1,50,2,true,false,true,false,8.82777,8.52374
gpu_reorg,512,8,1,50,4,true,false,true,false,9.59452,9.28983
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.11418,3.86418
gpu_array,512,32,1,20,2,true,false,true,false,3.5371,3.28254
gpu_array,512,32,1,20,4,true,false,true,false,3.81602,3.56341
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.58189,3.34426
gpu_sparse,512,32,1,20,2,true,false,true,false,3.71612,3.47393
gpu_sparse,512,32,1,20,4,true,false,true,false,3.58971,3.34036
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.57327,4.29007
gpu_reorg,512,32,1,20,2,true,false,true,false,4.44992,4.15695
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,2.84078,2.74313
2.74313
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,3.19682,3.11089
3.11089
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,3.33639,3.25697
3.25697
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,3.42362,3.33312
3.33312
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.74313
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 156 seconds of which 3.73377 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.158291,0.0319889
gpu_array,512,8,1,20,2,true,false,true,false,0.181416,0.056416
gpu_array,512,8,1,20,4,true,false,true,false,0.171087,0.0402279
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.162367,0.0315072
gpu_sparse,512,8,1,20,2,true,false,true,false,0.178076,0.0478678
gpu_sparse,512,8,1,20,4,true,false,true,false,0.174512,0.0456055
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.182096,0.0395182
gpu_reorg,512,8,1,20,2,true,false,true,false,0.213405,0.0610612
gpu_reorg,512,8,1,20,4,true,false,true,false,0.198952,0.0498633
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.161576,0.0307161
gpu_array,512,8,1,50,2,true,false,true,false,0.17723,0.0431152
gpu_array,512,8,1,50,4,true,false,true,false,0.167933,0.0429329
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.15526,0.0296094
gpu_sparse,512,8,1,50,2,true,false,true,false,0.166243,0.0451497
gpu_sparse,512,8,1,50,4,true,false,true,false,0.173327,0.0450716
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.197116,0.0369596
gpu_reorg,512,8,1,50,2,true,false,true,false,0.210719,0.047959
gpu_reorg,512,8,1,50,4,true,false,true,false,0.204128,0.0478776
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.156628,0.0309766
gpu_array,512,32,1,20,2,true,false,true,false,0.161852,0.0296908
gpu_array,512,32,1,20,4,true,false,true,false,0.14958,0.0304395
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.156331,0.0300293
gpu_sparse,512,32,1,20,2,true,false,true,false,0.147093,0.0266504
gpu_sparse,512,32,1,20,4,true,false,true,false,0.146029,0.0294922
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.197653,0.0381478
gpu_reorg,512,32,1,20,2,true,false,true,false,0.186979,0.0352865
gpu_reorg,512,32,1,20,4,true,false,true,false,0.19931,0.0404557
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.146771,0.0256771
0.0256771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.15026,0.0298177
0.0298177
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.140801,0.0255664
0.0255664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.149255,0.0262077
0.0262077
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.146546,0.0306608
0.0306608
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.146478,0.0318945
0.0318945
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0255664
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.126407 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.162819,0.0319596
gpu_array,512,8,1,20,2,true,false,true,false,0.178919,0.0565234
gpu_array,512,8,1,20,4,true,false,true,false,0.169118,0.0402116
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.159225,0.0316211
gpu_sparse,512,8,1,20,2,true,false,true,false,0.174268,0.0479655
gpu_sparse,512,8,1,20,4,true,false,true,false,0.178441,0.0456283
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.188115,0.0396777
gpu_reorg,512,8,1,20,2,true,false,true,false,0.211423,0.0610319
gpu_reorg,512,8,1,20,4,true,false,true,false,0.194323,0.0497917
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.156416,0.030765
gpu_array,512,8,1,50,2,true,false,true,false,0.173298,0.0430892
gpu_array,512,8,1,50,4,true,false,true,false,0.172201,0.0432943
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.14875,0.0296094
gpu_sparse,512,8,1,50,2,true,false,true,false,0.162448,0.0452604
gpu_sparse,512,8,1,50,4,true,false,true,false,0.167487,0.0450911
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.187965,0.0369238
gpu_reorg,512,8,1,50,2,true,false,true,false,0.193327,0.0481445
gpu_reorg,512,8,1,50,4,true,false,true,false,0.197705,0.0479655
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.150114,0.0309733
gpu_array,512,32,1,20,2,true,false,true,false,0.157484,0.0298796
gpu_array,512,32,1,20,4,true,false,true,false,0.160677,0.0304687
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.158301,0.0300456
gpu_sparse,512,32,1,20,2,true,false,true,false,0.151735,0.026735
gpu_sparse,512,32,1,20,4,true,false,true,false,0.148942,0.0298014
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.189642,0.0386003
gpu_reorg,512,32,1,20,2,true,false,true,false,0.184587,0.035498
gpu_reorg,512,32,1,20,4,true,false,true,false,0.193757,0.0407617
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.147155,0.0260612
0.0260612
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.150625,0.0301823
0.0301823
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.154801,0.0258952
0.0258952
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.157939,0.026429
0.026429
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.154023,0.0309766
0.0309766
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.160938,0.0320312
0.0320312
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0258952
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.126863 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.120522,0.0668115
gpu_array,1024,8,1,20,2,true,false,true,false,0.101772,0.0500146
gpu_array,1024,8,1,20,4,true,false,true,false,0.102798,0.0490869
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.119458,0.0686768
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.123125,0.0694141
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.125894,0.0633936
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.168877,0.0848926
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.133677,0.0496924
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.139385,0.0544238
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.115088,0.0633301
gpu_array,1024,8,1,50,2,true,false,true,false,0.101045,0.0551465
gpu_array,1024,8,1,50,4,true,false,true,false,0.108804,0.0570459
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.116133,0.0673047
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.117051,0.0672461
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.119053,0.0672949
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.167002,0.0810645
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.140952,0.0540381
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.146162,0.0641309
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.122905,0.0691943
gpu_array,1024,32,1,20,2,true,false,true,false,0.111133,0.0554687
gpu_array,1024,32,1,20,4,true,false,true,false,0.111313,0.056626
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.124917,0.0721826
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.117329,0.0636182
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.11623,0.0625195
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.170112,0.0861279
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.153774,0.0668604
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.158809,0.0738477
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.100312,0.0534375
0.0534375
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.100122,0.0522705
0.0522705
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.10127,0.0524414
0.0524414
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.104019,0.0551904
0.0551904
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.103857,0.0550293
0.0550293
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.1052,0.0583252
0.0583252
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0490869
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.423147 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.122207,0.066543
gpu_array,1024,8,1,20,2,true,false,true,false,0.101685,0.0499268
gpu_array,1024,8,1,20,4,true,false,true,false,0.100708,0.0489502
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.12041,0.0686523
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.12333,0.0696191
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.11605,0.0633154
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.167822,0.0848145
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.13082,0.0497656
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.139424,0.0544629
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.116006,0.0632715
gpu_array,1024,8,1,50,2,true,false,true,false,0.105972,0.0551904
gpu_array,1024,8,1,50,4,true,false,true,false,0.11062,0.0569092
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.118188,0.0674072
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.11897,0.0672119
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.119092,0.067334
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.168037,0.081123
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.138203,0.0542188
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.147998,0.0640137
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.122969,0.0692578
gpu_array,1024,32,1,20,2,true,false,true,false,0.108315,0.0555811
gpu_array,1024,32,1,20,4,true,false,true,false,0.111294,0.0566064
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.124082,0.0723242
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.117627,0.063916
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.130894,0.0625342
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.17209,0.0861523
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.151113,0.0671289
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.161821,0.0739307
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.102285,0.053457
0.053457
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.100381,0.0525293
0.0525293
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.0995264,0.0526514
0.0526514
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.103228,0.055376
0.055376
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.103008,0.0551562
0.0551562
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.104448,0.0585498
0.0585498
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0489502
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.423502 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.07896,0.0174365
gpu_array,1024,8,1,20,2,true,false,true,false,0.0673047,0.0165234
gpu_array,1024,8,1,20,4,true,false,true,false,0.0679883,0.017207
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0785205,0.0179736
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0690234,0.0182422
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0759912,0.018374
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.0994238,0.0212988
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.0989063,0.016875
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.0969141,0.0178125
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.07854,0.0199463
gpu_array,1024,8,1,50,2,true,false,true,false,0.0775879,0.0199707
gpu_array,1024,8,1,50,4,true,false,true,false,0.0815771,0.0200537
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.070459,0.0206543
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0718701,0.0240186
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0826904,0.0240967
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.157178,0.0243652
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.117085,0.0243115
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.104082,0.0240039
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0685498,0.0158154
gpu_array,1024,32,1,20,2,true,false,true,false,0.0692285,0.014541
gpu_array,1024,32,1,20,4,true,false,true,false,0.0658984,0.0141406
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0757715,0.0162012
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.072915,0.0152979
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0780566,0.0155566
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.10334,0.020332
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.0953467,0.0162451
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.0960352,0.015957
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0551172,0.0141016
0.0141016
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0559912,0.0149756
0.0149756
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0559375,0.0149219
0.0149219
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0529053,0.0157959
0.0157959
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0583789,0.0183398
0.0183398
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0643701,0.0184717
0.0184717
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0141016
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.12367 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0750049,0.0173877
gpu_array,1024,8,1,20,2,true,false,true,false,0.0918164,0.0166211
gpu_array,1024,8,1,20,4,true,false,true,false,0.0758691,0.0172754
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0767188,0.018125
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0779053,0.018335
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.077998,0.0184277
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.118154,0.0214746
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.108818,0.0170215
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.111543,0.017793
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.0805127,0.0199658
gpu_array,1024,8,1,50,2,true,false,true,false,0.0775781,0.0199609
gpu_array,1024,8,1,50,4,true,false,true,false,0.0784668,0.019873
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0832422,0.0207422
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.083623,0.0240527
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0836963,0.024126
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.118184,0.0244336
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.11896,0.0242334
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.120923,0.0242432
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0755225,0.0159521
gpu_array,1024,32,1,20,2,true,false,true,false,0.0742578,0.0146875
gpu_array,1024,32,1,20,4,true,false,true,false,0.072832,0.0142383
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0757227,0.0161523
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0738965,0.0153027
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0760938,0.0155469
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.116904,0.0202246
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.111113,0.0163867
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.109878,0.0161279
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0638818,0.0140771
0.0140771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0620508,0.0151758
0.0151758
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0627881,0.0149365
0.0149365
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0666406,0.0158594
0.0158594
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,0.0665723,0.0177441
0.0177441
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,0.0655615,0.01771
0.01771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0140771
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.123743 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.569683,0.139995
gpu_array,1024,8,1,20,2,true,false,true,false,0.532212,0.105454
gpu_array,1024,8,1,20,4,true,false,true,false,0.538516,0.105898
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.568442,0.149497
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.50082,0.0848047
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.514824,0.0988086
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.629541,0.168604
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.589136,0.0989014
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.58645,0.0942627
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.511274,0.0874463
gpu_array,1024,8,1,50,2,true,false,true,false,0.48937,0.0635889
gpu_array,1024,8,1,50,4,true,false,true,false,0.488599,0.0677002
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.508989,0.0900439
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.506045,0.0802637
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.481616,0.0773193
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.585771,0.0974902
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.527246,0.0682617
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.564985,0.0737744
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.47083,0.0606738
0.0606738
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.497622,0.0884424
0.0884424
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.485176,0.0759961
0.0759961
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.595444,0.184312
0.184312
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0606738
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 20 seconds of which 0.442683 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.570723,0.140059
gpu_array,1024,8,1,20,2,true,false,true,false,0.537495,0.113667
gpu_array,1024,8,1,20,4,true,false,true,false,0.536372,0.105708
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.568296,0.149351
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.501563,0.0845703
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.517422,0.0984766
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.653535,0.168184
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.588984,0.09875
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.579326,0.0939746
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.506118,0.0871729
gpu_array,1024,8,1,50,2,true,false,true,false,0.481567,0.0635986
gpu_array,1024,8,1,50,4,true,false,true,false,0.484844,0.0678516
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.514614,0.0898096
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.508564,0.0808301
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.501836,0.0770312
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.562969,0.0971484
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.536855,0.0681055
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.564736,0.0735254
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.473301,0.0611914
0.0611914
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.498906,0.08875
0.08875
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.522104,0.111948
0.111948
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.591479,0.180347
0.180347
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0611914
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 20 seconds of which 0.45057 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.159297,0.0782422
gpu_array,1024,8,1,20,2,true,false,true,false,0.153799,0.0698145
gpu_array,1024,8,1,20,4,true,false,true,false,0.16646,0.0805225
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.221646,0.0810205
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.158447,0.0822754
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.166084,0.0899121
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.2927,0.107153
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.270723,0.0851758
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.29876,0.114189
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.244888,0.10231
gpu_array,1024,8,1,50,2,true,false,true,false,0.241777,0.0982227
gpu_array,1024,8,1,50,4,true,false,true,false,0.24623,0.105605
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.243525,0.0999707
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.247861,0.104307
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.251104,0.112432
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.290034,0.107417
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.286865,0.104248
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.294478,0.113813
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.164082,0.0898633
gpu_array,1024,32,1,20,2,true,false,true,false,0.172192,0.0843018
gpu_array,1024,32,1,20,4,true,false,true,false,0.170781,0.0848437
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.215103,0.0803369
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.164043,0.0878711
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.162065,0.0868701
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.275059,0.0963477
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.280146,0.0926465
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.296167,0.114526
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.121343,0.0500537
0.0500537
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.140464,0.064292
0.064292
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.130669,0.0544971
0.0544971
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.16188,0.0896143
0.0896143
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.137026,0.0618311
0.0618311
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.146689,0.069541
0.069541
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0500537
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.602945 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.162295,0.0783105
gpu_array,1024,8,1,20,2,true,false,true,false,0.152974,0.0699658
gpu_array,1024,8,1,20,4,true,false,true,false,0.159844,0.0807422
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.218525,0.0808301
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.167847,0.0819092
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.174868,0.0899072
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.289663,0.107046
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.276357,0.0849512
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.300884,0.11436
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.243721,0.102119
gpu_array,1024,8,1,50,2,true,false,true,false,0.238706,0.0980811
gpu_array,1024,8,1,50,4,true,false,true,false,0.245361,0.105713
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.242197,0.0996191
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.242153,0.103481
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.252031,0.112383
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.290981,0.107388
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.349746,0.104629
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.302427,0.11395
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.165566,0.0903711
gpu_array,1024,32,1,20,2,true,false,true,false,0.1679,0.0848926
gpu_array,1024,32,1,20,4,true,false,true,false,0.16021,0.0850146
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.219888,0.0802393
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.171084,0.0880762
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.163584,0.0874121
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.278232,0.0965918
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.275386,0.0927686
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.2925,0.114766
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.124277,0.0500586
0.0500586
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.137153,0.0648877
0.0648877
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.129766,0.0545703
0.0545703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.166519,0.0893701
0.0893701
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.132222,0.0619092
0.0619092
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.141934,0.069668
0.069668
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0500586
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.603337 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.953276,0.0372607
gpu_array,1024,8,1,20,2,false,false,true,false,0.939814,0.0364941
gpu_array,1024,8,1,20,4,false,false,true,false,0.967329,0.0444775
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.969692,0.0400049
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.956147,0.0391553
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.970552,0.0486768
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.972847,0.0451123
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.990845,0.0426025
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.983086,0.0485156
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.966636,0.0389014
gpu_array,1024,8,1,50,2,false,false,true,false,0.942778,0.0414111
gpu_array,1024,8,1,50,4,false,false,true,false,0.965122,0.0412939
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,0.958662,0.0397168
gpu_sparse,1024,8,1,50,2,false,false,true,false,0.965361,0.0473926
gpu_sparse,1024,8,1,50,4,false,false,true,false,0.960396,0.0473096
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.977886,0.0413623
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.952939,0.0447363
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.933579,0.0449072
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.950732,0.0366699
gpu_array,1024,32,1,20,2,false,false,true,false,0.94168,0.0354297
gpu_array,1024,32,1,20,4,false,false,true,false,0.944414,0.0381641
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.958472,0.0365967
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.943115,0.0358887
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.950937,0.0388281
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.991675,0.0434326
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.978633,0.0411328
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.96103,0.042085
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.929858,0.0353271
0.0353271
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.944761,0.0375342
0.0375342
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.934326,0.0358887
0.0358887
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0353271
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.251148 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.926113,0.0374414
gpu_array,1024,8,1,20,2,false,false,true,false,0.959277,0.0364258
gpu_array,1024,8,1,20,4,false,false,true,false,0.952598,0.0443945
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.957681,0.0377588
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.979961,0.0366016
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.966357,0.045459
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.93292,0.0422949
gpu_reorg,1024,8,1,20,2,false,false,true,false,1.00062,0.0426123
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.989097,0.048667
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.969668,0.0390039
gpu_array,1024,8,1,50,2,false,false,true,false,0.965195,0.0413672
gpu_array,1024,8,1,50,4,false,false,true,false,0.963296,0.0414209
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,0.938223,0.0397852
gpu_sparse,1024,8,1,50,2,false,false,true,false,0.986602,0.0471484
gpu_sparse,1024,8,1,50,4,false,false,true,false,0.954688,0.0474609
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.962642,0.0417432
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.998823,0.0447217
gpu_reorg,1024,8,1,50,4,false,false,true,false,1.00612,0.0451807
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.943945,0.0367188
gpu_array,1024,32,1,20,2,false,false,true,false,0.936738,0.0353711
gpu_array,1024,32,1,20,4,false,false,true,false,0.963086,0.0382813
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.960322,0.0364941
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.951616,0.0356006
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.972515,0.0389209
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.967007,0.0431787
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.963931,0.0410791
gpu_reorg,1024,32,1,20,4,false,false,true,false,1.00245,0.0424854
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.953384,0.035415
0.035415
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.935937,0.0375
0.0375
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.941167,0.0358936
0.0358936
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0353711
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.249124 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0933545,0.0181592
gpu_array,1024,8,1,20,2,true,false,true,false,0.1023,0.0173389
gpu_array,1024,8,1,20,4,true,false,true,false,0.0991357,0.0190576
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0946826,0.0185107
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0923682,0.019126
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0931592,0.019917
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.137578,0.0233203
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.12916,0.0188086
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.140562,0.0214209
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.10519,0.0212061
gpu_array,1024,8,1,50,2,true,false,true,false,0.0954248,0.0221826
gpu_array,1024,8,1,50,4,true,false,true,false,0.106021,0.0220361
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.106743,0.0217822
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.101836,0.0246875
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.108711,0.0247266
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.139014,0.026709
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.137656,0.0263281
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.135757,0.0263818
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0918457,0.0166504
gpu_array,1024,32,1,20,2,true,false,true,false,0.0959131,0.015835
gpu_array,1024,32,1,20,4,true,false,true,false,0.0888379,0.0155957
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0912842,0.0170654
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0982031,0.0161719
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.096665,0.0165869
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.126489,0.0219971
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.122305,0.0187891
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.162808,0.0192529
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0837061,0.0153467
0.0153467
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0867529,0.017417
0.017417
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0851563,0.0158203
0.0158203
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0840381,0.0166553
0.0166553
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0880176,0.0196582
0.0196582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0882471,0.0198877
0.0198877
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0153467
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.134027 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.102969,0.0180078
gpu_array,1024,8,1,20,2,true,false,true,false,0.102173,0.0172119
gpu_array,1024,8,1,20,4,true,false,true,false,0.105122,0.0191846
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.104443,0.0185059
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0923877,0.0191455
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.102065,0.0200342
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.134336,0.0230078
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.131069,0.0187646
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.12499,0.0214746
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.0983252,0.0211768
gpu_array,1024,8,1,50,2,true,false,true,false,0.105186,0.0221777
gpu_array,1024,8,1,50,4,true,false,true,false,0.104146,0.0221143
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.104727,0.0217187
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.109751,0.02479
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0921387,0.0247559
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.138843,0.0265381
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.138975,0.0256934
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.14168,0.0264453
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0996484,0.0166406
gpu_array,1024,32,1,20,2,true,false,true,false,0.0919385,0.0157666
gpu_array,1024,32,1,20,4,true,false,true,false,0.0919385,0.0157666
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0944092,0.0172607
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.100239,0.0162549
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.101616,0.0166553
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.13355,0.0222217
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.125376,0.0189307
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.134663,0.0194287
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.0824561,0.0150732
0.0150732
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.0811084,0.0166553
0.0166553
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0832617,0.0158789
0.0158789
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0861084,0.0167725
0.0167725
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0851465,0.0197168
0.0197168
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0863867,0.0199805
0.0199805
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0150732
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.133888 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.24531,3.05391
gpu_array,1024,8,1,20,2,true,false,true,false,4.85293,4.66934
gpu_array,1024,8,1,20,4,true,false,true,false,4.52621,4.3309
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.8525,2.71188
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.74281,4.5934
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.85377,4.7024
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.69004,3.48301
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.88699,6.66629
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.32223,5.1357
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.70139,3.50314
gpu_array,1024,8,1,50,2,true,false,true,false,4.58461,4.42836
gpu_array,1024,8,1,50,4,true,false,true,false,6.97979,6.81768
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.36076,3.20939
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.62117,4.46687
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.35021,6.18518
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.15561,3.93783
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.34859,7.11324
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.0764,9.8567
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.23699,3.05047
gpu_array,1024,32,1,20,2,true,false,true,false,3.44275,3.29236
gpu_array,1024,32,1,20,4,true,false,true,false,4.05822,3.91662
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.0867,2.94998
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.51643,3.37189
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.72885,3.58236
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,3.96631,3.76123
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.74572,4.55236
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.93836,2.85926
2.85926
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.00223,2.92215
2.92215
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.07855,1.99164
1.99164
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.21945,2.13645
2.13645
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99164
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 147 seconds of which 6.5153 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.19918,3.01559
gpu_array,1024,8,1,20,2,true,false,true,false,4.7577,4.56531
gpu_array,1024,8,1,20,4,true,false,true,false,4.62504,4.46781
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.85203,2.7075
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.83312,4.64367
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.67277,4.48137
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.66137,3.47191
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.85129,6.63645
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.22971,5.03439
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.83879,3.63957
gpu_array,1024,8,1,50,2,true,false,true,false,4.50131,4.35287
gpu_array,1024,8,1,50,4,true,false,true,false,6.86789,6.71457
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.35736,3.2099
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.62574,4.47145
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.48193,6.33154
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.1115,3.93084
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.23953,7.04422
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.1123,9.916
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.28879,3.14621
gpu_array,1024,32,1,20,2,true,false,true,false,3.43766,3.28824
gpu_array,1024,32,1,20,4,true,false,true,false,3.91461,3.77594
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.09059,2.94996
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.50863,3.36996
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.71361,3.56908
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,3.94332,3.74117
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.76949,4.58785
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.94322,2.86021
2.86021
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.06135,2.96955
2.96955
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.09078,1.99215
1.99215
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.23184,2.14004
2.14004
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99215
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 145 seconds of which 6.5037 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.109917,0.0171436
gpu_array,1024,8,1,20,2,true,false,true,false,0.117349,0.029458
gpu_array,1024,8,1,20,4,true,false,true,false,0.117729,0.0269092
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.107192,0.0173486
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.116074,0.0311133
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.118164,0.0322266
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.148081,0.0221045
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.150698,0.0344873
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.149014,0.0328027
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.216001,0.021665
gpu_array,1024,8,1,50,2,true,false,true,false,0.238247,0.0341455
gpu_array,1024,8,1,50,4,true,false,true,false,0.210005,0.0342236
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.196201,0.0213965
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.275264,0.0360059
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.226519,0.0360889
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.213413,0.0278662
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.293872,0.0399658
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.235288,0.0399756
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0914111,0.0162158
gpu_array,1024,32,1,20,2,true,false,true,false,0.0925195,0.0163477
gpu_array,1024,32,1,20,4,true,false,true,false,0.0993994,0.0173682
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.095249,0.0161475
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.090957,0.0167383
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.105903,0.0180127
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.137236,0.0210254
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.133535,0.0212305
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.154092,0.0251855
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.102764,0.0158496
0.0158496
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.106128,0.0182373
0.0182373
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.103677,0.0167627
0.0167627
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.115073,0.017417
0.017417
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.105542,0.0186279
0.0186279
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.106074,0.0191602
0.0191602
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0158496
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.165735 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.105176,0.0163086
gpu_array,1024,8,1,20,2,true,false,true,false,0.115547,0.0276563
gpu_array,1024,8,1,20,4,true,false,true,false,0.11603,0.02521
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.112344,0.0166406
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.121982,0.0311621
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.126084,0.032334
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.14835,0.022373
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.163643,0.0347363
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.160962,0.0330322
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.19166,0.0217383
gpu_array,1024,8,1,50,2,true,false,true,false,0.258857,0.034248
gpu_array,1024,8,1,50,4,true,false,true,false,0.212075,0.0343408
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.190327,0.0213818
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.265474,0.0359814
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.214727,0.0360156
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.208774,0.0281104
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.287866,0.0398193
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.238984,0.0397656
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.103184,0.0162695
gpu_array,1024,32,1,20,2,true,false,true,false,0.105059,0.0161914
gpu_array,1024,32,1,20,4,true,false,true,false,0.107046,0.0172021
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.108887,0.0161133
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.107432,0.0166113
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.106597,0.0177295
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.145952,0.0209521
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.152231,0.0213721
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.153906,0.025
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.102622,0.015708
0.015708
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.105898,0.0180078
0.0180078
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.10353,0.0166162
0.0166162
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.10521,0.0173193
0.0173193
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.0985742,0.0184961
0.0184961
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.106855,0.0189648
0.0189648
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.015708
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.164538 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0924341,0.0670435
gpu_array,2048,8,1,20,2,true,false,true,false,0.0839453,0.0566016
gpu_array,2048,8,1,20,4,true,false,true,false,0.0806689,0.0552783
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.109934,0.0840552
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0927246,0.0668457
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0943921,0.0675366
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.12396,0.0780615
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.100786,0.0558643
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0895093,0.0440991
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0840967,0.0582178
gpu_array,2048,8,1,50,2,true,false,true,false,0.0763306,0.0504517
gpu_array,2048,8,1,50,4,true,false,true,false,0.0815454,0.0517603
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0886206,0.0627417
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.088916,0.0625488
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0889038,0.0625366
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.119939,0.0755054
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0950928,0.0487061
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.101824,0.0564136
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0879761,0.0625854
gpu_array,2048,32,1,20,2,true,false,true,false,0.0770508,0.0511719
gpu_array,2048,32,1,20,4,true,false,true,false,0.0773584,0.0519678
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0910352,0.0656445
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0731152,0.0447949
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0752344,0.0478906
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.123503,0.0771167
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.108228,0.0618408
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.100276,0.0538892
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,true,0.0899536,0.0445435
0.0445435
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,true,0.0976904,0.0532568
0.0532568
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,0.0922119,0.04729
0.04729
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,0.0978149,0.0533813
0.0533813
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,true,0.097605,0.0536597
0.0536597
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,true,0.101082,0.0571362
0.0571362
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0440991
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.790707 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0926074,0.0672168
gpu_array,2048,8,1,20,2,true,false,true,false,0.0819385,0.0565479
gpu_array,2048,8,1,20,4,true,false,true,false,0.0811182,0.0552393
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.105208,0.0778638
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.09375,0.0668945
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0945776,0.0672339
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.123389,0.0779785
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.101716,0.0558179
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0905444,0.0441577
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0848389,0.0584717
gpu_array,2048,8,1,50,2,true,false,true,false,0.0758984,0.0505078
gpu_array,2048,8,1,50,4,true,false,true,false,0.078208,0.0518408
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0935034,0.0627417
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0899561,0.0626123
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.090459,0.062627
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.120513,0.0755908
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0946851,0.0487866
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.101992,0.056582
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0889673,0.0626001
gpu_array,2048,32,1,20,2,true,false,true,false,0.0765894,0.0511987
gpu_array,2048,32,1,20,4,true,false,true,false,0.078396,0.0520288
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0915137,0.0656348
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0711475,0.0447803
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0767236,0.047915
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.122927,0.0770288
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.108394,0.0620068
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.110059,0.0539063
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,true,0.0905566,0.0446582
0.0446582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,true,0.0972656,0.0533203
0.0533203
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,0.0931763,0.0472778
0.0472778
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,0.0982373,0.0533154
0.0533154
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,true,0.097583,0.0536377
0.0536377
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,true,0.101453,0.057019
0.057019
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0441577
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.788496 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0510718,0.0144507
gpu_array,2048,8,1,20,2,true,false,true,false,0.0502222,0.0140894
gpu_array,2048,8,1,20,4,true,false,true,false,0.0508813,0.0147485
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0517334,0.0151123
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0502368,0.014104
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.052312,0.0142261
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0747241,0.0175952
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0728223,0.0137402
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0731519,0.0155347
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0557886,0.0157495
gpu_array,2048,8,1,50,2,true,false,true,false,0.0548999,0.0163257
gpu_array,2048,8,1,50,4,true,false,true,false,0.0543579,0.016272
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0573926,0.0168652
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0571118,0.0185376
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0579736,0.0184229
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0780933,0.0194995
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0785962,0.0190259
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0791602,0.0191016
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0475586,0.0119141
gpu_array,2048,32,1,20,2,true,false,true,false,0.0488037,0.0107178
gpu_array,2048,32,1,20,4,true,false,true,false,0.045957,0.0108008
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0483154,0.0121826
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0481299,0.0105322
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.04698,0.0118237
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0727417,0.0161011
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0703345,0.0127173
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0702246,0.013584
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,32,1,20,2,true,false,true,true,0.0446997,0.0100317
0.0100317
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,32,1,20,2,false,false,true,true,0.0410107,0.0117139
0.0117139
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,0.0434204,0.0141235
0.0141235
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,0.0426807,0.0138721
0.0138721
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.0470264,0.0157764
0.0157764
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.0478711,0.0156445
0.0156445
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0100317
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.19863 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0500488,0.0134277
gpu_array,2048,8,1,20,2,true,false,true,false,0.0527246,0.0131738
gpu_array,2048,8,1,20,4,true,false,true,false,0.0519019,0.0138159
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0536694,0.0141187
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0493408,0.013208
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0484521,0.0132959
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0700732,0.0163623
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0727002,0.0136182
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0734863,0.0153809
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0537769,0.0156909
gpu_array,2048,8,1,50,2,true,false,true,false,0.0552979,0.0162354
gpu_array,2048,8,1,50,4,true,false,true,false,0.0554346,0.0163721
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.052915,0.0167822
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0580127,0.0184619
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0535986,0.0184424
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0823486,0.0193604
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0786914,0.0191211
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0775977,0.0190039
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0503882,0.011814
gpu_array,2048,32,1,20,2,true,false,true,false,0.0482642,0.0106665
gpu_array,2048,32,1,20,4,true,false,true,false,0.046936,0.0108032
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0502612,0.0121753
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0461914,0.0105469
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0474414,0.0117969
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0805225,0.0160693
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0726147,0.0125562
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0694678,0.0138037
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,32,1,20,2,true,false,true,true,0.0387451,0.00993652
0.00993652
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,32,1,20,2,false,false,true,true,0.0434253,0.011687
0.011687
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,0.0468188,0.014104
0.014104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,0.0426196,0.013811
0.013811
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.0440381,0.0157178
0.0157178
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.0449609,0.0156641
0.0156641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.00993652
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.195389 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.43688,0.106313
gpu_array,2048,8,1,20,2,true,false,true,false,0.431016,0.0799414
gpu_array,2048,8,1,20,4,true,false,true,false,0.420161,0.0803174
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.444263,0.113696
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.387947,0.0617749
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.398569,0.0738623
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.492905,0.128159
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.422898,0.0732886
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.425815,0.0698584
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.408284,0.0811353
gpu_array,2048,8,1,50,2,true,false,true,false,0.396306,0.0579272
gpu_array,2048,8,1,50,4,true,false,true,false,0.39572,0.0617358
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.414819,0.0847412
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.389065,0.0677759
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.404272,0.0702881
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.450908,0.0900684
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.425884,0.0586963
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.425908,0.0675098
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.385037,0.0539819
0.0539819
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.413494,0.082439
0.082439
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.386301,0.0567114
0.0567114
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.618735,0.290122
0.290122
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0539819
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.782477 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.44283,0.106404
gpu_array,2048,8,1,20,2,true,false,true,false,0.418909,0.0863892
gpu_array,2048,8,1,20,4,true,false,true,false,0.416401,0.0799756
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.445671,0.11364
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.393115,0.0620605
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.406475,0.0739551
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.500564,0.128005
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.434531,0.0732031
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.429033,0.0701465
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.421216,0.0813721
gpu_array,2048,8,1,50,2,true,false,true,false,0.397957,0.0581128
gpu_array,2048,8,1,50,4,true,false,true,false,0.399773,0.0618823
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.417693,0.0846851
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.398191,0.0676245
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.40719,0.0702759
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.478535,0.0898633
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.416553,0.0586426
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.428298,0.0674585
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.385374,0.0538306
0.0538306
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.410986,0.082373
0.082373
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,0.418794,0.0852979
0.0852979
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,0.589285,0.260183
0.260183
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0538306
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.78454 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.157588,0.0843457
gpu_array,2048,8,1,20,2,true,false,true,false,0.158835,0.0846167
gpu_array,2048,8,1,20,4,true,false,true,false,0.164065,0.0908228
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.173582,0.0920386
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.171343,0.0956592
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.166699,0.093457
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.198987,0.10426
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.19209,0.0963867
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.182744,0.0885059
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.182378,0.101812
gpu_array,2048,8,1,50,2,true,false,true,false,0.171772,0.0965771
gpu_array,2048,8,1,50,4,true,false,true,false,0.179456,0.103284
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.187507,0.0981519
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.176084,0.1004
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.187554,0.107964
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.195312,0.101074
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.189277,0.098457
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.202231,0.105552
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.153862,0.0801318
gpu_array,2048,32,1,20,2,true,false,true,false,0.159929,0.083269
gpu_array,2048,32,1,20,4,true,false,true,false,0.161333,0.0871143
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.162187,0.0791797
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.16344,0.0838501
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.162341,0.0886108
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.182939,0.0887012
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.184097,0.0903467
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.182249,0.0870337
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,0.103943,0.0546265
0.0546265
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,0.119399,0.070083
0.070083
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,0.112793,0.0639648
0.0639648
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,0.120271,0.0690015
0.0690015
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.113289,0.0639722
0.0639722
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.119883,0.0700781
0.0700781
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0546265
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 1.1892 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.162549,0.0844238
gpu_array,2048,8,1,20,2,true,false,true,false,0.161787,0.0846387
gpu_array,2048,8,1,20,4,true,false,true,false,0.168159,0.0910107
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.178801,0.0923755
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.170554,0.0958472
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.167112,0.0933813
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.201201,0.104033
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.202671,0.0967139
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.180659,0.0888623
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.180942,0.101841
gpu_array,2048,8,1,50,2,true,false,true,false,0.177083,0.0965161
gpu_array,2048,8,1,50,4,true,false,true,false,0.17842,0.103225
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.184897,0.0984717
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.177065,0.100405
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.188179,0.108101
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.200625,0.101016
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.192563,0.0983252
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.207671,0.10562
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.157961,0.0803247
gpu_array,2048,32,1,20,2,true,false,true,false,0.15844,0.0832446
gpu_array,2048,32,1,20,4,true,false,true,false,0.165806,0.0871924
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.162686,0.0791895
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.166443,0.0839233
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.1695,0.0884448
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.185002,0.088811
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.186492,0.0903003
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.18584,0.087207
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,0.103711,0.0548828
0.0548828
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,0.119521,0.0702051
0.0702051
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,0.112898,0.0640698
0.0640698
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,0.119023,0.0692187
0.0692187
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.113816,0.0640112
0.0640112
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.119395,0.0700781
0.0700781
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0548828
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 1.19026 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,0.828611,0.0488257
gpu_array,2048,8,1,20,2,false,false,true,false,0.830491,0.0472876
gpu_array,2048,8,1,20,4,false,false,true,false,0.84769,0.0488623
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,0.835095,0.0489624
gpu_sparse,2048,8,1,20,2,false,false,true,false,0.837595,0.0470679
gpu_sparse,2048,8,1,20,4,false,false,true,false,0.836965,0.0493677
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,0.858499,0.053811
gpu_reorg,2048,8,1,20,2,false,false,true,false,0.861318,0.0502832
gpu_reorg,2048,8,1,20,4,false,false,true,false,0.838408,0.0571582
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,0.820693,0.033584
gpu_array,2048,8,1,50,2,false,false,true,false,0.796772,0.035542
gpu_array,2048,8,1,50,4,false,false,true,false,0.807505,0.0355322
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,0.815007,0.0357104
gpu_sparse,2048,8,1,50,2,false,false,true,false,0.832661,0.0411572
gpu_sparse,2048,8,1,50,4,false,false,true,false,0.807673,0.0410718
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,1.01029,0.0391016
gpu_reorg,2048,8,1,50,2,false,false,true,false,1.0018,0.0403784
gpu_reorg,2048,8,1,50,4,false,false,true,false,0.877705,0.0403027
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,0.833362,0.0428345
gpu_array,2048,32,1,20,2,false,false,true,false,0.839114,0.0412622
gpu_array,2048,32,1,20,4,false,false,true,false,0.813228,0.0329541
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,0.838811,0.0429126
gpu_sparse,2048,32,1,20,2,false,false,true,false,0.826116,0.0414478
gpu_sparse,2048,32,1,20,4,false,false,true,false,0.813613,0.0333398
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,0.841265,0.050249
gpu_reorg,2048,32,1,20,2,false,false,true,false,0.851663,0.0479517
gpu_reorg,2048,32,1,20,4,false,false,true,false,0.818577,0.0387915
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,0.824644,0.0331396
0.0331396
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.806106,0.0316919
0.0316919
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.823552,0.0462085
0.0462085
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.0316919
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.522973 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,0.832134,0.0450244
gpu_array,2048,8,1,20,2,false,false,true,false,0.831282,0.0436841
gpu_array,2048,8,1,20,4,false,false,true,false,0.839536,0.0451025
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,0.826011,0.045249
gpu_sparse,2048,8,1,20,2,false,false,true,false,0.809587,0.0434741
gpu_sparse,2048,8,1,20,4,false,false,true,false,0.840044,0.0456104
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,0.839495,0.0499438
gpu_reorg,2048,8,1,20,2,false,false,true,false,0.85145,0.0501807
gpu_reorg,2048,8,1,20,4,false,false,true,false,0.858359,0.0570898
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,0.786455,0.0335254
gpu_array,2048,8,1,50,2,false,false,true,false,0.820244,0.0355762
gpu_array,2048,8,1,50,4,false,false,true,false,0.819775,0.0355957
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,0.820828,0.0356714
gpu_sparse,2048,8,1,50,2,false,false,true,false,0.834048,0.0410791
gpu_sparse,2048,8,1,50,4,false,false,true,false,0.831599,0.0410718
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,0.87644,0.0390381
gpu_reorg,2048,8,1,50,2,false,false,true,false,0.996855,0.0403125
gpu_reorg,2048,8,1,50,4,false,false,true,false,0.991545,0.0403735
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,0.833831,0.0428149
gpu_array,2048,32,1,20,2,false,false,true,false,0.82696,0.0413159
gpu_array,2048,32,1,20,4,false,false,true,false,0.831313,0.0329736
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,0.825525,0.0428101
gpu_sparse,2048,32,1,20,2,false,false,true,false,0.823201,0.0414624
gpu_sparse,2048,32,1,20,4,false,false,true,false,0.820371,0.0332617
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,0.843457,0.0495117
gpu_reorg,2048,32,1,20,2,false,false,true,false,0.850305,0.0475708
gpu_reorg,2048,32,1,20,4,false,false,true,false,0.84936,0.0388135
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,0.809937,0.0330811
0.0330811
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.813477,0.0317383
0.0317383
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.819583,0.046145
0.046145
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.0317383
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.511632 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0626099,0.0147583
gpu_array,2048,8,1,20,2,true,false,true,false,0.0641602,0.0143555
gpu_array,2048,8,1,20,4,true,false,true,false,0.0627271,0.0153638
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0648584,0.0160303
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0620728,0.015686
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.063728,0.0158765
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0803418,0.0193066
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0785034,0.0160034
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0815332,0.0209863
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0650342,0.0166943
gpu_array,2048,8,1,50,2,true,false,true,false,0.0651782,0.0168384
gpu_array,2048,8,1,50,4,true,false,true,false,0.0666553,0.0168506
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0684229,0.0176416
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0658569,0.0180054
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0657666,0.017915
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.125093,0.0215771
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.125737,0.0202686
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.123247,0.0202197
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0605811,0.0127295
gpu_array,2048,32,1,20,2,true,false,true,false,0.0634863,0.0117285
gpu_array,2048,32,1,20,4,true,false,true,false,0.0626514,0.0123584
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0611694,0.0133179
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0580933,0.0121948
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0598193,0.0114795
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0852051,0.0187988
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.083103,0.0152319
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.080625,0.0161719
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,32,1,20,4,true,false,true,true,0.05052,0.0109692
0.0109692
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,32,1,20,4,false,false,true,true,0.0513818,0.0118311
0.0118311
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,0.0563843,0.0148804
0.0148804
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,0.0534106,0.0143481
0.0143481
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.0571094,0.016582
0.016582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.0567969,0.0167578
0.0167578
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0109692
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.214531 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0680225,0.0138232
gpu_array,2048,8,1,20,2,true,false,true,false,0.0628076,0.0134912
gpu_array,2048,8,1,20,4,true,false,true,false,0.061709,0.0143457
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0603589,0.0149487
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0634351,0.0146069
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0621631,0.0147998
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0799414,0.0179297
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0813989,0.0159692
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.082561,0.0210376
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0673584,0.0165771
gpu_array,2048,8,1,50,2,true,false,true,false,0.066626,0.0168213
gpu_array,2048,8,1,50,4,true,false,true,false,0.0671362,0.0168433
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0688403,0.0175708
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0687109,0.0179297
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0662378,0.0178979
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.126472,0.0214917
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.125659,0.0201904
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.124211,0.0202075
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0683252,0.0126611
gpu_array,2048,32,1,20,2,true,false,true,false,0.0615283,0.0117236
gpu_array,2048,32,1,20,4,true,false,true,false,0.060166,0.0123145
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0601221,0.0132471
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0590747,0.0121997
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0607642,0.0114478
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0791699,0.018623
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0843823,0.0150464
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0832178,0.0163232
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,32,1,20,4,true,false,true,true,0.0498828,0.0108203
0.0108203
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,32,1,20,4,false,false,true,true,0.0513232,0.0117725
0.0117725
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,0.0542944,0.0147437
0.0147437
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,0.0532959,0.0142334
0.0142334
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.0554614,0.0163989
0.0163989
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.0562085,0.0166577
0.0166577
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0108203
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.210819 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,4.40114,4.29714
gpu_array,2048,8,1,20,2,true,false,true,false,5.08362,5.00354
gpu_array,2048,8,1,20,4,true,false,true,false,4.66366,4.57675
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,4.11511,4.0404
gpu_sparse,2048,8,1,20,2,true,false,true,false,5.19747,5.11935
gpu_sparse,2048,8,1,20,4,true,false,true,false,4.07489,4.00019
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,4.95256,4.85734
gpu_reorg,2048,8,1,20,2,true,false,true,false,5.42823,5.33253
gpu_reorg,2048,8,1,20,4,true,false,true,false,5.13711,5.04141
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,3.73793,3.65687
gpu_array,2048,8,1,50,2,true,false,true,false,4.43439,4.34504
gpu_array,2048,8,1,50,4,true,false,true,false,6.82008,6.72682
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,3.55296,3.46897
gpu_sparse,2048,8,1,50,2,true,false,true,false,4.42396,4.339
gpu_sparse,2048,8,1,50,4,true,false,true,false,6.21773,6.13424
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,4.22021,4.11328
gpu_reorg,2048,8,1,50,2,true,false,true,false,7.84193,7.73598
gpu_reorg,2048,8,1,50,4,true,false,true,false,10.175,10.071
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,3.65586,3.58018
gpu_array,2048,32,1,20,2,true,false,true,false,2.96987,2.88003
gpu_array,2048,32,1,20,4,true,false,true,false,3.06284,2.96128
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,3.14273,3.06656
gpu_sparse,2048,32,1,20,2,true,false,true,false,3.01563,2.94093
gpu_sparse,2048,32,1,20,4,true,false,true,false,2.92201,2.82191
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,4.18148,4.0892
gpu_reorg,2048,32,1,20,2,true,false,true,false,3.52617,3.42021
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,1.95579,1.92112
1.92112
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,2.09743,2.06276
2.06276
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,4,true,false,true,true,4.27481,4.23868
4.23868
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,4,false,false,true,true,6.18932,6.15367
6.15367
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.92112
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 168 seconds of which 13.6188 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,4.32631,4.2267
gpu_array,2048,8,1,20,2,true,false,true,false,5.07796,5.00179
gpu_array,2048,8,1,20,4,true,false,true,false,4.59841,4.51687
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,3.96669,3.89394
gpu_sparse,2048,8,1,20,2,true,false,true,false,5.19019,5.1106
gpu_sparse,2048,8,1,20,4,true,false,true,false,3.99584,3.9182
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,4.94329,4.8471
gpu_reorg,2048,8,1,20,2,true,false,true,false,5.48652,5.3874
gpu_reorg,2048,8,1,20,4,true,false,true,false,5.11277,5.01561
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,3.7479,3.66685
gpu_array,2048,8,1,50,2,true,false,true,false,4.4488,4.36042
gpu_array,2048,8,1,50,4,true,false,true,false,6.7792,6.69277
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,3.41153,3.32804
gpu_sparse,2048,8,1,50,2,true,false,true,false,4.40072,4.31576
gpu_sparse,2048,8,1,50,4,true,false,true,false,6.25802,6.16866
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,4.20732,4.10625
gpu_reorg,2048,8,1,50,2,true,false,true,false,7.88024,7.77526
gpu_reorg,2048,8,1,50,4,true,false,true,false,10.1518,10.0493
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,3.70902,3.63285
gpu_array,2048,32,1,20,2,true,false,true,false,2.93501,2.85835
gpu_array,2048,32,1,20,4,true,false,true,false,3.00838,2.93172
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,3.03588,2.96264
gpu_sparse,2048,32,1,20,2,true,false,true,false,3.02848,2.9484
gpu_sparse,2048,32,1,20,4,true,false,true,false,2.85631,2.78111
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,4.18184,4.08564
gpu_reorg,2048,32,1,20,2,true,false,true,false,3.4875,3.34932
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,1.96071,1.92604
1.92604
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,2.03324,2.00004
2.00004
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,2.22101,2.18683
2.18683
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,2.19548,2.1613
2.1613
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.92604
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 158 seconds of which 12.9235 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.162346,0.0134204
gpu_array,2048,8,1,20,2,true,false,true,false,0.182791,0.0250757
gpu_array,2048,8,1,20,4,true,false,true,false,0.178994,0.020791
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.170591,0.0148291
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.189082,0.0245313
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.17384,0.0244263
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.157039,0.0183667
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.199043,0.0315625
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.188494,0.0322437
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.184285,0.0168042
gpu_array,2048,8,1,50,2,true,false,true,false,0.175859,0.029375
gpu_array,2048,8,1,50,4,true,false,true,false,0.174043,0.0295117
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.149065,0.0167407
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.194104,0.0310181
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.168149,0.0309424
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.171433,0.0234839
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.217043,0.0344263
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.184941,0.0345508
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.151262,0.0121021
gpu_array,2048,32,1,20,2,true,false,true,false,0.167886,0.012124
gpu_array,2048,32,1,20,4,true,false,true,false,0.172034,0.012854
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.159124,0.0121509
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.174824,0.0127148
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.177219,0.013645
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.154031,0.017312
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.18887,0.0174829
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.165547,0.0215039
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,true,false,false,true,0.137273,0.0117847
0.0117847
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,false,false,false,true,0.15833,0.0137988
0.0137988
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,0.174561,0.0129395
0.0129395
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,0.160513,0.01354
0.01354
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.159421,0.0144019
0.0144019
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.15938,0.0148486
0.0148486
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0117847
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.272508 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.154702,0.0126123
gpu_array,2048,8,1,20,2,true,false,true,false,0.177202,0.0233936
gpu_array,2048,8,1,20,4,true,false,true,false,0.175107,0.0193457
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.142537,0.0136304
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.188767,0.0247046
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.167478,0.0244116
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.150955,0.0186304
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.211052,0.0323413
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.175662,0.0316187
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.144988,0.0165698
gpu_array,2048,8,1,50,2,true,false,true,false,0.187917,0.0292261
gpu_array,2048,8,1,50,4,true,false,true,false,0.163545,0.0292676
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.147114,0.0167432
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.176096,0.0310767
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.172029,0.0309155
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.16741,0.0233667
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.202917,0.0344604
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.187708,0.0343872
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.13906,0.0121069
gpu_array,2048,32,1,20,2,true,false,true,false,0.161494,0.0120801
gpu_array,2048,32,1,20,4,true,false,true,false,0.161697,0.012771
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.153701,0.0120996
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.167051,0.0127539
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.172739,0.0135596
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.151614,0.0173364
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.18915,0.0172754
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.163984,0.0214063
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.143113,0.0107886
0.0107886
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.166565,0.0142212
0.0142212
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,0.162866,0.0129639
0.0129639
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,0.162898,0.0134839
0.0134839
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.161511,0.0145386
0.0145386
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.164995,0.0146045
0.0146045
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0107886
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.2698 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.142659,0.123616
gpu_array,4096,32,1,2,2,true,false,true,false,0.100652,0.081853
gpu_array,4096,32,1,2,4,true,false,true,false,0.0778711,0.0593164
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.140093,0.122026
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0889868,0.070188
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0957544,0.0774438
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0789771,0.0599341
gpu_array,4096,32,1,10,2,true,false,true,false,0.0682349,0.0479712
gpu_array,4096,32,1,10,4,true,false,true,false,0.0606299,0.0423193
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0817896,0.0622583
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0704248,0.0501611
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0679541,0.0484229
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.151614,0.133059
gpu_array,4096,64,1,2,2,true,false,true,false,0.106541,0.0877417
gpu_array,4096,64,1,2,4,true,false,true,false,0.081189,0.0631226
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.151316,0.132273
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0885742,0.0700195
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0974585,0.0771948
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0810107,0.0600146
gpu_array,4096,64,1,10,2,true,false,true,false,0.0687915,0.0482837
gpu_array,4096,64,1,10,4,true,false,true,false,0.0586279,0.0383643
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0810156,0.0624609
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0619922,0.0431934
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0629492,0.0439063
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0545288,0.0371948
0.0371948
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0659155,0.0483374
0.0483374
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0608423,0.0432642
0.0432642
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0619263,0.0443481
0.0443481
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0704224,0.052356
0.052356
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.104629,0.0868066
0.0868066
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0371948
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.826348 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.142507,0.123708
gpu_array,4096,32,1,2,2,true,false,true,false,0.101677,0.0819019
gpu_array,4096,32,1,2,4,true,false,true,false,0.0809058,0.0594214
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.140427,0.122117
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0892358,0.0701929
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0969751,0.0774438
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.079707,0.0599316
gpu_array,4096,32,1,10,2,true,false,true,false,0.0655664,0.0479883
gpu_array,4096,32,1,10,4,true,false,true,false,0.0616748,0.0423877
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0820288,0.0622534
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0689331,0.0501343
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0662109,0.0486328
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.152349,0.133062
gpu_array,4096,64,1,2,2,true,false,true,false,0.10657,0.087771
gpu_array,4096,64,1,2,4,true,false,true,false,0.0814282,0.0633618
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.151292,0.132249
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0880322,0.0699658
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0959302,0.0771313
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0792896,0.0600024
gpu_array,4096,64,1,10,2,true,false,true,false,0.0675903,0.0483032
gpu_array,4096,64,1,10,4,true,false,true,false,0.0579297,0.0383984
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0800903,0.0625122
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0616992,0.0431445
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0624805,0.0439258
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0547754,0.0371973
0.0371973
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0661035,0.0482812
0.0482812
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0607251,0.043147
0.043147
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0619507,0.0443726
0.0443726
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0709326,0.0523779
0.0523779
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.10427,0.0864478
0.0864478
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0371973
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.826476 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0429028,0.0187329
gpu_array,4096,32,1,2,2,true,false,true,false,0.0385229,0.0150854
gpu_array,4096,32,1,2,4,true,false,true,false,0.0364551,0.0142383
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0452344,0.018623
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0365039,0.0103809
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0386206,0.0127417
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0344849,0.00909424
gpu_array,4096,32,1,10,2,true,false,true,false,0.0314014,0.00771973
gpu_array,4096,32,1,10,4,true,false,true,false,0.0312061,0.00752441
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0319971,0.00953613
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0303564,0.00691895
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0339795,0.00810059
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0413403,0.0186353
gpu_array,4096,64,1,2,2,true,false,true,false,0.0404199,0.0150293
gpu_array,4096,64,1,2,4,true,false,true,false,0.0377979,0.0141162
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0424146,0.0184888
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0364624,0.0103394
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0371362,0.0127222
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.033335,0.00916504
gpu_array,4096,64,1,10,2,true,false,true,false,0.033645,0.00776611
gpu_array,4096,64,1,10,4,true,false,true,false,0.0349878,0.00764404
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0357227,0.00959961
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0354175,0.00709717
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0330176,0.00738281
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0276611,0.00690918
0.00690918
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0300952,0.00909912
0.00909912
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0263721,0.00708496
0.00708496
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0299463,0.00919434
0.00919434
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,true,0.0298413,0.0103101
0.0103101
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,true,0.0371484,0.0163965
0.0163965
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00690918
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.137493 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0435962,0.0174731
gpu_array,4096,32,1,2,2,true,false,true,false,0.0414429,0.0140991
gpu_array,4096,32,1,2,4,true,false,true,false,0.0372021,0.0132764
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0437476,0.0173804
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0336084,0.00968262
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0375586,0.0119238
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.033064,0.00913818
gpu_array,4096,32,1,10,2,true,false,true,false,0.0329248,0.00777832
gpu_array,4096,32,1,10,4,true,false,true,false,0.0330005,0.00760986
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0354712,0.00959229
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0345264,0.00693848
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0352563,0.00815674
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0465405,0.0187085
gpu_array,4096,64,1,2,2,true,false,true,false,0.0431787,0.0151025
gpu_array,4096,64,1,2,4,true,false,true,false,0.0407715,0.0141602
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0460767,0.0184888
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0365112,0.0103882
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0369214,0.0127515
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0368311,0.00924316
gpu_array,4096,64,1,10,2,true,false,true,false,0.0356128,0.00778076
gpu_array,4096,64,1,10,4,true,false,true,false,0.0342676,0.00765625
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0342627,0.00960449
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0315771,0.00716309
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0347852,0.00744141
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0291943,0.00697754
0.00697754
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0296875,0.00917969
0.00917969
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0281372,0.00714111
0.00714111
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0294775,0.00921387
0.00921387
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0313647,0.0103687
0.0103687
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0378979,0.0164136
0.0164136
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00693848
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.135509 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.391497,0.100969
gpu_array,4096,8,1,20,2,true,false,true,false,0.359641,0.0749731
gpu_array,4096,8,1,20,4,true,false,true,false,0.363091,0.0754932
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.399519,0.108015
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.346812,0.0589697
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.352078,0.0698511
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.37418,0.0748633
gpu_array,4096,8,1,50,2,true,false,true,false,0.40646,0.0536768
gpu_array,4096,8,1,50,4,true,false,true,false,0.363711,0.0585352
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.430298,0.0780029
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.366772,0.0640381
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.415198,0.0641235
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.333745,0.0520068
0.0520068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.359905,0.0776782
0.0776782
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,true,false,true,true,0.332546,0.0530054
0.0530054
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,false,false,true,true,0.534858,0.256782
0.256782
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0520068
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.541075 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.385837,0.100925
gpu_array,4096,8,1,20,2,true,false,true,false,0.370234,0.0811719
gpu_array,4096,8,1,20,4,true,false,true,false,0.367737,0.0755005
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.394385,0.108008
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.342444,0.0589966
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.359434,0.0698828
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.382708,0.0746021
gpu_array,4096,8,1,50,2,true,false,true,false,0.359995,0.0538428
gpu_array,4096,8,1,50,4,true,false,true,false,0.363406,0.0584741
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.388074,0.0780151
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.371323,0.0641943
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.364202,0.0641528
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.332949,0.0516992
0.0516992
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.361135,0.077688
0.077688
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,true,false,true,true,0.362229,0.0802466
0.0802466
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,false,false,true,true,0.549834,0.269316
0.269316
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0516992
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.559807 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.150327,0.111265
gpu_array,4096,32,1,2,2,true,false,true,false,0.112236,0.073418
gpu_array,4096,32,1,2,4,true,false,true,false,0.095481,0.0561743
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.167981,0.108655
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.120725,0.0792212
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.109565,0.0705029
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.123257,0.0722314
gpu_array,4096,32,1,10,2,true,false,true,false,0.122905,0.0740771
gpu_array,4096,32,1,10,4,true,false,true,false,0.115051,0.06427
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.152239,0.0702075
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.144741,0.071499
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.116443,0.0659058
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.16186,0.124019
gpu_array,4096,64,1,2,2,true,false,true,false,0.117573,0.0804639
gpu_array,4096,64,1,2,4,true,false,true,false,0.102705,0.062666
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.17377,0.113223
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.121404,0.0806323
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.113086,0.0718262
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.122991,0.0741626
gpu_array,4096,64,1,10,2,true,false,true,false,0.122126,0.0735425
gpu_array,4096,64,1,10,4,true,false,true,false,0.11282,0.0617944
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.151746,0.0721558
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.121611,0.0727832
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.115034,0.0642529
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.111267,0.0751343
0.0751343
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.116643,0.0797778
0.0797778
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0763477,0.0392383
0.0392383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0988599,0.0622388
0.0622388
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.111799,0.0754224
0.0754224
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.118396,0.0825073
0.0825073
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0392383
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.935226 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.151707,0.111912
gpu_array,4096,32,1,2,2,true,false,true,false,0.110771,0.073418
gpu_array,4096,32,1,2,4,true,false,true,false,0.094082,0.0564844
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.168792,0.108
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.116829,0.0789868
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.109167,0.0703491
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.120005,0.0721533
gpu_array,4096,32,1,10,2,true,false,true,false,0.123684,0.0738794
gpu_array,4096,32,1,10,4,true,false,true,false,0.114102,0.0640527
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.149243,0.0701416
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.122102,0.0710767
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.116731,0.0657056
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.161106,0.12302
gpu_array,4096,64,1,2,2,true,false,true,false,0.12166,0.0801562
gpu_array,4096,64,1,2,4,true,false,true,false,0.0998047,0.0624512
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.172888,0.113318
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.119849,0.0802979
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.110071,0.0717407
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.122012,0.0734277
gpu_array,4096,64,1,10,2,true,false,true,false,0.121309,0.0732129
gpu_array,4096,64,1,10,4,true,false,true,false,0.109185,0.061333
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.144851,0.071853
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.124277,0.0722754
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.112751,0.0641675
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.112576,0.0757104
0.0757104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.116375,0.0797534
0.0797534
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0726538,0.0392065
0.0392065
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0989014,0.0622803
0.0622803
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.110576,0.0754199
0.0754199
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.1199,0.0825464
0.0825464
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0392065
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 0.933204 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.755916,0.0393628
gpu_array,4096,8,1,20,2,false,false,true,false,0.75699,0.0399487
gpu_array,4096,8,1,20,4,false,false,true,false,0.770427,0.0450854
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.765693,0.0408398
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.759998,0.0410034
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.783369,0.0455762
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.923901,0.0393799
gpu_array,4096,8,1,50,2,false,false,true,false,0.923325,0.0400244
gpu_array,4096,8,1,50,4,false,false,true,false,0.772471,0.0400488
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.919087,0.0401807
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.92925,0.0437524
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.784092,0.0436133
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.752085,0.0347998
gpu_array,4096,32,1,20,2,false,false,true,false,0.750862,0.0343091
gpu_array,4096,32,1,20,4,false,false,true,false,0.754204,0.0359424
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.753767,0.0350171
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.753945,0.0344629
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.76031,0.0364331
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.741824,0.0379663
0.0379663
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.742163,0.0400146
0.0400146
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.748469,0.0353345
0.0353345
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0343091
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.33714 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.758638,0.0396436
gpu_array,4096,8,1,20,2,false,false,true,false,0.758005,0.0399878
gpu_array,4096,8,1,20,4,false,false,true,false,0.762834,0.045061
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.753057,0.0406543
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.761873,0.0409253
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.764009,0.0452588
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.924409,0.0393994
gpu_array,4096,8,1,50,2,false,false,true,false,0.784973,0.0401001
gpu_array,4096,8,1,50,4,false,false,true,false,0.921909,0.0400732
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.773604,0.0402051
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.784023,0.0435449
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.78614,0.0437085
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.749143,0.0347876
gpu_array,4096,32,1,20,2,false,false,true,false,0.75749,0.0343457
gpu_array,4096,32,1,20,4,false,false,true,false,0.76075,0.035896
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.749858,0.0350146
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.760635,0.0345605
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.749285,0.036394
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.747676,0.037959
0.037959
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.746636,0.0354541
0.0354541
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.75876,0.0400098
0.0400098
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0343457
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.337094 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0579932,0.0189307
gpu_array,4096,32,1,2,2,true,false,true,false,0.0543384,0.0152759
gpu_array,4096,32,1,2,4,true,false,true,false,0.0492236,0.0143115
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.055813,0.0189478
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0467944,0.0106616
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0504028,0.0130493
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0463281,0.00970703
gpu_array,4096,32,1,10,2,true,false,true,false,0.0459058,0.00855225
gpu_array,4096,32,1,10,4,true,false,true,false,0.046604,0.00851807
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0484375,0.0103516
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0453833,0.00876221
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0475439,0.00872559
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0554687,0.0188477
gpu_array,4096,64,1,2,2,true,false,true,false,0.0545386,0.0152319
gpu_array,4096,64,1,2,4,true,false,true,false,0.051936,0.0145825
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0550537,0.0189209
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0468164,0.0106836
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.051792,0.0129736
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0485767,0.0097583
gpu_array,4096,64,1,10,2,true,false,true,false,0.0464771,0.00863525
gpu_array,4096,64,1,10,4,true,false,true,false,0.0466626,0.00857666
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0487256,0.0103955
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0455615,0.00771973
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0466626,0.00857666
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0377661,0.00773682
0.00773682
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0380762,0.00975586
0.00975586
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.0395557,0.00879395
0.00879395
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.038064,0.00925537
0.00925537
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0392017,0.0106372
0.0106372
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.045271,0.0169507
0.0169507
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00771973
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.144927 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0544263,0.017561
gpu_array,4096,32,1,2,2,true,false,true,false,0.0505322,0.0141553
gpu_array,4096,32,1,2,4,true,false,true,false,0.0529468,0.013396
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0546802,0.0175708
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0466138,0.00999268
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0481958,0.012063
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0455737,0.00968506
gpu_array,4096,32,1,10,2,true,false,true,false,0.0448901,0.00851318
gpu_array,4096,32,1,10,4,true,false,true,false,0.0460693,0.00847168
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0486597,0.0103296
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0451025,0.00872559
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.045144,0.00876709
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0565747,0.0189771
gpu_array,4096,64,1,2,2,true,false,true,false,0.0515063,0.0151294
gpu_array,4096,64,1,2,4,true,false,true,false,0.0516797,0.0143262
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0552759,0.0188989
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0500732,0.0107666
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0493042,0.0129272
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0471094,0.00975586
gpu_array,4096,64,1,10,2,true,false,true,false,0.0459253,0.00857178
gpu_array,4096,64,1,10,4,true,false,true,false,0.0446729,0.00854004
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0497119,0.0104053
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0433911,0.00774658
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0446313,0.00849854
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0367383,0.00768555
0.00768555
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0380298,0.00970947
0.00970947
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0374341,0.00862549
0.00862549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0388745,0.0100659
0.0100659
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0396973,0.0106445
0.0106445
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0460303,0.0169775
0.0169775
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00768555
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.142329 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.81093,4.77064
gpu_array,4096,32,1,2,2,true,false,true,false,3.18067,3.13648
gpu_array,4096,32,1,2,4,true,false,true,false,3.10122,3.05923
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.49956,4.46221
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.30557,3.26382
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.65343,2.61339
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.67299,3.62025
gpu_array,4096,32,1,10,2,true,false,true,false,2.9441,2.89112
gpu_array,4096,32,1,10,4,true,false,true,false,2.76555,2.71989
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.13118,3.09017
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.98939,2.94887
gpu_sparse,4096,32,1,10,4,true,false,true,false,2.98016,2.92718
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,3.9642,3.92343
gpu_array,4096,64,1,2,2,true,false,true,false,3.0041,2.95186
gpu_array,4096,64,1,2,4,true,false,true,false,2.90313,2.84819
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.75091,3.71209
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.03799,2.99648
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.62913,2.58958
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.61626,3.56377
gpu_array,4096,64,1,10,2,true,false,true,false,2.88022,2.83872
gpu_array,4096,64,1,10,4,true,false,true,false,3.00044,2.95186
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.72426,2.68373
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.93091,2.88086
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.74593,2.69051
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,2.09771,2.07599
2.07599
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,2.01792,1.99619
1.99619
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,2.16699,2.14526
2.14526
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,2.02416,2.00048
2.00048
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.99619
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 125 seconds of which 8.63767 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.71453,4.67327
gpu_array,4096,32,1,2,2,true,false,true,false,3.26354,3.21031
gpu_array,4096,32,1,2,4,true,false,true,false,3.17902,3.12434
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.50224,4.46269
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.30952,3.26802
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.65124,2.60925
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.71729,3.65552
gpu_array,4096,32,1,10,2,true,false,true,false,2.98697,2.94889
gpu_array,4096,32,1,10,4,true,false,true,false,2.79906,2.74657
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.11057,3.07321
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.95071,2.90481
gpu_sparse,4096,32,1,10,4,true,false,true,false,3.01356,2.97255
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,4.0141,3.97333
gpu_array,4096,64,1,2,2,true,false,true,false,2.99396,2.94293
gpu_array,4096,64,1,2,4,true,false,true,false,2.90235,2.8506
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.74389,3.70678
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.02012,2.98057
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.58289,2.54358
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.60938,3.56666
gpu_array,4096,64,1,10,2,true,false,true,false,2.83171,2.78923
gpu_array,4096,64,1,10,4,true,false,true,false,2.97379,2.93253
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.70941,2.67035
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.90269,2.86216
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.70541,2.66342
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,2.09407,2.07259
2.07259
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,1.99172,1.97023
1.97023
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,2.13289,2.11116
2.11116
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,1.9858,1.96383
1.96383
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.96383
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 130 seconds of which 8.62713 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.112981,0.0172778
gpu_array,4096,32,1,2,2,true,false,true,false,0.111887,0.0137427
gpu_array,4096,32,1,2,4,true,false,true,false,0.112441,0.0133203
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.118442,0.017124
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.102571,0.0105298
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.10875,0.0118262
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0972144,0.00883545
gpu_array,4096,32,1,10,2,true,false,true,false,0.10457,0.00837891
gpu_array,4096,32,1,10,4,true,false,true,false,0.100601,0.00807129
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.104634,0.0091748
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.102661,0.00866699
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.104895,0.00821533
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.111152,0.0171582
gpu_array,4096,64,1,2,2,true,false,true,false,0.108984,0.0137695
gpu_array,4096,64,1,2,4,true,false,true,false,0.110425,0.0132568
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.115605,0.0169727
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.108787,0.0106421
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.107212,0.0117529
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0994922,0.00891602
gpu_array,4096,64,1,10,2,true,false,true,false,0.104167,0.00846436
gpu_array,4096,64,1,10,4,true,false,true,false,0.106318,0.00817383
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.108435,0.00931396
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.109258,0.0094043
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.102087,0.00809326
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.107019,0.00789795
0.00789795
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.107046,0.0106104
0.0106104
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0977393,0.00789551
0.00789551
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.107607,0.011416
0.011416
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.0953271,0.0115869
0.0115869
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.11311,0.0156982
0.0156982
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00789551
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.137702 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.109243,0.0159814
gpu_array,4096,32,1,2,2,true,false,true,false,0.102971,0.0128833
gpu_array,4096,32,1,2,4,true,false,true,false,0.105396,0.0123779
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.116287,0.0159448
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.105266,0.00980713
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.106416,0.010957
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.106077,0.00890869
gpu_array,4096,32,1,10,2,true,false,true,false,0.106743,0.00835449
gpu_array,4096,32,1,10,4,true,false,true,false,0.108196,0.00809814
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.102336,0.00931885
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.108083,0.00871826
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.106357,0.00821289
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.1145,0.0170874
gpu_array,4096,64,1,2,2,true,false,true,false,0.108704,0.0137329
gpu_array,4096,64,1,2,4,true,false,true,false,0.10896,0.0132568
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.108816,0.017019
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.101367,0.0105469
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.110369,0.0117358
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.100488,0.00893555
gpu_array,4096,64,1,10,2,true,false,true,false,0.11436,0.00864746
gpu_array,4096,64,1,10,4,true,false,true,false,0.109431,0.00835693
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.105701,0.00926514
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.102732,0.00922607
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0995532,0.00800049
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,true,0.106589,0.00746826
0.00746826
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,true,0.103584,0.0103223
0.0103223
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.102859,0.0073999
0.0073999
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.113237,0.0109424
0.0109424
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.101914,0.0103613
0.0103613
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.114541,0.0178613
0.0178613
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.0073999
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.135057 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0747522,0.0638879
gpu_array,8192,32,1,2,2,true,false,true,false,0.0541687,0.0419617
gpu_array,8192,32,1,2,4,true,false,true,false,0.0452979,0.0346777
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0775708,0.0653638
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0548865,0.0424353
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0563,0.0437268
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0565625,0.04521
gpu_array,8192,32,1,10,2,true,false,true,false,0.0478333,0.0356262
gpu_array,8192,32,1,10,4,true,false,true,false,0.0446143,0.0326514
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0593579,0.0470288
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0510449,0.0383496
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0489453,0.0375928
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0817627,0.0696777
gpu_array,8192,64,1,2,2,true,false,true,false,0.0571838,0.0460754
gpu_array,8192,64,1,2,4,true,false,true,false,0.0523962,0.0395789
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0853186,0.0727454
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0563721,0.0450195
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0582092,0.0460022
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.058241,0.0453015
gpu_array,8192,64,1,10,2,true,false,true,false,0.0481177,0.0357886
gpu_array,8192,64,1,10,4,true,false,true,false,0.0475171,0.0357983
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0584204,0.0471899
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0526904,0.0406055
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0519458,0.0408374
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0449207,0.033446
0.033446
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0459851,0.0342664
0.0342664
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.051178,0.0399475
0.0399475
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0569397,0.045343
0.045343
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0472693,0.0355505
0.0355505
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0487585,0.0380164
0.0380164
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0326514
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 1.0811 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0759448,0.0638599
gpu_array,8192,32,1,2,2,true,false,true,false,0.0526953,0.0419531
gpu_array,8192,32,1,2,4,true,false,true,false,0.0466174,0.0346545
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0774695,0.0653845
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0536829,0.0424524
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0555627,0.0437219
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0572925,0.0452075
gpu_array,8192,32,1,10,2,true,false,true,false,0.047301,0.0355823
gpu_array,8192,32,1,10,4,true,false,true,false,0.044458,0.0326172
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.059823,0.0470056
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0501953,0.0383545
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0499158,0.0375867
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0818201,0.069613
gpu_array,8192,64,1,2,2,true,false,true,false,0.0581299,0.0460449
gpu_array,8192,64,1,2,4,true,false,true,false,0.051532,0.0395691
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0857031,0.0726416
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0579333,0.0449939
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0581873,0.0459802
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0611646,0.0452954
gpu_array,8192,64,1,10,2,true,false,true,false,0.048468,0.0357727
gpu_array,8192,64,1,10,4,true,false,true,false,0.0465625,0.0358203
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.059552,0.0472229
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0531726,0.0405994
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0529517,0.0408667
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0433813,0.0333716
0.0333716
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0457544,0.0342798
0.0342798
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0515515,0.0399548
0.0399548
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0565674,0.0453369
0.0453369
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0472632,0.0355444
0.0355444
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0496521,0.0380554
0.0380554
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0326172
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 1.08081 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0301941,0.00956421
gpu_array,8192,32,1,2,2,true,false,true,false,0.0282959,0.00766602
gpu_array,8192,32,1,2,4,true,false,true,false,0.0269751,0.00719971
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0306531,0.00965698
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0270471,0.00629517
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.027262,0.00675415
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0273706,0.00649658
gpu_array,8192,32,1,10,2,true,false,true,false,0.0258081,0.00542236
gpu_array,8192,32,1,10,4,true,false,true,false,0.0252661,0.00524658
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0267371,0.0068396
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0267017,0.0055835
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0256958,0.00579834
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0297839,0.00952026
gpu_array,8192,64,1,2,2,true,false,true,false,0.0287439,0.00762573
gpu_array,8192,64,1,2,4,true,false,true,false,0.0270605,0.00716309
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0308594,0.00974121
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0258191,0.00616577
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.027312,0.00692627
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0266785,0.00653687
gpu_array,8192,64,1,10,2,true,false,true,false,0.0256067,0.00546509
gpu_array,8192,64,1,10,4,true,false,true,false,0.0253271,0.00530762
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0273499,0.00684204
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0260645,0.00592285
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.026178,0.00603638
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0207996,0.00529663
0.00529663
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0220337,0.00567627
0.00567627
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0212146,0.00534546
0.00534546
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0218762,0.00564087
0.00564087
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.0235327,0.0075415
0.0075415
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.0231287,0.00762573
0.00762573
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00524658
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.166218 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0298584,0.0088623
gpu_array,8192,32,1,2,2,true,false,true,false,0.0279541,0.00708008
gpu_array,8192,32,1,2,4,true,false,true,false,0.0271716,0.00666382
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0298108,0.00893677
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0267249,0.00585083
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0267822,0.00627441
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0263684,0.00647095
gpu_array,8192,32,1,10,2,true,false,true,false,0.0260449,0.00541504
gpu_array,8192,32,1,10,4,true,false,true,false,0.0251514,0.00525391
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.026709,0.00681152
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.025957,0.00557129
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0271643,0.005802
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0302124,0.00946045
gpu_array,8192,64,1,2,2,true,false,true,false,0.0287036,0.00758545
gpu_array,8192,64,1,2,4,true,false,true,false,0.0275708,0.00718506
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0303674,0.00973755
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0266833,0.00617554
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0274548,0.00694702
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.027168,0.00653809
gpu_array,8192,64,1,10,2,true,false,true,false,0.0258289,0.00544312
gpu_array,8192,64,1,10,4,true,false,true,false,0.0253149,0.00529541
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0270935,0.00682983
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0269165,0.00592041
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0260754,0.00605591
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0206714,0.00529053
0.00529053
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0216882,0.00569702
0.00569702
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0209839,0.00535889
0.00535889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0216406,0.00564941
0.00564941
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0229333,0.00755249
0.00755249
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0233752,0.00762817
0.00762817
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00525391
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.163302 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.363512,0.0977649
gpu_array,8192,8,1,20,2,true,false,true,false,0.34688,0.0775928
gpu_array,8192,8,1,20,4,true,false,true,false,0.339261,0.0720496
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.371125,0.105745
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.324832,0.0568872
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.331528,0.0666357
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.33989,0.0725562
gpu_array,8192,8,1,50,2,true,false,true,false,0.320454,0.0517773
gpu_array,8192,8,1,50,4,true,false,true,false,0.321704,0.0560791
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.344851,0.0751978
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.336233,0.0662134
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.332388,0.062124
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.319008,0.055946
0.055946
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.338645,0.0742407
0.0742407
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.340435,0.0761523
0.0761523
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.559331,0.2898
0.2898
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0517773
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 1.11146 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.367299,0.0974011
gpu_array,8192,8,1,20,2,true,false,true,false,0.33853,0.0716846
gpu_array,8192,8,1,20,4,true,false,true,false,0.335901,0.0666138
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.37244,0.105717
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.32056,0.052738
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.336342,0.0666882
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.342516,0.0726184
gpu_array,8192,8,1,50,2,true,false,true,false,0.322169,0.0517834
gpu_array,8192,8,1,50,4,true,false,true,false,0.325065,0.0560217
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.342377,0.0751648
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.334415,0.0661047
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.329086,0.0621179
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.317941,0.0559778
0.0559778
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.338763,0.0742371
0.0742371
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.34141,0.0761511
0.0761511
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.550778,0.287472
0.287472
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0517834
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 1.09649 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.116648,0.0747778
gpu_array,8192,32,1,2,2,true,false,true,false,0.0980273,0.0562793
gpu_array,8192,32,1,2,4,true,false,true,false,0.0934277,0.0530225
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.133043,0.078844
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.104834,0.0625977
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.10474,0.0632361
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.108208,0.059502
gpu_array,8192,32,1,10,2,true,false,true,false,0.108281,0.0568896
gpu_array,8192,32,1,10,4,true,false,true,false,0.113351,0.0606165
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.12494,0.0574353
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.112399,0.0586877
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.115397,0.0609534
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.124353,0.0828491
gpu_array,8192,64,1,2,2,true,false,true,false,0.103068,0.0618079
gpu_array,8192,64,1,2,4,true,false,true,false,0.0978345,0.0566968
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.135692,0.0805164
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.106185,0.0646814
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.103976,0.0632043
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.115029,0.0602197
gpu_array,8192,64,1,10,2,true,false,true,false,0.105068,0.0566064
gpu_array,8192,64,1,10,4,true,false,true,false,0.109885,0.0598364
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.126819,0.0578491
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.108362,0.0596558
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.110522,0.0613281
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.110183,0.0706323
0.0706323
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.119558,0.0790308
0.0790308
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0714648,0.0321582
0.0321582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0969775,0.0564502
0.0564502
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.111929,0.0715234
0.0715234
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.122498,0.0817261
0.0817261
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0321582
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.55616 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.115801,0.0747852
gpu_array,8192,32,1,2,2,true,false,true,false,0.098291,0.0562988
gpu_array,8192,32,1,2,4,true,false,true,false,0.0951501,0.0530359
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.133291,0.0789697
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.104264,0.0626379
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.105477,0.063363
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.114817,0.0596411
gpu_array,8192,32,1,10,2,true,false,true,false,0.106216,0.0570215
gpu_array,8192,32,1,10,4,true,false,true,false,0.109687,0.0607373
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.121084,0.0577295
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.109438,0.0589014
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.116364,0.0610657
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.123973,0.0828357
gpu_array,8192,64,1,2,2,true,false,true,false,0.102958,0.0620642
gpu_array,8192,64,1,2,4,true,false,true,false,0.098573,0.056947
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.134653,0.080332
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.107352,0.0649939
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.106478,0.0636316
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.11416,0.0602051
gpu_array,8192,64,1,10,2,true,false,true,false,0.112024,0.0568481
gpu_array,8192,64,1,10,4,true,false,true,false,0.114886,0.0599548
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.120952,0.0579639
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.115612,0.0595813
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.110217,0.0615112
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.110403,0.07073
0.07073
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.119594,0.0789441
0.0789441
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.072627,0.0322217
0.0322217
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0968457,0.0565625
0.0565625
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.112072,0.0715442
0.0715442
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.122112,0.0815845
0.0815845
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0322217
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.55865 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.711534,0.0433215
gpu_array,8192,8,1,20,2,false,false,true,false,0.714513,0.0456897
gpu_array,8192,8,1,20,4,false,false,true,false,0.716404,0.0468481
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.709802,0.046106
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.711565,0.0488452
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.71531,0.0495386
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.717958,0.0365613
gpu_array,8192,8,1,50,2,false,false,true,false,0.717339,0.0411914
gpu_array,8192,8,1,50,4,false,false,true,false,0.72022,0.0411426
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.715132,0.0362988
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.847775,0.042843
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.724165,0.0428906
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.708254,0.042605
gpu_array,8192,32,1,20,2,false,false,true,false,0.715388,0.0424146
gpu_array,8192,32,1,20,4,false,false,true,false,0.70748,0.0391455
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.711715,0.0424036
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.709766,0.0424072
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.704352,0.03797
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.695398,0.0312134
0.0312134
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.700646,0.0393909
0.0393909
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.712072,0.0469104
0.0469104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0312134
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.725596 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.710074,0.0433264
gpu_array,8192,8,1,20,2,false,false,true,false,0.71797,0.0457288
gpu_array,8192,8,1,20,4,false,false,true,false,0.714644,0.0469189
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.71652,0.0461096
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.721785,0.048689
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.721799,0.0495581
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.836742,0.0363269
gpu_array,8192,8,1,50,2,false,false,true,false,0.72387,0.0411304
gpu_array,8192,8,1,50,4,false,false,true,false,0.843182,0.0411804
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.713625,0.0362573
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.842736,0.0428088
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.848102,0.042804
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.710464,0.0426172
gpu_array,8192,32,1,20,2,false,false,true,false,0.710941,0.0424841
gpu_array,8192,32,1,20,4,false,false,true,false,0.71186,0.0391309
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.715021,0.0424133
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.706426,0.0423633
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.709976,0.0379785
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.692612,0.0311133
0.0311133
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.707272,0.039425
0.039425
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.713595,0.0468469
0.0468469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0311133
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.725165 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0402063,0.00981079
gpu_array,8192,32,1,2,2,true,false,true,false,0.0387,0.00769409
gpu_array,8192,32,1,2,4,true,false,true,false,0.0384631,0.00733521
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0400146,0.00998535
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0379529,0.00694702
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0380127,0.00712891
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0382605,0.00688843
gpu_array,8192,32,1,10,2,true,false,true,false,0.037179,0.00592896
gpu_array,8192,32,1,10,4,true,false,true,false,0.0364124,0.00589478
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.038363,0.00735718
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0358691,0.00620605
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.037063,0.00630127
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0412512,0.00975708
gpu_array,8192,64,1,2,2,true,false,true,false,0.0402954,0.00782471
gpu_array,8192,64,1,2,4,true,false,true,false,0.0368262,0.00740723
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0405762,0.0101807
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0369507,0.00679932
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0382617,0.00737793
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0381641,0.00691406
gpu_array,8192,64,1,10,2,true,false,true,false,0.0372241,0.00597412
gpu_array,8192,64,1,10,4,true,false,true,false,0.036543,0.00590332
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0377551,0.00735962
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0359924,0.00645142
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0362451,0.00658203
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0293054,0.00586792
0.00586792
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0306921,0.00688843
0.00688843
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.029856,0.00593018
0.00593018
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0300659,0.0071167
0.0071167
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0312573,0.00769775
0.00769775
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.031925,0.00824341
0.00824341
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00586792
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.178384 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0394629,0.00906738
gpu_array,8192,32,1,2,2,true,false,true,false,0.037832,0.00719238
gpu_array,8192,32,1,2,4,true,false,true,false,0.0373816,0.00686401
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0396472,0.00925171
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0363135,0.00640625
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0376404,0.00663452
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0361768,0.0063916
gpu_array,8192,32,1,10,2,true,false,true,false,0.037157,0.00590698
gpu_array,8192,32,1,10,4,true,false,true,false,0.0354163,0.00587524
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0380945,0.00733276
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0369543,0.00619263
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0378052,0.00631104
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0408398,0.00971191
gpu_array,8192,64,1,2,2,true,false,true,false,0.0389258,0.00779785
gpu_array,8192,64,1,2,4,true,false,true,false,0.0383337,0.00744995
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0411951,0.0101892
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0377881,0.00678223
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0379187,0.00740112
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0390454,0.00694092
gpu_array,8192,64,1,10,2,true,false,true,false,0.0362292,0.00595581
gpu_array,8192,64,1,10,4,true,false,true,false,0.0369312,0.00592529
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0386377,0.0073877
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0372302,0.00646851
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0369653,0.00656982
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0300598,0.00588989
0.00588989
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0314319,0.00689575
0.00689575
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.029021,0.00594971
0.00594971
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0308887,0.00708496
0.00708496
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0318518,0.00768188
0.00768188
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0324048,0.00823486
0.00823486
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00587524
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.175099 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.40426,3.37631
gpu_array,8192,32,1,2,2,true,false,true,false,2.55505,2.52563
gpu_array,8192,32,1,2,4,true,false,true,false,2.53977,2.50913
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.27452,3.25218
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.69048,2.66778
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.51741,2.49483
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.66354,2.63779
gpu_array,8192,32,1,10,2,true,false,true,false,2.77321,2.74147
gpu_array,8192,32,1,10,4,true,false,true,false,2.8224,2.79713
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.56138,2.53709
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.77168,2.7469
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.69579,2.66795
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,2.99909,2.97467
gpu_array,8192,64,1,2,2,true,false,true,false,2.63652,2.61455
gpu_array,8192,64,1,2,4,true,false,true,false,2.6584,2.63582
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,2.95629,2.93395
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.73929,2.71573
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.57628,2.55358
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.73883,2.71417
gpu_array,8192,64,1,10,2,true,false,true,false,2.8305,2.79485
gpu_array,8192,64,1,10,4,true,false,true,false,3.11293,3.08827
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.65002,2.62744
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.80603,2.77087
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.67191,2.64566
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,true,false,true,true,2.07879,2.06353
2.06353
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,false,false,true,true,2.33254,2.31912
2.31912
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,true,false,false,true,1.8879,1.87227
1.87227
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,false,false,false,true,2.01019,1.99664
1.99664
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,true,false,true,true,2.22352,2.20851
2.20851
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,false,false,true,true,2.43332,2.41843
2.41843
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.87227
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 132 seconds of which 16.1592 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.37674,3.35086
gpu_array,8192,32,1,2,2,true,false,true,false,2.5927,2.56243
gpu_array,8192,32,1,2,4,true,false,true,false,2.54148,2.51878
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.26348,3.242
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.64575,2.62402
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.52254,2.49959
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.66868,2.64085
gpu_array,8192,32,1,10,2,true,false,true,false,2.76931,2.73513
gpu_array,8192,32,1,10,4,true,false,true,false,2.80001,2.7701
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.5577,2.53524
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.8065,2.77843
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.69394,2.66684
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.04551,3.01621
gpu_array,8192,64,1,2,2,true,false,true,false,2.66551,2.64183
gpu_array,8192,64,1,2,4,true,false,true,false,2.67442,2.65086
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,2.97619,2.95446
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.71125,2.68965
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.59166,2.56858
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.73843,2.70339
gpu_array,8192,64,1,10,2,true,false,true,false,2.78977,2.76157
gpu_array,8192,64,1,10,4,true,false,true,false,3.10023,3.06557
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.64947,2.62566
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.8364,2.80795
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.61449,2.58604
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,true,false,true,true,2.08337,2.0697
2.0697
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,false,false,true,true,2.30174,2.28783
2.28783
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,true,false,false,true,1.92961,1.91497
1.91497
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,false,false,false,true,1.97826,1.96336
1.96336
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,true,false,true,true,2.23255,2.21693
2.21693
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,false,false,true,true,2.43281,2.41743
2.41743
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.91497
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 133 seconds of which 16.1518 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0799158,0.0152185
gpu_array,8192,32,1,2,2,true,false,true,false,0.0731775,0.0118982
gpu_array,8192,32,1,2,4,true,false,true,false,0.0722717,0.0113586
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0811084,0.0151904
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0733423,0.00937744
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0753113,0.0102478
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0729468,0.00629639
gpu_array,8192,32,1,10,2,true,false,true,false,0.0699707,0.00588379
gpu_array,8192,32,1,10,4,true,false,true,false,0.0724646,0.00569214
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0695007,0.00651245
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0686511,0.00627319
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0694714,0.0058728
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0765686,0.0151672
gpu_array,8192,64,1,2,2,true,false,true,false,0.0776892,0.0118933
gpu_array,8192,64,1,2,4,true,false,true,false,0.0765735,0.01151
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0815881,0.015304
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0737146,0.00938354
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0741919,0.0102271
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0692432,0.00637695
gpu_array,8192,64,1,10,2,true,false,true,false,0.0699316,0.0059668
gpu_array,8192,64,1,10,4,true,false,true,false,0.0705676,0.00562622
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0689758,0.0065979
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0712231,0.00652588
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.070033,0.00631226
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0685974,0.00548706
0.00548706
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0705615,0.00806152
0.00806152
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0637207,0.00549316
0.00549316
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.072832,0.00764648
0.00764648
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0709814,0.0100684
0.0100684
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0787524,0.0158862
0.0158862
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00548706
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.223933 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0757275,0.014082
gpu_array,8192,32,1,2,2,true,false,true,false,0.074552,0.0110754
gpu_array,8192,32,1,2,4,true,false,true,false,0.0744153,0.0105725
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0768042,0.0140601
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0723511,0.00875244
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.07547,0.009552
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0690808,0.00584839
gpu_array,8192,32,1,10,2,true,false,true,false,0.0660254,0.00584473
gpu_array,8192,32,1,10,4,true,false,true,false,0.0665088,0.00571777
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0727368,0.00657471
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0714612,0.00627563
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0680945,0.00596069
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0760144,0.0152234
gpu_array,8192,64,1,2,2,true,false,true,false,0.0796667,0.0119177
gpu_array,8192,64,1,2,4,true,false,true,false,0.0751477,0.0115491
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0788696,0.015271
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0699622,0.00941528
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0752539,0.0101904
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0686206,0.00636475
gpu_array,8192,64,1,10,2,true,false,true,false,0.0684937,0.00599365
gpu_array,8192,64,1,10,4,true,false,true,false,0.0708911,0.00570557
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0713208,0.00662354
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0701392,0.00654053
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0743396,0.00634644
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0714465,0.00552856
0.00552856
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0687915,0.00800049
0.00800049
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.066145,0.00547607
0.00547607
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0704834,0.00761719
0.00761719
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0669275,0.0100427
0.0100427
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0797876,0.0159448
0.0159448
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00547607
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.219601 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
