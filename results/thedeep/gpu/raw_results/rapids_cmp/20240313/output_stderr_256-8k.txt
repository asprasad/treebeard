abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.408876,0.250951
gpu_array,256,8,1,20,2,true,false,true,false,0.28589,0.168145
gpu_array,256,8,1,20,4,true,false,true,false,0.274897,0.157151
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.372765,0.247207
gpu_sparse,256,8,1,20,2,true,false,true,false,0.25286,0.134556
gpu_sparse,256,8,1,20,4,true,false,true,false,0.280092,0.162347
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.434364,0.303225
gpu_reorg,256,8,1,20,2,true,false,true,false,0.295951,0.160907
gpu_reorg,256,8,1,20,4,true,false,true,false,0.269927,0.135999
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.266281,0.134026
gpu_array,256,8,1,50,2,true,false,true,false,0.228516,0.10519
gpu_array,256,8,1,50,4,true,false,true,false,0.240134,0.104531
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.26579,0.134651
gpu_sparse,256,8,1,50,2,true,false,true,false,0.242441,0.113535
gpu_sparse,256,8,1,50,4,true,false,true,false,0.238661,0.118125
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.317999,0.176258
gpu_reorg,256,8,1,50,2,true,false,true,false,0.244194,0.110823
gpu_reorg,256,8,1,50,4,true,false,true,false,0.246752,0.106127
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.362282,0.250675
gpu_array,256,32,1,20,2,true,false,true,false,0.276256,0.162416
gpu_array,256,32,1,20,4,true,false,true,false,0.268948,0.155667
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.3599,0.235458
gpu_sparse,256,32,1,20,2,true,false,true,false,0.275801,0.140198
gpu_sparse,256,32,1,20,4,true,false,true,false,0.290954,0.170419
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.458401,0.31945
gpu_reorg,256,32,1,20,2,true,false,true,false,0.31046,0.171509
gpu_reorg,256,32,1,20,4,true,false,true,false,0.291769,0.15226
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.193033,0.0903544
0.0903544
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.207681,0.0994224
0.0994224
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.28892,0.180103
0.180103
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.278334,0.172307
0.172307
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.293624,0.184249
0.184249
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.284099,0.176956
0.176956
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0903544
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 13 seconds of which 0.280842 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.360672,0.250181
gpu_array,256,8,1,20,2,true,false,true,false,0.280907,0.167626
gpu_array,256,8,1,20,4,true,false,true,false,0.28019,0.156864
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.366802,0.246825
gpu_sparse,256,8,1,20,2,true,false,true,false,0.255346,0.13481
gpu_sparse,256,8,1,20,4,true,false,true,false,0.29803,0.174146
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.46216,0.325441
gpu_reorg,256,8,1,20,2,true,false,true,false,0.309487,0.170536
gpu_reorg,256,8,1,20,4,true,false,true,false,0.271423,0.135262
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.26457,0.132874
gpu_array,256,8,1,50,2,true,false,true,false,0.239877,0.104275
gpu_array,256,8,1,50,4,true,false,true,false,0.235248,0.104668
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.264023,0.134559
gpu_sparse,256,8,1,50,2,true,false,true,false,0.244191,0.113052
gpu_sparse,256,8,1,50,4,true,false,true,false,0.246973,0.118066
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.31524,0.176289
gpu_reorg,256,8,1,50,2,true,false,true,false,0.251942,0.110759
gpu_reorg,256,8,1,50,4,true,false,true,false,0.247467,0.106283
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.363284,0.250561
gpu_array,256,32,1,20,2,true,false,true,false,0.279143,0.159724
gpu_array,256,32,1,20,4,true,false,true,false,0.272637,0.153775
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.355703,0.231819
gpu_sparse,256,32,1,20,2,true,false,true,false,0.259807,0.139272
gpu_sparse,256,32,1,20,4,true,false,true,false,0.26774,0.158923
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.424294,0.295388
gpu_reorg,256,32,1,20,2,true,false,true,false,0.295831,0.170831
gpu_reorg,256,32,1,20,4,true,false,true,false,0.290201,0.151808
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.187927,0.0902706
0.0902706
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.215028,0.109559
0.109559
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.274925,0.168898
0.168898
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.286551,0.172712
0.172712
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.287628,0.184392
0.184392
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.283926,0.177341
0.177341
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0902706
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.280463 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.179579,0.0584849
gpu_array,256,8,1,20,2,true,false,true,false,0.178298,0.05274
gpu_array,256,8,1,20,4,true,false,true,false,0.173027,0.0446791
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.186783,0.0584347
gpu_sparse,256,8,1,20,2,true,false,true,false,0.176638,0.0494057
gpu_sparse,256,8,1,20,4,true,false,true,false,0.179768,0.0469559
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.224682,0.0762444
gpu_reorg,256,8,1,20,2,true,false,true,false,0.20397,0.0549749
gpu_reorg,256,8,1,20,4,true,false,true,false,0.195045,0.0521875
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.186504,0.0497852
gpu_array,256,8,1,50,2,true,false,true,false,0.179515,0.046144
gpu_array,256,8,1,50,4,true,false,true,false,0.177648,0.0459515
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.187299,0.0500223
gpu_sparse,256,8,1,50,2,true,false,true,false,0.178371,0.0477902
gpu_sparse,256,8,1,50,4,true,false,true,false,0.173278,0.0477204
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.207458,0.0579046
gpu_reorg,256,8,1,50,2,true,false,true,false,0.20803,0.050106
gpu_reorg,256,8,1,50,4,true,false,true,false,0.198898,0.0504604
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.192905,0.0606501
gpu_array,256,32,1,20,2,true,false,true,false,0.187821,0.0544503
gpu_array,256,32,1,20,4,true,false,true,false,0.174515,0.0461663
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.19339,0.0600195
gpu_sparse,256,32,1,20,2,true,false,true,false,0.17346,0.0490179
gpu_sparse,256,32,1,20,4,true,false,true,false,0.177436,0.0479715
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.229807,0.0769057
gpu_reorg,256,32,1,20,2,true,false,true,false,0.213362,0.0559961
gpu_reorg,256,32,1,20,4,true,false,true,false,0.20375,0.0519643
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.16303,0.0458426
0.0458426
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.160455,0.0471735
0.0471735
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.15731,0.0445871
0.0445871
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.157586,0.0443052
0.0443052
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.152553,0.0448521
0.0448521
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.160873,0.047034
0.047034
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0443052
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 8 seconds of which 0.0879067 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.191066,0.0621596
gpu_array,256,8,1,20,2,true,false,true,false,0.189565,0.0561942
gpu_array,256,8,1,20,4,true,false,true,false,0.180254,0.0468834
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.192977,0.0618387
gpu_sparse,256,8,1,20,2,true,false,true,false,0.177667,0.0498772
gpu_sparse,256,8,1,20,4,true,false,true,false,0.176451,0.0475446
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.233064,0.0773717
gpu_reorg,256,8,1,20,2,true,false,true,false,0.210134,0.055558
gpu_reorg,256,8,1,20,4,true,false,true,false,0.20293,0.0533761
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.184978,0.0504911
gpu_array,256,8,1,50,2,true,false,true,false,0.174272,0.0464816
gpu_array,256,8,1,50,4,true,false,true,false,0.174381,0.0465904
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.179104,0.0507561
gpu_sparse,256,8,1,50,2,true,false,true,false,0.178719,0.048139
gpu_sparse,256,8,1,50,4,true,false,true,false,0.179261,0.0481222
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.205979,0.0586579
gpu_reorg,256,8,1,50,2,true,false,true,false,0.202065,0.050279
gpu_reorg,256,8,1,50,4,true,false,true,false,0.204311,0.050851
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.202958,0.0606585
gpu_array,256,32,1,20,2,true,false,true,false,0.196844,0.0545452
gpu_array,256,32,1,20,4,true,false,true,false,0.181959,0.046356
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.199431,0.0599219
gpu_sparse,256,32,1,20,2,true,false,true,false,0.182349,0.0489788
gpu_sparse,256,32,1,20,4,true,false,true,false,0.183546,0.0479436
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.228764,0.0758622
gpu_reorg,256,32,1,20,2,true,false,true,false,0.20695,0.0557227
gpu_reorg,256,32,1,20,4,true,false,true,false,0.204018,0.0511161
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.154927,0.0449944
0.0449944
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.156353,0.0469782
0.0469782
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.156166,0.0445592
0.0445592
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.158039,0.0441992
0.0441992
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.150165,0.0458119
0.0458119
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.159911,0.0471875
0.0471875
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0441992
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0888836 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.777935,0.310301
gpu_array,256,8,1,20,2,true,false,true,false,0.724116,0.239741
gpu_array,256,8,1,20,4,true,false,true,false,0.689495,0.222419
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.821069,0.325533
gpu_sparse,256,8,1,20,2,true,false,true,false,0.628608,0.158742
gpu_sparse,256,8,1,20,4,true,false,true,false,0.736214,0.21445
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.27273,0.397732
gpu_reorg,256,8,1,20,2,true,false,true,false,1.07086,0.210926
gpu_reorg,256,8,1,20,4,true,false,true,false,1.05177,0.199096
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.666211,0.182394
gpu_array,256,8,1,50,2,true,false,true,false,0.621655,0.138954
gpu_array,256,8,1,50,4,true,false,true,false,0.602645,0.118828
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.653273,0.181733
gpu_sparse,256,8,1,50,2,true,false,true,false,0.605767,0.12195
gpu_sparse,256,8,1,50,4,true,false,true,false,0.611046,0.13002
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.09953,0.216158
gpu_reorg,256,8,1,50,2,true,false,true,false,0.992997,0.128599
gpu_reorg,256,8,1,50,4,true,false,true,false,0.981169,0.121236
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.551549,0.100098
0.100098
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.595709,0.141468
0.141468
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.708708,0.253351
0.253351
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.739104,0.279841
0.279841
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.100098
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.224951 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.774467,0.310181
gpu_array,256,8,1,20,2,true,false,true,false,0.720195,0.239169
gpu_array,256,8,1,20,4,true,false,true,false,0.688585,0.222626
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.803535,0.327531
gpu_sparse,256,8,1,20,2,true,false,true,false,0.628627,0.158761
gpu_sparse,256,8,1,20,4,true,false,true,false,0.698574,0.214757
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.25277,0.405117
gpu_reorg,256,8,1,20,2,true,false,true,false,1.06126,0.210818
gpu_reorg,256,8,1,20,4,true,false,true,false,1.05079,0.19923
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.65363,0.18209
gpu_array,256,8,1,50,2,true,false,true,false,0.620848,0.138705
gpu_array,256,8,1,50,4,true,false,true,false,0.695151,0.118142
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.652662,0.18168
gpu_sparse,256,8,1,50,2,true,false,true,false,0.601094,0.121741
gpu_sparse,256,8,1,50,4,true,false,true,false,0.603181,0.130525
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.08847,0.215698
gpu_reorg,256,8,1,50,2,true,false,true,false,1.02097,0.128108
gpu_reorg,256,8,1,50,4,true,false,true,false,0.984799,0.121518
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.55382,0.100137
0.100137
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.59887,0.141281
0.141281
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.734782,0.253198
0.253198
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.737907,0.280318
0.280318
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.100137
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.225348 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.406077,0.252617
gpu_array,256,8,1,20,2,true,false,true,false,0.311197,0.160527
gpu_array,256,8,1,20,4,true,false,true,false,0.287252,0.137698
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.395988,0.240854
gpu_sparse,256,8,1,20,2,true,false,true,false,0.332026,0.176334
gpu_sparse,256,8,1,20,4,true,false,true,false,0.315017,0.167137
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.483267,0.330924
gpu_reorg,256,8,1,20,2,true,false,true,false,0.349568,0.202804
gpu_reorg,256,8,1,20,4,true,false,true,false,0.344283,0.190823
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.613831,0.189166
gpu_array,256,8,1,50,2,true,false,true,false,0.58615,0.165949
gpu_array,256,8,1,50,4,true,false,true,false,0.598747,0.17185
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.335352,0.181892
gpu_sparse,256,8,1,50,2,true,false,true,false,0.6101,0.178181
gpu_sparse,256,8,1,50,4,true,false,true,false,0.630882,0.172176
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.360438,0.205862
gpu_reorg,256,8,1,50,2,true,false,true,false,0.337771,0.17594
gpu_reorg,256,8,1,50,4,true,false,true,false,0.322701,0.167567
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.412963,0.262852
gpu_array,256,32,1,20,2,true,false,true,false,0.32716,0.17928
gpu_array,256,32,1,20,4,true,false,true,false,0.312852,0.164972
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.399194,0.24964
gpu_sparse,256,32,1,20,2,true,false,true,false,0.336574,0.185904
gpu_sparse,256,32,1,20,4,true,false,true,false,0.324855,0.18144
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.431451,0.285804
gpu_reorg,256,32,1,20,2,true,false,true,false,0.37248,0.215672
gpu_reorg,256,32,1,20,4,true,false,true,false,0.373633,0.215151
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.31168,0.165474
0.165474
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.312997,0.17572
0.17572
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.31125,0.172299
0.172299
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.371504,0.231995
0.231995
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.252497,0.116895
0.116895
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.286747,0.14947
0.14947
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.116895
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 19 seconds of which 0.328748 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.401401,0.252963
gpu_array,256,8,1,20,2,true,false,true,false,0.302503,0.160204
gpu_array,256,8,1,20,4,true,false,true,false,0.285039,0.137718
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.392584,0.240798
gpu_sparse,256,8,1,20,2,true,false,true,false,0.306345,0.164046
gpu_sparse,256,8,1,20,4,true,false,true,false,0.299682,0.155151
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.454428,0.305991
gpu_reorg,256,8,1,20,2,true,false,true,false,0.336719,0.187723
gpu_reorg,256,8,1,20,4,true,false,true,false,0.336989,0.176833
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.584891,0.175851
gpu_array,256,8,1,50,2,true,false,true,false,0.578956,0.165452
gpu_array,256,8,1,50,4,true,false,true,false,0.575778,0.170645
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.394902,0.180617
gpu_sparse,256,8,1,50,2,true,false,true,false,0.587059,0.178019
gpu_sparse,256,8,1,50,4,true,false,true,false,0.592377,0.171618
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.356013,0.204785
gpu_reorg,256,8,1,50,2,true,false,true,false,0.326077,0.175407
gpu_reorg,256,8,1,50,4,true,false,true,false,0.321124,0.166549
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.396429,0.261942
gpu_array,256,32,1,20,2,true,false,true,false,0.315413,0.168092
gpu_array,256,32,1,20,4,true,false,true,false,0.305656,0.154986
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.365977,0.233722
gpu_sparse,256,32,1,20,2,true,false,true,false,0.325349,0.18863
gpu_sparse,256,32,1,20,4,true,false,true,false,0.334269,0.184157
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.440114,0.288887
gpu_reorg,256,32,1,20,2,true,false,true,false,0.365424,0.21029
gpu_reorg,256,32,1,20,4,true,false,true,false,0.36055,0.208764
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.294297,0.161484
0.161484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.315315,0.17469
0.17469
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.305742,0.171256
0.171256
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.347737,0.223853
0.223853
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.240812,0.115812
0.115812
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.277193,0.148845
0.148845
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.115812
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.320808 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.05311,0.0787779
gpu_array,256,8,1,20,2,false,false,true,false,1.05693,0.071995
gpu_array,256,8,1,20,4,false,false,true,false,1.04538,0.0576535
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.05954,0.077394
gpu_sparse,256,8,1,20,2,false,false,true,false,1.05331,0.0717243
gpu_sparse,256,8,1,20,4,false,false,true,false,1.07285,0.0655999
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.06742,0.085279
gpu_reorg,256,8,1,20,2,false,false,true,false,1.07134,0.0763672
gpu_reorg,256,8,1,20,4,false,false,true,false,1.07184,0.0679297
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.07104,0.0643415
gpu_array,256,8,1,50,2,false,false,true,false,1.04365,0.0598298
gpu_array,256,8,1,50,4,false,false,true,false,1.0485,0.0596568
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.06376,0.0648772
gpu_sparse,256,8,1,50,2,false,false,true,false,1.07225,0.0744838
gpu_sparse,256,8,1,50,4,false,false,true,false,1.06352,0.0746819
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.07015,0.0707031
gpu_reorg,256,8,1,50,2,false,false,true,false,1.09488,0.0664202
gpu_reorg,256,8,1,50,4,false,false,true,false,1.08618,0.0672098
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.07197,0.085918
gpu_array,256,32,1,20,2,false,false,true,false,1.12514,0.0810575
gpu_array,256,32,1,20,4,false,false,true,false,1.06045,0.0738393
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.07321,0.0843694
gpu_sparse,256,32,1,20,2,false,false,true,false,1.20323,0.0799051
gpu_sparse,256,32,1,20,4,false,false,true,false,1.0679,0.075159
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.10538,0.0897517
gpu_reorg,256,32,1,20,2,false,false,true,false,1.09025,0.0824358
gpu_reorg,256,32,1,20,4,false,false,true,false,1.08681,0.0756529
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.0091,0.0576451
0.0576451
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.02379,0.0555943
0.0555943
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.02057,0.0713477
0.0713477
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0555943
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.110981 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.05672,0.0779297
gpu_array,256,8,1,20,2,false,false,true,false,1.06627,0.0718499
gpu_array,256,8,1,20,4,false,false,true,false,1.05789,0.0578906
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.07357,0.0774721
gpu_sparse,256,8,1,20,2,false,false,true,false,1.06778,0.0716825
gpu_sparse,256,8,1,20,4,false,false,true,false,1.05235,0.0657478
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.10382,0.0854018
gpu_reorg,256,8,1,20,2,false,false,true,false,1.10348,0.0772517
gpu_reorg,256,8,1,20,4,false,false,true,false,1.07591,0.0675363
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.0488,0.0649833
gpu_array,256,8,1,50,2,false,false,true,false,1.04435,0.0599749
gpu_array,256,8,1,50,4,false,false,true,false,1.04648,0.0598689
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.05717,0.0649777
gpu_sparse,256,8,1,50,2,false,false,true,false,1.07272,0.0755078
gpu_sparse,256,8,1,50,4,false,false,true,false,1.05901,0.0746345
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.07897,0.0706027
gpu_reorg,256,8,1,50,2,false,false,true,false,1.07636,0.0668778
gpu_reorg,256,8,1,50,4,false,false,true,false,1.09706,0.0674888
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.07605,0.086091
gpu_array,256,32,1,20,2,false,false,true,false,1.06639,0.0803376
gpu_array,256,32,1,20,4,false,false,true,false,1.06632,0.0730162
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.09285,0.0844782
gpu_sparse,256,32,1,20,2,false,false,true,false,1.07876,0.0804325
gpu_sparse,256,32,1,20,4,false,false,true,false,1.06417,0.0753265
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.08734,0.0901283
gpu_reorg,256,32,1,20,2,false,false,true,false,1.08192,0.0824777
gpu_reorg,256,32,1,20,4,false,false,true,false,1.06924,0.0753795
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.01202,0.0577762
0.0577762
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.02259,0.0566267
0.0566267
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.03136,0.0709766
0.0709766
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0566267
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.111141 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.197567,0.0597321
gpu_array,256,8,1,20,2,true,false,true,false,0.1888,0.0537556
gpu_array,256,8,1,20,4,true,false,true,false,0.191892,0.0456864
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.208839,0.063192
gpu_sparse,256,8,1,20,2,true,false,true,false,0.185935,0.050332
gpu_sparse,256,8,1,20,4,true,false,true,false,0.180756,0.0479436
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.237349,0.0783092
gpu_reorg,256,8,1,20,2,true,false,true,false,0.219344,0.057514
gpu_reorg,256,8,1,20,4,true,false,true,false,0.206097,0.0537528
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.196306,0.0517746
gpu_array,256,8,1,50,2,true,false,true,false,0.179947,0.0476925
gpu_array,256,8,1,50,4,true,false,true,false,0.188943,0.0477595
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.190915,0.0519643
gpu_sparse,256,8,1,50,2,true,false,true,false,0.186568,0.0487333
gpu_sparse,256,8,1,50,4,true,false,true,false,0.188237,0.0487277
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.222913,0.0599665
gpu_reorg,256,8,1,50,2,true,false,true,false,0.22721,0.0525446
gpu_reorg,256,8,1,50,4,true,false,true,false,0.216523,0.0524609
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.200614,0.0611049
gpu_array,256,32,1,20,2,true,false,true,false,0.192871,0.0550363
gpu_array,256,32,1,20,4,true,false,true,false,0.186828,0.0484347
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.204925,0.0603934
gpu_sparse,256,32,1,20,2,true,false,true,false,0.189364,0.0498549
gpu_sparse,256,32,1,20,4,true,false,true,false,0.189004,0.049495
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.234584,0.0783343
gpu_reorg,256,32,1,20,2,true,false,true,false,0.216889,0.0578488
gpu_reorg,256,32,1,20,4,true,false,true,false,0.212533,0.0540513
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.17183,0.0462723
0.0462723
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.167824,0.047846
0.047846
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.171359,0.0452427
0.0452427
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.176228,0.0450893
0.0450893
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.167104,0.0471261
0.0471261
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.167935,0.0501897
0.0501897
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0450893
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.0905299 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.203691,0.0630664
gpu_array,256,8,1,20,2,true,false,true,false,0.193878,0.0566016
gpu_array,256,8,1,20,4,true,false,true,false,0.183842,0.0476814
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.205672,0.0628153
gpu_sparse,256,8,1,20,2,true,false,true,false,0.190631,0.0505636
gpu_sparse,256,8,1,20,4,true,false,true,false,0.182196,0.0488253
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.23022,0.0778767
gpu_reorg,256,8,1,20,2,true,false,true,false,0.215209,0.0567271
gpu_reorg,256,8,1,20,4,true,false,true,false,0.212333,0.0538504
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.189757,0.0519224
gpu_array,256,8,1,50,2,true,false,true,false,0.181875,0.0479464
gpu_array,256,8,1,50,4,true,false,true,false,0.185126,0.0478488
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.20339,0.0516044
gpu_sparse,256,8,1,50,2,true,false,true,false,0.1912,0.0489007
gpu_sparse,256,8,1,50,4,true,false,true,false,0.179997,0.0488588
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.212185,0.059841
gpu_reorg,256,8,1,50,2,true,false,true,false,0.214693,0.0539788
gpu_reorg,256,8,1,50,4,true,false,true,false,0.215497,0.0531083
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.205845,0.0618722
gpu_array,256,32,1,20,2,true,false,true,false,0.201825,0.0556194
gpu_array,256,32,1,20,4,true,false,true,false,0.195209,0.0490039
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.200831,0.0613225
gpu_sparse,256,32,1,20,2,true,false,true,false,0.191895,0.0501535
gpu_sparse,256,32,1,20,4,true,false,true,false,0.188465,0.0495145
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.233613,0.0779213
gpu_reorg,256,32,1,20,2,true,false,true,false,0.214531,0.0582812
gpu_reorg,256,32,1,20,4,true,false,true,false,0.222095,0.0546847
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.169799,0.0464732
0.0464732
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.179096,0.0479576
0.0479576
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.171069,0.0455106
0.0455106
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.170564,0.0455636
0.0455636
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.180226,0.0474135
0.0474135
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.176828,0.0507115
0.0507115
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0455106
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0913419 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.5335,6.39567
gpu_array,256,8,1,20,2,true,false,true,false,13.3699,13.2154
gpu_array,256,8,1,20,4,true,false,true,false,12.3714,12.2229
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.32414,6.17459
gpu_sparse,256,8,1,20,2,true,false,true,false,12.8854,12.7515
gpu_sparse,256,8,1,20,4,true,false,true,false,8.94079,8.78398
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.38049,7.22926
gpu_reorg,256,8,1,20,2,true,false,true,false,10.8573,10.7011
gpu_reorg,256,8,1,20,4,true,false,true,false,8.3695,8.22664
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.10935,3.96315
gpu_array,256,8,1,50,2,true,false,true,false,7.30434,7.16483
gpu_array,256,8,1,50,4,true,false,true,false,8.50265,8.34974
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,3.79173,3.64552
gpu_sparse,256,8,1,50,2,true,false,true,false,7.17494,7.02762
gpu_sparse,256,8,1,50,4,true,false,true,false,7.6517,7.49824
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,4.76739,4.61393
gpu_reorg,256,8,1,50,2,true,false,true,false,7.6541,7.4984
gpu_reorg,256,8,1,50,4,true,false,true,false,11.6184,11.4694
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,6.77347,6.63396
gpu_array,256,32,1,20,2,true,false,true,false,5.39694,5.25687
gpu_array,256,32,1,20,4,true,false,true,false,6.10944,5.96993
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.27757,6.13192
gpu_sparse,256,32,1,20,2,true,false,true,false,5.53381,5.38146
gpu_sparse,256,32,1,20,4,true,false,true,false,5.47555,5.34106
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.66737,7.51725
gpu_reorg,256,32,1,20,2,true,false,true,false,6.66508,6.50325
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.84617,2.71057
2.71057
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,2.97096,2.83647
2.83647
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,6.00407,5.89247
5.89247
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.20256,6.08537
6.08537
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.71057
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 206 seconds of which 2.72886 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.55069,6.41007
gpu_array,256,8,1,20,2,true,false,true,false,13.3034,13.1511
gpu_array,256,8,1,20,4,true,false,true,false,12.3092,12.1719
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.32449,6.19
gpu_sparse,256,8,1,20,2,true,false,true,false,12.9336,12.779
gpu_sparse,256,8,1,20,4,true,false,true,false,8.89106,8.73537
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.40455,7.25388
gpu_reorg,256,8,1,20,2,true,false,true,false,10.8935,10.7484
gpu_reorg,256,8,1,20,4,true,false,true,false,8.26248,8.12688
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.16996,4.01259
gpu_array,256,8,1,50,2,true,false,true,false,7.37208,7.23145
gpu_array,256,8,1,50,4,true,false,true,false,8.46121,8.31667
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,3.8155,3.65981
gpu_sparse,256,8,1,50,2,true,false,true,false,7.20283,7.04547
gpu_sparse,256,8,1,50,4,true,false,true,false,7.67289,7.52055
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,4.77768,4.62924
gpu_reorg,256,8,1,50,2,true,false,true,false,7.74291,7.5995
gpu_reorg,256,8,1,50,4,true,false,true,false,11.624,11.4728
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,6.82616,6.68609
gpu_array,256,32,1,20,2,true,false,true,false,5.40057,5.2566
gpu_array,256,32,1,20,4,true,false,true,false,6.07677,5.92834
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.11682,5.97898
gpu_sparse,256,32,1,20,2,true,false,true,false,5.51838,5.3772
gpu_sparse,256,32,1,20,4,true,false,true,false,5.52385,5.38044
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.70003,7.55215
gpu_reorg,256,32,1,20,2,true,false,true,false,6.72028,6.57407
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.86836,2.73722
2.73722
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,3.01106,2.87434
2.87434
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.99738,5.87349
5.87349
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.20598,6.08433
6.08433
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.73722
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 166 seconds of which 2.73098 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.24308,0.0594866
gpu_array,256,8,1,20,2,true,false,true,false,0.28892,0.105326
gpu_array,256,8,1,20,4,true,false,true,false,0.267129,0.0773968
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.28286,0.0613198
gpu_sparse,256,8,1,20,2,true,false,true,false,0.28236,0.0926283
gpu_sparse,256,8,1,20,4,true,false,true,false,0.277246,0.0869559
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.288189,0.0772517
gpu_reorg,256,8,1,20,2,true,false,true,false,0.361992,0.118131
gpu_reorg,256,8,1,20,4,true,false,true,false,0.334774,0.0953767
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.265399,0.0550195
gpu_array,256,8,1,50,2,true,false,true,false,0.27572,0.0809654
gpu_array,256,8,1,50,4,true,false,true,false,0.27486,0.0806641
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.240446,0.0546205
gpu_sparse,256,8,1,50,2,true,false,true,false,0.306443,0.0809961
gpu_sparse,256,8,1,50,4,true,false,true,false,0.277768,0.0802232
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.261596,0.0651674
gpu_reorg,256,8,1,50,2,true,false,true,false,0.30178,0.0897266
gpu_reorg,256,8,1,50,4,true,false,true,false,0.324816,0.0893248
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.270935,0.0611133
gpu_array,256,32,1,20,2,true,false,true,false,0.242411,0.0582589
gpu_array,256,32,1,20,4,true,false,true,false,0.275949,0.0560826
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.27983,0.0588477
gpu_sparse,256,32,1,20,2,true,false,true,false,0.236769,0.0526172
gpu_sparse,256,32,1,20,4,true,false,true,false,0.241459,0.0556334
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.269821,0.0745089
gpu_reorg,256,32,1,20,2,true,false,true,false,0.294662,0.0619615
gpu_reorg,256,32,1,20,4,true,false,true,false,0.310536,0.0683482
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.222517,0.0495257
0.0495257
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.251108,0.0585854
0.0585854
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.231401,0.0478069
0.0478069
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.224202,0.0484208
0.0484208
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.253608,0.0599693
0.0599693
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.249972,0.0619141
0.0619141
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0478069
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 20 seconds of which 0.118998 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.244275,0.0617969
gpu_array,256,8,1,20,2,true,false,true,false,0.322517,0.112137
gpu_array,256,8,1,20,4,true,false,true,false,0.294459,0.0779408
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.255854,0.0610993
gpu_sparse,256,8,1,20,2,true,false,true,false,0.27579,0.0927539
gpu_sparse,256,8,1,20,4,true,false,true,false,0.296819,0.0869978
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.280343,0.0761021
gpu_reorg,256,8,1,20,2,true,false,true,false,0.347746,0.117835
gpu_reorg,256,8,1,20,4,true,false,true,false,0.33159,0.0944252
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.249576,0.0553795
gpu_array,256,8,1,50,2,true,false,true,false,0.265293,0.0811412
gpu_array,256,8,1,50,4,true,false,true,false,0.301417,0.0809933
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.240499,0.0546735
gpu_sparse,256,8,1,50,2,true,false,true,false,0.304422,0.0806501
gpu_sparse,256,8,1,50,4,true,false,true,false,0.270173,0.0809989
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.272787,0.0651981
gpu_reorg,256,8,1,50,2,true,false,true,false,0.333343,0.0905971
gpu_reorg,256,8,1,50,4,true,false,true,false,0.345254,0.0907896
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.257547,0.0611189
gpu_array,256,32,1,20,2,true,false,true,false,0.244238,0.0584124
gpu_array,256,32,1,20,4,true,false,true,false,0.258477,0.0564676
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.241953,0.0589174
gpu_sparse,256,32,1,20,2,true,false,true,false,0.254155,0.0527037
gpu_sparse,256,32,1,20,4,true,false,true,false,0.272748,0.0545564
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.279654,0.0742969
gpu_reorg,256,32,1,20,2,true,false,true,false,0.280151,0.0630748
gpu_reorg,256,32,1,20,4,true,false,true,false,0.28678,0.0680301
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.233061,0.0494671
0.0494671
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.226959,0.0584319
0.0584319
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.23365,0.0478237
0.0478237
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.231903,0.0483092
0.0483092
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.250578,0.0597294
0.0597294
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.24315,0.0617885
0.0617885
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0478237
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.119533 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.209255,0.127223
gpu_array,512,8,1,20,2,true,false,true,false,0.166243,0.0855143
gpu_array,512,8,1,20,4,true,false,true,false,0.162969,0.0809375
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.208164,0.126133
gpu_sparse,512,8,1,20,2,true,false,true,false,0.1618,0.0797689
gpu_sparse,512,8,1,20,4,true,false,true,false,0.178522,0.0919336
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.268451,0.164284
gpu_reorg,512,8,1,20,2,true,false,true,false,0.193581,0.088763
gpu_reorg,512,8,1,20,4,true,false,true,false,0.174831,0.0719661
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.150716,0.0725911
gpu_array,512,8,1,50,2,true,false,true,false,0.14252,0.0630924
gpu_array,512,8,1,50,4,true,false,true,false,0.143405,0.0652799
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.162002,0.0760645
gpu_sparse,512,8,1,50,2,true,false,true,false,0.156927,0.078151
gpu_sparse,512,8,1,50,4,true,false,true,false,0.156354,0.0769271
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.371768,0.0918197
gpu_reorg,512,8,1,50,2,true,false,true,false,0.346797,0.0622917
gpu_reorg,512,8,1,50,4,true,false,true,false,0.365013,0.0876693
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.207835,0.125804
gpu_array,512,32,1,20,2,true,false,true,false,0.16875,0.0867187
gpu_array,512,32,1,20,4,true,false,true,false,0.165003,0.082972
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.207975,0.125293
gpu_sparse,512,32,1,20,2,true,false,true,false,0.156494,0.0751139
gpu_sparse,512,32,1,20,4,true,false,true,false,0.16723,0.0858496
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.258395,0.160088
gpu_reorg,512,32,1,20,2,true,false,true,false,0.188411,0.0927083
gpu_reorg,512,32,1,20,4,true,false,true,false,0.179928,0.0822721
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.151755,0.0593066
0.0593066
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.167217,0.0663053
0.0663053
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.165231,0.0714811
0.0714811
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.178988,0.0800293
0.0800293
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.184437,0.0822233
0.0822233
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.18056,0.0874609
0.0874609
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0593066
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.302493 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.207832,0.127103
gpu_array,512,8,1,20,2,true,false,true,false,0.166715,0.0853353
gpu_array,512,8,1,20,4,true,false,true,false,0.161689,0.0809603
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.212865,0.126276
gpu_sparse,512,8,1,20,2,true,false,true,false,0.165954,0.0800163
gpu_sparse,512,8,1,20,4,true,false,true,false,0.179753,0.091862
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.269219,0.165052
gpu_reorg,512,8,1,20,2,true,false,true,false,0.182526,0.088776
gpu_reorg,512,8,1,20,4,true,false,true,false,0.168411,0.0720573
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.156562,0.0725781
gpu_array,512,8,1,50,2,true,false,true,false,0.14168,0.0635547
gpu_array,512,8,1,50,4,true,false,true,false,0.146702,0.0653223
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.156387,0.0763086
gpu_sparse,512,8,1,50,2,true,false,true,false,0.151888,0.0783203
gpu_sparse,512,8,1,50,4,true,false,true,false,0.168812,0.077015
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.369336,0.0919922
gpu_reorg,512,8,1,50,2,true,false,true,false,0.338385,0.0623438
gpu_reorg,512,8,1,50,4,true,false,true,false,0.369681,0.0877799
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.209798,0.126465
gpu_array,512,32,1,20,2,true,false,true,false,0.17001,0.0866764
gpu_array,512,32,1,20,4,true,false,true,false,0.171367,0.0828255
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.215654,0.12516
gpu_sparse,512,32,1,20,2,true,false,true,false,0.158307,0.074974
gpu_sparse,512,32,1,20,4,true,false,true,false,0.168551,0.0858691
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.265843,0.160374
gpu_reorg,512,32,1,20,2,true,false,true,false,0.194502,0.0929395
gpu_reorg,512,32,1,20,4,true,false,true,false,0.203327,0.0828841
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.154421,0.0593685
0.0593685
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.157432,0.0662858
0.0662858
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.163057,0.0712598
0.0712598
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.169053,0.07986
0.07986
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.175947,0.0821973
0.0821973
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.187077,0.0868164
0.0868164
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0593685
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.302757 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.121481,0.0322884
gpu_array,512,8,1,20,2,true,false,true,false,0.118757,0.0295638
gpu_array,512,8,1,20,4,true,false,true,false,0.114378,0.0264876
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.124222,0.0324251
gpu_sparse,512,8,1,20,2,true,false,true,false,0.117819,0.0279753
gpu_sparse,512,8,1,20,4,true,false,true,false,0.116094,0.0275521
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.15237,0.0397396
gpu_reorg,512,8,1,20,2,true,false,true,false,0.146094,0.0302083
gpu_reorg,512,8,1,20,4,true,false,true,false,0.141471,0.0288411
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.116979,0.0277865
gpu_array,512,8,1,50,2,true,false,true,false,0.113089,0.0265007
gpu_array,512,8,1,50,4,true,false,true,false,0.117617,0.0264714
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.121465,0.0283659
gpu_sparse,512,8,1,50,2,true,false,true,false,0.118822,0.0341862
gpu_sparse,512,8,1,50,4,true,false,true,false,0.128577,0.0341764
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.136579,0.0330632
gpu_reorg,512,8,1,50,2,true,false,true,false,0.141383,0.0333105
gpu_reorg,512,8,1,50,4,true,false,true,false,0.146647,0.0333659
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.128229,0.0305729
gpu_array,512,32,1,20,2,true,false,true,false,0.109004,0.0276237
gpu_array,512,32,1,20,4,true,false,true,false,0.105973,0.0239421
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.118125,0.0302344
gpu_sparse,512,32,1,20,2,true,false,true,false,0.111696,0.0251074
gpu_sparse,512,32,1,20,4,true,false,true,false,0.10599,0.0246094
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.158099,0.0383073
gpu_reorg,512,32,1,20,2,true,false,true,false,0.144105,0.0288704
gpu_reorg,512,32,1,20,4,true,false,true,false,0.13929,0.0273112
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0865104,0.0233594
0.0233594
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.0921126,0.0244043
0.0244043
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.0956087,0.0246452
0.0246452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.100947,0.0254264
0.0254264
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.0926823,0.024974
0.024974
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.10417,0.0253939
0.0253939
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0233594
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.098006 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.123542,0.0323958
gpu_array,512,8,1,20,2,true,false,true,false,0.116162,0.0295736
gpu_array,512,8,1,20,4,true,false,true,false,0.114945,0.026403
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.122168,0.0323242
gpu_sparse,512,8,1,20,2,true,false,true,false,0.121006,0.0279069
gpu_sparse,512,8,1,20,4,true,false,true,false,0.120654,0.0275553
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.146442,0.0396712
gpu_reorg,512,8,1,20,2,true,false,true,false,0.145296,0.0300618
gpu_reorg,512,8,1,20,4,true,false,true,false,0.150521,0.028776
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.115729,0.0278385
gpu_array,512,8,1,50,2,true,false,true,false,0.113099,0.0265104
gpu_array,512,8,1,50,4,true,false,true,false,0.115081,0.0265397
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.114281,0.0283431
gpu_sparse,512,8,1,50,2,true,false,true,false,0.121413,0.0341732
gpu_sparse,512,8,1,50,4,true,false,true,false,0.12349,0.0342969
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.145658,0.0330273
gpu_reorg,512,8,1,50,2,true,false,true,false,0.15166,0.0331706
gpu_reorg,512,8,1,50,4,true,false,true,false,0.147246,0.0333138
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.124977,0.0305762
gpu_array,512,32,1,20,2,true,false,true,false,0.119997,0.0275488
gpu_array,512,32,1,20,4,true,false,true,false,0.107952,0.0239681
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.118057,0.030166
gpu_sparse,512,32,1,20,2,true,false,true,false,0.111423,0.024834
gpu_sparse,512,32,1,20,4,true,false,true,false,0.107852,0.0245182
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.139896,0.0383333
gpu_reorg,512,32,1,20,2,true,false,true,false,0.147718,0.0285775
gpu_reorg,512,32,1,20,4,true,false,true,false,0.137028,0.027002
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0960807,0.0231641
0.0231641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.0931608,0.0241504
0.0241504
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.101562,0.0247396
0.0247396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.0930013,0.025293
0.025293
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.0929753,0.0246159
0.0246159
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.0930111,0.0253027
0.0253027
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0231641
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0977583 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.735934,0.156507
gpu_array,512,8,1,20,2,true,false,true,false,0.705075,0.130205
gpu_array,512,8,1,20,4,true,false,true,false,0.700651,0.121224
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.766901,0.166641
gpu_sparse,512,8,1,20,2,true,false,true,false,0.669889,0.0878581
gpu_sparse,512,8,1,20,4,true,false,true,false,0.702952,0.109202
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.814118,0.191071
gpu_reorg,512,8,1,20,2,true,false,true,false,0.744082,0.111921
gpu_reorg,512,8,1,20,4,true,false,true,false,0.723135,0.106598
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.695837,0.0975293
gpu_array,512,8,1,50,2,true,false,true,false,0.657936,0.0746029
gpu_array,512,8,1,50,4,true,false,true,false,0.648708,0.0725358
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.707191,0.0991178
gpu_sparse,512,8,1,50,2,true,false,true,false,0.664479,0.0922135
gpu_sparse,512,8,1,50,4,true,false,true,false,0.665104,0.0882813
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.728154,0.112269
gpu_reorg,512,8,1,50,2,true,false,true,false,0.698639,0.0794987
gpu_reorg,512,8,1,50,4,true,false,true,false,0.732591,0.10043
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.641797,0.0792969
0.0792969
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.670446,0.0994824
0.0994824
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.76583,0.127809
0.127809
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.719076,0.153971
0.153971
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0725358
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.251726 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.732474,0.157604
gpu_array,512,8,1,20,2,true,false,true,false,0.715436,0.131452
gpu_array,512,8,1,20,4,true,false,true,false,0.708291,0.122354
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.766126,0.166517
gpu_sparse,512,8,1,20,2,true,false,true,false,0.682448,0.0886979
gpu_sparse,512,8,1,20,4,true,false,true,false,0.702142,0.109694
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.812858,0.191764
gpu_reorg,512,8,1,20,2,true,false,true,false,0.753275,0.111999
gpu_reorg,512,8,1,20,4,true,false,true,false,0.717536,0.10751
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.688949,0.0984538
gpu_array,512,8,1,50,2,true,false,true,false,0.677087,0.074873
gpu_array,512,8,1,50,4,true,false,true,false,0.674551,0.0729883
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.692435,0.099987
gpu_sparse,512,8,1,50,2,true,false,true,false,0.68486,0.0930632
gpu_sparse,512,8,1,50,4,true,false,true,false,0.671458,0.088776
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.730286,0.113099
gpu_reorg,512,8,1,50,2,true,false,true,false,0.70752,0.0805664
gpu_reorg,512,8,1,50,4,true,false,true,false,0.741589,0.100964
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.642806,0.080306
0.080306
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.668018,0.100309
0.100309
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.700505,0.128239
0.128239
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.720872,0.155117
0.155117
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0729883
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.253372 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.253307,0.134818
gpu_array,512,8,1,20,2,true,false,true,false,0.218034,0.0969401
gpu_array,512,8,1,20,4,true,false,true,false,0.218851,0.0925488
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.257025,0.139186
gpu_sparse,512,8,1,20,2,true,false,true,false,0.229098,0.108656
gpu_sparse,512,8,1,20,4,true,false,true,false,0.222861,0.110231
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.29792,0.174222
gpu_reorg,512,8,1,20,2,true,false,true,false,0.261644,0.12167
gpu_reorg,512,8,1,20,4,true,false,true,false,0.243698,0.118047
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.355023,0.115439
gpu_array,512,8,1,50,2,true,false,true,false,0.34473,0.112959
gpu_array,512,8,1,50,4,true,false,true,false,0.36721,0.127627
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.23026,0.11112
gpu_sparse,512,8,1,50,2,true,false,true,false,0.361696,0.118857
gpu_sparse,512,8,1,50,4,true,false,true,false,0.368053,0.129121
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.250745,0.121839
gpu_reorg,512,8,1,50,2,true,false,true,false,0.241364,0.117666
gpu_reorg,512,8,1,50,4,true,false,true,false,0.271165,0.153327
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.259453,0.140964
gpu_array,512,32,1,20,2,true,false,true,false,0.229069,0.108626
gpu_array,512,32,1,20,4,true,false,true,false,0.231569,0.106569
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.260804,0.134502
gpu_sparse,512,32,1,20,2,true,false,true,false,0.229694,0.111855
gpu_sparse,512,32,1,20,4,true,false,true,false,0.238662,0.115615
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.278743,0.156348
gpu_reorg,512,32,1,20,2,true,false,true,false,0.250023,0.128278
gpu_reorg,512,32,1,20,4,true,false,true,false,0.25641,0.128805
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.197464,0.0861361
0.0861361
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.195762,0.090944
0.090944
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.198698,0.0860677
0.0860677
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.218402,0.112282
0.112282
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.185999,0.0727181
0.0727181
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.185557,0.08139
0.08139
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0727181
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.395814 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.250319,0.134434
gpu_array,512,8,1,20,2,true,false,true,false,0.21849,0.0967448
gpu_array,512,8,1,20,4,true,false,true,false,0.206914,0.0923307
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.259242,0.137497
gpu_sparse,512,8,1,20,2,true,false,true,false,0.229326,0.108232
gpu_sparse,512,8,1,20,4,true,false,true,false,0.232256,0.10986
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.30014,0.173838
gpu_reorg,512,8,1,20,2,true,false,true,false,0.24012,0.121631
gpu_reorg,512,8,1,20,4,true,false,true,false,0.237526,0.115781
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.352119,0.114489
gpu_array,512,8,1,50,2,true,false,true,false,0.345892,0.112819
gpu_array,512,8,1,50,4,true,false,true,false,0.36627,0.127337
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.224215,0.110934
gpu_sparse,512,8,1,50,2,true,false,true,false,0.356156,0.117874
gpu_sparse,512,8,1,50,4,true,false,true,false,0.374167,0.128724
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.2471,0.1221
gpu_reorg,512,8,1,50,2,true,false,true,false,0.241878,0.117529
gpu_reorg,512,8,1,50,4,true,false,true,false,0.281276,0.153672
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.265192,0.140843
gpu_array,512,32,1,20,2,true,false,true,false,0.230791,0.108395
gpu_array,512,32,1,20,4,true,false,true,false,0.234284,0.10668
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.258851,0.133851
gpu_sparse,512,32,1,20,2,true,false,true,false,0.237318,0.111667
gpu_sparse,512,32,1,20,4,true,false,true,false,0.234733,0.115592
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.274548,0.156709
gpu_reorg,512,32,1,20,2,true,false,true,false,0.243346,0.128112
gpu_reorg,512,32,1,20,4,true,false,true,false,0.254238,0.128587
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.192178,0.0860579
0.0860579
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.193604,0.0907389
0.0907389
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.200485,0.0859017
0.0859017
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.227012,0.11373
0.11373
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.185117,0.072487
0.072487
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.19222,0.081543
0.081543
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.072487
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.394928 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.06,0.044375
gpu_array,512,8,1,20,2,false,false,true,false,1.07735,0.042194
gpu_array,512,8,1,20,4,false,false,true,false,1.10139,0.0414941
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.09134,0.0444661
gpu_sparse,512,8,1,20,2,false,false,true,false,1.10831,0.0425586
gpu_sparse,512,8,1,20,4,false,false,true,false,1.08338,0.0423665
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.13098,0.0554622
gpu_reorg,512,8,1,20,2,false,false,true,false,1.13395,0.0499609
gpu_reorg,512,8,1,20,4,false,false,true,false,1.13391,0.0466732
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.11762,0.0479557
gpu_array,512,8,1,50,2,false,false,true,false,1.12387,0.0496484
gpu_array,512,8,1,50,4,false,false,true,false,1.11925,0.0495898
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.10684,0.0456413
gpu_sparse,512,8,1,50,2,false,false,true,false,1.10571,0.0549316
gpu_sparse,512,8,1,50,4,false,false,true,false,1.10197,0.0550977
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.13638,0.0484928
gpu_reorg,512,8,1,50,2,false,false,true,false,1.11232,0.0537305
gpu_reorg,512,8,1,50,4,false,false,true,false,1.11247,0.0538802
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.12549,0.0467122
gpu_array,512,32,1,20,2,false,false,true,false,1.10822,0.0437663
gpu_array,512,32,1,20,4,false,false,true,false,1.12267,0.0425911
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.1284,0.0463639
gpu_sparse,512,32,1,20,2,false,false,true,false,1.11188,0.0441699
gpu_sparse,512,32,1,20,4,false,false,true,false,1.11435,0.0440397
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.1379,0.0558724
gpu_reorg,512,32,1,20,2,false,false,true,false,1.12042,0.0514063
gpu_reorg,512,32,1,20,4,false,false,true,false,1.16966,0.0492187
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.10347,0.0422721
0.0422721
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.10686,0.0424056
0.0424056
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.10565,0.0425033
0.0425033
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0414941
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.145392 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.11672,0.0444564
gpu_array,512,8,1,20,2,false,false,true,false,1.08722,0.0423014
gpu_array,512,8,1,20,4,false,false,true,false,1.10916,0.0414551
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.1201,0.0445801
gpu_sparse,512,8,1,20,2,false,false,true,false,1.10414,0.0422884
gpu_sparse,512,8,1,20,4,false,false,true,false,1.10016,0.0422168
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.13961,0.0556217
gpu_reorg,512,8,1,20,2,false,false,true,false,1.12338,0.050459
gpu_reorg,512,8,1,20,4,false,false,true,false,1.16583,0.0466927
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.13789,0.0480436
gpu_array,512,8,1,50,2,false,false,true,false,1.13702,0.0497852
gpu_array,512,8,1,50,4,false,false,true,false,1.11002,0.0494759
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.10007,0.0453874
gpu_sparse,512,8,1,50,2,false,false,true,false,1.10657,0.0551367
gpu_sparse,512,8,1,50,4,false,false,true,false,1.13386,0.0550846
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.12609,0.0486198
gpu_reorg,512,8,1,50,2,false,false,true,false,1.12232,0.0539583
gpu_reorg,512,8,1,50,4,false,false,true,false,1.12682,0.053903
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.10406,0.0467643
gpu_array,512,32,1,20,2,false,false,true,false,1.11808,0.0438639
gpu_array,512,32,1,20,4,false,false,true,false,1.11486,0.0425977
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.11275,0.0463477
gpu_sparse,512,32,1,20,2,false,false,true,false,1.11316,0.0441504
gpu_sparse,512,32,1,20,4,false,false,true,false,1.11756,0.0439876
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.12438,0.0560221
gpu_reorg,512,32,1,20,2,false,false,true,false,1.13945,0.0515592
gpu_reorg,512,32,1,20,4,false,false,true,false,1.12186,0.0489388
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.1035,0.0423014
0.0423014
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.0999,0.0426074
0.0426074
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.08863,0.0424056
0.0424056
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0414551
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.145512 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.131602,0.0332943
gpu_array,512,8,1,20,2,true,false,true,false,0.120876,0.0303809
gpu_array,512,8,1,20,4,true,false,true,false,0.128581,0.0276693
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.131644,0.0333366
gpu_sparse,512,8,1,20,2,true,false,true,false,0.12182,0.0287207
gpu_sparse,512,8,1,20,4,true,false,true,false,0.121589,0.0284896
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.164652,0.0416048
gpu_reorg,512,8,1,20,2,true,false,true,false,0.148548,0.0320117
gpu_reorg,512,8,1,20,4,true,false,true,false,0.156383,0.0307324
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.122826,0.0297266
gpu_array,512,8,1,50,2,true,false,true,false,0.119391,0.0315007
gpu_array,512,8,1,50,4,true,false,true,false,0.119313,0.0314225
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.117699,0.0298079
gpu_sparse,512,8,1,50,2,true,false,true,false,0.125729,0.0352344
gpu_sparse,512,8,1,50,4,true,false,true,false,0.132725,0.0350684
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.15637,0.0352767
gpu_reorg,512,8,1,50,2,true,false,true,false,0.156855,0.0364128
gpu_reorg,512,8,1,50,4,true,false,true,false,0.151178,0.0365951
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.129593,0.0312858
gpu_array,512,32,1,20,2,true,false,true,false,0.122959,0.0285579
gpu_array,512,32,1,20,4,true,false,true,false,0.119395,0.0256445
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.12623,0.0311784
gpu_sparse,512,32,1,20,2,true,false,true,false,0.127913,0.0263509
gpu_sparse,512,32,1,20,4,true,false,true,false,0.113916,0.0260254
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.16182,0.0400749
gpu_reorg,512,32,1,20,2,true,false,true,false,0.153203,0.0308073
gpu_reorg,512,32,1,20,4,true,false,true,false,0.160742,0.0292318
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0989518,0.0247331
0.0247331
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.106963,0.0262337
0.0262337
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.106595,0.0258659
0.0258659
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.0991113,0.0261947
0.0261947
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.110244,0.0269108
0.0269108
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.104749,0.0272754
0.0272754
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0247331
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.103798 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.125062,0.033265
gpu_array,512,8,1,20,2,true,false,true,false,0.125664,0.030612
gpu_array,512,8,1,20,4,true,false,true,false,0.127249,0.02764
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.133454,0.0331934
gpu_sparse,512,8,1,20,2,true,false,true,false,0.120472,0.0286751
gpu_sparse,512,8,1,20,4,true,false,true,false,0.121605,0.0285059
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.163945,0.0415495
gpu_reorg,512,8,1,20,2,true,false,true,false,0.154463,0.0320671
gpu_reorg,512,8,1,20,4,true,false,true,false,0.145866,0.0306315
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.120179,0.0296842
gpu_array,512,8,1,50,2,true,false,true,false,0.11931,0.0314193
gpu_array,512,8,1,50,4,true,false,true,false,0.119434,0.031543
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.113841,0.0298568
gpu_sparse,512,8,1,50,2,true,false,true,false,0.126351,0.0352051
gpu_sparse,512,8,1,50,4,true,false,true,false,0.126318,0.0351725
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.154424,0.0352832
gpu_reorg,512,8,1,50,2,true,false,true,false,0.159567,0.0365202
gpu_reorg,512,8,1,50,4,true,false,true,false,0.147813,0.0364844
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.124417,0.0313184
gpu_array,512,32,1,20,2,true,false,true,false,0.122122,0.0283724
gpu_array,512,32,1,20,4,true,false,true,false,0.110846,0.0255599
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.13012,0.0311621
gpu_sparse,512,32,1,20,2,true,false,true,false,0.121403,0.0263509
gpu_sparse,512,32,1,20,4,true,false,true,false,0.120342,0.0259408
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.16583,0.040179
gpu_reorg,512,32,1,20,2,true,false,true,false,0.150052,0.0309115
gpu_reorg,512,32,1,20,4,true,false,true,false,0.148324,0.0291829
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0964941,0.0248796
0.0248796
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.112982,0.0263932
0.0263932
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.109313,0.0259798
0.0259798
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.105023,0.0262467
0.0262467
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.10972,0.0270378
0.0270378
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.107878,0.0271484
0.0271484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0248796
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103831 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.08715,3.81111
gpu_array,512,8,1,20,2,true,false,true,false,7.90704,7.61733
gpu_array,512,8,1,20,4,true,false,true,false,7.52392,7.24658
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.69221,3.44156
gpu_sparse,512,8,1,20,2,true,false,true,false,7.659,7.409
gpu_sparse,512,8,1,20,4,true,false,true,false,5.61414,5.36219
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.59661,4.32578
gpu_reorg,512,8,1,20,2,true,false,true,false,6.07702,5.77884
gpu_reorg,512,8,1,20,4,true,false,true,false,5.32078,5.03823
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.71486,3.42579
gpu_array,512,8,1,50,2,true,false,true,false,4.51975,4.20595
gpu_array,512,8,1,50,4,true,false,true,false,9.15488,8.86322
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.43168,3.14978
gpu_sparse,512,8,1,50,2,true,false,true,false,4.49458,4.1925
gpu_sparse,512,8,1,50,4,true,false,true,false,8.23466,7.93844
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,4.02418,3.68824
gpu_reorg,512,8,1,50,2,true,false,true,false,8.89451,8.58201
gpu_reorg,512,8,1,50,4,true,false,true,false,9.55875,9.23909
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.14906,3.90427
gpu_array,512,32,1,20,2,true,false,true,false,3.63783,3.39434
gpu_array,512,32,1,20,4,true,false,true,false,3.90927,3.62477
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.57607,3.33974
gpu_sparse,512,32,1,20,2,true,false,true,false,3.75142,3.51053
gpu_sparse,512,32,1,20,4,true,false,true,false,3.64776,3.40036
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.54096,4.27208
gpu_reorg,512,32,1,20,2,true,false,true,false,4.5412,4.27297
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.57988,2.49134
2.49134
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.82723,2.75887
2.75887
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.05504,2.95999
2.95999
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.26691,3.16991
3.16991
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.49134
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 189 seconds of which 3.69702 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,3.95967,3.68624
gpu_array,512,8,1,20,2,true,false,true,false,7.87277,7.59413
gpu_array,512,8,1,20,4,true,false,true,false,7.58167,7.28479
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.6653,3.42116
gpu_sparse,512,8,1,20,2,true,false,true,false,7.72704,7.4777
gpu_sparse,512,8,1,20,4,true,false,true,false,5.58452,5.33908
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.57414,4.30266
gpu_reorg,512,8,1,20,2,true,false,true,false,6.01047,5.72401
gpu_reorg,512,8,1,20,4,true,false,true,false,5.43871,5.15551
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.83457,3.53704
gpu_array,512,8,1,50,2,true,false,true,false,4.51461,4.21318
gpu_array,512,8,1,50,4,true,false,true,false,9.14384,8.80465
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.42895,3.15095
gpu_sparse,512,8,1,50,2,true,false,true,false,4.62034,4.32672
gpu_sparse,512,8,1,50,4,true,false,true,false,8.15491,7.86324
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,4.01036,3.68549
gpu_reorg,512,8,1,50,2,true,false,true,false,8.99233,8.67788
gpu_reorg,512,8,1,50,4,true,false,true,false,9.64813,9.32977
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.0093,3.7619
gpu_array,512,32,1,20,2,true,false,true,false,3.56374,3.30918
gpu_array,512,32,1,20,4,true,false,true,false,3.85591,3.59615
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.60014,3.34298
gpu_sparse,512,32,1,20,2,true,false,true,false,3.68754,3.43689
gpu_sparse,512,32,1,20,4,true,false,true,false,3.56736,3.30499
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.55004,4.28051
gpu_reorg,512,32,1,20,2,true,false,true,false,4.59094,4.29667
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.67083,2.58099
2.58099
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.84776,2.75531
2.75531
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.04607,2.95622
2.95622
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.17846,3.07951
3.07951
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.58099
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 157 seconds of which 3.69345 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.157035,0.0320345
gpu_array,512,8,1,20,2,true,false,true,false,0.183262,0.0569596
gpu_array,512,8,1,20,4,true,false,true,false,0.173213,0.0404004
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.155514,0.0318164
gpu_sparse,512,8,1,20,2,true,false,true,false,0.175462,0.0478581
gpu_sparse,512,8,1,20,4,true,false,true,false,0.172734,0.0457813
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.190472,0.0400814
gpu_reorg,512,8,1,20,2,true,false,true,false,0.210111,0.0610221
gpu_reorg,512,8,1,20,4,true,false,true,false,0.207604,0.0500521
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.167533,0.0308138
gpu_array,512,8,1,50,2,true,false,true,false,0.168089,0.0430892
gpu_array,512,8,1,50,4,true,false,true,false,0.170742,0.043138
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.152074,0.0296777
gpu_sparse,512,8,1,50,2,true,false,true,false,0.168379,0.045332
gpu_sparse,512,8,1,50,4,true,false,true,false,0.169759,0.0454102
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.196501,0.0369954
gpu_reorg,512,8,1,50,2,true,false,true,false,0.192064,0.0481836
gpu_reorg,512,8,1,50,4,true,false,true,false,0.199515,0.0484733
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.166351,0.0309342
gpu_array,512,32,1,20,2,true,false,true,false,0.165156,0.0297396
gpu_array,512,32,1,20,4,true,false,true,false,0.160241,0.0306836
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.154466,0.0301172
gpu_sparse,512,32,1,20,2,true,false,true,false,0.151921,0.0269206
gpu_sparse,512,32,1,20,4,true,false,true,false,0.163665,0.0295508
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.208535,0.0386133
gpu_reorg,512,32,1,20,2,true,false,true,false,0.183402,0.0356152
gpu_reorg,512,32,1,20,4,true,false,true,false,0.197594,0.0406934
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.15026,0.0259115
0.0259115
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.149844,0.0300521
0.0300521
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.139642,0.0257096
0.0257096
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.141025,0.0264421
0.0264421
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.157217,0.0309147
0.0309147
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.153617,0.0318717
0.0318717
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0257096
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 19 seconds of which 0.127067 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.168649,0.0319303
gpu_array,512,8,1,20,2,true,false,true,false,0.184235,0.0566309
gpu_array,512,8,1,20,4,true,false,true,false,0.17126,0.0404004
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.157995,0.0316927
gpu_sparse,512,8,1,20,2,true,false,true,false,0.183232,0.0478158
gpu_sparse,512,8,1,20,4,true,false,true,false,0.181891,0.0458236
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.195723,0.0401237
gpu_reorg,512,8,1,20,2,true,false,true,false,0.231165,0.0618945
gpu_reorg,512,8,1,20,4,true,false,true,false,0.2082,0.0499967
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.157174,0.0308724
gpu_array,512,8,1,50,2,true,false,true,false,0.174196,0.0433366
gpu_array,512,8,1,50,4,true,false,true,false,0.175186,0.0430241
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.160544,0.0296842
gpu_sparse,512,8,1,50,2,true,false,true,false,0.184847,0.0455241
gpu_sparse,512,8,1,50,4,true,false,true,false,0.17946,0.0453451
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.180384,0.0371549
gpu_reorg,512,8,1,50,2,true,false,true,false,0.205173,0.0482715
gpu_reorg,512,8,1,50,4,true,false,true,false,0.1986,0.0482096
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.163822,0.0310091
gpu_array,512,32,1,20,2,true,false,true,false,0.160726,0.0298665
gpu_array,512,32,1,20,4,true,false,true,false,0.167419,0.0306999
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.157096,0.0301432
gpu_sparse,512,32,1,20,2,true,false,true,false,0.15446,0.0268555
gpu_sparse,512,32,1,20,4,true,false,true,false,0.153138,0.0294401
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.188278,0.0385384
gpu_reorg,512,32,1,20,2,true,false,true,false,0.197324,0.0352148
gpu_reorg,512,32,1,20,4,true,false,true,false,0.191488,0.040446
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.141549,0.0256641
0.0256641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.150231,0.0297884
0.0297884
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.141419,0.0255339
0.0255339
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.147194,0.0261003
0.0261003
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.153659,0.030612
0.030612
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.160557,0.0316504
0.0316504
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0255339
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.126904 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.118477,0.0667187
gpu_array,1024,8,1,20,2,true,false,true,false,0.101694,0.0499365
gpu_array,1024,8,1,20,4,true,false,true,false,0.101895,0.0491602
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.117544,0.0687158
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.124438,0.069751
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.118716,0.0640283
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.173901,0.0850342
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.138604,0.0497363
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.141519,0.0546045
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.115269,0.0635107
gpu_array,1024,8,1,50,2,true,false,true,false,0.108027,0.055293
gpu_array,1024,8,1,50,4,true,false,true,false,0.107842,0.0570605
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.118345,0.0675635
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.118125,0.0673437
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.119214,0.0674561
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.168164,0.08125
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.143003,0.0541357
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.152124,0.0642334
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.123989,0.0693018
gpu_array,1024,32,1,20,2,true,false,true,false,0.110254,0.0555664
gpu_array,1024,32,1,20,4,true,false,true,false,0.109316,0.056582
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.121904,0.0720996
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.115312,0.0635547
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.118096,0.0624316
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.173779,0.0858887
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.154097,0.0671826
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.158691,0.0737305
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.102197,0.0533691
0.0533691
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.0992285,0.0523535
0.0523535
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.1004,0.0525488
0.0525488
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.105,0.0551953
0.0551953
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.102793,0.0549414
0.0549414
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.112007,0.0582959
0.0582959
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0491602
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.423644 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.120288,0.0665771
gpu_array,1024,8,1,20,2,true,false,true,false,0.102808,0.0500732
gpu_array,1024,8,1,20,4,true,false,true,false,0.100684,0.0489258
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.120474,0.0687158
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.122295,0.0695605
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.117192,0.0634814
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.170894,0.0849561
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.132549,0.049541
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.143159,0.054292
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.115142,0.0633838
gpu_array,1024,8,1,50,2,true,false,true,false,0.105859,0.0550781
gpu_array,1024,8,1,50,4,true,false,true,false,0.108599,0.0568408
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.117065,0.0672607
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.117925,0.0671436
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.118052,0.0672705
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.165962,0.081001
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.13813,0.0541455
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.152896,0.0640283
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.1248,0.0691357
gpu_array,1024,32,1,20,2,true,false,true,false,0.108149,0.055415
gpu_array,1024,32,1,20,4,true,false,true,false,0.110151,0.0564404
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.124028,0.0722705
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.116504,0.0637695
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.126055,0.0625781
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.172983,0.0860693
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.152319,0.0673584
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.16165,0.0737598
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.101353,0.053501
0.053501
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.0984521,0.0525537
0.0525537
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.0993457,0.0524707
0.0524707
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.103169,0.0553174
0.0553174
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.103066,0.0552148
0.0552148
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.105308,0.0584326
0.0584326
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0489258
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.423232 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0791357,0.0176123
gpu_array,1024,8,1,20,2,true,false,true,false,0.0792236,0.0167236
gpu_array,1024,8,1,20,4,true,false,true,false,0.0779053,0.0173584
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0776709,0.0181006
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0799219,0.0183984
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0771143,0.0185205
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.120366,0.0217334
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.113916,0.0172363
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.115503,0.0178467
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.0794922,0.0199219
gpu_array,1024,8,1,50,2,true,false,true,false,0.0785693,0.0199756
gpu_array,1024,8,1,50,4,true,false,true,false,0.079707,0.0201367
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0803125,0.0207422
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0837451,0.0241748
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0839453,0.024375
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.121074,0.0243945
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.121074,0.0243945
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.119063,0.0243359
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0784961,0.0159961
gpu_array,1024,32,1,20,2,true,false,true,false,0.0762207,0.0146973
gpu_array,1024,32,1,20,4,true,false,true,false,0.0740137,0.0144434
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0757861,0.0162158
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0769141,0.0153906
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0742236,0.0156299
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.126748,0.0203027
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.111323,0.0165967
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.111064,0.0163379
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.072793,0.0141992
0.0141992
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0659424,0.0151611
0.0151611
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0630225,0.0151709
0.0151709
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0656592,0.0158545
0.0158545
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0703662,0.0186084
0.0186084
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0684473,0.0186426
0.0186426
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0141992
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 8 seconds of which 0.12477 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0790234,0.0175
gpu_array,1024,8,1,20,2,true,false,true,false,0.078208,0.0166846
gpu_array,1024,8,1,20,4,true,false,true,false,0.0770508,0.0174805
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0777393,0.0181689
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0789111,0.0183643
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0771094,0.0185156
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.115542,0.021792
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.112759,0.0170557
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.113535,0.017832
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.0795117,0.0199414
gpu_array,1024,8,1,50,2,true,false,true,false,0.07854,0.0199463
gpu_array,1024,8,1,50,4,true,false,true,false,0.0795605,0.0199902
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0803809,0.0208105
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0837354,0.024165
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.082749,0.0241553
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.118169,0.0244189
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.12104,0.0243604
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.122134,0.0244775
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0746729,0.0160791
gpu_array,1024,32,1,20,2,true,false,true,false,0.0740771,0.0145068
gpu_array,1024,32,1,20,4,true,false,true,false,0.0737109,0.0141406
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0765918,0.0160449
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0747461,0.0151758
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0759766,0.0154297
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.113013,0.0202393
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.112876,0.0161963
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.110674,0.0159473
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0648828,0.0141016
0.0141016
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0638525,0.0150244
0.0150244
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0637646,0.0149365
0.0149365
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0636035,0.015752
0.015752
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0671924,0.0183643
0.0183643
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0683643,0.0185596
0.0185596
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0141016
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.124141 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.56915,0.140439
gpu_array,1024,8,1,20,2,true,false,true,false,0.536821,0.109087
gpu_array,1024,8,1,20,4,true,false,true,false,0.555317,0.106099
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.581836,0.150195
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.505083,0.0851611
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.534434,0.0988867
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.669673,0.168696
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.595845,0.0987744
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.566089,0.0944092
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.522119,0.0875488
gpu_array,1024,8,1,50,2,true,false,true,false,0.503398,0.0639453
gpu_array,1024,8,1,50,4,true,false,true,false,0.512847,0.0685107
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.5123,0.0904248
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.513584,0.0809668
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.510215,0.0775977
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.587534,0.0972998
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.573145,0.0682617
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.572041,0.0739941
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.473687,0.0615771
0.0615771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.51167,0.0888184
0.0888184
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.527422,0.112383
0.112383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.602495,0.181597
0.181597
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0615771
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.451517 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.57604,0.140493
gpu_array,1024,8,1,20,2,true,false,true,false,0.54877,0.114199
gpu_array,1024,8,1,20,4,true,false,true,false,0.525166,0.106221
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.583384,0.14979
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.514673,0.0849854
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.514087,0.0990479
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.667783,0.16876
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.578276,0.0987842
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.594521,0.0945215
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.514204,0.0874463
gpu_array,1024,8,1,50,2,true,false,true,false,0.488726,0.0639209
gpu_array,1024,8,1,50,4,true,false,true,false,0.50292,0.0693262
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.517051,0.090293
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.507373,0.0815918
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.499941,0.0780664
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.598389,0.0974121
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.544922,0.0683594
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.542842,0.0740918
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.481602,0.0616797
0.0616797
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.504834,0.0888184
0.0888184
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.530435,0.112466
0.112466
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.597388,0.180396
0.180396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0616797
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.452745 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.164038,0.0781006
gpu_array,1024,8,1,20,2,true,false,true,false,0.1521,0.0700684
gpu_array,1024,8,1,20,4,true,false,true,false,0.166875,0.0809375
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.221641,0.0810156
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.164507,0.0824756
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.173145,0.0901367
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.285181,0.107446
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.269111,0.0855176
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.298984,0.113437
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.252466,0.102075
gpu_array,1024,8,1,50,2,true,false,true,false,0.237578,0.0979297
gpu_array,1024,8,1,50,4,true,false,true,false,0.250107,0.105576
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.239297,0.0996484
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.242451,0.103779
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.248931,0.112212
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.287227,0.106563
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.285488,0.103848
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.300176,0.113652
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.175508,0.0895703
gpu_array,1024,32,1,20,2,true,false,true,false,0.168457,0.0844727
gpu_array,1024,32,1,20,4,true,false,true,false,0.171963,0.0850488
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.216025,0.0802832
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.173579,0.0876416
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.162524,0.0873291
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.285293,0.0997461
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.275264,0.0926465
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.296182,0.114541
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.125181,0.0499854
0.0499854
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.138569,0.0643506
0.0643506
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.129722,0.0545264
0.0545264
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.166768,0.0896191
0.0896191
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.138047,0.061875
0.061875
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.145894,0.0697217
0.0697217
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0499854
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.603295 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.159917,0.0778857
gpu_array,1024,8,1,20,2,true,false,true,false,0.143145,0.0699023
gpu_array,1024,8,1,20,4,true,false,true,false,0.160059,0.0799805
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.21854,0.0808447
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.164658,0.082627
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.170205,0.090127
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.357256,0.107256
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.271279,0.0857324
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.298154,0.113584
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.242646,0.102021
gpu_array,1024,8,1,50,2,true,false,true,false,0.242812,0.0982813
gpu_array,1024,8,1,50,4,true,false,true,false,0.248281,0.105703
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.240254,0.0996289
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.249224,0.103716
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.254541,0.112939
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.291177,0.106606
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.286831,0.104214
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.303247,0.113794
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.173721,0.0897363
gpu_array,1024,32,1,20,2,true,false,true,false,0.151943,0.0845605
gpu_array,1024,32,1,20,4,true,false,true,false,0.171089,0.0851514
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.217031,0.0803125
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.170093,0.0880615
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.170103,0.0870947
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.283779,0.099209
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.281304,0.0928271
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.320283,0.114229
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.12417,0.0499512
0.0499512
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.138296,0.0640771
0.0640771
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.128774,0.0545557
0.0545557
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.164634,0.0894385
0.0894385
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.136294,0.0620752
0.0620752
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.144775,0.0695801
0.0695801
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0499512
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.60328 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.946226,0.0370459
gpu_array,1024,8,1,20,2,false,false,true,false,0.950542,0.0364795
gpu_array,1024,8,1,20,4,false,false,true,false,0.94187,0.0444092
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.963589,0.0378076
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.968115,0.0364746
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.970815,0.0450342
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,1.00298,0.0449756
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.97416,0.0425195
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.999355,0.0481836
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.9375,0.0390625
gpu_array,1024,8,1,50,2,false,false,true,false,0.961182,0.0412598
gpu_array,1024,8,1,50,4,false,false,true,false,0.946772,0.041499
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,0.96356,0.0397314
gpu_sparse,1024,8,1,50,2,false,false,true,false,0.959321,0.0472119
gpu_sparse,1024,8,1,50,4,false,false,true,false,0.949546,0.0472021
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.95145,0.0412939
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.952607,0.0444043
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.995791,0.0455957
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.962334,0.0365527
gpu_array,1024,32,1,20,2,false,false,true,false,0.946216,0.035083
gpu_array,1024,32,1,20,4,false,false,true,false,0.939536,0.0381689
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.977749,0.0363428
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.949727,0.0356641
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.961445,0.0385938
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.986553,0.0431934
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.969854,0.0411426
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.979653,0.0421533
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.928745,0.0351904
0.0351904
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.94978,0.0376709
0.0376709
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.93314,0.0356787
0.0356787
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.035083
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.24896 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.970601,0.0370068
gpu_array,1024,8,1,20,2,false,false,true,false,0.935845,0.0364307
gpu_array,1024,8,1,20,4,false,false,true,false,0.947847,0.0445264
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.976895,0.0374414
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.943794,0.0365674
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.950449,0.0451758
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.965996,0.042168
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.990571,0.0423291
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.980825,0.048208
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.972646,0.0390527
gpu_array,1024,8,1,50,2,false,false,true,false,0.958242,0.04125
gpu_array,1024,8,1,50,4,false,false,true,false,0.96417,0.0413184
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,0.957661,0.0396924
gpu_sparse,1024,8,1,50,2,false,false,true,false,0.939604,0.0470264
gpu_sparse,1024,8,1,50,4,false,false,true,false,0.992563,0.047251
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.988931,0.041665
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.995718,0.0445459
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.959434,0.0453711
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.943848,0.0366211
gpu_array,1024,32,1,20,2,false,false,true,false,0.935679,0.0352881
gpu_array,1024,32,1,20,4,false,false,true,false,0.947476,0.0382959
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.943794,0.0365674
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.940762,0.0354883
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.940806,0.0384619
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.96708,0.043252
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.963848,0.0409961
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.969824,0.0420898
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.941533,0.0352832
0.0352832
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.94584,0.0376367
0.0376367
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.938989,0.0356689
0.0356689
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0352832
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.248356 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0941992,0.0180273
gpu_array,1024,8,1,20,2,true,false,true,false,0.0825879,0.0181348
gpu_array,1024,8,1,20,4,true,false,true,false,0.104063,0.0191016
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0994238,0.0183691
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0921387,0.0188965
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0969824,0.019834
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.133472,0.0231201
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.131807,0.0185254
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.133667,0.0213623
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.104966,0.0209814
gpu_array,1024,8,1,50,2,true,false,true,false,0.101206,0.0221045
gpu_array,1024,8,1,50,4,true,false,true,false,0.105063,0.0220557
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0988281,0.0216797
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0947998,0.0244873
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0958301,0.024541
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.132827,0.0263818
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.143232,0.0260449
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.137417,0.0260889
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0977002,0.0166455
gpu_array,1024,32,1,20,2,true,false,true,false,0.0919434,0.0157715
gpu_array,1024,32,1,20,4,true,false,true,false,0.0906885,0.0154932
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0911572,0.0169385
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0989648,0.015957
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.100327,0.0163428
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.134316,0.0220117
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.125088,0.0186426
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.133599,0.0193408
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0816406,0.0152344
0.0152344
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0847461,0.0173633
0.0173633
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,0.0855127,0.0171533
0.0171533
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,0.0850488,0.017666
0.017666
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0858789,0.0194727
0.0194727
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.094873,0.0196777
0.0196777
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0152344
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.133826 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0931885,0.0179932
gpu_array,1024,8,1,20,2,true,false,true,false,0.0933203,0.0171484
gpu_array,1024,8,1,20,4,true,false,true,false,0.103018,0.0190332
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0994775,0.0184229
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0843994,0.0189697
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0921631,0.0198975
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.132256,0.0228809
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.131006,0.0187012
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.125962,0.0214697
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.10396,0.0209521
gpu_array,1024,8,1,50,2,true,false,true,false,0.10415,0.0221191
gpu_array,1024,8,1,50,4,true,false,true,false,0.107197,0.0222363
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0920898,0.0217773
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0969775,0.0247119
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0999414,0.0247461
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.139839,0.0265576
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.137124,0.0257959
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.138525,0.0262207
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.103574,0.0166602
gpu_array,1024,32,1,20,2,true,false,true,false,0.0919238,0.015752
gpu_array,1024,32,1,20,4,true,false,true,false,0.0994971,0.0155127
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0991406,0.0171094
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.103062,0.0161475
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0917334,0.0165381
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.134316,0.0220117
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.132134,0.0188525
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.134551,0.0193164
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0837988,0.0154395
0.0154395
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0829199,0.0174902
0.0174902
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0851855,0.0158496
0.0158496
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0859521,0.0166162
0.0166162
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0889307,0.0195947
0.0195947
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0883008,0.0199414
0.0199414
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0154395
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.133625 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.2524,3.05318
gpu_array,1024,8,1,20,2,true,false,true,false,4.92305,4.73555
gpu_array,1024,8,1,20,4,true,false,true,false,4.54336,4.33633
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.85697,2.71342
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.8959,4.7123
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.7457,4.58848
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.68873,3.47486
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.95506,6.73631
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.45998,5.27053
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.75498,3.60654
gpu_array,1024,8,1,50,2,true,false,true,false,4.6434,4.48715
gpu_array,1024,8,1,50,4,true,false,true,false,6.98686,6.83549
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.35783,3.21037
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.53937,4.38605
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.32307,6.16193
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.15885,3.94498
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.30418,7.11082
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.1051,9.89119
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.31102,3.14793
gpu_array,1024,32,1,20,2,true,false,true,false,3.45613,3.29891
gpu_array,1024,32,1,20,4,true,false,true,false,4.11141,3.95418
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.08162,2.94393
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.52781,3.37547
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.80164,3.59852
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,3.94457,3.75609
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.65121,4.4266
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.91973,2.86016
2.86016
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.02447,2.96881
2.96881
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.0566,1.99215
1.99215
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.19775,2.12549
2.12549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99215
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 186 seconds of which 6.53843 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.2317,3.05396
gpu_array,1024,8,1,20,2,true,false,true,false,4.87574,4.68434
gpu_array,1024,8,1,20,4,true,false,true,false,4.64355,4.49023
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.85291,2.70643
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.89385,4.7415
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.7791,4.6248
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.64209,3.46826
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.72268,6.53811
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.31451,5.10357
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.65799,3.51053
gpu_array,1024,8,1,50,2,true,false,true,false,4.57439,4.424
gpu_array,1024,8,1,50,4,true,false,true,false,6.9166,6.75449
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.35766,3.21117
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.52688,4.33547
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.43686,6.27572
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.11068,3.92514
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.2759,7.08254
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.1266,9.93516
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.27602,3.11977
gpu_array,1024,32,1,20,2,true,false,true,false,3.35918,3.19609
gpu_array,1024,32,1,20,4,true,false,true,false,4.14473,3.95234
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.07861,2.93604
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.53051,3.37426
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.78445,3.6243
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,3.95201,3.76646
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.75215,4.56465
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.88693,2.79514
2.79514
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.06684,2.96918
2.96918
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.08793,1.99223
1.99223
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.2352,2.14047
2.14047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99223
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 147 seconds of which 6.51757 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.105098,0.017207
gpu_array,1024,8,1,20,2,true,false,true,false,0.115513,0.0295752
gpu_array,1024,8,1,20,4,true,false,true,false,0.118521,0.0267236
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.108354,0.0175342
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.120112,0.0312451
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.121143,0.0322754
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.150396,0.0224658
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.165591,0.0347314
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.16895,0.033208
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.194692,0.0218408
gpu_array,1024,8,1,50,2,true,false,true,false,0.258906,0.0342969
gpu_array,1024,8,1,50,4,true,false,true,false,0.212017,0.0342822
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.206187,0.0216162
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.271567,0.0362158
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.223726,0.0362256
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.217441,0.0279883
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.300718,0.0399756
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.250937,0.04
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.105273,0.0164063
gpu_array,1024,32,1,20,2,true,false,true,false,0.107334,0.0165137
gpu_array,1024,32,1,20,4,true,false,true,false,0.108164,0.0173438
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.10313,0.0162158
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.111611,0.0168848
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.106934,0.0180664
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.149155,0.0212256
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.149385,0.0214551
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.142456,0.0252686
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.103682,0.015791
0.015791
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.106108,0.0182178
0.0182178
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.104712,0.0168213
0.0168213
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.102524,0.0175635
0.0175635
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.103589,0.0186279
0.0186279
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.106084,0.0191699
0.0191699
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.015791
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 19 seconds of which 0.166498 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.108022,0.0162256
gpu_array,1024,8,1,20,2,true,false,true,false,0.119414,0.0276172
gpu_array,1024,8,1,20,4,true,false,true,false,0.118008,0.0252344
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.103555,0.0166406
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.118096,0.0311816
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.122163,0.0323193
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.146475,0.0224512
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.161685,0.0347314
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.150322,0.0331348
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.214292,0.0219092
gpu_array,1024,8,1,50,2,true,false,true,false,0.259922,0.0343359
gpu_array,1024,8,1,50,4,true,false,true,false,0.227749,0.0343896
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.194219,0.0213672
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.26063,0.0360205
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.236162,0.0359668
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.209414,0.0277734
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.292544,0.0396143
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.243726,0.039624
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.102222,0.0162842
gpu_array,1024,32,1,20,2,true,false,true,false,0.105186,0.0163184
gpu_array,1024,32,1,20,4,true,false,true,false,0.107915,0.0170947
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.103022,0.0161084
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0976367,0.016582
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.110605,0.017832
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.138184,0.0209961
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.147246,0.0212695
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.143286,0.0251221
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.102598,0.0156836
0.0156836
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.104902,0.0179883
0.0179883
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.102554,0.0166162
0.0166162
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.105127,0.0172363
0.0172363
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.105313,0.0183984
0.0183984
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.10792,0.0190527
0.0190527
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0156836
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.164479 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.141323,0.123745
gpu_array,4096,32,1,2,2,true,false,true,false,0.0995361,0.081958
gpu_array,4096,32,1,2,4,true,false,true,false,0.0817871,0.064209
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.15032,0.132498
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0882715,0.0702051
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0951685,0.0775903
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0769995,0.0599097
gpu_array,4096,32,1,10,2,true,false,true,false,0.0650464,0.0479565
gpu_array,4096,32,1,10,4,true,false,true,false,0.0602979,0.0422314
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0799902,0.062168
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0681787,0.0501123
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0659326,0.0485986
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.15073,0.133152
gpu_array,4096,64,1,2,2,true,false,true,false,0.104385,0.0877832
gpu_array,4096,64,1,2,4,true,false,true,false,0.0801807,0.063335
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.149792,0.132214
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0885034,0.0699487
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0948853,0.0773071
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0780884,0.060022
gpu_array,4096,64,1,10,2,true,false,true,false,0.0648462,0.0482446
gpu_array,4096,64,1,10,4,true,false,true,false,0.0563647,0.0382983
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0799561,0.0623779
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.060459,0.043125
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0616602,0.0438379
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0523657,0.037229
0.037229
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0641089,0.0482397
0.0482397
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0586597,0.0427905
0.0427905
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0604297,0.0443164
0.0443164
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.0670337,0.0516528
0.0516528
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.100942,0.0858057
0.0858057
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.037229
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.831841 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.141843,0.123777
gpu_array,4096,32,1,2,2,true,false,true,false,0.0992603,0.0819263
gpu_array,4096,32,1,2,4,true,false,true,false,0.0770361,0.0592139
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.138762,0.122161
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0876733,0.0703394
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0955688,0.0777466
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0770654,0.0599756
gpu_array,4096,32,1,10,2,true,false,true,false,0.0651123,0.0480225
gpu_array,4096,32,1,10,4,true,false,true,false,0.0585889,0.0422314
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.079397,0.0623071
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0674756,0.0501416
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0653467,0.048501
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.150225,0.133379
gpu_array,4096,64,1,2,2,true,false,true,false,0.105576,0.087998
gpu_array,4096,64,1,2,4,true,false,true,false,0.0801147,0.0635132
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.150657,0.13259
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0867651,0.0701636
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0950854,0.0775073
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.079082,0.0600391
gpu_array,4096,64,1,10,2,true,false,true,false,0.0677612,0.04823
gpu_array,4096,64,1,10,4,true,false,true,false,0.0576562,0.0383691
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0800146,0.0624365
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0606665,0.0430884
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0611597,0.0438257
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0522974,0.0371606
0.0371606
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0638647,0.0482397
0.0482397
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0583301,0.0429492
0.0429492
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0594751,0.0443384
0.0443384
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0683911,0.052522
0.052522
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.102993,0.0868799
0.0868799
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0371606
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.827217 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0459814,0.0186377
gpu_array,4096,32,1,2,2,true,false,true,false,0.0421191,0.0150195
gpu_array,4096,32,1,2,4,true,false,true,false,0.0405151,0.0141479
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0453052,0.0186938
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.036748,0.0103809
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.039895,0.0127954
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0364282,0.00908447
gpu_array,4096,32,1,10,2,true,false,true,false,0.0350684,0.00772461
gpu_array,4096,32,1,10,4,true,false,true,false,0.034668,0.00756836
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0370752,0.0094873
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0342798,0.00693604
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0354761,0.00813232
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0427295,0.0185596
gpu_array,4096,64,1,2,2,true,false,true,false,0.0416113,0.015
gpu_array,4096,64,1,2,4,true,false,true,false,0.037959,0.0140332
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0428809,0.0184668
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0340601,0.0103784
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0398804,0.0127808
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0364624,0.00911865
gpu_array,4096,64,1,10,2,true,false,true,false,0.0350684,0.00772461
gpu_array,4096,64,1,10,4,true,false,true,false,0.0315161,0.00759033
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0366333,0.00953369
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0347168,0.00712891
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0313403,0.00741455
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0262305,0.00694336
0.00694336
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.030144,0.00914795
0.00914795
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0283374,0.00709717
0.00709717
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0304712,0.00923096
0.00923096
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,true,0.0295581,0.010271
0.010271
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,true,0.0371704,0.0164185
0.0164185
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00693604
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.137399 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0455371,0.0186816
gpu_array,4096,32,1,2,2,true,false,true,false,0.0389819,0.0150562
gpu_array,4096,32,1,2,4,true,false,true,false,0.0380566,0.0141309
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0445825,0.0187036
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0345337,0.0103638
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0364087,0.0127271
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0329639,0.00903809
gpu_array,4096,32,1,10,2,true,false,true,false,0.0350146,0.0076709
gpu_array,4096,32,1,10,4,true,false,true,false,0.0317773,0.00760742
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.03375,0.00958008
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0345703,0.00698242
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0357642,0.00817627
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0450024,0.0186353
gpu_array,4096,64,1,2,2,true,false,true,false,0.0426099,0.015022
gpu_array,4096,64,1,2,4,true,false,true,false,0.0387451,0.0140869
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0426807,0.0185107
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0367603,0.0103931
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0406226,0.0127905
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0355176,0.00915039
gpu_array,4096,64,1,10,2,true,false,true,false,0.0358423,0.00776611
gpu_array,4096,64,1,10,4,true,false,true,false,0.0347217,0.00762207
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0352051,0.00957031
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0347217,0.00713379
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0320679,0.00740967
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0279175,0.00692139
0.00692139
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0301416,0.00914551
0.00914551
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0280786,0.00708252
0.00708252
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0287402,0.00920898
0.00920898
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0313135,0.0103174
0.0103174
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0374365,0.0164404
0.0164404
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00692139
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.137595 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.394392,0.100935
gpu_array,4096,8,1,20,2,true,false,true,false,0.368237,0.0750244
gpu_array,4096,8,1,20,4,true,false,true,false,0.367573,0.0753369
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.397793,0.108242
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.346184,0.0588306
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.363245,0.0697876
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.37001,0.0748438
gpu_array,4096,8,1,50,2,true,false,true,false,0.341548,0.0537061
gpu_array,4096,8,1,50,4,true,false,true,false,0.349353,0.0602905
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.369692,0.0781885
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.349067,0.0646436
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.357705,0.065957
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.332974,0.0514795
0.0514795
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.362581,0.0776685
0.0776685
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,true,false,true,true,0.337307,0.0528833
0.0528833
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,false,false,true,true,0.539148,0.257166
0.257166
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0514795
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.542713 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.388694,0.100852
gpu_array,4096,8,1,20,2,true,false,true,false,0.366616,0.0748682
gpu_array,4096,8,1,20,4,true,false,true,false,0.367861,0.0751367
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.402974,0.108052
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.3452,0.0588232
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.357659,0.0695728
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.361404,0.0747827
gpu_array,4096,8,1,50,2,true,false,true,false,0.341848,0.0535181
gpu_array,4096,8,1,50,4,true,false,true,false,0.348784,0.0597217
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.371079,0.0781104
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.350781,0.0641602
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.353264,0.0661548
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.338701,0.0513477
0.0513477
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.359324,0.0778296
0.0778296
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,true,false,true,true,0.33947,0.0528491
0.0528491
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,false,false,true,true,0.543938,0.259514
0.259514
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0513477
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.54284 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.173159,0.111392
gpu_array,4096,32,1,2,2,true,false,true,false,0.137151,0.0792896
gpu_array,4096,32,1,2,4,true,false,true,false,0.121133,0.0605859
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.147871,0.10832
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.137515,0.0789209
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.130354,0.069563
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.14481,0.0713232
gpu_array,4096,32,1,10,2,true,false,true,false,0.150435,0.0742627
gpu_array,4096,32,1,10,4,true,false,true,false,0.13886,0.0639087
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.128103,0.0704858
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.147271,0.0710986
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.142527,0.0656226
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.190969,0.12554
gpu_array,4096,64,1,2,2,true,false,true,false,0.140032,0.0802173
gpu_array,4096,64,1,2,4,true,false,true,false,0.122607,0.0625488
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.153779,0.112275
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.140483,0.0801807
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.132815,0.0715356
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.145916,0.0729175
gpu_array,4096,64,1,10,2,true,false,true,false,0.148677,0.0732373
gpu_array,4096,64,1,10,4,true,false,true,false,0.140371,0.0612695
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.131533,0.0714746
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.146692,0.0717407
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.137188,0.0639453
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.130698,0.0752783
0.0752783
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.137375,0.0802466
0.0802466
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0966919,0.0393188
0.0393188
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.118599,0.0624463
0.0624463
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.131594,0.0747095
0.0747095
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.139189,0.0823047
0.0823047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0393188
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.936329 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.1697,0.11135
gpu_array,4096,32,1,2,2,true,false,true,false,0.132463,0.0733813
gpu_array,4096,32,1,2,4,true,false,true,false,0.115347,0.0560205
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.148506,0.107979
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.136936,0.0788306
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.13021,0.0696631
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.144805,0.0708301
gpu_array,4096,32,1,10,2,true,false,true,false,0.147153,0.0741553
gpu_array,4096,32,1,10,4,true,false,true,false,0.139043,0.0640918
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.12438,0.0701807
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.148425,0.0710327
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.13853,0.0657764
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.18449,0.122966
gpu_array,4096,64,1,2,2,true,false,true,false,0.136848,0.0802075
gpu_array,4096,64,1,2,4,true,false,true,false,0.124148,0.0626245
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.154109,0.113826
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.141882,0.0803589
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.132026,0.0719678
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.150659,0.0735107
gpu_array,4096,64,1,10,2,true,false,true,false,0.146943,0.0732129
gpu_array,4096,64,1,10,4,true,false,true,false,0.134919,0.0614331
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.12843,0.0727661
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.14449,0.0717358
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.140366,0.0641943
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.132839,0.0754663
0.0754663
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.135842,0.0801782
0.0801782
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0967285,0.0393555
0.0393555
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.119719,0.0625903
0.0625903
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.133052,0.0754346
0.0754346
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.13981,0.0826807
0.0826807
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0393555
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 0.932987 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.75667,0.0393848
gpu_array,4096,8,1,20,2,false,false,true,false,0.760544,0.0400854
gpu_array,4096,8,1,20,4,false,false,true,false,0.762258,0.0454614
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.757046,0.0407373
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.75386,0.0409692
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.765669,0.0488721
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.761689,0.0395215
gpu_array,4096,8,1,50,2,false,false,true,false,0.758765,0.0400146
gpu_array,4096,8,1,50,4,false,false,true,false,0.762009,0.0398413
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.75968,0.0401978
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.764583,0.044856
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.763845,0.0443628
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.755837,0.0348901
gpu_array,4096,32,1,20,2,false,false,true,false,0.75196,0.0344312
gpu_array,4096,32,1,20,4,false,false,true,false,0.760813,0.0359595
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.754646,0.0351636
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.749819,0.0347314
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.755815,0.036333
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.753486,0.0379102
0.0379102
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.756875,0.0408105
0.0408105
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.753354,0.0355811
0.0355811
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0344312
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.340015 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.756487,0.0392017
gpu_array,4096,8,1,20,2,false,false,true,false,0.760911,0.0402075
gpu_array,4096,8,1,20,4,false,false,true,false,0.76322,0.0454468
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.757283,0.04073
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.762705,0.0412695
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.776013,0.0489624
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.765229,0.0396436
gpu_array,4096,8,1,50,2,false,false,true,false,0.759592,0.0398657
gpu_array,4096,8,1,50,4,false,false,true,false,0.76072,0.0400171
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.761357,0.040166
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.767808,0.0446631
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.769856,0.0447583
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.754895,0.0349243
gpu_array,4096,32,1,20,2,false,false,true,false,0.760349,0.034519
gpu_array,4096,32,1,20,4,false,false,true,false,0.758416,0.0360034
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.759219,0.0350977
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.753494,0.0347437
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.75073,0.0363745
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.752927,0.0378394
0.0378394
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.755479,0.0408789
0.0408789
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.7495,0.0353882
0.0353882
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.034519
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.340255 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0558203,0.0189551
gpu_array,4096,32,1,2,2,true,false,true,false,0.05229,0.0151807
gpu_array,4096,32,1,2,4,true,false,true,false,0.0518604,0.0142627
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0566333,0.0190356
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0495752,0.0107568
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0486353,0.0129907
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0467334,0.00962402
gpu_array,4096,32,1,10,2,true,false,true,false,0.0481055,0.00855469
gpu_array,4096,32,1,10,4,true,false,true,false,0.0453394,0.00847412
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0469531,0.010332
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0454077,0.00878662
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0453809,0.00875977
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0572168,0.0188867
gpu_array,4096,64,1,2,2,true,false,true,false,0.0531665,0.0150806
gpu_array,4096,64,1,2,4,true,false,true,false,0.0505811,0.0142041
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0545386,0.018894
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.04729,0.0106689
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0500366,0.0129272
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0465942,0.009729
gpu_array,4096,64,1,10,2,true,false,true,false,0.0461646,0.00856689
gpu_array,4096,64,1,10,4,true,false,true,false,0.0473706,0.00855225
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0505029,0.0104639
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0465625,0.00774414
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0460229,0.00866943
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0373047,0.00776367
0.00776367
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0388086,0.00975586
0.00975586
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.0378857,0.00883301
0.00883301
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.0373242,0.00924805
0.00924805
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,true,0.0402173,0.0106763
0.0106763
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,true,0.044834,0.017002
0.017002
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00774414
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.144744 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0549512,0.0175977
gpu_array,4096,32,1,2,2,true,false,true,false,0.0501758,0.014043
gpu_array,4096,32,1,2,4,true,false,true,false,0.0522437,0.0131812
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0530249,0.0176245
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0463525,0.00997559
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0504541,0.012124
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0492163,0.00966553
gpu_array,4096,32,1,10,2,true,false,true,false,0.0459106,0.00855713
gpu_array,4096,32,1,10,4,true,false,true,false,0.0444019,0.00851318
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.046521,0.0103882
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0473193,0.00874512
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0441577,0.00875732
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0574194,0.0188452
gpu_array,4096,64,1,2,2,true,false,true,false,0.0526392,0.0150415
gpu_array,4096,64,1,2,4,true,false,true,false,0.0527759,0.0142017
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0562598,0.0189062
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0458472,0.0106909
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.05104,0.0129541
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0470776,0.00972412
gpu_array,4096,64,1,10,2,true,false,true,false,0.0444556,0.00856689
gpu_array,4096,64,1,10,4,true,false,true,false,0.0444116,0.00852295
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.047041,0.0104199
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0457935,0.00770752
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.04479,0.00865723
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0377344,0.00770508
0.00770508
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0420483,0.00982178
0.00982178
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0409082,0.00868164
0.00868164
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0403369,0.0100635
0.0100635
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0407642,0.0107349
0.0107349
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0475659,0.0170483
0.0170483
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00770508
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.142322 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.62698,4.60403
gpu_array,4096,32,1,2,2,true,false,true,false,3.20521,3.18079
gpu_array,4096,32,1,2,4,true,false,true,false,3.16232,3.13913
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.43769,4.41669
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.29413,3.27143
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.57115,2.54771
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.59101,3.54926
gpu_array,4096,32,1,10,2,true,false,true,false,3.02396,2.9683
gpu_array,4096,32,1,10,4,true,false,true,false,2.8376,2.78413
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.11852,3.07677
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.89786,2.85709
gpu_sparse,4096,32,1,10,4,true,false,true,false,2.95663,2.91415
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,3.9487,3.92209
gpu_array,4096,64,1,2,2,true,false,true,false,3.11111,3.08841
gpu_array,4096,64,1,2,4,true,false,true,false,2.99405,2.96793
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.7316,3.70938
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.12908,3.10394
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.70295,2.67731
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.53234,3.49108
gpu_array,4096,64,1,10,2,true,false,true,false,2.89499,2.84201
gpu_array,4096,64,1,10,4,true,false,true,false,3.10197,3.04899
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,3.04232,3.00009
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.84915,2.80862
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.70503,2.64888
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,1.91938,1.89741
1.89741
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,1.95258,1.93207
1.93207
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,1.89621,1.87668
1.87668
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,1.9523,1.93009
1.93009
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.87668
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 134 seconds of which 8.62766 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.6731,4.65161
gpu_array,4096,32,1,2,2,true,false,true,false,3.23675,3.21185
gpu_array,4096,32,1,2,4,true,false,true,false,3.14698,3.11915
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.46551,4.44207
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.33927,3.31266
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.68772,2.66551
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.60916,3.56717
gpu_array,4096,32,1,10,2,true,false,true,false,3.01074,2.95752
gpu_array,4096,32,1,10,4,true,false,true,false,2.85421,2.80245
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.11421,3.07515
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.96981,2.92855
gpu_sparse,4096,32,1,10,4,true,false,true,false,2.97529,2.93452
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,3.98171,3.95485
gpu_array,4096,64,1,2,2,true,false,true,false,3.0525,3.02735
gpu_array,4096,64,1,2,4,true,false,true,false,2.97377,2.94643
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.73664,3.71442
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.08485,3.0602
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.65251,2.62883
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.68963,3.64886
gpu_array,4096,64,1,10,2,true,false,true,false,2.91177,2.85708
gpu_array,4096,64,1,10,4,true,false,true,false,3.05855,3.00362
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.89925,2.86019
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.87942,2.83841
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.76287,2.72308
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,1.84622,1.82522
1.82522
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,1.94664,1.92345
1.92345
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,1.93988,1.91767
1.91767
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,1.95985,1.93861
1.93861
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.82522
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 130 seconds of which 8.65653 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.114341,0.0171729
gpu_array,4096,32,1,2,2,true,false,true,false,0.115044,0.0137256
gpu_array,4096,32,1,2,4,true,false,true,false,0.113254,0.0134009
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.117375,0.0170337
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.111433,0.010603
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.107734,0.0117871
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.104829,0.00888184
gpu_array,4096,32,1,10,2,true,false,true,false,0.106853,0.00846436
gpu_array,4096,32,1,10,4,true,false,true,false,0.105012,0.00808838
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.108364,0.00924316
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.102339,0.00883301
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.110803,0.00826416
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.117244,0.017146
gpu_array,4096,64,1,2,2,true,false,true,false,0.109937,0.0137451
gpu_array,4096,64,1,2,4,true,false,true,false,0.110674,0.0132617
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.112603,0.0168994
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.1077,0.0105322
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.112107,0.0117651
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.107395,0.00900635
gpu_array,4096,64,1,10,2,true,false,true,false,0.102024,0.00851807
gpu_array,4096,64,1,10,4,true,false,true,false,0.0997144,0.00816162
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.105212,0.00926514
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.105969,0.00928955
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.102019,0.0080249
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,true,0.103198,0.00749512
0.00749512
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,true,0.104233,0.0102393
0.0102393
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.10584,0.00745117
0.00745117
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.10699,0.0107983
0.0107983
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,true,0.107727,0.0103149
0.0103149
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,true,0.116421,0.0163232
0.0163232
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00745117
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 12 seconds of which 0.136698 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.111396,0.0159375
gpu_array,4096,32,1,2,2,true,false,true,false,0.110667,0.0127661
gpu_array,4096,32,1,2,4,true,false,true,false,0.101958,0.0123584
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.11425,0.0158618
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.109551,0.00994141
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.108811,0.0109106
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.113716,0.00897949
gpu_array,4096,32,1,10,2,true,false,true,false,0.104792,0.00835693
gpu_array,4096,32,1,10,4,true,false,true,false,0.105244,0.00807617
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.106313,0.00914551
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.106072,0.00865967
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.106853,0.00822021
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.115239,0.0170947
gpu_array,4096,64,1,2,2,true,false,true,false,0.10637,0.0138403
gpu_array,4096,64,1,2,4,true,false,true,false,0.104968,0.0134155
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.112954,0.0170068
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.110242,0.0106323
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.107192,0.0117334
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.107617,0.00898437
gpu_array,4096,64,1,10,2,true,false,true,false,0.102275,0.00852539
gpu_array,4096,64,1,10,4,true,false,true,false,0.11085,0.00831055
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.105281,0.0093335
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.106694,0.00928223
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.108916,0.00808594
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.107666,0.00805664
0.00805664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.103574,0.0105566
0.0105566
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0937671,0.00807373
0.00807373
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.108357,0.0114331
0.0114331
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0968213,0.0116162
0.0116162
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.112319,0.0171045
0.0171045
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00805664
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.13611 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0763599,0.064397
gpu_array,8192,32,1,2,2,true,false,true,false,0.0539392,0.0423425
gpu_array,8192,32,1,2,4,true,false,true,false,0.0463452,0.0348706
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.087406,0.0654333
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0544153,0.0424524
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0555701,0.0437292
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0573157,0.0453528
gpu_array,8192,32,1,10,2,true,false,true,false,0.0475,0.0356592
gpu_array,8192,32,1,10,4,true,false,true,false,0.0443823,0.0326636
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0691919,0.0470972
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0503198,0.0383569
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0496948,0.0376099
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0816003,0.0703699
gpu_array,8192,64,1,2,2,true,false,true,false,0.0581018,0.0465051
gpu_array,8192,64,1,2,4,true,false,true,false,0.0506165,0.0397522
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0933472,0.0728394
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.05625,0.0450195
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0574622,0.0459875
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.05755,0.0454651
gpu_array,8192,64,1,10,2,true,false,true,false,0.0479541,0.0358691
gpu_array,8192,64,1,10,4,true,false,true,false,0.0476685,0.0358276
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0690308,0.0473022
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0519861,0.0406335
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0531934,0.0408643
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0445874,0.0333569
0.0333569
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0455005,0.0340259
0.0340259
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0509595,0.0399731
0.0399731
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0569958,0.0457654
0.0457654
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0470007,0.0356482
0.0356482
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.047616,0.0358972
0.0358972
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0326636
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 1.08222 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0765088,0.0643018
gpu_array,8192,32,1,2,2,true,false,true,false,0.0530469,0.0423047
gpu_array,8192,32,1,2,4,true,false,true,false,0.0470435,0.0348364
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0870459,0.0654395
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0534949,0.0423865
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0555225,0.0436816
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0563098,0.0453235
gpu_array,8192,32,1,10,2,true,false,true,false,0.0479749,0.0356458
gpu_array,8192,32,1,10,4,true,false,true,false,0.0449817,0.0326526
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0689185,0.0470679
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0504578,0.0383728
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0491724,0.0375757
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0829114,0.070094
gpu_array,8192,64,1,2,2,true,false,true,false,0.0571362,0.046272
gpu_array,8192,64,1,2,4,true,false,true,false,0.0519189,0.0397119
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0947986,0.0728259
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0575952,0.045022
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0579333,0.0459705
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0574646,0.0453796
gpu_array,8192,64,1,10,2,true,false,true,false,0.0469458,0.0358374
gpu_array,8192,64,1,10,4,true,false,true,false,0.0479175,0.0358325
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0691748,0.0472021
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0526953,0.0406104
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0517981,0.0408118
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.044928,0.0333313
0.0333313
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0445288,0.0341528
0.0341528
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0511963,0.0399658
0.0399658
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0572778,0.0456812
0.0456812
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0468945,0.0356641
0.0356641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0467822,0.035918
0.035918
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0326526
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 1.08124 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0292981,0.00952271
gpu_array,8192,32,1,2,2,true,false,true,false,0.0266614,0.00761841
gpu_array,8192,32,1,2,4,true,false,true,false,0.0260852,0.00716431
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0291858,0.00965454
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0252393,0.00619629
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0254346,0.00675781
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.038606,0.00650146
gpu_array,8192,32,1,10,2,true,false,true,false,0.0403455,0.00543335
gpu_array,8192,32,1,10,4,true,false,true,false,0.0388452,0.00527588
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0421924,0.00679199
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0404761,0.00556396
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0403503,0.00580444
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0291357,0.00948242
gpu_array,8192,64,1,2,2,true,false,true,false,0.0264221,0.00762329
gpu_array,8192,64,1,2,4,true,false,true,false,0.026355,0.00718994
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0288159,0.00977295
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0258618,0.0062085
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0263696,0.00696045
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0402271,0.00653564
gpu_array,8192,64,1,10,2,true,false,true,false,0.0377966,0.005448
gpu_array,8192,64,1,10,4,true,false,true,false,0.0384912,0.00528809
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0407593,0.00682373
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0399866,0.00592896
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0409741,0.00606201
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0199304,0.00528198
0.00528198
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0202075,0.00568115
0.00568115
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0201477,0.0053772
0.0053772
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0201599,0.00563354
0.00563354
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0218335,0.00755127
0.00755127
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.022019,0.00761475
0.00761475
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00527588
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.166092 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0296313,0.00887939
gpu_array,8192,32,1,2,2,true,false,true,false,0.0266394,0.00710815
gpu_array,8192,32,1,2,4,true,false,true,false,0.0255774,0.00665649
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0283691,0.00895996
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0258069,0.00578735
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0248132,0.00625854
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0415125,0.00647827
gpu_array,8192,32,1,10,2,true,false,true,false,0.0379932,0.00540039
gpu_array,8192,32,1,10,4,true,false,true,false,0.0400342,0.00524414
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0418164,0.00678223
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0407361,0.00557983
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0399951,0.00581543
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0286353,0.00947021
gpu_array,8192,64,1,2,2,true,false,true,false,0.0278723,0.00760864
gpu_array,8192,64,1,2,4,true,false,true,false,0.0260913,0.00717041
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0290161,0.009729
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0253357,0.00617065
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0262585,0.00697144
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0402295,0.00653809
gpu_array,8192,64,1,10,2,true,false,true,false,0.0390173,0.005448
gpu_array,8192,64,1,10,4,true,false,true,false,0.040708,0.00530762
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0434778,0.00685669
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0395166,0.00594727
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0408557,0.00606567
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0200537,0.0052832
0.0052832
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0205432,0.00565063
0.00565063
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.020354,0.00533936
0.00533936
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0206628,0.00564819
0.00564819
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0223315,0.00756104
0.00756104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0232336,0.00760864
0.00760864
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00524414
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.163287 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.364633,0.0991296
gpu_array,8192,8,1,20,2,true,false,true,false,0.367875,0.0720984
gpu_array,8192,8,1,20,4,true,false,true,false,0.332891,0.0672656
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.375168,0.10637
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.323231,0.0571179
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.33224,0.0668591
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.345929,0.0728577
gpu_array,8192,8,1,50,2,true,false,true,false,0.327963,0.0518396
gpu_array,8192,8,1,50,4,true,false,true,false,0.325896,0.0553882
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.352457,0.0756018
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.389487,0.0645361
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.338126,0.0610266
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.317629,0.0546899
0.0546899
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.341506,0.0742944
0.0742944
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.337928,0.0758435
0.0758435
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.535536,0.275038
0.275038
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0518396
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 17 seconds of which 1.0895 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.368207,0.0990417
gpu_array,8192,8,1,20,2,true,false,true,false,0.337898,0.0719067
gpu_array,8192,8,1,20,4,true,false,true,false,0.334739,0.0671606
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.373418,0.106328
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.318655,0.0530298
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.333762,0.0667944
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.391631,0.0727832
gpu_array,8192,8,1,50,2,true,false,true,false,0.322671,0.0517969
gpu_array,8192,8,1,50,4,true,false,true,false,0.377222,0.0553223
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.346113,0.0754834
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.386251,0.0644739
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.379124,0.0611304
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.316339,0.0546204
0.0546204
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.33439,0.0742578
0.0742578
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.334607,0.0759399
0.0759399
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.541813,0.27985
0.27985
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0517969
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 17 seconds of which 1.08947 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.116117,0.0754675
gpu_array,8192,32,1,2,2,true,false,true,false,0.0961658,0.0555164
gpu_array,8192,32,1,2,4,true,false,true,false,0.0938269,0.0522009
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.125984,0.0787427
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.101796,0.0618787
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.101697,0.0622681
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.11369,0.059491
gpu_array,8192,32,1,10,2,true,false,true,false,0.105333,0.0571155
gpu_array,8192,32,1,10,4,true,false,true,false,0.115844,0.0607898
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.113629,0.0573547
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.10858,0.0586536
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.114362,0.0611389
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.125114,0.0834875
gpu_array,8192,64,1,2,2,true,false,true,false,0.101809,0.0614038
gpu_array,8192,64,1,2,4,true,false,true,false,0.0970703,0.056665
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.129255,0.0810376
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.105657,0.0642749
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.102708,0.0621802
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.109154,0.0600818
gpu_array,8192,64,1,10,2,true,false,true,false,0.106224,0.0566638
gpu_array,8192,64,1,10,4,true,false,true,false,0.108947,0.0599963
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.11887,0.0575903
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.114932,0.0598779
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.11156,0.0615112
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.110116,0.0706873
0.0706873
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.118475,0.0789246
0.0789246
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0718604,0.0320654
0.0320654
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.095636,0.0564514
0.0564514
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.110739,0.0714319
0.0714319
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.122683,0.0823999
0.0823999
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0320654
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 1.55431 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.116705,0.0755676
gpu_array,8192,32,1,2,2,true,false,true,false,0.0967859,0.0555261
gpu_array,8192,32,1,2,4,true,false,true,false,0.0927966,0.0521472
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.126512,0.0785388
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.102955,0.0616956
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.102583,0.0621777
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.109893,0.0594775
gpu_array,8192,32,1,10,2,true,false,true,false,0.105454,0.0571143
gpu_array,8192,32,1,10,4,true,false,true,false,0.114392,0.0608032
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.117174,0.0573596
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.107369,0.0587854
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.111057,0.0611304
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.124347,0.0832092
gpu_array,8192,64,1,2,2,true,false,true,false,0.103566,0.0614514
gpu_array,8192,64,1,2,4,true,false,true,false,0.0970312,0.056626
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.128292,0.080929
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.103971,0.064176
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.103346,0.0620862
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.118593,0.0599988
gpu_array,8192,64,1,10,2,true,false,true,false,0.111777,0.0567236
gpu_array,8192,64,1,10,4,true,false,true,false,0.113538,0.0599487
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.119274,0.0576282
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.109657,0.0597302
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.110385,0.0614343
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.110254,0.0707031
0.0707031
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.119603,0.0788318
0.0788318
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.111505,0.0714661
0.0714661
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.122039,0.0823657
0.0823657
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0715479,0.0321191
0.0321191
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0960437,0.0563708
0.0563708
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0321191
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.5533 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.718799,0.0435059
gpu_array,8192,8,1,20,2,false,false,true,false,0.723344,0.0460974
gpu_array,8192,8,1,20,4,false,false,true,false,0.849653,0.0472852
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.721943,0.04604
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.849962,0.0489368
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.8534,0.0494446
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.713865,0.0384497
gpu_array,8192,8,1,50,2,false,false,true,false,0.841908,0.0413708
gpu_array,8192,8,1,50,4,false,false,true,false,0.717991,0.041355
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.840046,0.0385327
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.842605,0.0435327
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.844409,0.0435059
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.840079,0.0421057
gpu_array,8192,32,1,20,2,false,false,true,false,0.723447,0.0420508
gpu_array,8192,32,1,20,4,false,false,true,false,0.719927,0.0393848
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.84366,0.0423901
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.720951,0.0419958
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.837008,0.0379358
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.707858,0.0395227
0.0395227
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.696731,0.0338892
0.0338892
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.711765,0.0470923
0.0470923
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0338892
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.732712 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.843987,0.0434497
gpu_array,8192,8,1,20,2,false,false,true,false,0.724301,0.0460779
gpu_array,8192,8,1,20,4,false,false,true,false,0.847484,0.0471912
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.723374,0.0460059
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.727246,0.0490234
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.850718,0.0494482
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.716357,0.038501
gpu_array,8192,8,1,50,2,false,false,true,false,0.841729,0.0413135
gpu_array,8192,8,1,50,4,false,false,true,false,0.7187,0.0415759
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.716508,0.0385291
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.839889,0.0435022
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.844474,0.0434485
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.721034,0.0420789
gpu_array,8192,32,1,20,2,false,false,true,false,0.842684,0.0421472
gpu_array,8192,32,1,20,4,false,false,true,false,0.83791,0.0394482
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.841465,0.0423926
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.84416,0.0420361
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.835616,0.038009
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.70058,0.039447
0.039447
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.697605,0.0339087
0.0339087
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.711344,0.0470374
0.0470374
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0339087
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.732833 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0403455,0.00970581
gpu_array,8192,32,1,2,2,true,false,true,false,0.0354187,0.00770874
gpu_array,8192,32,1,2,4,true,false,true,false,0.038114,0.00735229
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0388684,0.00993774
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0355969,0.0069104
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0365259,0.00710693
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0439539,0.00684448
gpu_array,8192,32,1,10,2,true,false,true,false,0.0371887,0.00593872
gpu_array,8192,32,1,10,4,true,false,true,false,0.0359998,0.00584839
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0369055,0.0073645
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.034762,0.00619751
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0355725,0.00627563
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0371765,0.00971069
gpu_array,8192,64,1,2,2,true,false,true,false,0.0376587,0.00775146
gpu_array,8192,64,1,2,4,true,false,true,false,0.0381531,0.00739136
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0388123,0.0101257
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0354712,0.00678467
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0367896,0.00737061
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0349133,0.00695923
gpu_array,8192,64,1,10,2,true,false,true,false,0.0362109,0.0059375
gpu_array,8192,64,1,10,4,true,false,true,false,0.0359253,0.005896
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0353003,0.00734619
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0357507,0.00645386
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0346301,0.00655396
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0270654,0.0058252
0.0058252
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0279431,0.00682495
0.00682495
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0271069,0.0058667
0.0058667
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0290332,0.00706055
0.00706055
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0310706,0.00763306
0.00763306
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0294641,0.00797974
0.00797974
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.0058252
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.17749 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0400684,0.0090625
gpu_array,8192,32,1,2,2,true,false,true,false,0.0374915,0.00721802
gpu_array,8192,32,1,2,4,true,false,true,false,0.0422998,0.00677734
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.039386,0.00923462
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0353491,0.00641846
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0354346,0.00662598
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0356775,0.00638062
gpu_array,8192,32,1,10,2,true,false,true,false,0.0347522,0.0059436
gpu_array,8192,32,1,10,4,true,false,true,false,0.0349719,0.00591919
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0389844,0.00736816
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0366138,0.00621826
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0338257,0.00623779
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.037771,0.00981689
gpu_array,8192,64,1,2,2,true,false,true,false,0.0358105,0.00773437
gpu_array,8192,64,1,2,4,true,false,true,false,0.0365295,0.00735474
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0389392,0.0101306
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0361023,0.00680542
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0350964,0.00738647
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0360828,0.00690796
gpu_array,8192,64,1,10,2,true,false,true,false,0.0357495,0.00596436
gpu_array,8192,64,1,10,4,true,false,true,false,0.0338379,0.00588379
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0357764,0.00733398
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0363574,0.0064502
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0359814,0.0065625
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0297119,0.0059082
0.0059082
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0314465,0.00715454
0.00715454
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0271936,0.0058313
0.0058313
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0303479,0.0069104
0.0069104
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0308398,0.00764648
0.00764648
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0332812,0.0080127
0.0080127
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.0058313
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.174653 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.40127,3.3738
gpu_array,8192,32,1,2,2,true,false,true,false,2.60417,2.57744
gpu_array,8192,32,1,2,4,true,false,true,false,2.61114,2.58856
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.36007,3.33859
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.68072,2.65923
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.53571,2.51228
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.67197,2.64817
gpu_array,8192,32,1,10,2,true,false,true,false,2.77753,2.75385
gpu_array,8192,32,1,10,4,true,false,true,false,2.78324,2.7587
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.57061,2.54705
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.78923,2.7592
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.70777,2.6847
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.03635,3.01059
gpu_array,8192,64,1,2,2,true,false,true,false,2.61445,2.59248
gpu_array,8192,64,1,2,4,true,false,true,false,2.68604,2.66406
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,2.9472,2.92559
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.71974,2.69508
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.6225,2.60016
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.72464,2.70059
gpu_array,8192,64,1,10,2,true,false,true,false,2.76121,2.73692
gpu_array,8192,64,1,10,4,true,false,true,false,3.03012,3.00277
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.65471,2.63079
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.83013,2.80742
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.60079,2.57723
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,true,false,true,true,2.10019,2.08566
2.08566
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,false,false,true,true,2.35069,2.33666
2.33666
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,true,false,false,true,1.91063,1.89684
1.89684
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,false,false,false,true,2.03222,2.01757
2.01757
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.89684
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 133 seconds of which 15.2539 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.39403,3.36425
gpu_array,8192,32,1,2,2,true,false,true,false,2.58487,2.55362
gpu_array,8192,32,1,2,4,true,false,true,false,2.60491,2.57391
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.27992,3.25746
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.6901,2.6685
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.56173,2.54025
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.68854,2.66462
gpu_array,8192,32,1,10,2,true,false,true,false,2.78191,2.75859
gpu_array,8192,32,1,10,4,true,false,true,false,2.82201,2.7965
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.57038,2.54426
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.79967,2.77672
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.71404,2.69097
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.02126,2.99929
gpu_array,8192,64,1,2,2,true,false,true,false,2.62975,2.6035
gpu_array,8192,64,1,2,4,true,false,true,false,2.69448,2.67263
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,2.95177,2.92845
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.68858,2.66575
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.56528,2.54367
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.72408,2.70113
gpu_array,8192,64,1,10,2,true,false,true,false,2.76984,2.73676
gpu_array,8192,64,1,10,4,true,false,true,false,3.04435,3.02055
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.65205,2.62861
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.81576,2.79306
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.60799,2.58553
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,true,false,true,true,2.1871,2.17307
2.17307
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,false,false,true,true,2.37417,2.35916
2.35916
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,true,false,true,true,2.33941,2.32464
2.32464
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,false,false,true,true,2.3986,2.38493
2.38493
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,true,false,false,true,1.94038,1.92708
1.92708
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,false,false,false,true,1.99106,1.97654
1.97654
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.92708
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 133 seconds of which 16.223 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0797339,0.0151587
gpu_array,8192,32,1,2,2,true,false,true,false,0.072179,0.0118762
gpu_array,8192,32,1,2,4,true,false,true,false,0.0757166,0.0113855
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0767798,0.0152563
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0759778,0.00932739
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0768347,0.0101843
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0714661,0.00628052
gpu_array,8192,32,1,10,2,true,false,true,false,0.0715759,0.0059021
gpu_array,8192,32,1,10,4,true,false,true,false,0.0704675,0.00564819
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0727209,0.00655884
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0700439,0.00620117
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0707385,0.00591919
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0803796,0.015072
gpu_array,8192,64,1,2,2,true,false,true,false,0.0757788,0.011936
gpu_array,8192,64,1,2,4,true,false,true,false,0.0760156,0.0113184
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0785156,0.0152832
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0708777,0.00935425
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0738428,0.0102441
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0702185,0.00637573
gpu_array,8192,64,1,10,2,true,false,true,false,0.06698,0.00594482
gpu_array,8192,64,1,10,4,true,false,true,false,0.0695618,0.00571899
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0714392,0.00661987
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0713196,0.00650024
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0696985,0.00622192
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.071228,0.00543213
0.00543213
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.071969,0.00763794
0.00763794
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0652722,0.00545776
0.00545776
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0724988,0.00804565
0.00804565
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.0676465,0.0100293
0.0100293
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.08172,0.0160461
0.0160461
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00543213
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 12 seconds of which 0.22359 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.078042,0.0139551
gpu_array,8192,32,1,2,2,true,false,true,false,0.07479,0.0109473
gpu_array,8192,32,1,2,4,true,false,true,false,0.0715857,0.0105505
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0782434,0.0140344
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0726135,0.00864868
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0736279,0.00941895
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0703711,0.00628418
gpu_array,8192,32,1,10,2,true,false,true,false,0.0707825,0.00584106
gpu_array,8192,32,1,10,4,true,false,true,false,0.0707117,0.00564819
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.070835,0.00650391
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0708887,0.00619141
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0712964,0.0058667
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0783276,0.0150952
gpu_array,8192,64,1,2,2,true,false,true,false,0.0760034,0.0119165
gpu_array,8192,64,1,2,4,true,false,true,false,0.0760938,0.0113965
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0790271,0.0153064
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0755103,0.00934814
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0753821,0.0101965
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0678821,0.00635864
gpu_array,8192,64,1,10,2,true,false,true,false,0.0714392,0.00588745
gpu_array,8192,64,1,10,4,true,false,true,false,0.0720752,0.00566895
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0699622,0.00660767
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.072229,0.00655518
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0711353,0.00631592
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.068894,0.00553955
0.00553955
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0710144,0.00765991
0.00765991
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0654468,0.00551025
0.00551025
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0697168,0.00807129
0.00807129
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.068009,0.0100256
0.0100256
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0793762,0.0158997
0.0158997
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00551025
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.218931 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
