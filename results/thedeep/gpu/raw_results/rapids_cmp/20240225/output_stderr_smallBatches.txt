abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.421063,0.251978
gpu_array,256,8,1,20,2,true,false,true,0.299397,0.168259
gpu_array,256,8,1,20,4,true,false,true,0.284235,0.158677
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.374389,0.248831
gpu_sparse,256,8,1,20,2,true,false,true,0.263337,0.136105
gpu_sparse,256,8,1,20,4,true,false,true,0.30416,0.164093
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.448474,0.304501
gpu_reorg,256,8,1,20,2,true,false,true,0.302093,0.162584
gpu_reorg,256,8,1,20,4,true,false,true,0.272472,0.129615
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.272796,0.12659
gpu_array,256,8,1,50,2,true,false,true,0.234609,0.100123
gpu_array,256,8,1,50,4,true,false,true,0.231295,0.0984821
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.27678,0.135597
gpu_sparse,256,8,1,50,2,true,false,true,0.251158,0.114439
gpu_sparse,256,8,1,50,4,true,false,true,0.252302,0.119489
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.327274,0.177162
gpu_reorg,256,8,1,50,2,true,false,true,0.263231,0.110887
gpu_reorg,256,8,1,50,4,true,false,true,0.251649,0.105444
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.386222,0.252852
gpu_array,256,32,1,20,2,true,false,true,0.302391,0.172369
gpu_array,256,32,1,20,4,true,false,true,0.294012,0.165664
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.379135,0.250787
gpu_sparse,256,32,1,20,2,true,false,true,0.279342,0.147645
gpu_sparse,256,32,1,20,4,true,false,true,0.297606,0.169258
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.459967,0.314319
gpu_reorg,256,32,1,20,2,true,false,true,0.317852,0.182807
gpu_reorg,256,32,1,20,4,true,false,true,0.317201,0.162068
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,0.208075,0.0970257
0.0970257
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,0.228396,0.108418
0.108418
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.293647,0.186504
0.186504
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.295681,0.179051
0.179051
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.291641,0.182266
0.182266
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.287631,0.17435
0.17435
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0970257
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 13 seconds of which 0.284582 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.188362,0.0594559
gpu_array,256,8,1,20,2,true,false,true,0.199414,0.0537667
gpu_array,256,8,1,20,4,true,false,true,0.173488,0.0456975
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.201649,0.0621401
gpu_sparse,256,8,1,20,2,true,false,true,0.174235,0.0503516
gpu_sparse,256,8,1,20,4,true,false,true,0.183326,0.0477232
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.232243,0.0782254
gpu_reorg,256,8,1,20,2,true,false,true,0.207946,0.0567187
gpu_reorg,256,8,1,20,4,true,false,true,0.217852,0.0537891
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.202503,0.0518331
gpu_array,256,8,1,50,2,true,false,true,0.17529,0.046942
gpu_array,256,8,1,50,4,true,false,true,0.181325,0.0468387
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.193142,0.0508426
gpu_sparse,256,8,1,50,2,true,false,true,0.176189,0.0483984
gpu_sparse,256,8,1,50,4,true,false,true,0.17894,0.0483594
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.221403,0.0601311
gpu_reorg,256,8,1,50,2,true,false,true,0.205555,0.0520954
gpu_reorg,256,8,1,50,4,true,false,true,0.211861,0.0522628
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.19524,0.0613114
gpu_array,256,32,1,20,2,true,false,true,0.186219,0.0550809
gpu_array,256,32,1,20,4,true,false,true,0.185463,0.0470703
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.189612,0.0601479
gpu_sparse,256,32,1,20,2,true,false,true,0.170603,0.0489509
gpu_sparse,256,32,1,20,4,true,false,true,0.172313,0.0478711
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.230647,0.0766295
gpu_reorg,256,32,1,20,2,true,false,true,0.207411,0.055625
gpu_reorg,256,32,1,20,4,true,false,true,0.1937,0.0508426
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.156875,0.0463839
0.0463839
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.161897,0.0475
0.0475
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,0.161141,0.0450698
0.0450698
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,0.154043,0.0441099
0.0441099
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.164891,0.0449135
0.0449135
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.151172,0.0468192
0.0468192
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0441099
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0892876 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.802826,0.312871
gpu_array,256,8,1,20,2,true,false,true,0.726225,0.241292
gpu_array,256,8,1,20,4,true,false,true,0.705204,0.224177
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,1.14274,0.329685
gpu_sparse,256,8,1,20,2,true,false,true,0.640223,0.159754
gpu_sparse,256,8,1,20,4,true,false,true,0.704732,0.215335
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.919464,0.406071
gpu_reorg,256,8,1,20,2,true,false,true,0.699997,0.211716
gpu_reorg,256,8,1,20,4,true,false,true,0.711244,0.200642
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.670399,0.183792
gpu_array,256,8,1,50,2,true,false,true,0.63142,0.140907
gpu_array,256,8,1,50,4,true,false,true,0.721147,0.119584
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.989395,0.182475
gpu_sparse,256,8,1,50,2,true,false,true,0.612617,0.122104
gpu_sparse,256,8,1,50,4,true,false,true,0.627017,0.130924
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.717581,0.217581
gpu_reorg,256,8,1,50,2,true,false,true,0.631493,0.129819
gpu_reorg,256,8,1,50,4,true,false,true,0.617553,0.122017
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,0.565338,0.100494
0.100494
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,0.598909,0.142436
0.142436
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.717896,0.25361
0.25361
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.724157,0.2688
0.2688
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.100494
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.226104 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.410223,0.254531
gpu_array,256,8,1,20,2,true,false,true,0.322871,0.161599
gpu_array,256,8,1,20,4,true,false,true,0.299051,0.139453
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.389609,0.243404
gpu_sparse,256,8,1,20,2,true,false,true,0.341468,0.177405
gpu_sparse,256,8,1,20,4,true,false,true,0.319297,0.168069
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.485572,0.332112
gpu_reorg,256,8,1,20,2,true,false,true,0.333379,0.18829
gpu_reorg,256,8,1,20,4,true,false,true,0.323532,0.177885
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.593075,0.177338
gpu_array,256,8,1,50,2,true,false,true,0.586244,0.16716
gpu_array,256,8,1,50,4,true,false,true,0.586336,0.172832
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.342271,0.182115
gpu_sparse,256,8,1,50,2,true,false,true,0.593719,0.179099
gpu_sparse,256,8,1,50,4,true,false,true,0.581479,0.172997
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.363881,0.206515
gpu_reorg,256,8,1,50,2,true,false,true,0.335734,0.176694
gpu_reorg,256,8,1,50,4,true,false,true,0.321462,0.16856
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.41769,0.266462
gpu_array,256,32,1,20,2,true,false,true,0.314648,0.169001
gpu_array,256,32,1,20,4,true,false,true,0.302065,0.155859
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.382174,0.234852
gpu_sparse,256,32,1,20,2,true,false,true,0.334249,0.189718
gpu_sparse,256,32,1,20,4,true,false,true,0.340728,0.186152
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.448209,0.291959
gpu_reorg,256,32,1,20,2,true,false,true,0.381537,0.215801
gpu_reorg,256,32,1,20,4,true,false,true,0.36865,0.216306
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.314632,0.16731
0.16731
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.48613,0.175862
0.175862
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.312316,0.173923
0.173923
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.36548,0.222065
0.222065
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,0.260583,0.118284
0.118284
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,0.293039,0.151297
0.151297
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.118284
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.326703 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,1.43066,0.0785379
gpu_array,256,8,1,20,2,false,false,true,1.40318,0.0717076
gpu_array,256,8,1,20,4,false,false,true,1.37393,0.0575195
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,1.42715,0.07726
gpu_sparse,256,8,1,20,2,false,false,true,1.6022,0.0709515
gpu_sparse,256,8,1,20,4,false,false,true,1.41529,0.0626116
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,1.46408,0.0840597
gpu_reorg,256,8,1,20,2,false,false,true,1.47759,0.0774833
gpu_reorg,256,8,1,20,4,false,false,true,1.44517,0.0673828
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,1.40509,0.0646903
gpu_array,256,8,1,50,2,false,false,true,1.38846,0.059216
gpu_array,256,8,1,50,4,false,false,true,1.42306,0.0592243
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,1.40773,0.0645424
gpu_sparse,256,8,1,50,2,false,false,true,1.43113,0.0734291
gpu_sparse,256,8,1,50,4,false,false,true,1.43059,0.0734431
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,1.45407,0.0695843
gpu_reorg,256,8,1,50,2,false,false,true,1.45436,0.0665262
gpu_reorg,256,8,1,50,4,false,false,true,1.45951,0.0655385
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,1.44069,0.0857757
gpu_array,256,32,1,20,2,false,false,true,1.42541,0.079428
gpu_array,256,32,1,20,4,false,false,true,1.43759,0.0731948
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,1.47967,0.0851395
gpu_sparse,256,32,1,20,2,false,false,true,1.44029,0.0797991
gpu_sparse,256,32,1,20,4,false,false,true,1.42265,0.0749888
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,1.48988,0.0903292
gpu_reorg,256,32,1,20,2,false,false,true,1.66818,0.0822377
gpu_reorg,256,32,1,20,4,false,false,true,1.45059,0.0750363
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,1.37411,0.0577065
0.0577065
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,1.39155,0.0556166
0.0556166
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,1.38483,0.0706585
0.0706585
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0556166
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.110265 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.213811,0.0603516
gpu_array,256,8,1,20,2,true,false,true,0.189551,0.0539481
gpu_array,256,8,1,20,4,true,false,true,0.192586,0.0463811
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.191995,0.0608566
gpu_sparse,256,8,1,20,2,true,false,true,0.192503,0.0513198
gpu_sparse,256,8,1,20,4,true,false,true,0.193373,0.0488421
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.244194,0.0795731
gpu_reorg,256,8,1,20,2,true,false,true,0.23101,0.058577
gpu_reorg,256,8,1,20,4,true,false,true,0.219093,0.0544727
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.206197,0.0527372
gpu_array,256,8,1,50,2,true,false,true,0.178895,0.0488728
gpu_array,256,8,1,50,4,true,false,true,0.189023,0.0489565
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.198577,0.0523717
gpu_sparse,256,8,1,50,2,true,false,true,0.182249,0.0488783
gpu_sparse,256,8,1,50,4,true,false,true,0.185806,0.0490876
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.227464,0.060611
gpu_reorg,256,8,1,50,2,true,false,true,0.209096,0.053404
gpu_reorg,256,8,1,50,4,true,false,true,0.209623,0.0528153
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.203714,0.0619727
gpu_array,256,32,1,20,2,true,false,true,0.211083,0.0559487
gpu_array,256,32,1,20,4,true,false,true,0.178761,0.0492969
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.210089,0.0616518
gpu_sparse,256,32,1,20,2,true,false,true,0.186878,0.0507171
gpu_sparse,256,32,1,20,4,true,false,true,0.189043,0.0500921
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.242866,0.079361
gpu_reorg,256,32,1,20,2,true,false,true,0.216097,0.0587305
gpu_reorg,256,32,1,20,4,true,false,true,0.22832,0.0547712
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.176688,0.0472238
0.0472238
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.177935,0.049029
0.049029
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,0.171847,0.045731
0.045731
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,0.175698,0.0456752
0.0456752
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.175488,0.0476981
0.0476981
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.185349,0.0508622
0.0508622
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0456752
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0916899 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,6.66416,6.51517
gpu_array,256,8,1,20,2,true,false,true,14.3157,14.1678
gpu_array,256,8,1,20,4,true,false,true,13.5621,13.4142
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,6.15555,6.00823
gpu_sparse,256,8,1,20,2,true,false,true,13.9829,13.8445
gpu_sparse,256,8,1,20,4,true,false,true,9.72632,9.57844
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,7.38288,7.24058
gpu_reorg,256,8,1,20,2,true,false,true,10.8324,10.6873
gpu_reorg,256,8,1,20,4,true,false,true,8.0775,7.92292
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,4.47381,4.03184
gpu_array,256,8,1,50,2,true,false,true,7.84172,7.39808
gpu_array,256,8,1,50,4,true,false,true,9.09172,8.62074
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,4.07636,3.65449
gpu_sparse,256,8,1,50,2,true,false,true,7.68996,7.24464
gpu_sparse,256,8,1,50,4,true,false,true,8.05146,7.61117
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,5.08252,4.61768
gpu_reorg,256,8,1,50,2,true,false,true,7.98949,7.52743
gpu_reorg,256,8,1,50,4,true,false,true,11.8038,11.3283
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,6.72661,6.58598
gpu_array,256,32,1,20,2,true,false,true,5.63769,5.48535
gpu_array,256,32,1,20,4,true,false,true,6.18489,6.03645
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,6.25989,6.11871
gpu_sparse,256,32,1,20,2,true,false,true,5.54317,5.39752
gpu_sparse,256,32,1,20,4,true,false,true,5.60619,5.46166
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,7.64008,7.50894
gpu_reorg,256,32,1,20,2,true,false,true,6.7191,6.57456
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,2.93421,2.79079
2.79079
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,3.0977,2.96042
2.96042
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,5.93588,5.79693
5.79693
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,6.20886,6.06656
6.06656
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.79079
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 167 seconds of which 2.79293 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.272907,0.0597377
gpu_array,256,8,1,20,2,true,false,true,0.320251,0.104291
gpu_array,256,8,1,20,4,true,false,true,0.267162,0.074082
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.26466,0.0587444
gpu_sparse,256,8,1,20,2,true,false,true,0.300248,0.0943331
gpu_sparse,256,8,1,20,4,true,false,true,0.281387,0.0888644
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.32368,0.0759124
gpu_reorg,256,8,1,20,2,true,false,true,0.371448,0.1181
gpu_reorg,256,8,1,20,4,true,false,true,0.345753,0.0957533
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.254922,0.0562612
gpu_array,256,8,1,50,2,true,false,true,0.295745,0.0809012
gpu_array,256,8,1,50,4,true,false,true,0.286264,0.0814648
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.257104,0.0550949
gpu_sparse,256,8,1,50,2,true,false,true,0.295614,0.0818862
gpu_sparse,256,8,1,50,4,true,false,true,0.292536,0.0815988
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.27897,0.0663588
gpu_reorg,256,8,1,50,2,true,false,true,0.328677,0.0909542
gpu_reorg,256,8,1,50,4,true,false,true,0.314866,0.0894196
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.2675,0.0615848
gpu_array,256,32,1,20,2,true,false,true,0.257748,0.0590876
gpu_array,256,32,1,20,4,true,false,true,0.279841,0.0583008
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.302949,0.0596456
gpu_sparse,256,32,1,20,2,true,false,true,0.270963,0.0522126
gpu_sparse,256,32,1,20,4,true,false,true,0.25853,0.0554046
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.290647,0.0752455
gpu_reorg,256,32,1,20,2,true,false,true,0.299509,0.0629018
gpu_reorg,256,32,1,20,4,true,false,true,0.307584,0.0687444
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,0.243209,0.0501283
0.0501283
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,0.258996,0.0608929
0.0608929
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,0.240432,0.0484682
0.0484682
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,0.245988,0.0490011
0.0490011
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,0.266948,0.0604743
0.0604743
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,0.25875,0.0623214
0.0623214
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0484682
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.119714 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.224453,0.127448
gpu_array,512,8,1,20,2,true,false,true,0.170677,0.0853906
gpu_array,512,8,1,20,4,true,false,true,0.172064,0.080918
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.218405,0.126608
gpu_sparse,512,8,1,20,2,true,false,true,0.171563,0.0804167
gpu_sparse,512,8,1,20,4,true,false,true,0.182796,0.0923014
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.277598,0.164967
gpu_reorg,512,8,1,20,2,true,false,true,0.189554,0.0886426
gpu_reorg,512,8,1,20,4,true,false,true,0.179372,0.0726009
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.154609,0.0732292
gpu_array,512,8,1,50,2,true,false,true,0.146536,0.0632031
gpu_array,512,8,1,50,4,true,false,true,0.145977,0.0658984
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.163434,0.0761947
gpu_sparse,512,8,1,50,2,true,false,true,0.161286,0.0773014
gpu_sparse,512,8,1,50,4,true,false,true,0.165052,0.0765104
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.198639,0.0925195
gpu_reorg,512,8,1,50,2,true,false,true,0.160212,0.0632064
gpu_reorg,512,8,1,50,4,true,false,true,0.199274,0.089248
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.21181,0.126523
gpu_array,512,32,1,20,2,true,false,true,0.171468,0.0868327
gpu_array,512,32,1,20,4,true,false,true,0.166611,0.082627
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.220758,0.125055
gpu_sparse,512,32,1,20,2,true,false,true,0.164694,0.0748503
gpu_sparse,512,32,1,20,4,true,false,true,0.172949,0.0863607
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.273385,0.160755
gpu_reorg,512,32,1,20,2,true,false,true,0.207201,0.0932682
gpu_reorg,512,32,1,20,4,true,false,true,0.198301,0.0830664
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,0.134222,0.0600033
0.0600033
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,0.137298,0.0637305
0.0637305
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.170319,0.0941471
0.0941471
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.161449,0.090485
0.090485
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.165443,0.0905729
0.0905729
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.1571,0.0867871
0.0867871
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0600033
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.307371 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.128929,0.0325749
gpu_array,512,8,1,20,2,true,false,true,0.119746,0.0299023
gpu_array,512,8,1,20,4,true,false,true,0.117048,0.0265527
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.124984,0.0325358
gpu_sparse,512,8,1,20,2,true,false,true,0.10958,0.0281999
gpu_sparse,512,8,1,20,4,true,false,true,0.112285,0.0276497
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.157855,0.0400163
gpu_reorg,512,8,1,20,2,true,false,true,0.141898,0.0305697
gpu_reorg,512,8,1,20,4,true,false,true,0.140059,0.0293815
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.111279,0.027946
gpu_array,512,8,1,50,2,true,false,true,0.114196,0.0269564
gpu_array,512,8,1,50,4,true,false,true,0.112816,0.0268783
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.123092,0.0286914
gpu_sparse,512,8,1,50,2,true,false,true,0.129284,0.0348828
gpu_sparse,512,8,1,50,4,true,false,true,0.133874,0.0349154
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.149453,0.0335677
gpu_reorg,512,8,1,50,2,true,false,true,0.139193,0.0311198
gpu_reorg,512,8,1,50,4,true,false,true,0.141745,0.0310677
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.117767,0.0305273
gpu_array,512,32,1,20,2,true,false,true,0.115404,0.027513
gpu_array,512,32,1,20,4,true,false,true,0.0994434,0.0239225
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.117493,0.0302539
gpu_sparse,512,32,1,20,2,true,false,true,0.10444,0.025013
gpu_sparse,512,32,1,20,4,true,false,true,0.105895,0.024515
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.139993,0.038431
gpu_reorg,512,32,1,20,2,true,false,true,0.133799,0.0289811
gpu_reorg,512,32,1,20,4,true,false,true,0.146227,0.0270866
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.0897298,0.0233236
0.0233236
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.0997884,0.0242676
0.0242676
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.0956576,0.024694
0.024694
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.0982324,0.0253158
0.0253158
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,0.0956445,0.024681
0.024681
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,0.0998568,0.025638
0.025638
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0233236
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0980553 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.567601,0.158096
gpu_array,512,8,1,20,2,true,false,true,0.548786,0.130817
gpu_array,512,8,1,20,4,true,false,true,0.622988,0.121035
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.755882,0.166689
gpu_sparse,512,8,1,20,2,true,false,true,0.499671,0.0888639
gpu_sparse,512,8,1,20,4,true,false,true,0.521494,0.110036
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.8314,0.191426
gpu_reorg,512,8,1,20,2,true,false,true,0.733607,0.111862
gpu_reorg,512,8,1,20,4,true,false,true,0.705479,0.10652
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.514066,0.0973991
gpu_array,512,8,1,50,2,true,false,true,0.497168,0.075293
gpu_array,512,8,1,50,4,true,false,true,0.484772,0.0720117
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.691146,0.1
gpu_sparse,512,8,1,50,2,true,false,true,0.513604,0.0930306
gpu_sparse,512,8,1,50,4,true,false,true,0.508213,0.088291
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.711217,0.112259
gpu_reorg,512,8,1,50,2,true,false,true,0.689518,0.0794922
gpu_reorg,512,8,1,50,4,true,false,true,0.794525,0.100514
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,0.492168,0.0794076
0.0794076
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,0.513665,0.100254
0.100254
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.530124,0.128431
0.128431
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.562578,0.155026
0.155026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0720117
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.252596 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.265286,0.135078
gpu_array,512,8,1,20,2,true,false,true,0.230859,0.0973958
gpu_array,512,8,1,20,4,true,false,true,0.213454,0.0936621
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.26111,0.138714
gpu_sparse,512,8,1,20,2,true,false,true,0.238298,0.108089
gpu_sparse,512,8,1,20,4,true,false,true,0.233864,0.110817
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.310329,0.174912
gpu_reorg,512,8,1,20,2,true,false,true,0.246582,0.121582
gpu_reorg,512,8,1,20,4,true,false,true,0.255837,0.117165
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.353581,0.115299
gpu_array,512,8,1,50,2,true,false,true,0.347507,0.111829
gpu_array,512,8,1,50,4,true,false,true,0.371579,0.127438
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.22834,0.111152
gpu_sparse,512,8,1,50,2,true,false,true,0.352559,0.117533
gpu_sparse,512,8,1,50,4,true,false,true,0.367373,0.129092
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.251826,0.12292
gpu_reorg,512,8,1,50,2,true,false,true,0.24694,0.117383
gpu_reorg,512,8,1,50,4,true,false,true,0.28126,0.152354
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.267611,0.14196
gpu_array,512,32,1,20,2,true,false,true,0.225957,0.10877
gpu_array,512,32,1,20,4,true,false,true,0.230482,0.106784
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.255462,0.134368
gpu_sparse,512,32,1,20,2,true,false,true,0.238473,0.11152
gpu_sparse,512,32,1,20,4,true,false,true,0.250267,0.115501
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.281553,0.157204
gpu_reorg,512,32,1,20,2,true,false,true,0.261816,0.129004
gpu_reorg,512,32,1,20,4,true,false,true,0.26238,0.128916
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.207061,0.0859668
0.0859668
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.203011,0.0903809
0.0903809
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.20445,0.0866113
0.0866113
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.237979,0.115583
0.115583
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,0.183294,0.0732682
0.0732682
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,0.199268,0.081429
0.081429
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0732682
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.396255 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,1.15047,0.045
gpu_array,512,8,1,20,2,false,false,true,1.14699,0.0434701
gpu_array,512,8,1,20,4,false,false,true,1.14376,0.0421973
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,1.1549,0.0442188
gpu_sparse,512,8,1,20,2,false,false,true,1.14389,0.0436328
gpu_sparse,512,8,1,20,4,false,false,true,1.13782,0.0427702
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,1.17709,0.0553418
gpu_reorg,512,8,1,20,2,false,false,true,1.19201,0.0507389
gpu_reorg,512,8,1,20,4,false,false,true,1.15445,0.0476823
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,1.15081,0.0466406
gpu_array,512,8,1,50,2,false,false,true,1.16833,0.0498437
gpu_array,512,8,1,50,4,false,false,true,1.16956,0.0497656
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,1.13789,0.0467448
gpu_sparse,512,8,1,50,2,false,false,true,1.15382,0.0548568
gpu_sparse,512,8,1,50,4,false,false,true,1.15558,0.054668
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,1.16293,0.0496484
gpu_reorg,512,8,1,50,2,false,false,true,1.18345,0.054541
gpu_reorg,512,8,1,50,4,false,false,true,1.18916,0.0543978
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,1.14161,0.0465592
gpu_array,512,32,1,20,2,false,false,true,1.16658,0.0441829
gpu_array,512,32,1,20,4,false,false,true,1.12119,0.0424154
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,1.15071,0.046543
gpu_sparse,512,32,1,20,2,false,false,true,1.14007,0.0443717
gpu_sparse,512,32,1,20,4,false,false,true,1.15389,0.0438607
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,1.17766,0.0559115
gpu_reorg,512,32,1,20,2,false,false,true,1.16363,0.0516471
gpu_reorg,512,32,1,20,4,false,false,true,1.17765,0.0493978
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,1.12322,0.0424902
0.0424902
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,1.13771,0.042653
0.042653
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,1.13486,0.0424121
0.0424121
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0421973
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.146289 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.132347,0.0333887
gpu_array,512,8,1,20,2,true,false,true,0.12307,0.0306217
gpu_array,512,8,1,20,4,true,false,true,0.126569,0.0276107
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.131621,0.0333138
gpu_sparse,512,8,1,20,2,true,false,true,0.121383,0.0289355
gpu_sparse,512,8,1,20,4,true,false,true,0.12652,0.0282129
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.164775,0.0417285
gpu_reorg,512,8,1,20,2,true,false,true,0.15263,0.0321875
gpu_reorg,512,8,1,20,4,true,false,true,0.14929,0.0308008
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.117588,0.0296973
gpu_array,512,8,1,50,2,true,false,true,0.124469,0.0313704
gpu_array,512,8,1,50,4,true,false,true,0.115524,0.0315397
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.115869,0.0299316
gpu_sparse,512,8,1,50,2,true,false,true,0.124678,0.035485
gpu_sparse,512,8,1,50,4,true,false,true,0.122682,0.0354427
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.157083,0.0353385
gpu_reorg,512,8,1,50,2,true,false,true,0.161152,0.0368034
gpu_reorg,512,8,1,50,4,true,false,true,0.164427,0.0368229
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.13623,0.0314128
gpu_array,512,32,1,20,2,true,false,true,0.127562,0.0286035
gpu_array,512,32,1,20,4,true,false,true,0.116162,0.0256673
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.119808,0.0312663
gpu_sparse,512,32,1,20,2,true,false,true,0.1207,0.0262988
gpu_sparse,512,32,1,20,4,true,false,true,0.120889,0.0258366
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.16332,0.0402734
gpu_reorg,512,32,1,20,2,true,false,true,0.159915,0.0310091
gpu_reorg,512,32,1,20,4,true,false,true,0.153021,0.0293229
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.0944922,0.0248307
0.0248307
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.103812,0.0263379
0.0263379
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.109232,0.0258984
0.0258984
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.110124,0.0261393
0.0261393
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,0.115189,0.0272982
0.0272982
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,0.113431,0.0274935
0.0274935
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0248307
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.104133 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,3.96598,3.88134
gpu_array,512,8,1,20,2,true,false,true,7.9398,7.84215
gpu_array,512,8,1,20,4,true,false,true,7.42815,7.32594
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,3.55565,3.46451
gpu_sparse,512,8,1,20,2,true,false,true,7.84958,7.75583
gpu_sparse,512,8,1,20,4,true,false,true,5.5332,5.4362
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,4.45411,4.36167
gpu_reorg,512,8,1,20,2,true,false,true,5.71445,5.61484
gpu_reorg,512,8,1,20,4,true,false,true,5.25677,5.17083
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,3.60928,3.32999
gpu_array,512,8,1,50,2,true,false,true,4.59418,4.31033
gpu_array,512,8,1,50,4,true,false,true,9.0954,8.80699
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,3.38439,3.11421
gpu_sparse,512,8,1,50,2,true,false,true,4.53135,4.25271
gpu_sparse,512,8,1,50,4,true,false,true,8.09559,7.81043
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,3.95108,3.65681
gpu_reorg,512,8,1,50,2,true,false,true,8.97553,8.67736
gpu_reorg,512,8,1,50,4,true,false,true,9.63781,9.32857
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,3.92957,3.84884
gpu_array,512,32,1,20,2,true,false,true,3.45717,3.36993
gpu_array,512,32,1,20,4,true,false,true,3.67805,3.58104
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,3.46431,3.37577
gpu_sparse,512,32,1,20,2,true,false,true,3.50065,3.41276
gpu_sparse,512,32,1,20,4,true,false,true,3.39676,3.31342
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,4.42621,4.33441
gpu_reorg,512,32,1,20,2,true,false,true,4.45126,4.35426
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,2.62564,2.55077
2.55077
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,2.85284,2.76299
2.76299
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,3.17111,3.08973
3.08973
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,3.31469,3.23526
3.23526
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.55077
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 157 seconds of which 3.72147 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.160189,0.0306315
gpu_array,512,8,1,20,2,true,false,true,0.177487,0.053138
gpu_array,512,8,1,20,4,true,false,true,0.166488,0.0382324
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.15458,0.0302311
gpu_sparse,512,8,1,20,2,true,false,true,0.184639,0.0479199
gpu_sparse,512,8,1,20,4,true,false,true,0.174512,0.0456055
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.204857,0.0401432
gpu_reorg,512,8,1,20,2,true,false,true,0.219671,0.0614681
gpu_reorg,512,8,1,20,4,true,false,true,0.214831,0.0501172
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.158568,0.0303125
gpu_array,512,8,1,50,2,true,false,true,0.177666,0.0429004
gpu_array,512,8,1,50,4,true,false,true,0.186725,0.0428451
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.159574,0.0300163
gpu_sparse,512,8,1,50,2,true,false,true,0.183936,0.0452637
gpu_sparse,512,8,1,50,4,true,false,true,0.176611,0.0451009
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.194111,0.0372103
gpu_reorg,512,8,1,50,2,true,false,true,0.196637,0.0488509
gpu_reorg,512,8,1,50,4,true,false,true,0.206172,0.0486198
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.157025,0.0313737
gpu_array,512,32,1,20,2,true,false,true,0.161468,0.0299577
gpu_array,512,32,1,20,4,true,false,true,0.164206,0.0307422
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.158408,0.030153
gpu_sparse,512,32,1,20,2,true,false,true,0.157249,0.027041
gpu_sparse,512,32,1,20,4,true,false,true,0.172308,0.0297298
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.189827,0.0387858
gpu_reorg,512,32,1,20,2,true,false,true,0.191823,0.0355729
gpu_reorg,512,32,1,20,4,true,false,true,0.193102,0.0407585
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,0.149574,0.0258757
0.0258757
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,0.15793,0.0303255
0.0303255
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,0.145612,0.0258203
0.0258203
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,0.156738,0.0265299
0.0265299
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,0.15264,0.0308952
0.0308952
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,0.155264,0.0322168
0.0322168
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0258203
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.126401 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.125586,0.0669922
gpu_array,1024,8,1,20,2,true,false,true,0.109834,0.0502637
gpu_array,1024,8,1,20,4,true,false,true,0.106865,0.049248
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.126611,0.0689941
gpu_sparse,1024,8,1,20,2,true,false,true,0.129028,0.0704346
gpu_sparse,1024,8,1,20,4,true,false,true,0.123936,0.0633887
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.171841,0.0849268
gpu_reorg,1024,8,1,20,2,true,false,true,0.139668,0.0498242
gpu_reorg,1024,8,1,20,4,true,false,true,0.144766,0.0539453
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.115146,0.0633887
gpu_array,1024,8,1,50,2,true,false,true,0.107988,0.0552539
gpu_array,1024,8,1,50,4,true,false,true,0.108696,0.0569385
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.119175,0.067417
gpu_sparse,1024,8,1,50,2,true,false,true,0.119419,0.0686377
gpu_sparse,1024,8,1,50,4,true,false,true,0.119487,0.0677295
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.167881,0.0809668
gpu_reorg,1024,8,1,50,2,true,false,true,0.143506,0.0546387
gpu_reorg,1024,8,1,50,4,true,false,true,0.153569,0.0656787
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.128096,0.069502
gpu_array,1024,32,1,20,2,true,false,true,0.114268,0.0556738
gpu_array,1024,32,1,20,4,true,false,true,0.113188,0.0565479
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.129692,0.0720752
gpu_sparse,1024,32,1,20,2,true,false,true,0.122554,0.06396
gpu_sparse,1024,32,1,20,4,true,false,true,0.112432,0.062627
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.175054,0.0861865
gpu_reorg,1024,32,1,20,2,true,false,true,0.157173,0.0673291
gpu_reorg,1024,32,1,20,4,true,false,true,0.165137,0.0743164
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,0.0993945,0.0534961
0.0534961
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,0.100308,0.0524561
0.0524561
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,0.105049,0.0523145
0.0523145
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,0.100396,0.0554736
0.0554736
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,0.101099,0.0552002
0.0552002
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,0.105464,0.0585889
0.0585889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.049248
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.42484 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.0791064,0.017583
gpu_array,1024,8,1,20,2,true,false,true,0.0800977,0.0166211
gpu_array,1024,8,1,20,4,true,false,true,0.0819238,0.0174707
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.0796582,0.0181348
gpu_sparse,1024,8,1,20,2,true,false,true,0.0810986,0.0185986
gpu_sparse,1024,8,1,20,4,true,false,true,0.0819434,0.0184668
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.118135,0.0214551
gpu_reorg,1024,8,1,20,2,true,false,true,0.113765,0.017085
gpu_reorg,1024,8,1,20,4,true,false,true,0.115186,0.0175293
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.154766,0.02
gpu_array,1024,8,1,50,2,true,false,true,0.150684,0.0217773
gpu_array,1024,8,1,50,4,true,false,true,0.155498,0.021709
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.15375,0.0209375
gpu_sparse,1024,8,1,50,2,true,false,true,0.155371,0.0245117
gpu_sparse,1024,8,1,50,4,true,false,true,0.159092,0.0243262
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.140034,0.0247998
gpu_reorg,1024,8,1,50,2,true,false,true,0.121685,0.0240283
gpu_reorg,1024,8,1,50,4,true,false,true,0.13249,0.0240918
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.0871924,0.0159033
gpu_array,1024,32,1,20,2,true,false,true,0.0771143,0.0146143
gpu_array,1024,32,1,20,4,true,false,true,0.0736475,0.0140771
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.0775732,0.0160498
gpu_sparse,1024,32,1,20,2,true,false,true,0.076792,0.0152686
gpu_sparse,1024,32,1,20,4,true,false,true,0.0770752,0.0155518
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.118975,0.0203418
gpu_reorg,1024,32,1,20,2,true,false,true,0.114839,0.0162061
gpu_reorg,1024,32,1,20,4,true,false,true,0.111626,0.0159229
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,0.0648633,0.014082
0.014082
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,0.0700732,0.0153857
0.0153857
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.0700879,0.0154004
0.0154004
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.0689209,0.0161865
0.0161865
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,0.0705566,0.0187988
0.0187988
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,0.0716211,0.0188867
0.0188867
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0140771
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.125297 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.554307,0.140244
gpu_array,1024,8,1,20,2,true,false,true,0.527983,0.113921
gpu_array,1024,8,1,20,4,true,false,true,0.536685,0.106021
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.581494,0.149854
gpu_sparse,1024,8,1,20,2,true,false,true,0.499014,0.0849512
gpu_sparse,1024,8,1,20,4,true,false,true,0.511064,0.0989551
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.680195,0.168477
gpu_reorg,1024,8,1,20,2,true,false,true,0.553818,0.0987402
gpu_reorg,1024,8,1,20,4,true,false,true,0.573579,0.0940869
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.49272,0.0874463
gpu_array,1024,8,1,50,2,true,false,true,0.480439,0.0634473
gpu_array,1024,8,1,50,4,true,false,true,0.481567,0.0684814
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.519971,0.0902832
gpu_sparse,1024,8,1,50,2,true,false,true,0.486294,0.0810205
gpu_sparse,1024,8,1,50,4,true,false,true,0.480454,0.0781104
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.55333,0.0972754
gpu_reorg,1024,8,1,50,2,true,false,true,0.501802,0.068208
gpu_reorg,1024,8,1,50,4,true,false,true,0.536606,0.0737158
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,0.457495,0.0610107
0.0610107
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,0.484946,0.0884619
0.0884619
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,0.514707,0.112363
0.112363
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,0.587178,0.180928
0.180928
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0610107
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 20 seconds of which 0.451789 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.217192,0.0785205
gpu_array,1024,8,1,20,2,true,false,true,0.215469,0.0699609
gpu_array,1024,8,1,20,4,true,false,true,0.234692,0.0803955
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.166855,0.0818945
gpu_sparse,1024,8,1,20,2,true,false,true,0.223906,0.0823047
gpu_sparse,1024,8,1,20,4,true,false,true,0.231963,0.0913379
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.200527,0.107754
gpu_reorg,1024,8,1,20,2,true,false,true,0.179297,0.0855469
gpu_reorg,1024,8,1,20,4,true,false,true,0.208359,0.114609
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.246089,0.102534
gpu_array,1024,8,1,50,2,true,false,true,0.239854,0.098252
gpu_array,1024,8,1,50,4,true,false,true,0.245029,0.106357
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.268589,0.0996436
gpu_sparse,1024,8,1,50,2,true,false,true,0.243423,0.103774
gpu_sparse,1024,8,1,50,4,true,false,true,0.255166,0.112588
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.28293,0.108125
gpu_reorg,1024,8,1,50,2,true,false,true,0.274858,0.10396
gpu_reorg,1024,8,1,50,4,true,false,true,0.288345,0.114517
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.219341,0.0826221
gpu_array,1024,32,1,20,2,true,false,true,0.216074,0.0783789
gpu_array,1024,32,1,20,4,true,false,true,0.222593,0.0829443
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.16459,0.081582
gpu_sparse,1024,32,1,20,2,true,false,true,0.223452,0.0838037
gpu_sparse,1024,32,1,20,4,true,false,true,0.22583,0.0871582
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.182217,0.106045
gpu_reorg,1024,32,1,20,2,true,false,true,0.17272,0.0955713
gpu_reorg,1024,32,1,20,4,true,false,true,0.198799,0.113838
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.128115,0.0499902
0.0499902
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.140771,0.063623
0.063623
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,0.13375,0.0546484
0.0546484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,0.171294,0.0931689
0.0931689
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,0.139238,0.0620898
0.0620898
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,0.143237,0.0699951
0.0699951
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0499902
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.603655 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,0.934365,0.0378809
gpu_array,1024,8,1,20,2,false,false,true,0.943945,0.0367188
gpu_array,1024,8,1,20,4,false,false,true,0.966685,0.0448096
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,0.953662,0.0376465
gpu_sparse,1024,8,1,20,2,false,false,true,0.957876,0.0369775
gpu_sparse,1024,8,1,20,4,false,false,true,0.957847,0.0447607
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,0.967187,0.0414062
gpu_reorg,1024,8,1,20,2,false,false,true,0.970605,0.0418945
gpu_reorg,1024,8,1,20,4,false,false,true,0.961963,0.0479004
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,0.947979,0.0378223
gpu_array,1024,8,1,50,2,false,false,true,0.937158,0.0406738
gpu_array,1024,8,1,50,4,false,false,true,0.953481,0.0403955
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,0.940557,0.0391895
gpu_sparse,1024,8,1,50,2,false,false,true,0.948037,0.0456934
gpu_sparse,1024,8,1,50,4,false,false,true,0.956035,0.0458789
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,0.955586,0.0415234
gpu_reorg,1024,8,1,50,2,false,false,true,0.96126,0.0442676
gpu_reorg,1024,8,1,50,4,false,false,true,1.00806,0.0441943
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,0.935176,0.0367383
gpu_array,1024,32,1,20,2,false,false,true,0.9571,0.0352246
gpu_array,1024,32,1,20,4,false,false,true,0.931313,0.0387354
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,0.950444,0.0363818
gpu_sparse,1024,32,1,20,2,false,false,true,0.950767,0.0357275
gpu_sparse,1024,32,1,20,4,false,false,true,0.94668,0.0384766
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,0.960186,0.0431934
gpu_reorg,1024,32,1,20,2,false,false,true,0.992642,0.0414697
gpu_reorg,1024,32,1,20,4,false,false,true,0.992319,0.042124
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,0.920498,0.0347559
0.0347559
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.948911,0.0377783
0.0377783
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,0.922124,0.0354053
0.0354053
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0347559
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.246916 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.0893213,0.0180322
gpu_array,1024,8,1,20,2,true,false,true,0.0817285,0.0172754
gpu_array,1024,8,1,20,4,true,false,true,0.0905811,0.019292
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.0908447,0.0185791
gpu_sparse,1024,8,1,20,2,true,false,true,0.0904443,0.0191553
gpu_sparse,1024,8,1,20,4,true,false,true,0.0902881,0.0199756
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.134316,0.0229883
gpu_reorg,1024,8,1,20,2,true,false,true,0.129287,0.0189355
gpu_reorg,1024,8,1,20,4,true,false,true,0.125991,0.021499
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.0926709,0.0213818
gpu_array,1024,8,1,50,2,true,false,true,0.0923535,0.022041
gpu_array,1024,8,1,50,4,true,false,true,0.0893799,0.0219971
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.0899072,0.0215479
gpu_sparse,1024,8,1,50,2,true,false,true,0.0960156,0.0247266
gpu_sparse,1024,8,1,50,4,true,false,true,0.0961182,0.0248291
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.131138,0.0266455
gpu_reorg,1024,8,1,50,2,true,false,true,0.132705,0.0262598
gpu_reorg,1024,8,1,50,4,true,false,true,0.130796,0.0263037
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.0869238,0.0166113
gpu_array,1024,32,1,20,2,true,false,true,0.0869092,0.0156201
gpu_array,1024,32,1,20,4,true,false,true,0.0867871,0.015498
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.0804004,0.0169238
gpu_sparse,1024,32,1,20,2,true,false,true,0.0814795,0.0160498
gpu_sparse,1024,32,1,20,4,true,false,true,0.0800586,0.016582
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.133232,0.0219043
gpu_reorg,1024,32,1,20,2,true,false,true,0.127207,0.0188086
gpu_reorg,1024,32,1,20,4,true,false,true,0.128564,0.0191895
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,0.0699365,0.015249
0.015249
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,0.0749902,0.017373
0.017373
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.0744092,0.0158154
0.0158154
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.0887402,0.0164746
0.0164746
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,0.082168,0.019668
0.019668
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,0.0754883,0.0198242
0.0198242
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.015249
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.133746 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,3.20324,3.05969
gpu_array,1024,8,1,20,2,true,false,true,4.86035,4.71484
gpu_array,1024,8,1,20,4,true,false,true,4.76768,4.62314
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,2.85953,2.71891
gpu_sparse,1024,8,1,20,2,true,false,true,4.85996,4.72031
gpu_sparse,1024,8,1,20,4,true,false,true,4.87332,4.73465
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,3.63494,3.46014
gpu_reorg,1024,8,1,20,2,true,false,true,6.7575,6.58465
gpu_reorg,1024,8,1,20,4,true,false,true,5.18803,5.01518
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,3.85254,3.70996
gpu_array,1024,8,1,50,2,true,false,true,4.62695,4.48145
gpu_array,1024,8,1,50,4,true,false,true,6.86602,6.70879
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,3.36184,3.21633
gpu_sparse,1024,8,1,50,2,true,false,true,4.57848,4.43004
gpu_sparse,1024,8,1,50,4,true,false,true,6.29555,6.12367
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,4.13658,3.93834
gpu_reorg,1024,8,1,50,2,true,false,true,7.34734,7.16473
gpu_reorg,1024,8,1,50,4,true,false,true,10.0004,9.81092
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,3.2291,3.08359
gpu_array,1024,32,1,20,2,true,false,true,3.52723,3.34754
gpu_array,1024,32,1,20,4,true,false,true,4.05436,3.91275
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,3.11686,2.97135
gpu_sparse,1024,32,1,20,2,true,false,true,3.52891,3.38535
gpu_sparse,1024,32,1,20,4,true,false,true,3.71082,3.56922
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,3.97723,3.8034
gpu_reorg,1024,32,1,20,2,true,false,true,4.73504,4.56414
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,2.94471,2.85975
2.85975
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,2.98717,2.89342
2.89342
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,2.08887,1.99316
1.99316
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,2.22406,2.13129
2.13129
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99316
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 144 seconds of which 6.53981 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.105049,0.0171582
gpu_array,1024,8,1,20,2,true,false,true,0.128188,0.0295557
gpu_array,1024,8,1,20,4,true,false,true,0.118433,0.0266357
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.108198,0.0173779
gpu_sparse,1024,8,1,20,2,true,false,true,0.131973,0.0313867
gpu_sparse,1024,8,1,20,4,true,false,true,0.125879,0.0321289
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.138306,0.0220947
gpu_reorg,1024,8,1,20,2,true,false,true,0.165088,0.0342285
gpu_reorg,1024,8,1,20,4,true,false,true,0.163315,0.0334326
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.119907,0.0212744
gpu_array,1024,8,1,50,2,true,false,true,0.131348,0.034668
gpu_array,1024,8,1,50,4,true,false,true,0.126338,0.034541
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.114087,0.0213135
gpu_sparse,1024,8,1,50,2,true,false,true,0.13498,0.0363477
gpu_sparse,1024,8,1,50,4,true,false,true,0.124897,0.0360303
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.187485,0.0283057
gpu_reorg,1024,8,1,50,2,true,false,true,0.172988,0.0401758
gpu_reorg,1024,8,1,50,4,true,false,true,0.170889,0.0400293
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.114023,0.0163672
gpu_array,1024,32,1,20,2,true,false,true,0.114126,0.0164697
gpu_array,1024,32,1,20,4,true,false,true,0.107212,0.0173682
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.105957,0.0161133
gpu_sparse,1024,32,1,20,2,true,false,true,0.106641,0.0167969
gpu_sparse,1024,32,1,20,4,true,false,true,0.110752,0.0179785
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.15104,0.0211572
gpu_reorg,1024,32,1,20,2,true,false,true,0.155322,0.0215332
gpu_reorg,1024,32,1,20,4,true,false,true,0.15939,0.0256006
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,0.102588,0.0156738
0.0156738
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,0.104927,0.0180127
0.0180127
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,0.10457,0.0166797
0.0166797
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,0.107178,0.017334
0.017334
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,0.106392,0.018501
0.018501
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,0.107988,0.0191211
0.0191211
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0156738
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 14 seconds of which 0.166173 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.0964868,0.0671899
gpu_array,2048,8,1,20,2,true,false,true,0.0880762,0.0568262
gpu_array,2048,8,1,20,4,true,false,true,0.084751,0.0554541
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.105686,0.077854
gpu_sparse,2048,8,1,20,2,true,false,true,0.10054,0.0668481
gpu_sparse,2048,8,1,20,4,true,false,true,0.098772,0.067522
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.124041,0.0776538
gpu_reorg,2048,8,1,20,2,true,false,true,0.102754,0.0549023
gpu_reorg,2048,8,1,20,4,true,false,true,0.0927173,0.0443774
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.0898438,0.0581055
gpu_array,2048,8,1,50,2,true,false,true,0.0831567,0.0504419
gpu_array,2048,8,1,50,4,true,false,true,0.0817407,0.0519556
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.091543,0.0627344
gpu_sparse,2048,8,1,50,2,true,false,true,0.0923633,0.0625781
gpu_sparse,2048,8,1,50,4,true,false,true,0.0929395,0.062666
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.122283,0.0754077
gpu_reorg,2048,8,1,50,2,true,false,true,0.0953784,0.0485034
gpu_reorg,2048,8,1,50,4,true,false,true,0.102146,0.0567358
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.0938379,0.0625879
gpu_array,2048,32,1,20,2,true,false,true,0.0809692,0.0511841
gpu_array,2048,32,1,20,4,true,false,true,0.0827075,0.0519458
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.0939014,0.0655811
gpu_sparse,2048,32,1,20,2,true,false,true,0.0769702,0.0447437
gpu_sparse,2048,32,1,20,4,true,false,true,0.0805518,0.0483252
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.124734,0.0768823
gpu_reorg,2048,32,1,20,2,true,false,true,0.109143,0.0617798
gpu_reorg,2048,32,1,20,4,true,false,true,0.104678,0.0538965
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,0.0881885,0.0447314
0.0447314
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,0.0966577,0.0532007
0.0532007
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,0.091189,0.0472437
0.0472437
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,0.0990063,0.0531079
0.0531079
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,0.0975024,0.0535571
0.0535571
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,0.104788,0.056936
0.056936
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0443774
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.787849 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline 13 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.0505054,0.0143726
gpu_array,2048,8,1,20,2,true,false,true,0.053042,0.0139795
gpu_array,2048,8,1,20,4,true,false,true,0.0559546,0.014939
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.0511938,0.015061
gpu_sparse,2048,8,1,20,2,true,false,true,0.0516968,0.0140991
gpu_sparse,2048,8,1,20,4,true,false,true,0.0465942,0.014856
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.0765796,0.0174976
gpu_reorg,2048,8,1,20,2,true,false,true,0.0716382,0.0135327
gpu_reorg,2048,8,1,20,4,true,false,true,0.0743921,0.0148218
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.0518359,0.0157031
gpu_array,2048,8,1,50,2,true,false,true,0.0553247,0.0162622
gpu_array,2048,8,1,50,4,true,false,true,0.0557715,0.0162207
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.0534326,0.0168115
gpu_sparse,2048,8,1,50,2,true,false,true,0.0575195,0.0174805
gpu_sparse,2048,8,1,50,4,true,false,true,0.0534912,0.0173584
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.0765015,0.0193726
gpu_reorg,2048,8,1,50,2,true,false,true,0.0771411,0.0185474
gpu_reorg,2048,8,1,50,4,true,false,true,0.0784985,0.0189282
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.0500146,0.0119287
gpu_array,2048,32,1,20,2,true,false,true,0.0487842,0.0106982
gpu_array,2048,32,1,20,4,true,false,true,0.0474048,0.00980713
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.0512378,0.0121753
gpu_sparse,2048,32,1,20,2,true,false,true,0.045332,0.0101758
gpu_sparse,2048,32,1,20,4,true,false,true,0.0494727,0.011875
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.0746216,0.0160278
gpu_reorg,2048,32,1,20,2,true,false,true,0.0705786,0.0124731
gpu_reorg,2048,32,1,20,4,true,false,true,0.069707,0.0135547
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,0.038252,0.00944336
0.00944336
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,0.0390942,0.00979736
0.00979736
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,0.0410889,0.0127686
0.0127686
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.045918,0.0136914
0.0136914
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,0.0441479,0.0148511
0.0148511
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.0446313,0.0148462
0.0148462
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.00944336
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.194133 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.441377,0.106416
gpu_array,2048,8,1,20,2,true,false,true,0.421299,0.0799902
gpu_array,2048,8,1,20,4,true,false,true,0.424431,0.0801929
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.449873,0.113936
gpu_sparse,2048,8,1,20,2,true,false,true,0.400808,0.0619409
gpu_sparse,2048,8,1,20,4,true,false,true,0.408225,0.0737524
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.491077,0.128284
gpu_reorg,2048,8,1,20,2,true,false,true,0.448428,0.0734277
gpu_reorg,2048,8,1,20,4,true,false,true,0.432393,0.0700879
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.417622,0.0811963
gpu_array,2048,8,1,50,2,true,false,true,0.401689,0.0579395
gpu_array,2048,8,1,50,4,true,false,true,0.394373,0.0608765
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.426882,0.0845972
gpu_sparse,2048,8,1,50,2,true,false,true,0.408079,0.0687231
gpu_sparse,2048,8,1,50,4,true,false,true,0.398425,0.0707886
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.449255,0.0903687
gpu_reorg,2048,8,1,50,2,true,false,true,0.430833,0.0587622
gpu_reorg,2048,8,1,50,4,true,false,true,0.431775,0.0675171
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,0.386191,0.0541602
0.0541602
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,0.413015,0.0824487
0.0824487
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,0.389221,0.0567017
0.0567017
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.616304,0.283296
0.283296
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0541602
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.780453 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.15675,0.0839966
gpu_array,2048,8,1,20,2,true,false,true,0.162866,0.0842529
gpu_array,2048,8,1,20,4,true,false,true,0.166152,0.0904688
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.179607,0.0917163
gpu_sparse,2048,8,1,20,2,true,false,true,0.17689,0.0977881
gpu_sparse,2048,8,1,20,4,true,false,true,0.175605,0.0945508
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.198904,0.104177
gpu_reorg,2048,8,1,20,2,true,false,true,0.192104,0.0968896
gpu_reorg,2048,8,1,20,4,true,false,true,0.186658,0.0890015
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.172266,0.0946289
gpu_array,2048,8,1,50,2,true,false,true,0.171895,0.0932812
gpu_array,2048,8,1,50,4,true,false,true,0.179043,0.0975
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.187651,0.0929248
gpu_sparse,2048,8,1,50,2,true,false,true,0.179766,0.0982227
gpu_sparse,2048,8,1,50,4,true,false,true,0.184985,0.106372
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.19667,0.0990137
gpu_reorg,2048,8,1,50,2,true,false,true,0.203286,0.0958643
gpu_reorg,2048,8,1,50,4,true,false,true,0.207368,0.104829
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.153132,0.0798901
gpu_array,2048,32,1,20,2,true,false,true,0.161538,0.0834131
gpu_array,2048,32,1,20,4,true,false,true,0.164441,0.0872925
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.16717,0.0792798
gpu_sparse,2048,32,1,20,2,true,false,true,0.158372,0.0836646
gpu_sparse,2048,32,1,20,4,true,false,true,0.162197,0.0884668
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.184675,0.090437
gpu_reorg,2048,32,1,20,2,true,false,true,0.188022,0.0908545
gpu_reorg,2048,32,1,20,4,true,false,true,0.180652,0.0873901
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,0.139849,0.0548877
0.0548877
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,0.120762,0.0699805
0.0699805
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,0.114902,0.0641211
0.0641211
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,0.121033,0.0702515
0.0702515
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,0.113318,0.0640015
0.0640015
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,0.119897,0.0700928
0.0700928
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0548877
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 1.17944 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,0.834888,0.0492432
gpu_array,2048,8,1,20,2,false,false,true,0.832688,0.04802
gpu_array,2048,8,1,20,4,false,false,true,0.832861,0.0491699
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,0.842039,0.0495581
gpu_sparse,2048,8,1,20,2,false,false,true,0.841533,0.0470996
gpu_sparse,2048,8,1,20,4,false,false,true,0.838567,0.0495044
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,0.862312,0.0546948
gpu_reorg,2048,8,1,20,2,false,false,true,0.857126,0.0509741
gpu_reorg,2048,8,1,20,4,false,false,true,0.868809,0.0582617
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,0.821453,0.0333667
gpu_array,2048,8,1,50,2,false,false,true,0.828381,0.0354126
gpu_array,2048,8,1,50,4,false,false,true,0.823872,0.0352979
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,0.819546,0.0358545
gpu_sparse,2048,8,1,50,2,false,false,true,0.829121,0.0410352
gpu_sparse,2048,8,1,50,4,false,false,true,0.821624,0.0408618
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,0.87449,0.0390405
gpu_reorg,2048,8,1,50,2,false,false,true,0.870364,0.0402856
gpu_reorg,2048,8,1,50,4,false,false,true,0.869158,0.038103
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,0.835425,0.0429443
gpu_array,2048,32,1,20,2,false,false,true,0.824121,0.0418945
gpu_array,2048,32,1,20,4,false,false,true,0.830974,0.0331226
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,0.832695,0.0431445
gpu_sparse,2048,32,1,20,2,false,false,true,0.840027,0.0421753
gpu_sparse,2048,32,1,20,4,false,false,true,0.82137,0.0332837
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,0.851641,0.0493945
gpu_reorg,2048,32,1,20,2,false,false,true,0.860801,0.0478125
gpu_reorg,2048,32,1,20,4,false,false,true,0.837595,0.0387671
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,0.804529,0.0330444
0.0330444
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.810513,0.0317041
0.0317041
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.832771,0.0461499
0.0461499
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.0317041
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.523969 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.0640552,0.0147388
gpu_array,2048,8,1,20,2,true,false,true,0.064165,0.0143604
gpu_array,2048,8,1,20,4,true,false,true,0.0660352,0.0152539
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.0687354,0.016001
gpu_sparse,2048,8,1,20,2,true,false,true,0.066123,0.0158301
gpu_sparse,2048,8,1,20,4,true,false,true,0.066665,0.0158838
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.0837939,0.0193408
gpu_reorg,2048,8,1,20,2,true,false,true,0.0784961,0.0159961
gpu_reorg,2048,8,1,20,4,true,false,true,0.0863281,0.0208984
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.0660181,0.0167017
gpu_array,2048,8,1,50,2,true,false,true,0.0644824,0.0171191
gpu_array,2048,8,1,50,4,true,false,true,0.0673779,0.017085
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.0656934,0.0178418
gpu_sparse,2048,8,1,50,2,true,false,true,0.0656445,0.017793
gpu_sparse,2048,8,1,50,4,true,false,true,0.0685645,0.0177832
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.133333,0.0210278
gpu_reorg,2048,8,1,50,2,true,false,true,0.130862,0.020022
gpu_reorg,2048,8,1,50,4,true,false,true,0.128762,0.0198755
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.0634985,0.0127173
gpu_array,2048,32,1,20,2,true,false,true,0.0630225,0.0117529
gpu_array,2048,32,1,20,4,true,false,true,0.0625977,0.0123047
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.0664697,0.0132471
gpu_sparse,2048,32,1,20,2,true,false,true,0.0610278,0.0121997
gpu_sparse,2048,32,1,20,4,true,false,true,0.0637646,0.0120068
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.0830664,0.0186133
gpu_reorg,2048,32,1,20,2,true,false,true,0.0769702,0.0149585
gpu_reorg,2048,32,1,20,4,true,false,true,0.0805981,0.0156567
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,0.0523657,0.0113501
0.0113501
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,0.0533789,0.0128516
0.0128516
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,0.0536035,0.0135645
0.0135645
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.0531128,0.0140503
0.0140503
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,0.0558838,0.0158447
0.0158447
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.0559424,0.0159033
0.0159033
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0113501
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.213227 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,4.23299,4.15633
gpu_array,2048,8,1,20,2,true,false,true,5.04472,4.96464
gpu_array,2048,8,1,20,4,true,false,true,4.58804,4.51235
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,3.89237,3.81864
gpu_sparse,2048,8,1,20,2,true,false,true,5.16057,5.08195
gpu_sparse,2048,8,1,20,4,true,false,true,3.98081,3.90415
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,4.90391,4.80869
gpu_reorg,2048,8,1,20,2,true,false,true,5.42945,5.33375
gpu_reorg,2048,8,1,20,4,true,false,true,4.93594,4.83779
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,3.70201,3.62047
gpu_array,2048,8,1,50,2,true,false,true,4.41115,4.32814
gpu_array,2048,8,1,50,4,true,false,true,6.79082,6.68535
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,3.39524,3.31272
gpu_sparse,2048,8,1,50,2,true,false,true,4.45402,4.36711
gpu_sparse,2048,8,1,50,4,true,false,true,6.14077,6.05044
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,4.21864,4.1161
gpu_reorg,2048,8,1,50,2,true,false,true,7.92345,7.81505
gpu_reorg,2048,8,1,50,4,true,false,true,10.2447,10.1378
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,3.67611,3.59848
gpu_array,2048,32,1,20,2,true,false,true,2.99114,2.91399
gpu_array,2048,32,1,20,4,true,false,true,3.065,2.98687
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,3.25214,3.17548
gpu_sparse,2048,32,1,20,2,true,false,true,3.02202,2.93804
gpu_sparse,2048,32,1,20,4,true,false,true,2.95141,2.87572
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,4.16736,4.07557
gpu_reorg,2048,32,1,20,2,true,false,true,3.47999,3.38429
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,1.95854,1.92533
1.92533
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,2.09687,2.06465
2.06465
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,2.20498,2.17031
2.17031
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,2.20514,2.17145
2.17145
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.92533
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 157 seconds of which 12.9159 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.165923,0.0126025
gpu_array,2048,8,1,20,2,true,false,true,0.185745,0.0251001
gpu_array,2048,8,1,20,4,true,false,true,0.184783,0.0207202
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.151702,0.0144946
gpu_sparse,2048,8,1,20,2,true,false,true,0.186851,0.0247412
gpu_sparse,2048,8,1,20,4,true,false,true,0.188872,0.0243213
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.155005,0.0182861
gpu_reorg,2048,8,1,20,2,true,false,true,0.199836,0.0318677
gpu_reorg,2048,8,1,20,4,true,false,true,0.187205,0.0319312
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.157271,0.0166455
gpu_array,2048,8,1,50,2,true,false,true,0.186199,0.0294604
gpu_array,2048,8,1,50,4,true,false,true,0.161252,0.0294165
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.152515,0.0167725
gpu_sparse,2048,8,1,50,2,true,false,true,0.183325,0.0309814
gpu_sparse,2048,8,1,50,4,true,false,true,0.170913,0.0307764
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.162041,0.0233691
gpu_reorg,2048,8,1,50,2,true,false,true,0.2024,0.0344312
gpu_reorg,2048,8,1,50,4,true,false,true,0.177527,0.0344604
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.155679,0.012124
gpu_array,2048,32,1,20,2,true,false,true,0.173125,0.0119922
gpu_array,2048,32,1,20,4,true,false,true,0.17429,0.0126685
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.155151,0.012085
gpu_sparse,2048,32,1,20,2,true,false,true,0.165134,0.0127905
gpu_sparse,2048,32,1,20,4,true,false,true,0.167739,0.0134424
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.165657,0.0172192
gpu_reorg,2048,32,1,20,2,true,false,true,0.192522,0.017229
gpu_reorg,2048,32,1,20,4,true,false,true,0.17115,0.0212476
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,0.141499,0.0106396
0.0106396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,0.159106,0.0140869
0.0140869
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,0.165054,0.01271
0.01271
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,0.163291,0.0133887
0.0133887
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,0.167114,0.0142822
0.0142822
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.168284,0.0144751
0.0144751
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0106396
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.270647 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
