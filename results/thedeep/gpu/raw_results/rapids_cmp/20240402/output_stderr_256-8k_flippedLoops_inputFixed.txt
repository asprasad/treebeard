abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.407015,0.245742
gpu_array,256,8,1,20,2,true,false,true,false,0.287098,0.166004
gpu_array,256,8,1,20,4,true,false,true,false,0.292469,0.165237
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.382958,0.260748
gpu_sparse,256,8,1,20,2,true,false,true,false,0.258284,0.130494
gpu_sparse,256,8,1,20,4,true,false,true,false,0.280834,0.159741
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.438298,0.298789
gpu_reorg,256,8,1,20,2,true,false,true,false,0.297969,0.159576
gpu_reorg,256,8,1,20,4,true,false,true,false,0.258323,0.123278
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.260444,0.123167
gpu_array,256,8,1,50,2,true,false,true,false,0.226646,0.0932757
gpu_array,256,8,1,50,4,true,false,true,false,0.216387,0.0897126
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.278909,0.13103
gpu_sparse,256,8,1,50,2,true,false,true,false,0.230151,0.105151
gpu_sparse,256,8,1,50,4,true,false,true,false,0.239311,0.107614
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.307126,0.170965
gpu_reorg,256,8,1,50,2,true,false,true,false,0.249096,0.102333
gpu_reorg,256,8,1,50,4,true,false,true,false,0.235762,0.0889983
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.372667,0.248225
gpu_array,256,32,1,20,2,true,false,true,false,0.289241,0.17317
gpu_array,256,32,1,20,4,true,false,true,false,0.291348,0.166906
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.37135,0.248583
gpu_sparse,256,32,1,20,2,true,false,true,false,0.28219,0.158864
gpu_sparse,256,32,1,20,4,true,false,true,false,0.291261,0.174074
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.46262,0.310834
gpu_reorg,256,32,1,20,2,true,false,true,false,0.30389,0.169403
gpu_reorg,256,32,1,20,4,true,false,true,false,0.301786,0.149442
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,50,4,true,false,true,true,0.209724,0.0824916
0.0824916
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,50,4,false,false,true,true,0.210067,0.0884152
0.0884152
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,20,4,true,false,true,true,0.244456,0.12392
0.12392
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,8,1,20,4,false,false,true,true,0.290008,0.151057
0.151057
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,32,1,20,4,true,false,true,true,0.293041,0.160229
0.160229
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,256,32,1,20,4,false,false,true,true,0.3018,0.168987
0.168987
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0824916
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 13 seconds of which 0.271179 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.358493,0.24577
gpu_array,256,8,1,20,2,true,false,true,false,0.286624,0.16553
gpu_array,256,8,1,20,4,true,false,true,false,0.274445,0.154467
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.357508,0.241995
gpu_sparse,256,8,1,20,2,true,false,true,false,0.263379,0.132241
gpu_sparse,256,8,1,20,4,true,false,true,false,0.283092,0.159208
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.429199,0.299735
gpu_reorg,256,8,1,20,2,true,false,true,false,0.306136,0.15993
gpu_reorg,256,8,1,20,4,true,false,true,false,0.268214,0.124799
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.259933,0.123214
gpu_array,256,8,1,50,2,true,false,true,false,0.22115,0.0933594
gpu_array,256,8,1,50,4,true,false,true,false,0.226373,0.0874219
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.266998,0.131395
gpu_sparse,256,8,1,50,2,true,false,true,false,0.232821,0.105589
gpu_sparse,256,8,1,50,4,true,false,true,false,0.241334,0.107405
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.31757,0.171922
gpu_reorg,256,8,1,50,2,true,false,true,false,0.245614,0.101641
gpu_reorg,256,8,1,50,4,true,false,true,false,0.237388,0.0895089
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.381685,0.248873
gpu_array,256,32,1,20,2,true,false,true,false,0.291747,0.161724
gpu_array,256,32,1,20,4,true,false,true,false,0.283934,0.155586
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.350558,0.231138
gpu_sparse,256,32,1,20,2,true,false,true,false,0.269062,0.147969
gpu_sparse,256,32,1,20,4,true,false,true,false,0.312109,0.174833
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.450689,0.311738
gpu_reorg,256,32,1,20,2,true,false,true,false,0.323298,0.181557
gpu_reorg,256,32,1,20,4,true,false,true,false,0.305555,0.16214
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.186948,0.0870592
0.0870592
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.206325,0.0991825
0.0991825
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.300717,0.182414
0.182414
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.284796,0.173747
0.173747
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.287969,0.181384
0.181384
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.274813,0.174367
0.174367
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0870592
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.274885 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.20053,0.0593471
gpu_array,256,8,1,20,2,true,false,true,false,0.182129,0.0537807
gpu_array,256,8,1,20,4,true,false,true,false,0.174618,0.0457115
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.19339,0.0600195
gpu_sparse,256,8,1,20,2,true,false,true,false,0.184757,0.0480385
gpu_sparse,256,8,1,20,4,true,false,true,false,0.175924,0.0459012
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.227531,0.0774191
gpu_reorg,256,8,1,20,2,true,false,true,false,0.214584,0.0566602
gpu_reorg,256,8,1,20,4,true,false,true,false,0.21166,0.053736
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.19103,0.0515206
gpu_array,256,8,1,50,2,true,false,true,false,0.186655,0.0477037
gpu_array,256,8,1,50,4,true,false,true,false,0.187179,0.0476702
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.18709,0.0509291
gpu_sparse,256,8,1,50,2,true,false,true,false,0.182347,0.048418
gpu_sparse,256,8,1,50,4,true,false,true,false,0.184049,0.0484459
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.212762,0.0598605
gpu_reorg,256,8,1,50,2,true,false,true,false,0.215594,0.0526479
gpu_reorg,256,8,1,50,4,true,false,true,false,0.220494,0.0525251
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.200831,0.0613225
gpu_array,256,32,1,20,2,true,false,true,false,0.194515,0.0555636
gpu_array,256,32,1,20,4,true,false,true,false,0.180008,0.0471959
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.186429,0.0597545
gpu_sparse,256,32,1,20,2,true,false,true,false,0.17615,0.0489174
gpu_sparse,256,32,1,20,4,true,false,true,false,0.18582,0.0485435
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.230513,0.0776116
gpu_reorg,256,32,1,20,2,true,false,true,false,0.199177,0.0563198
gpu_reorg,256,32,1,20,4,true,false,true,false,0.207773,0.0520815
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.153454,0.0457533
0.0457533
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.161094,0.0472545
0.0472545
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.160619,0.0456641
0.0456641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.159177,0.0475698
0.0475698
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.157316,0.0445926
0.0445926
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.153555,0.0441797
0.0441797
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0441797
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 8 seconds of which 0.0892241 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.19639,0.0619029
gpu_array,256,8,1,20,2,true,false,true,false,0.185313,0.0558482
gpu_array,256,8,1,20,4,true,false,true,false,0.168641,0.0469894
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.198016,0.0618555
gpu_sparse,256,8,1,20,2,true,false,true,false,0.181122,0.0499833
gpu_sparse,256,8,1,20,4,true,false,true,false,0.170561,0.0472349
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.225692,0.0778125
gpu_reorg,256,8,1,20,2,true,false,true,false,0.208044,0.0557003
gpu_reorg,256,8,1,20,4,true,false,true,false,0.202199,0.0537612
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.192347,0.0506055
gpu_array,256,8,1,50,2,true,false,true,false,0.186613,0.0471038
gpu_array,256,8,1,50,4,true,false,true,false,0.172612,0.0470536
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.183778,0.0504074
gpu_sparse,256,8,1,50,2,true,false,true,false,0.179467,0.0477706
gpu_sparse,256,8,1,50,4,true,false,true,false,0.175229,0.0479967
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.227324,0.0593555
gpu_reorg,256,8,1,50,2,true,false,true,false,0.203192,0.0525223
gpu_reorg,256,8,1,50,4,true,false,true,false,0.205639,0.0521791
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.194065,0.0606948
gpu_array,256,32,1,20,2,true,false,true,false,0.18221,0.0549777
gpu_array,256,32,1,20,4,true,false,true,false,0.172101,0.047101
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.198245,0.0598521
gpu_sparse,256,32,1,20,2,true,false,true,false,0.181021,0.0487667
gpu_sparse,256,32,1,20,4,true,false,true,false,0.171323,0.0479967
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.227835,0.0766071
gpu_reorg,256,32,1,20,2,true,false,true,false,0.21082,0.0562444
gpu_reorg,256,32,1,20,4,true,false,true,false,0.196741,0.0522098
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.151733,0.0457059
0.0457059
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.157224,0.0472907
0.0472907
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.16041,0.0443387
0.0443387
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.150667,0.044082
0.044082
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.152684,0.0455413
0.0455413
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.158976,0.0473689
0.0473689
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.044082
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0893369 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.790633,0.313513
gpu_array,256,8,1,20,2,true,false,true,false,0.709342,0.24115
gpu_array,256,8,1,20,4,true,false,true,false,0.685896,0.2244
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.792952,0.33034
gpu_sparse,256,8,1,20,2,true,false,true,false,0.625904,0.159944
gpu_sparse,256,8,1,20,4,true,false,true,false,0.677001,0.216063
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.23922,0.435092
gpu_reorg,256,8,1,20,2,true,false,true,false,1.01178,0.21714
gpu_reorg,256,8,1,20,4,true,false,true,false,0.999057,0.206646
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.656613,0.186747
gpu_array,256,8,1,50,2,true,false,true,false,0.622207,0.142854
gpu_array,256,8,1,50,4,true,false,true,false,0.627056,0.122592
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.651217,0.185815
gpu_sparse,256,8,1,50,2,true,false,true,false,0.609339,0.131102
gpu_sparse,256,8,1,50,4,true,false,true,false,0.61661,0.135025
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.04315,0.220045
gpu_reorg,256,8,1,50,2,true,false,true,false,0.93721,0.1275
gpu_reorg,256,8,1,50,4,true,false,true,false,0.94445,0.125254
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.557882,0.105315
0.105315
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.60072,0.143689
0.143689
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.705,0.254665
0.254665
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.734129,0.283237
0.283237
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.105315
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.230816 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.771409,0.313262
gpu_array,256,8,1,20,2,true,false,true,false,0.712762,0.240664
gpu_array,256,8,1,20,4,true,false,true,false,0.704291,0.224381
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.804012,0.330798
gpu_sparse,256,8,1,20,2,true,false,true,false,0.668797,0.159869
gpu_sparse,256,8,1,20,4,true,false,true,false,0.688214,0.216116
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.24782,0.434199
gpu_reorg,256,8,1,20,2,true,false,true,false,1.02645,0.216183
gpu_reorg,256,8,1,20,4,true,false,true,false,1.00303,0.20671
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.650432,0.186147
gpu_array,256,8,1,50,2,true,false,true,false,0.614018,0.143036
gpu_array,256,8,1,50,4,true,false,true,false,0.605268,0.122567
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.719249,0.185767
gpu_sparse,256,8,1,50,2,true,false,true,false,0.613463,0.13132
gpu_sparse,256,8,1,50,4,true,false,true,false,0.608449,0.134676
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.03834,0.220257
gpu_reorg,256,8,1,50,2,true,false,true,false,0.925218,0.127227
gpu_reorg,256,8,1,50,4,true,false,true,false,0.942388,0.125424
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.563211,0.105622
0.105622
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.587994,0.143797
0.143797
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.707254,0.254688
0.254688
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.71317,0.272879
0.272879
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.105622
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.230174 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.410399,0.263636
gpu_array,256,8,1,20,2,true,false,true,false,0.311077,0.164872
gpu_array,256,8,1,20,4,true,false,true,false,0.287751,0.152148
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.41865,0.272444
gpu_sparse,256,8,1,20,2,true,false,true,false,0.30284,0.168354
gpu_sparse,256,8,1,20,4,true,false,true,false,0.303616,0.160201
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.500282,0.351844
gpu_reorg,256,8,1,20,2,true,false,true,false,0.35041,0.201973
gpu_reorg,256,8,1,20,4,true,false,true,false,0.340974,0.191978
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.600273,0.186211
gpu_array,256,8,1,50,2,true,false,true,false,0.590619,0.171535
gpu_array,256,8,1,50,4,true,false,true,false,0.594032,0.177179
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.341498,0.193619
gpu_sparse,256,8,1,50,2,true,false,true,false,0.607422,0.183873
gpu_sparse,256,8,1,50,4,true,false,true,false,0.598234,0.180823
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.377919,0.226133
gpu_reorg,256,8,1,50,2,true,false,true,false,0.350614,0.192132
gpu_reorg,256,8,1,50,4,true,false,true,false,0.348795,0.184174
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.415725,0.2751
gpu_array,256,32,1,20,2,true,false,true,false,0.331883,0.181214
gpu_array,256,32,1,20,4,true,false,true,false,0.310798,0.169057
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.405709,0.261735
gpu_sparse,256,32,1,20,2,true,false,true,false,0.314757,0.179155
gpu_sparse,256,32,1,20,4,true,false,true,false,0.317985,0.175686
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.449191,0.305776
gpu_reorg,256,32,1,20,2,true,false,true,false,0.390656,0.234406
gpu_reorg,256,32,1,20,4,true,false,true,false,0.377333,0.226663
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.301618,0.168248
0.168248
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.315184,0.179023
0.179023
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.30262,0.173714
0.173714
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.352958,0.224609
0.224609
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.262863,0.123912
0.123912
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.287659,0.152056
0.152056
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.123912
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 19 seconds of which 0.340658 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.403823,0.263198
gpu_array,256,8,1,20,2,true,false,true,false,0.314771,0.163544
gpu_array,256,8,1,20,4,true,false,true,false,0.291359,0.142363
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.408368,0.253234
gpu_sparse,256,8,1,20,2,true,false,true,false,0.328535,0.181214
gpu_sparse,256,8,1,20,4,true,false,true,false,0.31611,0.172695
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.525176,0.360555
gpu_reorg,256,8,1,20,2,true,false,true,false,0.353555,0.202327
gpu_reorg,256,8,1,20,4,true,false,true,false,0.357807,0.192628
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.623552,0.187168
gpu_array,256,8,1,50,2,true,false,true,false,0.60887,0.171928
gpu_array,256,8,1,50,4,true,false,true,false,0.600692,0.177701
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.338239,0.193708
gpu_sparse,256,8,1,50,2,true,false,true,false,0.616496,0.184018
gpu_sparse,256,8,1,50,4,true,false,true,false,0.61108,0.181392
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.373094,0.226331
gpu_reorg,256,8,1,50,2,true,false,true,false,0.342637,0.191967
gpu_reorg,256,8,1,50,4,true,false,true,false,0.348499,0.183878
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.422109,0.275346
gpu_array,256,32,1,20,2,true,false,true,false,0.322586,0.181403
gpu_array,256,32,1,20,4,true,false,true,false,0.321682,0.168781
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.399696,0.261303
gpu_sparse,256,32,1,20,2,true,false,true,false,0.327606,0.177494
gpu_sparse,256,32,1,20,4,true,false,true,false,0.31668,0.173823
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.459453,0.300413
gpu_reorg,256,32,1,20,2,true,false,true,false,0.382824,0.218203
gpu_reorg,256,32,1,20,4,true,false,true,false,0.371119,0.211521
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.290516,0.157704
0.157704
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.319632,0.180123
0.180123
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.313234,0.174841
0.174841
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.38178,0.231669
0.231669
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.257012,0.124757
0.124757
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.284492,0.152238
0.152238
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.124757
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 19 seconds of which 0.338917 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.06334,0.0789676
gpu_array,256,8,1,20,2,false,false,true,false,1.07273,0.0727316
gpu_array,256,8,1,20,4,false,false,true,false,1.05347,0.0612807
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.08163,0.0833036
gpu_sparse,256,8,1,20,2,false,false,true,false,1.07898,0.0761942
gpu_sparse,256,8,1,20,4,false,false,true,false,1.07735,0.0661914
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.0969,0.0857422
gpu_reorg,256,8,1,20,2,false,false,true,false,1.08552,0.0771456
gpu_reorg,256,8,1,20,4,false,false,true,false,1.13943,0.0679967
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.07442,0.064933
gpu_array,256,8,1,50,2,false,false,true,false,1.09039,0.0602511
gpu_array,256,8,1,50,4,false,false,true,false,1.06719,0.0604911
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.06948,0.0655776
gpu_sparse,256,8,1,50,2,false,false,true,false,1.0779,0.074548
gpu_sparse,256,8,1,50,4,false,false,true,false,1.08698,0.073591
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.09489,0.0703404
gpu_reorg,256,8,1,50,2,false,false,true,false,1.07886,0.0649051
gpu_reorg,256,8,1,50,4,false,false,true,false,1.08394,0.0649665
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.08879,0.0848884
gpu_array,256,32,1,20,2,false,false,true,false,1.08122,0.0795508
gpu_array,256,32,1,20,4,false,false,true,false,1.07146,0.073139
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.07342,0.0845815
gpu_sparse,256,32,1,20,2,false,false,true,false,1.1047,0.0795926
gpu_sparse,256,32,1,20,4,false,false,true,false,1.07127,0.075731
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.1024,0.091236
gpu_reorg,256,32,1,20,2,false,false,true,false,1.10137,0.0823996
gpu_reorg,256,32,1,20,4,false,false,true,false,1.07532,0.0753153
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,1.01723,0.055731
0.055731
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.03925,0.0576674
0.0576674
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.03957,0.0708203
0.0708203
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.055731
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.111606 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.07445,0.0789174
gpu_array,256,8,1,20,2,false,false,true,false,1.06098,0.0715876
gpu_array,256,8,1,20,4,false,false,true,false,1.06266,0.0576367
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.09103,0.0770759
gpu_sparse,256,8,1,20,2,false,false,true,false,1.10118,0.0710463
gpu_sparse,256,8,1,20,4,false,false,true,false,1.07152,0.0620368
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.09181,0.0851172
gpu_reorg,256,8,1,20,2,false,false,true,false,1.08415,0.0768945
gpu_reorg,256,8,1,20,4,false,false,true,false,1.06708,0.0681975
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.07009,0.0650725
gpu_array,256,8,1,50,2,false,false,true,false,1.07239,0.0606752
gpu_array,256,8,1,50,4,false,false,true,false,1.07457,0.0600586
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.07688,0.0657199
gpu_sparse,256,8,1,50,2,false,false,true,false,1.07373,0.0737305
gpu_sparse,256,8,1,50,4,false,false,true,false,1.08349,0.0745592
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.08473,0.070226
gpu_reorg,256,8,1,50,2,false,false,true,false,1.09398,0.0649665
gpu_reorg,256,8,1,50,4,false,false,true,false,1.08249,0.0657533
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.08575,0.0851925
gpu_array,256,32,1,20,2,false,false,true,false,1.09243,0.0795954
gpu_array,256,32,1,20,4,false,false,true,false,1.1081,0.0735017
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.0755,0.0849833
gpu_sparse,256,32,1,20,2,false,false,true,false,1.09697,0.0802316
gpu_sparse,256,32,1,20,4,false,false,true,false,1.2269,0.0756696
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.09579,0.0924442
gpu_reorg,256,32,1,20,2,false,false,true,false,1.12299,0.0839314
gpu_reorg,256,32,1,20,4,false,false,true,false,1.08459,0.0767746
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.02071,0.0580943
0.0580943
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.02371,0.0560742
0.0560742
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.06806,0.0725195
0.0725195
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0560742
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.111016 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.18988,0.0592997
gpu_array,256,8,1,20,2,true,false,true,false,0.207199,0.0531808
gpu_array,256,8,1,20,4,true,false,true,false,0.187556,0.0458147
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.20745,0.0595703
gpu_sparse,256,8,1,20,2,true,false,true,false,0.195045,0.0505134
gpu_sparse,256,8,1,20,4,true,false,true,false,0.18704,0.0480887
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.236825,0.0789007
gpu_reorg,256,8,1,20,2,true,false,true,false,0.226638,0.056995
gpu_reorg,256,8,1,20,4,true,false,true,false,0.213237,0.0547545
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.188253,0.0504185
gpu_array,256,8,1,50,2,true,false,true,false,0.189417,0.0471177
gpu_array,256,8,1,50,4,true,false,true,false,0.184389,0.0471122
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.183393,0.0505804
gpu_sparse,256,8,1,50,2,true,false,true,false,0.181175,0.0483622
gpu_sparse,256,8,1,50,4,true,false,true,false,0.190086,0.0483454
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.227182,0.0608873
gpu_reorg,256,8,1,50,2,true,false,true,false,0.222299,0.0537723
gpu_reorg,256,8,1,50,4,true,false,true,false,0.214026,0.054986
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.207762,0.0609989
gpu_array,256,32,1,20,2,true,false,true,false,0.205379,0.0552679
gpu_array,256,32,1,20,4,true,false,true,false,0.180547,0.0482924
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.203139,0.0608398
gpu_sparse,256,32,1,20,2,true,false,true,false,0.190368,0.0497433
gpu_sparse,256,32,1,20,4,true,false,true,false,0.188426,0.0489174
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.243011,0.0783901
gpu_reorg,256,32,1,20,2,true,false,true,false,0.227852,0.0593248
gpu_reorg,256,32,1,20,4,true,false,true,false,0.211758,0.0543917
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.159983,0.046144
0.046144
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.164442,0.0478125
0.0478125
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.175455,0.0448744
0.0448744
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.17522,0.0446401
0.0446401
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.170823,0.0469392
0.0469392
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.186124,0.0499637
0.0499637
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0446401
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.0903803 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.210153,0.062832
gpu_array,256,8,1,20,2,true,false,true,false,0.211515,0.0563811
gpu_array,256,8,1,20,4,true,false,true,false,0.18719,0.0476814
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.213491,0.0628209
gpu_sparse,256,8,1,20,2,true,false,true,false,0.192352,0.050611
gpu_sparse,256,8,1,20,4,true,false,true,false,0.18882,0.0481948
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.248217,0.0785742
gpu_reorg,256,8,1,20,2,true,false,true,false,0.23363,0.0584068
gpu_reorg,256,8,1,20,4,true,false,true,false,0.225424,0.0546652
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.200218,0.0506641
gpu_array,256,8,1,50,2,true,false,true,false,0.190639,0.0472238
gpu_array,256,8,1,50,4,true,false,true,false,0.189191,0.0468917
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.200508,0.0503962
gpu_sparse,256,8,1,50,2,true,false,true,false,0.204372,0.0481222
gpu_sparse,256,8,1,50,4,true,false,true,false,0.182132,0.0482031
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.229646,0.0616769
gpu_reorg,256,8,1,50,2,true,false,true,false,0.214927,0.0536551
gpu_reorg,256,8,1,50,4,true,false,true,false,0.210031,0.0537807
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.209718,0.0607227
gpu_array,256,32,1,20,2,true,false,true,false,0.200371,0.0547238
gpu_array,256,32,1,20,4,true,false,true,false,0.186498,0.0481055
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.205444,0.0609124
gpu_sparse,256,32,1,20,2,true,false,true,false,0.184766,0.049721
gpu_sparse,256,32,1,20,4,true,false,true,false,0.183418,0.0494894
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.249489,0.0781724
gpu_reorg,256,32,1,20,2,true,false,true,false,0.225061,0.0576507
gpu_reorg,256,32,1,20,4,true,false,true,false,0.213998,0.0538421
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.17204,0.0453655
0.0453655
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.170195,0.0451953
0.0451953
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.170804,0.0463616
0.0463616
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.187165,0.0482143
0.0482143
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.173968,0.0472935
0.0472935
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.171306,0.049654
0.049654
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0451953
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.0909417 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.55414,6.41128
gpu_array,256,8,1,20,2,true,false,true,false,13.2143,13.0804
gpu_array,256,8,1,20,4,true,false,true,false,12.6002,12.4563
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.15523,6.02298
gpu_sparse,256,8,1,20,2,true,false,true,false,12.9824,12.8479
gpu_sparse,256,8,1,20,4,true,false,true,false,8.89337,8.74549
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.39602,7.25427
gpu_reorg,256,8,1,20,2,true,false,true,false,10.8399,10.7049
gpu_reorg,256,8,1,20,4,true,false,true,false,8.22068,8.07782
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.15561,3.9949
gpu_array,256,8,1,50,2,true,false,true,false,7.41492,7.27262
gpu_array,256,8,1,50,4,true,false,true,false,8.65044,8.49753
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,3.78993,3.63815
gpu_sparse,256,8,1,50,2,true,false,true,false,7.23786,7.09054
gpu_sparse,256,8,1,50,4,true,false,true,false,7.66157,7.52095
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,4.73065,4.58165
gpu_reorg,256,8,1,50,2,true,false,true,false,7.4945,7.34439
gpu_reorg,256,8,1,50,4,true,false,true,false,11.1721,11.0214
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,6.81988,6.67925
gpu_array,256,32,1,20,2,true,false,true,false,5.37114,5.22605
gpu_array,256,32,1,20,4,true,false,true,false,5.95593,5.81977
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.14225,5.99828
gpu_sparse,256,32,1,20,2,true,false,true,false,5.53817,5.39643
gpu_sparse,256,32,1,20,4,true,false,true,false,5.53814,5.39249
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.65578,7.49786
gpu_reorg,256,32,1,20,2,true,false,true,false,6.62667,6.49107
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.8707,2.75352
2.75352
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,2.99364,2.86083
2.86083
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.9177,5.78712
5.78712
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.16461,6.02343
6.02343
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.75352
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 204 seconds of which 2.71987 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.49939,6.36825
gpu_array,256,8,1,20,2,true,false,true,false,13.2413,13.099
gpu_array,256,8,1,20,4,true,false,true,false,12.6511,12.5238
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.16065,6.02337
gpu_sparse,256,8,1,20,2,true,false,true,false,13.011,12.871
gpu_sparse,256,8,1,20,4,true,false,true,false,8.86761,8.72922
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.39877,7.26094
gpu_reorg,256,8,1,20,2,true,false,true,false,10.8878,10.7494
gpu_reorg,256,8,1,20,4,true,false,true,false,8.17855,8.03346
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.08346,3.93502
gpu_array,256,8,1,50,2,true,false,true,false,7.48097,7.33756
gpu_array,256,8,1,50,4,true,false,true,false,8.66526,8.5224
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,3.80012,3.66117
gpu_sparse,256,8,1,50,2,true,false,true,false,7.23949,7.09719
gpu_sparse,256,8,1,50,4,true,false,true,false,7.6817,7.54107
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,4.75533,4.60913
gpu_reorg,256,8,1,50,2,true,false,true,false,7.42625,7.28339
gpu_reorg,256,8,1,50,4,true,false,true,false,11.3619,11.2219
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,6.897,6.76028
gpu_array,256,32,1,20,2,true,false,true,false,5.38983,5.25367
gpu_array,256,32,1,20,4,true,false,true,false,6.01191,5.87296
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.16741,6.03237
gpu_sparse,256,32,1,20,2,true,false,true,false,5.57634,5.44799
gpu_sparse,256,32,1,20,4,true,false,true,false,5.65867,5.51414
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.68648,7.54195
gpu_reorg,256,32,1,20,2,true,false,true,false,6.62002,6.47382
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.83037,2.697
2.697
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,2.96944,2.83942
2.83942
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.9936,5.84907
5.84907
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.2292,6.08243
6.08243
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.697
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 165 seconds of which 2.72937 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.24512,0.058178
gpu_array,256,8,1,20,2,true,false,true,false,0.292079,0.103463
gpu_array,256,8,1,20,4,true,false,true,false,0.29534,0.0771484
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.271468,0.0605301
gpu_sparse,256,8,1,20,2,true,false,true,false,0.297347,0.0914314
gpu_sparse,256,8,1,20,4,true,false,true,false,0.288195,0.0861858
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.316144,0.0767467
gpu_reorg,256,8,1,20,2,true,false,true,false,0.346635,0.116166
gpu_reorg,256,8,1,20,4,true,false,true,false,0.33841,0.09399
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.244132,0.0538421
gpu_array,256,8,1,50,2,true,false,true,false,0.282291,0.0780497
gpu_array,256,8,1,50,4,true,false,true,false,0.274897,0.0784682
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.27428,0.05274
gpu_sparse,256,8,1,50,2,true,false,true,false,0.297388,0.0791964
gpu_sparse,256,8,1,50,4,true,false,true,false,0.315695,0.0790876
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.315723,0.0640485
gpu_reorg,256,8,1,50,2,true,false,true,false,0.34478,0.0897573
gpu_reorg,256,8,1,50,4,true,false,true,false,0.327132,0.0888504
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.28238,0.0608398
gpu_array,256,32,1,20,2,true,false,true,false,0.255798,0.0582533
gpu_array,256,32,1,20,4,true,false,true,false,0.284191,0.0565123
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.277888,0.0591378
gpu_sparse,256,32,1,20,2,true,false,true,false,0.258951,0.0513616
gpu_sparse,256,32,1,20,4,true,false,true,false,0.276797,0.0552567
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.294235,0.0760435
gpu_reorg,256,32,1,20,2,true,false,true,false,0.289478,0.0617997
gpu_reorg,256,32,1,20,4,true,false,true,false,0.288792,0.0678097
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.234654,0.0493862
0.0493862
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.2544,0.0590876
0.0590876
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.231585,0.047433
0.047433
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.238242,0.047952
0.047952
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.252366,0.0592857
0.0592857
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.259721,0.0616183
0.0616183
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.047433
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 20 seconds of which 0.117742 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.268477,0.0614453
gpu_array,256,8,1,20,2,true,false,true,false,0.305407,0.110095
gpu_array,256,8,1,20,4,true,false,true,false,0.266169,0.0764369
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.259802,0.0605831
gpu_sparse,256,8,1,20,2,true,false,true,false,0.272394,0.0910324
gpu_sparse,256,8,1,20,4,true,false,true,false,0.300533,0.0856892
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.287807,0.0763114
gpu_reorg,256,8,1,20,2,true,false,true,false,0.322299,0.115826
gpu_reorg,256,8,1,20,4,true,false,true,false,0.315578,0.0945954
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.249353,0.0540402
gpu_array,256,8,1,50,2,true,false,true,false,0.283318,0.0779604
gpu_array,256,8,1,50,4,true,false,true,false,0.275086,0.0786579
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.249124,0.0526953
gpu_sparse,256,8,1,50,2,true,false,true,false,0.290329,0.0793917
gpu_sparse,256,8,1,50,4,true,false,true,false,0.276847,0.0787444
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.307439,0.063019
gpu_reorg,256,8,1,50,2,true,false,true,false,0.337079,0.0887528
gpu_reorg,256,8,1,50,4,true,false,true,false,0.327771,0.0883733
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.275686,0.0602846
gpu_array,256,32,1,20,2,true,false,true,false,0.250332,0.0572517
gpu_array,256,32,1,20,4,true,false,true,false,0.285259,0.0559068
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.257009,0.0583482
gpu_sparse,256,32,1,20,2,true,false,true,false,0.244727,0.0516462
gpu_sparse,256,32,1,20,4,true,false,true,false,0.286479,0.0543359
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.315971,0.0754576
gpu_reorg,256,32,1,20,2,true,false,true,false,0.267374,0.0620173
gpu_reorg,256,32,1,20,4,true,false,true,false,0.316303,0.066861
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.23529,0.0494643
0.0494643
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.252762,0.0596819
0.0596819
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.244235,0.0478069
0.0478069
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.2431,0.0483454
0.0483454
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.266099,0.0596261
0.0596261
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.251493,0.0612026
0.0612026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0478069
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.117857 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.201322,0.124499
gpu_array,512,8,1,20,2,true,false,true,false,0.157848,0.0836296
gpu_array,512,8,1,20,4,true,false,true,false,0.161299,0.0786165
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.204759,0.123379
gpu_sparse,512,8,1,20,2,true,false,true,false,0.15751,0.0761296
gpu_sparse,512,8,1,20,4,true,false,true,false,0.176341,0.0884505
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.263659,0.160143
gpu_reorg,512,8,1,20,2,true,false,true,false,0.188418,0.0862044
gpu_reorg,512,8,1,20,4,true,false,true,false,0.163304,0.0676009
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.142048,0.0697819
gpu_array,512,8,1,50,2,true,false,true,false,0.130277,0.0580111
gpu_array,512,8,1,50,4,true,false,true,false,0.138333,0.0602083
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.161042,0.0725
gpu_sparse,512,8,1,50,2,true,false,true,false,0.149635,0.0708594
gpu_sparse,512,8,1,50,4,true,false,true,false,0.151589,0.0728125
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.36513,0.0877865
gpu_reorg,512,8,1,50,2,true,false,true,false,0.327552,0.0547656
gpu_reorg,512,8,1,50,4,true,false,true,false,0.338626,0.0716992
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.206803,0.124121
gpu_array,512,32,1,20,2,true,false,true,false,0.169831,0.0864974
gpu_array,512,32,1,20,4,true,false,true,false,0.159512,0.0833398
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.20666,0.124629
gpu_sparse,512,32,1,20,2,true,false,true,false,0.162751,0.0794173
gpu_sparse,512,32,1,20,4,true,false,true,false,0.16902,0.0869889
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.260667,0.156501
gpu_reorg,512,32,1,20,2,true,false,true,false,0.189824,0.0908659
gpu_reorg,512,32,1,20,4,true,false,true,false,0.177002,0.0806478
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.150508,0.0541536
0.0541536
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.162139,0.0638314
0.0638314
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.162959,0.0672559
0.0672559
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.16513,0.0772396
0.0772396
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.176563,0.0808594
0.0808594
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.174557,0.0853646
0.0853646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0541536
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.291716 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.203356,0.123278
gpu_array,512,8,1,20,2,true,false,true,false,0.166777,0.083444
gpu_array,512,8,1,20,4,true,false,true,false,0.154827,0.0786556
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.208936,0.122998
gpu_sparse,512,8,1,20,2,true,false,true,false,0.167041,0.0758952
gpu_sparse,512,8,1,20,4,true,false,true,false,0.169036,0.0883073
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.261387,0.159824
gpu_reorg,512,8,1,20,2,true,false,true,false,0.190381,0.0862142
gpu_reorg,512,8,1,20,4,true,false,true,false,0.169063,0.0675
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.155013,0.0697266
gpu_array,512,8,1,50,2,true,false,true,false,0.137695,0.0582682
gpu_array,512,8,1,50,4,true,false,true,false,0.148395,0.0605046
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.155915,0.0725814
gpu_sparse,512,8,1,50,2,true,false,true,false,0.19319,0.0707943
gpu_sparse,512,8,1,50,4,true,false,true,false,0.151481,0.0727051
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.367507,0.0875586
gpu_reorg,512,8,1,50,2,true,false,true,false,0.334919,0.0549707
gpu_reorg,512,8,1,50,4,true,false,true,false,0.350892,0.0722461
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.213916,0.124072
gpu_array,512,32,1,20,2,true,false,true,false,0.170924,0.0869401
gpu_array,512,32,1,20,4,true,false,true,false,0.17137,0.0841309
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.209896,0.124609
gpu_sparse,512,32,1,20,2,true,false,true,false,0.173148,0.0793978
gpu_sparse,512,32,1,20,4,true,false,true,false,0.169818,0.0877865
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.268164,0.156836
gpu_reorg,512,32,1,20,2,true,false,true,false,0.204404,0.091123
gpu_reorg,512,32,1,20,4,true,false,true,false,0.180156,0.0811979
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.160254,0.0541341
0.0541341
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.159694,0.0639909
0.0639909
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.161862,0.0674609
0.0674609
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.173636,0.0766309
0.0766309
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.185407,0.0805892
0.0805892
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.182087,0.0857324
0.0857324
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0541341
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.291851 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.128037,0.032334
gpu_array,512,8,1,20,2,true,false,true,false,0.125485,0.0297819
gpu_array,512,8,1,20,4,true,false,true,false,0.12374,0.026735
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.123548,0.0324023
gpu_sparse,512,8,1,20,2,true,false,true,false,0.110368,0.0276855
gpu_sparse,512,8,1,20,4,true,false,true,false,0.116982,0.0271387
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.15665,0.040765
gpu_reorg,512,8,1,20,2,true,false,true,false,0.140072,0.0313477
gpu_reorg,512,8,1,20,4,true,false,true,false,0.134785,0.0299674
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.114365,0.0284277
gpu_array,512,8,1,50,2,true,false,true,false,0.115127,0.0272363
gpu_array,512,8,1,50,4,true,false,true,false,0.11847,0.0273242
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.119508,0.0290137
gpu_sparse,512,8,1,50,2,true,false,true,false,0.122653,0.0334603
gpu_sparse,512,8,1,50,4,true,false,true,false,0.125026,0.0332292
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.148219,0.0342871
gpu_reorg,512,8,1,50,2,true,false,true,false,0.147568,0.0355892
gpu_reorg,512,8,1,50,4,true,false,true,false,0.140345,0.0355273
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.1289,0.0305924
gpu_array,512,32,1,20,2,true,false,true,false,0.117591,0.0277474
gpu_array,512,32,1,20,4,true,false,true,false,0.116068,0.0242708
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.127448,0.0304427
gpu_sparse,512,32,1,20,2,true,false,true,false,0.117829,0.0253809
gpu_sparse,512,32,1,20,4,true,false,true,false,0.114128,0.0249349
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.150508,0.0391797
gpu_reorg,512,32,1,20,2,true,false,true,false,0.141227,0.0298991
gpu_reorg,512,32,1,20,4,true,false,true,false,0.141234,0.0286035
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0946517,0.0236882
0.0236882
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.0930729,0.0247135
0.0247135
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.0992806,0.0250618
0.0250618
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.100511,0.0256413
0.0256413
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.0984049,0.0248372
0.0248372
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.101198,0.025026
0.025026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0236882
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 8 seconds of which 0.0995607 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.121536,0.0323437
gpu_array,512,8,1,20,2,true,false,true,false,0.119528,0.0296842
gpu_array,512,8,1,20,4,true,false,true,false,0.109382,0.0266992
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.124821,0.032373
gpu_sparse,512,8,1,20,2,true,false,true,false,0.114355,0.0277669
gpu_sparse,512,8,1,20,4,true,false,true,false,0.117747,0.0272526
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.156562,0.0406771
gpu_reorg,512,8,1,20,2,true,false,true,false,0.152562,0.0314681
gpu_reorg,512,8,1,20,4,true,false,true,false,0.151113,0.0300195
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.11625,0.0283594
gpu_array,512,8,1,50,2,true,false,true,false,0.121107,0.0273568
gpu_array,512,8,1,50,4,true,false,true,false,0.117132,0.0272884
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.125234,0.0288802
gpu_sparse,512,8,1,50,2,true,false,true,false,0.118021,0.0333854
gpu_sparse,512,8,1,50,4,true,false,true,false,0.122516,0.0333236
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.143678,0.0343034
gpu_reorg,512,8,1,50,2,true,false,true,false,0.141667,0.0355469
gpu_reorg,512,8,1,50,4,true,false,true,false,0.148854,0.0355729
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.119775,0.0305827
gpu_array,512,32,1,20,2,true,false,true,false,0.115788,0.0278971
gpu_array,512,32,1,20,4,true,false,true,false,0.105133,0.0244043
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.122135,0.0303385
gpu_sparse,512,32,1,20,2,true,false,true,false,0.116478,0.025332
gpu_sparse,512,32,1,20,4,true,false,true,false,0.114808,0.0249642
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.152347,0.0390658
gpu_reorg,512,32,1,20,2,true,false,true,false,0.135918,0.0297982
gpu_reorg,512,32,1,20,4,true,false,true,false,0.131953,0.0284375
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0881673,0.0237142
0.0237142
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.102738,0.0246126
0.0246126
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.0953255,0.025013
0.025013
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.0959668,0.0256543
0.0256543
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.103516,0.0247396
0.0247396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.101289,0.0251172
0.0251172
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0237142
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.09953 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.758796,0.158535
gpu_array,512,8,1,20,2,true,false,true,false,0.725088,0.131989
gpu_array,512,8,1,20,4,true,false,true,false,0.71082,0.12293
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.789785,0.168691
gpu_sparse,512,8,1,20,2,true,false,true,false,0.675355,0.0907194
gpu_sparse,512,8,1,20,4,true,false,true,false,0.700449,0.111908
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.825072,0.220905
gpu_reorg,512,8,1,20,2,true,false,true,false,0.729801,0.119124
gpu_reorg,512,8,1,20,4,true,false,true,false,0.72695,0.11432
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.700452,0.102145
gpu_array,512,8,1,50,2,true,false,true,false,0.649736,0.0774707
gpu_array,512,8,1,50,4,true,false,true,false,0.667555,0.0816178
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.696885,0.105739
gpu_sparse,512,8,1,50,2,true,false,true,false,0.697712,0.10266
gpu_sparse,512,8,1,50,4,true,false,true,false,0.688451,0.101862
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.738219,0.117777
gpu_reorg,512,8,1,50,2,true,false,true,false,0.728936,0.0831022
gpu_reorg,512,8,1,50,4,true,false,true,false,0.736924,0.105413
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.650221,0.081862
0.081862
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.677897,0.100423
0.100423
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.693343,0.129541
0.129541
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.735986,0.156559
0.156559
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0774707
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.264734 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.738132,0.159355
gpu_array,512,8,1,20,2,true,false,true,false,0.71166,0.122467
gpu_array,512,8,1,20,4,true,false,true,false,0.69915,0.122979
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.758906,0.169063
gpu_sparse,512,8,1,20,2,true,false,true,false,0.67707,0.0904818
gpu_sparse,512,8,1,20,4,true,false,true,false,0.696589,0.111302
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.847035,0.220732
gpu_reorg,512,8,1,20,2,true,false,true,false,0.742422,0.118724
gpu_reorg,512,8,1,20,4,true,false,true,false,0.774883,0.113424
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.695241,0.102142
gpu_array,512,8,1,50,2,true,false,true,false,0.684023,0.0772526
gpu_array,512,8,1,50,4,true,false,true,false,0.65834,0.0808659
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.686553,0.105824
gpu_sparse,512,8,1,50,2,true,false,true,false,0.670837,0.102477
gpu_sparse,512,8,1,50,4,true,false,true,false,0.685036,0.101702
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.718799,0.117236
gpu_reorg,512,8,1,50,2,true,false,true,false,0.683044,0.0827832
gpu_reorg,512,8,1,50,4,true,false,true,false,0.722243,0.105706
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.641266,0.0813704
0.0813704
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.663327,0.100827
0.100827
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,0.647985,0.0880892
0.0880892
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,0.750602,0.19266
0.19266
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0772526
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.262908 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.258652,0.141465
gpu_array,512,8,1,20,2,true,false,true,false,0.220534,0.100742
gpu_array,512,8,1,20,4,true,false,true,false,0.208206,0.0975293
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.266195,0.146403
gpu_sparse,512,8,1,20,2,true,false,true,false,0.232467,0.113327
gpu_sparse,512,8,1,20,4,true,false,true,false,0.236361,0.115918
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.31735,0.197559
gpu_reorg,512,8,1,20,2,true,false,true,false,0.255713,0.131364
gpu_reorg,512,8,1,20,4,true,false,true,false,0.257419,0.129814
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.358662,0.122985
gpu_array,512,8,1,50,2,true,false,true,false,0.345713,0.118499
gpu_array,512,8,1,50,4,true,false,true,false,0.36054,0.130723
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.248747,0.11984
gpu_sparse,512,8,1,50,2,true,false,true,false,0.359782,0.124756
gpu_sparse,512,8,1,50,4,true,false,true,false,0.373158,0.134876
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.267106,0.139502
gpu_reorg,512,8,1,50,2,true,false,true,false,0.254792,0.12849
gpu_reorg,512,8,1,50,4,true,false,true,false,0.291755,0.168057
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.266533,0.146742
gpu_array,512,32,1,20,2,true,false,true,false,0.230326,0.110534
gpu_array,512,32,1,20,4,true,false,true,false,0.227956,0.108815
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.258776,0.140286
gpu_sparse,512,32,1,20,2,true,false,true,false,0.234717,0.113623
gpu_sparse,512,32,1,20,4,true,false,true,false,0.241344,0.117646
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.305866,0.174355
gpu_reorg,512,32,1,20,2,true,false,true,false,0.266217,0.137962
gpu_reorg,512,32,1,20,4,true,false,true,false,0.263444,0.138444
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.195635,0.0875618
0.0875618
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.210394,0.0925553
0.0925553
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.201569,0.0882878
0.0882878
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.228076,0.113493
0.113493
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.179548,0.0760319
0.0760319
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.187331,0.0838151
0.0838151
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0760319
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.419021 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.264613,0.141566
gpu_array,512,8,1,20,2,true,false,true,false,0.219889,0.100749
gpu_array,512,8,1,20,4,true,false,true,false,0.213288,0.0980534
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.26637,0.146579
gpu_sparse,512,8,1,20,2,true,false,true,false,0.238047,0.113047
gpu_sparse,512,8,1,20,4,true,false,true,false,0.233506,0.115667
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.330742,0.197279
gpu_reorg,512,8,1,20,2,true,false,true,false,0.248229,0.132344
gpu_reorg,512,8,1,20,4,true,false,true,false,0.248493,0.130003
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.364694,0.123158
gpu_array,512,8,1,50,2,true,false,true,false,0.410788,0.11847
gpu_array,512,8,1,50,4,true,false,true,false,0.375199,0.131058
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.245762,0.120762
gpu_sparse,512,8,1,50,2,true,false,true,false,0.363073,0.125443
gpu_sparse,512,8,1,50,4,true,false,true,false,0.374886,0.135303
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.258545,0.140055
gpu_reorg,512,8,1,50,2,true,false,true,false,0.256758,0.128503
gpu_reorg,512,8,1,50,4,true,false,true,false,0.293086,0.168086
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.266361,0.146569
gpu_array,512,32,1,20,2,true,false,true,false,0.233659,0.110612
gpu_array,512,32,1,20,4,true,false,true,false,0.228301,0.10916
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.25736,0.140173
gpu_sparse,512,32,1,20,2,true,false,true,false,0.233564,0.113773
gpu_sparse,512,32,1,20,4,true,false,true,false,0.231048,0.117767
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.293949,0.174157
gpu_reorg,512,32,1,20,2,true,false,true,false,0.261699,0.13735
gpu_reorg,512,32,1,20,4,true,false,true,false,0.272425,0.138311
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.199896,0.0879167
0.0879167
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.197282,0.0931152
0.0931152
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.208763,0.0883203
0.0883203
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.228389,0.113154
0.113154
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.191364,0.0761296
0.0761296
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.189264,0.0837956
0.0837956
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0761296
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.419474 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.11979,0.0442741
gpu_array,512,8,1,20,2,false,false,true,false,1.10192,0.0426758
gpu_array,512,8,1,20,4,false,false,true,false,1.12941,0.0421712
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.11808,0.044515
gpu_sparse,512,8,1,20,2,false,false,true,false,1.10178,0.0425326
gpu_sparse,512,8,1,20,4,false,false,true,false,1.12102,0.0441927
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.1134,0.0554557
gpu_reorg,512,8,1,20,2,false,false,true,false,1.11834,0.0506348
gpu_reorg,512,8,1,20,4,false,false,true,false,1.12979,0.0471126
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.12435,0.0462272
gpu_array,512,8,1,50,2,false,false,true,false,1.1316,0.0508659
gpu_array,512,8,1,50,4,false,false,true,false,1.12753,0.0500553
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.121,0.0461328
gpu_sparse,512,8,1,50,2,false,false,true,false,1.12825,0.055332
gpu_sparse,512,8,1,50,4,false,false,true,false,1.12752,0.0552572
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.10612,0.0488314
gpu_reorg,512,8,1,50,2,false,false,true,false,1.11232,0.0543783
gpu_reorg,512,8,1,50,4,false,false,true,false,1.13053,0.0543555
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.12922,0.0465332
gpu_array,512,32,1,20,2,false,false,true,false,1.10828,0.0438249
gpu_array,512,32,1,20,4,false,false,true,false,1.12211,0.0426855
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.10314,0.0465039
gpu_sparse,512,32,1,20,2,false,false,true,false,1.11389,0.0442285
gpu_sparse,512,32,1,20,4,false,false,true,false,1.11822,0.0439974
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.11377,0.0558301
gpu_reorg,512,32,1,20,2,false,false,true,false,1.12034,0.0513249
gpu_reorg,512,32,1,20,4,false,false,true,false,1.1139,0.0487956
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.11242,0.0427604
0.0427604
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.09894,0.0422949
0.0422949
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.09925,0.0419629
0.0419629
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0419629
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.145996 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.10385,0.0439551
gpu_array,512,8,1,20,2,false,false,true,false,1.07793,0.0421191
gpu_array,512,8,1,20,4,false,false,true,false,1.09028,0.0414551
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.09447,0.0443392
gpu_sparse,512,8,1,20,2,false,false,true,false,1.11513,0.0422168
gpu_sparse,512,8,1,20,4,false,false,true,false,1.10759,0.042487
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.11584,0.0552897
gpu_reorg,512,8,1,20,2,false,false,true,false,1.11967,0.0506641
gpu_reorg,512,8,1,20,4,false,false,true,false,1.13095,0.0469629
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.12307,0.04625
gpu_array,512,8,1,50,2,false,false,true,false,1.12132,0.0497038
gpu_array,512,8,1,50,4,false,false,true,false,1.09927,0.0497949
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.10651,0.0459603
gpu_sparse,512,8,1,50,2,false,false,true,false,1.12977,0.0548991
gpu_sparse,512,8,1,50,4,false,false,true,false,1.11949,0.0550391
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.10868,0.0487891
gpu_reorg,512,8,1,50,2,false,false,true,false,1.1105,0.0545117
gpu_reorg,512,8,1,50,4,false,false,true,false,1.1398,0.0545182
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.1208,0.046582
gpu_array,512,32,1,20,2,false,false,true,false,1.10041,0.0437728
gpu_array,512,32,1,20,4,false,false,true,false,1.10197,0.0427279
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.11854,0.0462793
gpu_sparse,512,32,1,20,2,false,false,true,false,1.11963,0.0441048
gpu_sparse,512,32,1,20,4,false,false,true,false,1.11317,0.0441602
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.1394,0.0560677
gpu_reorg,512,32,1,20,2,false,false,true,false,1.11978,0.0514225
gpu_reorg,512,32,1,20,4,false,false,true,false,1.10889,0.0489974
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.09676,0.0427214
0.0427214
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.09257,0.0424447
0.0424447
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.0856,0.0419824
0.0419824
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0414551
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.14543 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.130869,0.0332129
gpu_array,512,8,1,20,2,true,false,true,false,0.123392,0.030293
gpu_array,512,8,1,20,4,true,false,true,false,0.125426,0.0271191
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.12696,0.0332096
gpu_sparse,512,8,1,20,2,true,false,true,false,0.1236,0.0285482
gpu_sparse,512,8,1,20,4,true,false,true,false,0.1204,0.0279525
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.174368,0.042207
gpu_reorg,512,8,1,20,2,true,false,true,false,0.154492,0.0327474
gpu_reorg,512,8,1,20,4,true,false,true,false,0.149635,0.0311458
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.124834,0.0291309
gpu_array,512,8,1,50,2,true,false,true,false,0.121003,0.0305078
gpu_array,512,8,1,50,4,true,false,true,false,0.126136,0.0304329
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.123779,0.0293783
gpu_sparse,512,8,1,50,2,true,false,true,false,0.132148,0.0344922
gpu_sparse,512,8,1,50,4,true,false,true,false,0.13015,0.0344466
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.165153,0.0355957
gpu_reorg,512,8,1,50,2,true,false,true,false,0.162982,0.0379818
gpu_reorg,512,8,1,50,4,true,false,true,false,0.161048,0.0380013
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.124326,0.0312272
gpu_array,512,32,1,20,2,true,false,true,false,0.123493,0.0284408
gpu_array,512,32,1,20,4,true,false,true,false,0.108802,0.0254687
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.119007,0.0311165
gpu_sparse,512,32,1,20,2,true,false,true,false,0.12109,0.0260384
gpu_sparse,512,32,1,20,4,true,false,true,false,0.127301,0.0257389
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.173219,0.0404069
gpu_reorg,512,32,1,20,2,true,false,true,false,0.150592,0.0308008
gpu_reorg,512,32,1,20,4,true,false,true,false,0.151644,0.029248
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0961947,0.0245801
0.0245801
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.108887,0.0262044
0.0262044
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.102891,0.0254167
0.0254167
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.105352,0.0259245
0.0259245
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.114808,0.0269173
0.0269173
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.113089,0.0271517
0.0271517
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0245801
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.103535 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.132181,0.0332227
gpu_array,512,8,1,20,2,true,false,true,false,0.126758,0.0304036
gpu_array,512,8,1,20,4,true,false,true,false,0.122132,0.0270801
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.130859,0.0332031
gpu_sparse,512,8,1,20,2,true,false,true,false,0.121006,0.0285579
gpu_sparse,512,8,1,20,4,true,false,true,false,0.124232,0.0278776
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.173008,0.0421484
gpu_reorg,512,8,1,20,2,true,false,true,false,0.154551,0.032806
gpu_reorg,512,8,1,20,4,true,false,true,false,0.14902,0.0311816
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.128096,0.0291374
gpu_array,512,8,1,50,2,true,false,true,false,0.117796,0.0305566
gpu_array,512,8,1,50,4,true,false,true,false,0.117718,0.0304785
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.119274,0.0294303
gpu_sparse,512,8,1,50,2,true,false,true,false,0.129596,0.0345443
gpu_sparse,512,8,1,50,4,true,false,true,false,0.123044,0.034502
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.158604,0.0355566
gpu_reorg,512,8,1,50,2,true,false,true,false,0.158343,0.0379004
gpu_reorg,512,8,1,50,4,true,false,true,false,0.160941,0.0378939
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.124928,0.0311784
gpu_array,512,32,1,20,2,true,false,true,false,0.12793,0.0283203
gpu_array,512,32,1,20,4,true,false,true,false,0.109964,0.0253288
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.131322,0.0310612
gpu_sparse,512,32,1,20,2,true,false,true,false,0.121764,0.0260612
gpu_sparse,512,32,1,20,4,true,false,true,false,0.127894,0.0256803
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.156383,0.040498
gpu_reorg,512,32,1,20,2,true,false,true,false,0.147324,0.0307878
gpu_reorg,512,32,1,20,4,true,false,true,false,0.15235,0.0293034
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.10543,0.0247005
0.0247005
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.106969,0.0262402
0.0262402
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.10748,0.0254492
0.0254492
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.110547,0.0259115
0.0259115
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.114141,0.026901
0.026901
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.111745,0.0271094
0.0271094
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0247005
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103528 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.08116,3.83376
gpu_array,512,8,1,20,2,true,false,true,false,7.82591,7.53359
gpu_array,512,8,1,20,4,true,false,true,false,7.47572,7.22116
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.68992,3.44383
gpu_sparse,512,8,1,20,2,true,false,true,false,7.82762,7.54507
gpu_sparse,512,8,1,20,4,true,false,true,false,5.52113,5.23272
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.5773,4.30712
gpu_reorg,512,8,1,20,2,true,false,true,false,6.01398,5.73013
gpu_reorg,512,8,1,20,4,true,false,true,false,5.35642,5.08624
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.66609,3.38159
gpu_array,512,8,1,50,2,true,false,true,false,4.59255,4.29307
gpu_array,512,8,1,50,4,true,false,true,false,8.92947,8.6404
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.60146,3.3124
gpu_sparse,512,8,1,50,2,true,false,true,false,4.48936,4.20551
gpu_sparse,512,8,1,50,4,true,false,true,false,8.15973,7.85634
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.94517,3.6509
gpu_reorg,512,8,1,50,2,true,false,true,false,8.48673,8.16902
gpu_reorg,512,8,1,50,4,true,false,true,false,9.58276,9.27417
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.09797,3.85188
gpu_array,512,32,1,20,2,true,false,true,false,3.67712,3.42452
gpu_array,512,32,1,20,4,true,false,true,false,3.84969,3.60034
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.81397,3.57439
gpu_sparse,512,32,1,20,2,true,false,true,false,3.61596,3.36206
gpu_sparse,512,32,1,20,4,true,false,true,false,3.64893,3.37029
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.53267,4.24816
gpu_reorg,512,32,1,20,2,true,false,true,false,4.49645,4.22236
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.6697,2.57074
2.57074
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.75236,2.67358
2.67358
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.14706,3.07154
3.07154
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.16552,3.0926
3.0926
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.57074
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 197 seconds of which 3.68075 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.12987,3.86359
gpu_array,512,8,1,20,2,true,false,true,false,7.80652,7.56043
gpu_array,512,8,1,20,4,true,false,true,false,7.39582,7.13866
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.69247,3.45549
gpu_sparse,512,8,1,20,2,true,false,true,false,7.73306,7.47915
gpu_sparse,512,8,1,20,4,true,false,true,false,5.55095,5.30421
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.59003,4.3244
gpu_reorg,512,8,1,20,2,true,false,true,false,5.98785,5.71832
gpu_reorg,512,8,1,20,4,true,false,true,false,5.34102,5.07083
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.66559,3.38173
gpu_array,512,8,1,50,2,true,false,true,false,4.53385,4.22005
gpu_array,512,8,1,50,4,true,false,true,false,8.98436,8.66145
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.39969,3.11648
gpu_sparse,512,8,1,50,2,true,false,true,false,4.50421,4.2171
gpu_sparse,512,8,1,50,4,true,false,true,false,8.20346,7.9157
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.97499,3.6703
gpu_reorg,512,8,1,50,2,true,false,true,false,8.50905,8.18613
gpu_reorg,512,8,1,50,4,true,false,true,false,9.53095,9.21389
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.12844,3.87974
gpu_array,512,32,1,20,2,true,false,true,false,3.55017,3.29431
gpu_array,512,32,1,20,4,true,false,true,false,3.88516,3.63646
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.62396,3.37721
gpu_sparse,512,32,1,20,2,true,false,true,false,3.63056,3.38382
gpu_sparse,512,32,1,20,4,true,false,true,false,3.57775,3.32645
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.53068,4.27091
gpu_reorg,512,32,1,20,2,true,false,true,false,4.4924,4.22091
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.61547,2.53474
2.53474
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.71991,2.63983
2.63983
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.17464,3.07047
3.07047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.1874,3.0969
3.0969
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.53474
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 156 seconds of which 3.66668 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.163402,0.0318913
gpu_array,512,8,1,20,2,true,false,true,false,0.173467,0.0562793
gpu_array,512,8,1,20,4,true,false,true,false,0.174541,0.0404264
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.162578,0.0317187
gpu_sparse,512,8,1,20,2,true,false,true,false,0.1679,0.0474577
gpu_sparse,512,8,1,20,4,true,false,true,false,0.172135,0.0458333
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.19347,0.0398242
gpu_reorg,512,8,1,20,2,true,false,true,false,0.218984,0.0601302
gpu_reorg,512,8,1,20,4,true,false,true,false,0.21985,0.0492773
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.162598,0.0297852
gpu_array,512,8,1,50,2,true,false,true,false,0.167559,0.0425586
gpu_array,512,8,1,50,4,true,false,true,false,0.173945,0.0424349
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.166374,0.0290039
gpu_sparse,512,8,1,50,2,true,false,true,false,0.175807,0.0449479
gpu_sparse,512,8,1,50,4,true,false,true,false,0.177539,0.0447266
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.185576,0.0364876
gpu_reorg,512,8,1,50,2,true,false,true,false,0.194535,0.0473991
gpu_reorg,512,8,1,50,4,true,false,true,false,0.200993,0.047347
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.159027,0.0307715
gpu_array,512,32,1,20,2,true,false,true,false,0.160345,0.0294857
gpu_array,512,32,1,20,4,true,false,true,false,0.160758,0.0305501
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.157425,0.029821
gpu_sparse,512,32,1,20,2,true,false,true,false,0.163109,0.02639
gpu_sparse,512,32,1,20,4,true,false,true,false,0.165973,0.0292546
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.196914,0.0380599
gpu_reorg,512,32,1,20,2,true,false,true,false,0.193975,0.0351204
gpu_reorg,512,32,1,20,4,true,false,true,false,0.203005,0.0389421
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.145267,0.0254753
0.0254753
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.162067,0.0299056
0.0299056
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.150277,0.0252767
0.0252767
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.158923,0.02611
0.02611
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.155791,0.030791
0.030791
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.161849,0.0316406
0.0316406
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0252767
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 20 seconds of which 0.125453 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.168584,0.0318652
gpu_array,512,8,1,20,2,true,false,true,false,0.186859,0.0566504
gpu_array,512,8,1,20,4,true,false,true,false,0.17319,0.0403776
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.165182,0.0317187
gpu_sparse,512,8,1,20,2,true,false,true,false,0.19013,0.0475521
gpu_sparse,512,8,1,20,4,true,false,true,false,0.170794,0.0457943
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.209121,0.0398503
gpu_reorg,512,8,1,20,2,true,false,true,false,0.220446,0.0602897
gpu_reorg,512,8,1,20,4,true,false,true,false,0.202171,0.0491764
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.152093,0.0296973
gpu_array,512,8,1,50,2,true,false,true,false,0.17013,0.042526
gpu_array,512,8,1,50,4,true,false,true,false,0.171289,0.0423828
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.162327,0.0288639
gpu_sparse,512,8,1,50,2,true,false,true,false,0.178678,0.0445638
gpu_sparse,512,8,1,50,4,true,false,true,false,0.173359,0.0444531
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.181921,0.0360872
gpu_reorg,512,8,1,50,2,true,false,true,false,0.203955,0.047054
gpu_reorg,512,8,1,50,4,true,false,true,false,0.204603,0.0470508
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.155433,0.0304329
gpu_array,512,32,1,20,2,true,false,true,false,0.158083,0.0291764
gpu_array,512,32,1,20,4,true,false,true,false,0.162324,0.0301628
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.157656,0.029401
gpu_sparse,512,32,1,20,2,true,false,true,false,0.157077,0.0262174
gpu_sparse,512,32,1,20,4,true,false,true,false,0.160928,0.0287663
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.197155,0.0376497
gpu_reorg,512,32,1,20,2,true,false,true,false,0.191706,0.0348047
gpu_reorg,512,32,1,20,4,true,false,true,false,0.197982,0.0384766
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.145599,0.0251563
0.0251563
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.150059,0.0296159
0.0296159
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.157194,0.0250326
0.0250326
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.14875,0.0257031
0.0257031
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.153402,0.0303548
0.0303548
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.153711,0.0313151
0.0313151
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0250326
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.124746 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.121484,0.0648438
gpu_array,1024,8,1,20,2,true,false,true,false,0.103467,0.0468262
gpu_array,1024,8,1,20,4,true,false,true,false,0.0990137,0.0453027
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.117876,0.0661182
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.118335,0.064624
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.114946,0.0592822
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.168115,0.0812012
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.133184,0.0462695
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.151558,0.0499951
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.117358,0.0607178
gpu_array,1024,8,1,50,2,true,false,true,false,0.103647,0.0499365
gpu_array,1024,8,1,50,4,true,false,true,false,0.10293,0.0501953
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.116035,0.0642773
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.111758,0.06
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.115146,0.0614355
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.162759,0.0768213
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.133965,0.0460742
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.138726,0.050835
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.134316,0.0718164
gpu_array,1024,32,1,20,2,true,false,true,false,0.11627,0.0606055
gpu_array,1024,32,1,20,4,true,false,true,false,0.116113,0.0614258
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.127476,0.0747412
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.123794,0.0681299
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.122979,0.0673145
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.173691,0.0848242
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.154551,0.0656836
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.158779,0.0718652
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.0969092,0.0500342
0.0500342
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.0955908,0.0487158
0.0487158
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.0955957,0.0467676
0.0467676
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.100088,0.0512598
0.0512598
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.107422,0.0605469
0.0605469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.1096,0.061748
0.061748
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0453027
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.4076 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.11938,0.0646924
gpu_array,1024,8,1,20,2,true,false,true,false,0.101436,0.046748
gpu_array,1024,8,1,20,4,true,false,true,false,0.0999365,0.045249
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.120513,0.0658252
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.121221,0.0645801
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.113999,0.0593115
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.168086,0.0811719
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.129248,0.0462402
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.135747,0.0498096
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.114468,0.0607568
gpu_array,1024,8,1,50,2,true,false,true,false,0.102681,0.0499463
gpu_array,1024,8,1,50,4,true,false,true,false,0.101914,0.0501562
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.116841,0.0641064
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.111724,0.0599658
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.115186,0.0614746
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.165527,0.0766602
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.130898,0.0459375
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.141685,0.0508643
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.127471,0.0718066
gpu_array,1024,32,1,20,2,true,false,true,false,0.11729,0.0606494
gpu_array,1024,32,1,20,4,true,false,true,false,0.117002,0.0613379
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.127451,0.0747168
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.122852,0.0681641
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.121973,0.0672852
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.1548,0.0844873
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.152671,0.0657568
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.158447,0.0715332
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.100742,0.0499609
0.0499609
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.0985742,0.0487695
0.0487695
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.0935303,0.0466553
0.0466553
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.0980371,0.0511621
0.0511621
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.107505,0.0606299
0.0606299
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.110527,0.0616992
0.0616992
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.045249
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.407165 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0782812,0.0177344
gpu_array,1024,8,1,20,2,true,false,true,false,0.0783984,0.016875
gpu_array,1024,8,1,20,4,true,false,true,false,0.0777148,0.017168
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0786719,0.018125
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0804102,0.0179102
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0810156,0.0185156
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.120356,0.0227002
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.115723,0.0180664
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.115571,0.0188916
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.0821875,0.0206641
gpu_array,1024,8,1,50,2,true,false,true,false,0.082627,0.020127
gpu_array,1024,8,1,50,4,true,false,true,false,0.0825293,0.0200293
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0830273,0.0215039
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0842773,0.0237305
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0852832,0.0237598
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.133281,0.0258594
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.12499,0.0253809
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.125918,0.025332
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0855322,0.0161963
gpu_array,1024,32,1,20,2,true,false,true,false,0.0805273,0.0150977
gpu_array,1024,32,1,20,4,true,false,true,false,0.0763525,0.0148291
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0789502,0.0164502
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.077793,0.015293
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0793311,0.0158545
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.119072,0.021416
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.117163,0.0175537
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.118521,0.0179346
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0674365,0.0147021
0.0147021
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0633301,0.0154785
0.0154785
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.068833,0.0151221
0.0151221
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0659229,0.0161182
0.0161182
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,0.0687109,0.0179297
0.0179297
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,0.0677588,0.0179541
0.0179541
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0147021
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.127038 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0821826,0.0177295
gpu_array,1024,8,1,20,2,true,false,true,false,0.0781982,0.0166748
gpu_array,1024,8,1,20,4,true,false,true,false,0.0796191,0.0171191
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.078667,0.0181201
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0782129,0.017666
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.0778857,0.0183154
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.121445,0.0228125
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.118433,0.0178467
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.115347,0.018667
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.0811328,0.0205859
gpu_array,1024,8,1,50,2,true,false,true,false,0.0804785,0.0199316
gpu_array,1024,8,1,50,4,true,false,true,false,0.0804736,0.0199268
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0829932,0.0214697
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0841162,0.0235693
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.084165,0.0236182
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.120615,0.0258887
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.123687,0.0250537
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.122871,0.0252148
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0816309,0.0162012
gpu_array,1024,32,1,20,2,true,false,true,false,0.085249,0.0149365
gpu_array,1024,32,1,20,4,true,false,true,false,0.0743359,0.0147656
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0768896,0.0163428
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0776855,0.0151855
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.0764014,0.0158545
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.11981,0.0211768
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.117856,0.0172705
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.11624,0.0176074
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0663281,0.0145703
0.0145703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0670654,0.0153076
0.0153076
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0688574,0.0151465
0.0151465
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0649121,0.016084
0.016084
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,0.0678467,0.018042
0.018042
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,0.0705566,0.0178223
0.0178223
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0145703
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.126264 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.594287,0.143115
gpu_array,1024,8,1,20,2,true,false,true,false,0.572329,0.113345
gpu_array,1024,8,1,20,4,true,false,true,false,0.548716,0.10731
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.589014,0.153467
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.535156,0.0898438
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.529507,0.102749
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.686748,0.194561
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.583691,0.105176
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.612559,0.102793
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.527212,0.0926416
gpu_array,1024,8,1,50,2,true,false,true,false,0.506426,0.0669727
gpu_array,1024,8,1,50,4,true,false,true,false,0.515283,0.0777832
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.547246,0.0970508
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.503022,0.0909131
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.516304,0.0905225
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.569673,0.102876
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.542368,0.071665
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.541641,0.0767969
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.50542,0.0776855
0.0776855
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.521187,0.091499
0.091499
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,0.568423,0.113345
0.113345
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,0.615371,0.182754
0.182754
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0669727
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.480228 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.581694,0.143218
gpu_array,1024,8,1,20,2,true,false,true,false,0.533418,0.10666
gpu_array,1024,8,1,20,4,true,false,true,false,0.543901,0.107378
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.601621,0.153379
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.548862,0.0898779
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.55126,0.103018
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.691929,0.194858
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.601489,0.105396
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.572568,0.102842
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.526421,0.0928271
gpu_array,1024,8,1,50,2,true,false,true,false,0.501455,0.0668848
gpu_array,1024,8,1,50,4,true,false,true,false,0.501123,0.0782715
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.541553,0.0972168
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.516108,0.0913037
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.531016,0.0905859
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.599795,0.102725
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.568921,0.0718506
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.570913,0.0767725
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.493115,0.0780762
0.0780762
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.528086,0.0915625
0.0915625
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.506899,0.0781885
0.0781885
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.592842,0.185615
0.185615
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0668848
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.472782 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.158677,0.084458
gpu_array,1024,8,1,20,2,true,false,true,false,0.147559,0.0723633
gpu_array,1024,8,1,20,4,true,false,true,false,0.164937,0.085835
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.224521,0.0887793
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.163491,0.0892725
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.169692,0.0954736
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.303389,0.117842
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.284141,0.0966406
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.321226,0.135679
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.253735,0.114087
gpu_array,1024,8,1,50,2,true,false,true,false,0.246675,0.10605
gpu_array,1024,8,1,50,4,true,false,true,false,0.257129,0.113574
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.248447,0.110752
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.253071,0.114399
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.259883,0.123164
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.315967,0.128467
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.302544,0.11895
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.316831,0.132261
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.178203,0.0971484
gpu_array,1024,32,1,20,2,true,false,true,false,0.173813,0.0868994
gpu_array,1024,32,1,20,4,true,false,true,false,0.163301,0.089082
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.222456,0.0847607
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.177627,0.0916895
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.171919,0.0908643
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.296655,0.115015
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.294155,0.100796
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.304575,0.120981
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.133633,0.0535547
0.0535547
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.137349,0.0660596
0.0660596
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.132021,0.0558496
0.0558496
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.164814,0.0896191
0.0896191
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.143242,0.0680469
0.0680469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.149976,0.0747803
0.0747803
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0535547
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.658062 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.162466,0.0843408
gpu_array,1024,8,1,20,2,true,false,true,false,0.144873,0.0726074
gpu_array,1024,8,1,20,4,true,false,true,false,0.165269,0.0851904
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.227222,0.0885498
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.173232,0.0902246
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.17562,0.095542
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.301704,0.11811
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.28854,0.0971338
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.323877,0.1354
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.26084,0.114355
gpu_array,1024,8,1,50,2,true,false,true,false,0.251084,0.106553
gpu_array,1024,8,1,50,4,true,false,true,false,0.258555,0.114023
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.251411,0.110786
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.257681,0.114126
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.266973,0.123418
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.316719,0.128242
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.307485,0.119009
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.319971,0.132471
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.171187,0.0969678
gpu_array,1024,32,1,20,2,true,false,true,false,0.163042,0.0868701
gpu_array,1024,32,1,20,4,true,false,true,false,0.168389,0.0892871
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.230415,0.0849072
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.166367,0.0921484
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.175864,0.0909033
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.311543,0.115254
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.291646,0.101216
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.307734,0.121211
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.135718,0.0536865
0.0536865
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.14252,0.0663477
0.0663477
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,0.126411,0.0560986
0.0560986
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.16002,0.089707
0.089707
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,0.138496,0.0681836
0.0681836
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,0.152075,0.0749268
0.0749268
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0536865
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.659005 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.964009,0.037251
gpu_array,1024,8,1,20,2,false,false,true,false,0.940962,0.036665
gpu_array,1024,8,1,20,4,false,false,true,false,0.960493,0.0444775
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.949453,0.0373438
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.950776,0.0367139
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.964146,0.0452002
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.957529,0.0454199
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.966636,0.0428076
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.937554,0.0488818
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.950117,0.0389844
gpu_array,1024,8,1,50,2,false,false,true,false,0.947871,0.0416211
gpu_array,1024,8,1,50,4,false,false,true,false,0.967251,0.0414697
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,0.93625,0.0397656
gpu_sparse,1024,8,1,50,2,false,false,true,false,0.979282,0.0476416
gpu_sparse,1024,8,1,50,4,false,false,true,false,0.950117,0.0477734
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.928525,0.0418066
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.966553,0.0456543
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.971382,0.044624
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.963003,0.0362451
gpu_array,1024,32,1,20,2,false,false,true,false,0.948369,0.0352832
gpu_array,1024,32,1,20,4,false,false,true,false,0.934941,0.038457
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.94355,0.0363232
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.941006,0.0357324
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.966255,0.0385205
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.952612,0.0434326
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.955078,0.0410156
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.958315,0.0422998
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.941729,0.034502
0.034502
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.941753,0.0374561
0.0374561
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.946797,0.0356641
0.0356641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.034502
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.249658 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,0.934902,0.0374414
gpu_array,1024,8,1,20,2,false,false,true,false,0.955454,0.0365088
gpu_array,1024,8,1,20,4,false,false,true,false,0.969985,0.0442041
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,0.938784,0.037417
gpu_sparse,1024,8,1,20,2,false,false,true,false,0.953735,0.0367432
gpu_sparse,1024,8,1,20,4,false,false,true,false,0.966948,0.0450732
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,0.939541,0.0420801
gpu_reorg,1024,8,1,20,2,false,false,true,false,0.950957,0.0427539
gpu_reorg,1024,8,1,20,4,false,false,true,false,0.941514,0.0489355
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,0.935479,0.0389941
gpu_array,1024,8,1,50,2,false,false,true,false,0.960366,0.0414209
gpu_array,1024,8,1,50,4,false,false,true,false,0.959482,0.0415137
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,0.943359,0.0400391
gpu_sparse,1024,8,1,50,2,false,false,true,false,0.975566,0.047832
gpu_sparse,1024,8,1,50,4,false,false,true,false,0.959917,0.0478076
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,0.942446,0.0420557
gpu_reorg,1024,8,1,50,2,false,false,true,false,0.957832,0.0457227
gpu_reorg,1024,8,1,50,4,false,false,true,false,0.960557,0.044541
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,0.939639,0.0363184
gpu_array,1024,32,1,20,2,false,false,true,false,0.94937,0.0353076
gpu_array,1024,32,1,20,4,false,false,true,false,0.971821,0.0382275
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,0.957319,0.0364209
gpu_sparse,1024,32,1,20,2,false,false,true,false,0.954526,0.0355811
gpu_sparse,1024,32,1,20,4,false,false,true,false,0.93104,0.0384619
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,0.961558,0.0435889
gpu_reorg,1024,32,1,20,2,false,false,true,false,0.930674,0.0410254
gpu_reorg,1024,32,1,20,4,false,false,true,false,0.950576,0.042373
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,0.937993,0.0346729
0.0346729
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.916309,0.0374023
0.0374023
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.945879,0.0357227
0.0357227
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0346729
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.249075 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.102803,0.0178418
gpu_array,1024,8,1,20,2,true,false,true,false,0.0950928,0.0169678
gpu_array,1024,8,1,20,4,true,false,true,false,0.104678,0.0187402
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0944385,0.0182666
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.102715,0.0187305
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.097749,0.019624
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.13583,0.0235254
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.129375,0.0190234
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.134829,0.0225244
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.101821,0.0207666
gpu_array,1024,8,1,50,2,true,false,true,false,0.0992432,0.0211182
gpu_array,1024,8,1,50,4,true,false,true,false,0.107227,0.0212891
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.0995117,0.0213867
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.0992871,0.0240918
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.0953271,0.0240381
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.143442,0.0272314
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.144888,0.0277002
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.138584,0.0272559
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.0907031,0.0164844
gpu_array,1024,32,1,20,2,true,false,true,false,0.090708,0.0155127
gpu_array,1024,32,1,20,4,true,false,true,false,0.099126,0.0151416
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0998682,0.0168604
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.100742,0.0157813
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.112886,0.0162061
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.133437,0.0221094
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.12522,0.0187744
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.152734,0.0189453
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0853418,0.0150293
0.0150293
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0864209,0.017085
0.017085
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0836768,0.0153174
0.0153174
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0818115,0.0163818
0.0163818
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0885449,0.019209
0.019209
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.0867676,0.0193848
0.0193848
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0150293
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.132781 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.0930225,0.0178271
gpu_array,1024,8,1,20,2,true,false,true,false,0.0941309,0.0169824
gpu_array,1024,8,1,20,4,true,false,true,false,0.10958,0.0187598
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.0934961,0.0183008
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.0930176,0.0187988
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.103633,0.0196484
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.133936,0.023584
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.133413,0.0191553
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.127461,0.0229687
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.110728,0.0208838
gpu_array,1024,8,1,50,2,true,false,true,false,0.0955176,0.0212988
gpu_array,1024,8,1,50,4,true,false,true,false,0.112114,0.0212939
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.108306,0.0213916
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.106235,0.0242041
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.10939,0.0244287
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.141333,0.0270752
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.142334,0.0270996
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.134272,0.0278271
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.102495,0.0165576
gpu_array,1024,32,1,20,2,true,false,true,false,0.0956104,0.0155322
gpu_array,1024,32,1,20,4,true,false,true,false,0.101309,0.0153711
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.0931934,0.0170215
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.0931152,0.0159668
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.101372,0.0164111
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.134404,0.0220996
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.136147,0.01896
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.125781,0.0193359
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,0.0834766,0.0151172
0.0151172
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,0.0886865,0.0173975
0.0173975
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,0.0829248,0.015542
0.015542
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,0.0965283,0.0164502
0.0164502
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,0.0819189,0.0194189
0.0194189
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,0.090918,0.0196289
0.0196289
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0151172
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.133599 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.19094,3.02102
gpu_array,1024,8,1,20,2,true,false,true,false,4.79965,4.60922
gpu_array,1024,8,1,20,4,true,false,true,false,4.54727,4.3959
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.97143,2.82787
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.81502,4.66365
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.63031,4.47992
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.66289,3.48223
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.75619,6.57553
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.39898,5.21637
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.72541,3.57404
gpu_array,1024,8,1,50,2,true,false,true,false,4.59283,4.43365
gpu_array,1024,8,1,50,4,true,false,true,false,7.05287,6.8849
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.36877,3.22229
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.43246,4.27816
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.43346,6.27721
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.12699,3.91117
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.23625,7.02629
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.1774,9.94205
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.3165,3.14365
gpu_array,1024,32,1,20,2,true,false,true,false,3.43889,3.29729
gpu_array,1024,32,1,20,4,true,false,true,false,4.00504,3.8527
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.25844,3.12367
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.53465,3.38523
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.80777,3.65836
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,4.05211,3.85973
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.6943,4.5068
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.91613,2.86145
2.86145
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.02406,2.96547
2.96547
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.04684,1.99215
1.99215
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.19598,2.14324
2.14324
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99215
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 187 seconds of which 6.53369 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,3.24275,3.06111
gpu_array,1024,8,1,20,2,true,false,true,false,4.79445,4.6509
gpu_array,1024,8,1,20,4,true,false,true,false,4.49586,4.35426
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,2.86646,2.72877
gpu_sparse,1024,8,1,20,2,true,false,true,false,4.79357,4.64611
gpu_sparse,1024,8,1,20,4,true,false,true,false,4.60676,4.46125
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,3.66635,3.48471
gpu_reorg,1024,8,1,20,2,true,false,true,false,6.7008,6.51818
gpu_reorg,1024,8,1,20,4,true,false,true,false,5.27428,5.07994
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,3.79688,3.64355
gpu_array,1024,8,1,50,2,true,false,true,false,4.54555,4.40102
gpu_array,1024,8,1,50,4,true,false,true,false,6.90492,6.74086
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,3.37229,3.22482
gpu_sparse,1024,8,1,50,2,true,false,true,false,4.54699,4.37414
gpu_sparse,1024,8,1,50,4,true,false,true,false,6.32764,6.16748
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,4.14805,3.93809
gpu_reorg,1024,8,1,50,2,true,false,true,false,7.0843,6.89289
gpu_reorg,1024,8,1,50,4,true,false,true,false,10.1004,9.90609
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,3.32779,3.18424
gpu_array,1024,32,1,20,2,true,false,true,false,3.4432,3.3016
gpu_array,1024,32,1,20,4,true,false,true,false,4.07373,3.93311
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,3.13766,2.99996
gpu_sparse,1024,32,1,20,2,true,false,true,false,3.53672,3.39512
gpu_sparse,1024,32,1,20,4,true,false,true,false,3.76014,3.61561
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,4.03869,3.86682
gpu_reorg,1024,32,1,20,2,true,false,true,false,4.70953,4.50055
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,2.97008,2.86656
2.86656
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,3.0273,2.97457
2.97457
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,2.05812,1.99758
1.99758
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,2.18385,2.13209
2.13209
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.99758
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 145 seconds of which 6.50455 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.108765,0.0169678
gpu_array,1024,8,1,20,2,true,false,true,false,0.122773,0.0290234
gpu_array,1024,8,1,20,4,true,false,true,false,0.115557,0.0266895
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.104902,0.0170117
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.117007,0.0310693
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.119121,0.032207
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.150557,0.0216504
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.151426,0.0342383
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.161479,0.0325732
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.19627,0.0204883
gpu_array,1024,8,1,50,2,true,false,true,false,0.256274,0.0336182
gpu_array,1024,8,1,50,4,true,false,true,false,0.216201,0.033584
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.193022,0.0201709
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.262002,0.0354395
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.222007,0.0354834
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.212476,0.0269287
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.28834,0.0383398
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.24146,0.038335
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.109829,0.0160791
gpu_array,1024,32,1,20,2,true,false,true,false,0.10583,0.0159863
gpu_array,1024,32,1,20,4,true,false,true,false,0.106489,0.0166455
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.110415,0.0156885
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.103003,0.0160889
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.105322,0.0174316
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.152041,0.0202051
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.148477,0.0195703
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.15416,0.0233008
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.104292,0.0154248
0.0154248
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.107676,0.017832
0.017832
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.105122,0.0162549
0.0162549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.106914,0.0170703
0.0170703
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.106709,0.0178418
0.0178418
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.107397,0.0185303
0.0185303
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0154248
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 18 seconds of which 0.161335 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,0.106924,0.0161035
gpu_array,1024,8,1,20,2,true,false,true,false,0.116138,0.0272705
gpu_array,1024,8,1,20,4,true,false,true,false,0.113848,0.0249805
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,0.102939,0.0160254
gpu_sparse,1024,8,1,20,2,true,false,true,false,0.121865,0.0310449
gpu_sparse,1024,8,1,20,4,true,false,true,false,0.119248,0.032334
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,0.151538,0.0216553
gpu_reorg,1024,8,1,20,2,true,false,true,false,0.166987,0.0341748
gpu_reorg,1024,8,1,20,4,true,false,true,false,0.165352,0.0325391
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,0.195356,0.0205518
gpu_array,1024,8,1,50,2,true,false,true,false,0.248481,0.0336377
gpu_array,1024,8,1,50,4,true,false,true,false,0.225981,0.0335986
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,0.190186,0.0202637
gpu_sparse,1024,8,1,50,2,true,false,true,false,0.243525,0.0355176
gpu_sparse,1024,8,1,50,4,true,false,true,false,0.219219,0.035625
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,0.218481,0.0270752
gpu_reorg,1024,8,1,50,2,true,false,true,false,0.292461,0.0385547
gpu_reorg,1024,8,1,50,4,true,false,true,false,0.245518,0.0384863
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,0.103125,0.0162109
gpu_array,1024,32,1,20,2,true,false,true,false,0.102979,0.0160645
gpu_array,1024,32,1,20,4,true,false,true,false,0.097749,0.0166943
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,0.103804,0.0159131
gpu_sparse,1024,32,1,20,2,true,false,true,false,0.109961,0.0162109
gpu_sparse,1024,32,1,20,4,true,false,true,false,0.112319,0.0175928
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,0.151211,0.0203516
gpu_reorg,1024,32,1,20,2,true,false,true,false,0.148735,0.0198291
gpu_reorg,1024,32,1,20,4,true,false,true,false,0.152217,0.0233105
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,0.104434,0.0155664
0.0155664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,0.102881,0.0179199
0.0179199
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,0.104219,0.0163281
0.0163281
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,0.104946,0.0170557
0.0170557
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,0.107568,0.0177246
0.0177246
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,0.104536,0.0185986
0.0185986
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0155664
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.160729 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0896021,0.0627466
gpu_array,2048,8,1,20,2,true,false,true,false,0.0775098,0.0516309
gpu_array,2048,8,1,20,4,true,false,true,false,0.072876,0.0469971
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0990015,0.072146
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0844482,0.0566162
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.086875,0.0595313
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.11948,0.0716284
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0915259,0.0456274
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0840698,0.0381714
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0813843,0.0555054
gpu_array,2048,8,1,50,2,true,false,true,false,0.0714966,0.0451294
gpu_array,2048,8,1,50,4,true,false,true,false,0.069978,0.0445874
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0845874,0.0591968
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0778345,0.0500024
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0785718,0.0522046
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.117712,0.0713257
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.085686,0.0412524
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0917212,0.0453345
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0916577,0.0657788
gpu_array,2048,32,1,20,2,true,false,true,false,0.0825244,0.0561572
gpu_array,2048,32,1,20,4,true,false,true,false,0.0822949,0.0569043
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.094873,0.0685059
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0744263,0.0480591
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.077417,0.0500732
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.122249,0.0763501
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.106067,0.0606567
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0984204,0.052522
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,true,0.0936255,0.038938
0.038938
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,true,0.0932617,0.0493164
0.0493164
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,0.0848437,0.0399219
0.0399219
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,0.0872217,0.0427881
0.0427881
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,true,0.096377,0.0524316
0.0524316
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,true,0.0982739,0.0553052
0.0553052
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0381714
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.730457 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.088291,0.0624121
gpu_array,2048,8,1,20,2,true,false,true,false,0.0766553,0.0512646
gpu_array,2048,8,1,20,4,true,false,true,false,0.0708301,0.0469043
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0976001,0.0717212
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0835376,0.0566821
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0857935,0.0594263
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.116555,0.0716333
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0910132,0.045603
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0840967,0.0381982
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0823706,0.0555151
gpu_array,2048,8,1,50,2,true,false,true,false,0.0715674,0.0452002
gpu_array,2048,8,1,50,4,true,false,true,false,0.0713306,0.0449634
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0852124,0.0593335
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0774585,0.0501147
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0795752,0.0522314
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.116873,0.0714624
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0868286,0.0414185
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0863184,0.0453027
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.091748,0.0658691
gpu_array,2048,32,1,20,2,true,false,true,false,0.0825977,0.0562305
gpu_array,2048,32,1,20,4,true,false,true,false,0.0832715,0.0569043
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0944678,0.0685889
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0755054,0.0481616
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0780103,0.0501782
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.121965,0.0765552
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.107156,0.060769
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0990527,0.052666
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,true,0.0839209,0.038999
0.038999
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,true,0.0937573,0.0493237
0.0493237
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,0.0833911,0.0399341
0.0399341
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,0.0882178,0.0428076
0.0428076
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,true,0.0965063,0.052561
0.052561
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,true,0.0998901,0.0554565
0.0554565
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0381982
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.730887 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0508862,0.0142651
gpu_array,2048,8,1,20,2,true,false,true,false,0.0555396,0.0140356
gpu_array,2048,8,1,20,4,true,false,true,false,0.0538647,0.0148022
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0536792,0.015105
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0507031,0.014082
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0541772,0.0146265
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0779712,0.0188892
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0742432,0.0146729
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0745044,0.0173755
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0556787,0.0161279
gpu_array,2048,8,1,50,2,true,false,true,false,0.0528857,0.0162646
gpu_array,2048,8,1,50,4,true,false,true,false,0.0558325,0.0162817
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0594214,0.0169409
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0558398,0.0172656
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0564282,0.0173657
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0775366,0.020896
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0769971,0.0203564
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0769897,0.0203491
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0482324,0.0120996
gpu_array,2048,32,1,20,2,true,false,true,false,0.0471729,0.01104
gpu_array,2048,32,1,20,4,true,false,true,false,0.0503223,0.0112598
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0519189,0.0123682
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0493774,0.0112915
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0492114,0.0111255
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0759741,0.0173804
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0729395,0.0138574
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0728394,0.0157104
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0396338,0.0103369
0.0103369
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0426538,0.0114038
0.0114038
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0462866,0.0130835
0.0130835
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.0432715,0.0134863
0.0134863
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0457935,0.0150317
0.0150317
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0449438,0.0151587
0.0151587
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0103369
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.20248 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0533838,0.0133447
gpu_array,2048,8,1,20,2,true,false,true,false,0.0488403,0.0131958
gpu_array,2048,8,1,20,4,true,false,true,false,0.0524414,0.0138672
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0497729,0.0141284
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0494336,0.0133008
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0504126,0.0137915
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0740283,0.0188525
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0709399,0.0147876
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0739087,0.0172681
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0570581,0.0160425
gpu_array,2048,8,1,50,2,true,false,true,false,0.055415,0.0163525
gpu_array,2048,8,1,50,4,true,false,true,false,0.0568286,0.0163013
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0535791,0.016958
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0563623,0.0172998
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0529883,0.0173438
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.0801685,0.0210864
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.0814819,0.0204468
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.0782202,0.020603
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0491382,0.0120288
gpu_array,2048,32,1,20,2,true,false,true,false,0.0481836,0.0110742
gpu_array,2048,32,1,20,4,true,false,true,false,0.0479687,0.0113477
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.052478,0.012439
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.04854,0.0114307
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0438916,0.0111768
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0765356,0.0174536
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0729224,0.0138403
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0757495,0.0156909
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0401685,0.0103833
0.0103833
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0407788,0.0114819
0.0114819
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0424854,0.0131885
0.0131885
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.0432983,0.0135132
0.0135132
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0468433,0.015105
0.015105
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0455444,0.015271
0.015271
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0103833
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.200866 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.451614,0.10884
gpu_array,2048,8,1,20,2,true,false,true,false,0.42448,0.08073
gpu_array,2048,8,1,20,4,true,false,true,false,0.416248,0.0812866
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.448721,0.116689
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.399641,0.066145
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.409788,0.0767798
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.512646,0.151807
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.43626,0.0793262
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.446123,0.0769824
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.428228,0.0869189
gpu_array,2048,8,1,50,2,true,false,true,false,0.400105,0.0617261
gpu_array,2048,8,1,50,4,true,false,true,false,0.411526,0.0707056
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.42686,0.0914111
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.415242,0.0778394
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.416726,0.079812
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.468596,0.0955493
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.423457,0.0645703
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.432952,0.0701587
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.3999,0.0688452
0.0688452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.415583,0.0850171
0.0850171
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.390229,0.0581982
0.0581982
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.637163,0.30562
0.30562
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0581982
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.841711 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.444912,0.108975
gpu_array,2048,8,1,20,2,true,false,true,false,0.422373,0.0805762
gpu_array,2048,8,1,20,4,true,false,true,false,0.422048,0.081228
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.444519,0.116394
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.399421,0.0659253
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.414241,0.0768384
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.519409,0.152222
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.445669,0.079458
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.445547,0.0768945
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.422283,0.0868335
gpu_array,2048,8,1,50,2,true,false,true,false,0.401936,0.061604
gpu_array,2048,8,1,50,4,true,false,true,false,0.41252,0.0707227
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.43009,0.0912231
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.408374,0.0778076
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.411443,0.0794116
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.449978,0.0954858
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.435183,0.0645776
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.430518,0.070166
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,0.400398,0.068855
0.068855
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,0.4151,0.085022
0.085022
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.386365,0.0582397
0.0582397
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.638967,0.308889
0.308889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0582397
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.84269 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.164719,0.0905005
gpu_array,2048,8,1,20,2,true,false,true,false,0.164858,0.0921045
gpu_array,2048,8,1,20,4,true,false,true,false,0.173293,0.0966333
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.189854,0.0990332
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.180044,0.106802
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.175132,0.100425
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.224138,0.12697
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.21446,0.119246
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.196101,0.106257
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.189009,0.114302
gpu_array,2048,8,1,50,2,true,false,true,false,0.179163,0.104456
gpu_array,2048,8,1,50,4,true,false,true,false,0.190234,0.112598
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.193601,0.107664
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.187766,0.109641
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.197109,0.118496
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.215164,0.12532
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.210815,0.115112
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.220615,0.123936
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.162251,0.0875439
gpu_array,2048,32,1,20,2,true,false,true,false,0.161384,0.086189
gpu_array,2048,32,1,20,4,true,false,true,false,0.168169,0.0900439
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.17342,0.0845532
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.164329,0.0857153
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.166978,0.0917822
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.204434,0.10873
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.20157,0.104402
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.192517,0.0963257
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,0.109966,0.0606494
0.0606494
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,0.123958,0.076106
0.076106
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,0.118335,0.0699951
0.0699951
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,0.122754,0.0739258
0.0739258
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.116301,0.0679614
0.0679614
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.123301,0.0749609
0.0749609
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0606494
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.32234 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.165073,0.0903662
gpu_array,2048,8,1,20,2,true,false,true,false,0.168462,0.0908252
gpu_array,2048,8,1,20,4,true,false,true,false,0.166565,0.0889282
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.186953,0.0995508
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.182827,0.106655
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.175955,0.100759
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.221907,0.126692
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.211016,0.119219
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.200632,0.106394
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.190596,0.114424
gpu_array,2048,8,1,50,2,true,false,true,false,0.18219,0.104553
gpu_array,2048,8,1,50,4,true,false,true,false,0.188916,0.113232
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.197791,0.107947
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.186472,0.109812
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.195239,0.118579
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.221604,0.124924
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.211025,0.114834
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.215369,0.12406
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.165164,0.0875269
gpu_array,2048,32,1,20,2,true,false,true,false,0.160039,0.0863086
gpu_array,2048,32,1,20,4,true,false,true,false,0.167786,0.0901489
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.167383,0.084375
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.159285,0.0860425
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.167161,0.0914771
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.199419,0.109087
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.194373,0.104529
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.187158,0.0963379
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,0.109341,0.0605127
0.0605127
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,0.125032,0.0762036
0.0762036
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,0.123618,0.0699072
0.0699072
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,0.122715,0.0738867
0.0738867
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,0.148486,0.0679199
0.0679199
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,0.123711,0.0748828
0.0748828
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0605127
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.31928 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,0.844077,0.0457373
gpu_array,2048,8,1,20,2,false,false,true,false,0.820889,0.0435449
gpu_array,2048,8,1,20,4,false,false,true,false,0.83125,0.0456055
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,0.826633,0.0453833
gpu_sparse,2048,8,1,20,2,false,false,true,false,0.817764,0.0433496
gpu_sparse,2048,8,1,20,4,false,false,true,false,0.846458,0.0466528
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,0.843621,0.0530933
gpu_reorg,2048,8,1,20,2,false,false,true,false,0.831626,0.0508643
gpu_reorg,2048,8,1,20,4,false,false,true,false,0.847803,0.0572754
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,0.816113,0.0338867
gpu_array,2048,8,1,50,2,false,false,true,false,0.832676,0.0353125
gpu_array,2048,8,1,50,4,false,false,true,false,0.824456,0.0353931
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,0.817134,0.0353955
gpu_sparse,2048,8,1,50,2,false,false,true,false,0.832268,0.0412524
gpu_sparse,2048,8,1,50,4,false,false,true,false,0.83895,0.0410986
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,0.981638,0.0387671
gpu_reorg,2048,8,1,50,2,false,false,true,false,0.875857,0.0399194
gpu_reorg,2048,8,1,50,4,false,false,true,false,0.986851,0.0400732
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,0.840637,0.0427856
gpu_array,2048,32,1,20,2,false,false,true,false,0.836328,0.0414062
gpu_array,2048,32,1,20,4,false,false,true,false,0.835515,0.033269
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,0.833862,0.0428467
gpu_sparse,2048,32,1,20,2,false,false,true,false,0.820862,0.0415649
gpu_sparse,2048,32,1,20,4,false,false,true,false,0.822329,0.0337549
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,0.839949,0.0494214
gpu_reorg,2048,32,1,20,2,false,false,true,false,0.855789,0.0481714
gpu_reorg,2048,32,1,20,4,false,false,true,false,0.830977,0.0384961
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,0.822471,0.0334082
0.0334082
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.815889,0.031709
0.031709
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.830847,0.0466675
0.0466675
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.031709
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.514501 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,0.84623,0.0459375
gpu_array,2048,8,1,20,2,false,false,true,false,0.832676,0.0436133
gpu_array,2048,8,1,20,4,false,false,true,false,0.82656,0.0457983
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,0.841077,0.0451782
gpu_sparse,2048,8,1,20,2,false,false,true,false,0.833152,0.0431128
gpu_sparse,2048,8,1,20,4,false,false,true,false,0.839187,0.0467065
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,0.855874,0.0531396
gpu_reorg,2048,8,1,20,2,false,false,true,false,0.860034,0.0509521
gpu_reorg,2048,8,1,20,4,false,false,true,false,0.862524,0.0573486
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,0.822375,0.0338013
gpu_array,2048,8,1,50,2,false,false,true,false,0.835686,0.0353931
gpu_array,2048,8,1,50,4,false,false,true,false,0.832781,0.0354175
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,0.833298,0.0354468
gpu_sparse,2048,8,1,50,2,false,false,true,false,0.841326,0.0410327
gpu_sparse,2048,8,1,50,4,false,false,true,false,0.825344,0.0411646
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,0.89873,0.0388672
gpu_reorg,2048,8,1,50,2,false,false,true,false,0.869648,0.0400586
gpu_reorg,2048,8,1,50,4,false,false,true,false,0.996987,0.0399561
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,0.831416,0.0428418
gpu_array,2048,32,1,20,2,false,false,true,false,0.831951,0.0414233
gpu_array,2048,32,1,20,4,false,false,true,false,0.818879,0.0332349
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,0.832476,0.0429248
gpu_sparse,2048,32,1,20,2,false,false,true,false,0.836423,0.0415015
gpu_sparse,2048,32,1,20,4,false,false,true,false,0.831099,0.0337354
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,0.861047,0.0495239
gpu_reorg,2048,32,1,20,2,false,false,true,false,0.855884,0.0482666
gpu_reorg,2048,32,1,20,4,false,false,true,false,0.842151,0.0384399
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,0.823423,0.0333838
0.0333838
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.815903,0.0317236
0.0317236
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.826155,0.0468579
0.0468579
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.0317236
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.514778 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0660791,0.0143213
gpu_array,2048,8,1,20,2,true,false,true,false,0.0662329,0.0139868
gpu_array,2048,8,1,20,4,true,false,true,false,0.062793,0.0149414
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.0569067,0.0154028
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0620044,0.0151294
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.0608081,0.0153979
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.083938,0.0194849
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0791479,0.0161597
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0911182,0.0227588
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0650806,0.0162524
gpu_array,2048,8,1,50,2,true,false,true,false,0.0641187,0.0162671
gpu_array,2048,8,1,50,4,true,false,true,false,0.0650684,0.0162402
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0634351,0.0170483
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0644458,0.0175708
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0668042,0.0174878
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.125229,0.0217139
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.136311,0.0205884
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.120762,0.0206641
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0598364,0.0124731
gpu_array,2048,32,1,20,2,true,false,true,false,0.0621582,0.011377
gpu_array,2048,32,1,20,4,true,false,true,false,0.0599976,0.012146
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0573315,0.0128979
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.058291,0.0119043
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0602319,0.0128687
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0878467,0.0185107
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.080127,0.0146973
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0826074,0.0166895
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0531909,0.0111987
0.0111987
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0517798,0.0127173
0.0127173
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0538013,0.0132739
0.0132739
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.0536206,0.0135815
0.0135815
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,true,0.0549561,0.0144287
0.0144287
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,true,0.0540698,0.0135425
0.0135425
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0111987
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 8 seconds of which 0.210421 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.0602808,0.0134058
gpu_array,2048,8,1,20,2,true,false,true,false,0.0594897,0.013103
gpu_array,2048,8,1,20,4,true,false,true,false,0.063252,0.0139355
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.061814,0.0144507
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.0600879,0.0141895
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.062793,0.0144531
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.0794336,0.0179102
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.0779663,0.0164429
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.0894531,0.0225586
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.0626245,0.0162378
gpu_array,2048,8,1,50,2,true,false,true,false,0.0655615,0.0162451
gpu_array,2048,8,1,50,4,true,false,true,false,0.0646143,0.0162744
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.0663818,0.0170654
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.0653931,0.0175415
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.0673975,0.0175928
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.127383,0.0214258
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.124993,0.0205005
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.125522,0.020542
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.0583252,0.0124268
gpu_array,2048,32,1,20,2,true,false,true,false,0.057356,0.0114575
gpu_array,2048,32,1,20,4,true,false,true,false,0.0624683,0.0121753
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.0607666,0.012915
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.0612256,0.0119092
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.0602368,0.0128735
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.0831763,0.0182349
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.0834839,0.0146362
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.0818848,0.0169434
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.0506934,0.0111426
0.0111426
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.0518555,0.012793
0.012793
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,true,0.0523291,0.0132666
0.0132666
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,true,0.053562,0.0135229
0.0135229
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.0563574,0.0153418
0.0153418
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.0545923,0.0155298
0.0155298
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0111426
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.208504 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,4.35257,4.26272
gpu_array,2048,8,1,20,2,true,false,true,false,5.15229,5.039
gpu_array,2048,8,1,20,4,true,false,true,false,4.63144,4.55282
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,4.05786,3.98022
gpu_sparse,2048,8,1,20,2,true,false,true,false,5.15406,5.07594
gpu_sparse,2048,8,1,20,4,true,false,true,false,3.98832,3.91068
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,4.77771,4.68152
gpu_reorg,2048,8,1,20,2,true,false,true,false,5.23865,5.14148
gpu_reorg,2048,8,1,20,4,true,false,true,false,5.10269,5.00747
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,3.72574,3.63785
gpu_array,2048,8,1,50,2,true,false,true,false,4.44123,4.35627
gpu_array,2048,8,1,50,4,true,false,true,false,6.65916,6.5659
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,3.38745,3.30249
gpu_sparse,2048,8,1,50,2,true,false,true,false,4.3849,4.29848
gpu_sparse,2048,8,1,50,4,true,false,true,false,6.14931,6.05019
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,4.20698,4.09517
gpu_reorg,2048,8,1,50,2,true,false,true,false,7.62878,7.5238
gpu_reorg,2048,8,1,50,4,true,false,true,false,10.2379,10.1153
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,3.70265,3.61866
gpu_array,2048,32,1,20,2,true,false,true,false,2.9871,2.90702
gpu_array,2048,32,1,20,4,true,false,true,false,2.97412,2.87207
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,3.20404,3.12885
gpu_sparse,2048,32,1,20,2,true,false,true,false,2.95778,2.87624
gpu_sparse,2048,32,1,20,4,true,false,true,false,2.89139,2.80789
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,4.17256,4.06562
gpu_reorg,2048,32,1,20,2,true,false,true,false,3.54169,3.42987
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,1.89612,1.86146
1.86146
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,2.04833,2.0122
2.0122
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,4,true,false,true,true,4.31241,4.2753
4.2753
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,4,false,false,true,true,6.02876,5.99214
5.99214
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.86146
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 212 seconds of which 13.4599 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,4.32758,4.22895
gpu_array,2048,8,1,20,2,true,false,true,false,5.11874,5.04013
gpu_array,2048,8,1,20,4,true,false,true,false,4.5687,4.4896
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,3.8487,3.77253
gpu_sparse,2048,8,1,20,2,true,false,true,false,5.08669,5.00905
gpu_sparse,2048,8,1,20,4,true,false,true,false,3.97173,3.89019
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,4.75532,4.66255
gpu_reorg,2048,8,1,20,2,true,false,true,false,5.33338,5.21814
gpu_reorg,2048,8,1,20,4,true,false,true,false,5.11672,5.02053
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,3.60039,3.51738
gpu_array,2048,8,1,50,2,true,false,true,false,4.41363,4.3277
gpu_array,2048,8,1,50,4,true,false,true,false,6.72273,6.63387
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,3.3936,3.30815
gpu_sparse,2048,8,1,50,2,true,false,true,false,4.447,4.36155
gpu_sparse,2048,8,1,50,4,true,false,true,false,6.18155,6.09073
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,4.2106,4.11343
gpu_reorg,2048,8,1,50,2,true,false,true,false,7.74146,7.636
gpu_reorg,2048,8,1,50,4,true,false,true,false,10.2377,10.1293
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,3.70872,3.63108
gpu_array,2048,32,1,20,2,true,false,true,false,3.06699,2.98154
gpu_array,2048,32,1,20,4,true,false,true,false,3.0742,2.99363
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,3.39861,3.32049
gpu_sparse,2048,32,1,20,2,true,false,true,false,2.94964,2.87103
gpu_sparse,2048,32,1,20,4,true,false,true,false,2.89791,2.79342
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,4.19402,4.08855
gpu_reorg,2048,32,1,20,2,true,false,true,false,3.53238,3.43473
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,1.93684,1.90168
1.90168
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,2.05451,2.01887
2.01887
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,2.14701,2.11234
2.11234
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,2.23851,2.20335
2.20335
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.90168
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 160 seconds of which 12.882 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.166543,0.0132227
gpu_array,2048,8,1,20,2,true,false,true,false,0.170701,0.0247046
gpu_array,2048,8,1,20,4,true,false,true,false,0.178298,0.0205835
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.159648,0.0141406
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.184001,0.0243335
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.178506,0.024209
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.158242,0.0176172
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.20415,0.0288574
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.173179,0.029624
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.161306,0.0157983
gpu_array,2048,8,1,50,2,true,false,true,false,0.190439,0.0288184
gpu_array,2048,8,1,50,4,true,false,true,false,0.163828,0.0285742
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.147659,0.0158228
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.187021,0.0302832
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.164993,0.0302271
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.153235,0.0223755
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.219385,0.0333496
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.190513,0.0332861
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.145234,0.0119336
gpu_array,2048,32,1,20,2,true,false,true,false,0.162029,0.0116382
gpu_array,2048,32,1,20,4,true,false,true,false,0.168857,0.0121191
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.154954,0.0118872
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.171943,0.0122754
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.176003,0.0129175
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.152004,0.0162622
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.199648,0.0155664
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.175186,0.0189355
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.148503,0.0103198
0.0103198
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.166353,0.0140088
0.0140088
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,0.160564,0.0126147
0.0126147
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,0.162454,0.0135278
0.0135278
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.166296,0.0139526
0.0139526
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.166516,0.0141724
0.0141724
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0103198
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 19 seconds of which 0.261308 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,0.165369,0.0125366
gpu_array,2048,8,1,20,2,true,false,true,false,0.180913,0.0231982
gpu_array,2048,8,1,20,4,true,false,true,false,0.181843,0.0192456
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,0.143701,0.0133301
gpu_sparse,2048,8,1,20,2,true,false,true,false,0.184631,0.0244751
gpu_sparse,2048,8,1,20,4,true,false,true,false,0.173159,0.0242334
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,0.154919,0.0177124
gpu_reorg,2048,8,1,20,2,true,false,true,false,0.194053,0.0290137
gpu_reorg,2048,8,1,20,4,true,false,true,false,0.17478,0.0307373
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,0.161438,0.0159302
gpu_array,2048,8,1,50,2,true,false,true,false,0.187993,0.0288135
gpu_array,2048,8,1,50,4,true,false,true,false,0.16689,0.0287061
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,0.161526,0.0160181
gpu_sparse,2048,8,1,50,2,true,false,true,false,0.195916,0.0303882
gpu_sparse,2048,8,1,50,4,true,false,true,false,0.165535,0.0302808
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,0.152649,0.0222778
gpu_reorg,2048,8,1,50,2,true,false,true,false,0.21936,0.0333252
gpu_reorg,2048,8,1,50,4,true,false,true,false,0.194026,0.0333813
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,0.154937,0.0118701
gpu_array,2048,32,1,20,2,true,false,true,false,0.171326,0.0116577
gpu_array,2048,32,1,20,4,true,false,true,false,0.168364,0.0121143
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,0.143804,0.0119678
gpu_sparse,2048,32,1,20,2,true,false,true,false,0.16999,0.0122754
gpu_sparse,2048,32,1,20,4,true,false,true,false,0.172542,0.0128735
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,0.154355,0.0161719
gpu_reorg,2048,32,1,20,2,true,false,true,false,0.179138,0.015564
gpu_reorg,2048,32,1,20,4,true,false,true,false,0.162917,0.0188745
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,0.141289,0.0104297
0.0104297
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,0.167871,0.0140625
0.0140625
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,0.165918,0.0125977
0.0125977
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,0.155557,0.0134668
0.0134668
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,0.168604,0.0138184
0.0138184
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,0.156926,0.0138599
0.0138599
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0104297
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.260181 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.137825,0.120247
gpu_array,4096,32,1,2,2,true,false,true,false,0.097793,0.0799707
gpu_array,4096,32,1,2,4,true,false,true,false,0.0767236,0.0591455
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.137729,0.119419
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0878442,0.0697778
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0951587,0.0763599
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.082666,0.0628906
gpu_array,4096,32,1,10,2,true,false,true,false,0.0726563,0.053125
gpu_array,4096,32,1,10,4,true,false,true,false,0.0647339,0.0471558
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.083269,0.0652026
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0718311,0.0540088
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0729102,0.0528906
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.147837,0.129526
gpu_array,4096,64,1,2,2,true,false,true,false,0.105254,0.0857227
gpu_array,4096,64,1,2,4,true,false,true,false,0.0830737,0.0632983
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.148633,0.129102
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.087439,0.0696167
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0955151,0.0757397
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0807544,0.0629321
gpu_array,4096,64,1,10,2,true,false,true,false,0.0754736,0.0532568
gpu_array,4096,64,1,10,4,true,false,true,false,0.0615283,0.0417529
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.084563,0.0652759
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.066377,0.0466016
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0663818,0.0468506
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.058877,0.0412988
0.0412988
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0623706,0.0440601
0.0440601
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0617456,0.0446558
0.0446558
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0669922,0.0491699
0.0491699
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0716699,0.0533594
0.0533594
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.1028,0.0847339
0.0847339
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0412988
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.838511 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.139287,0.120244
gpu_array,4096,32,1,2,2,true,false,true,false,0.0990283,0.0802295
gpu_array,4096,32,1,2,4,true,false,true,false,0.0776538,0.0590991
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.139128,0.119353
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0895557,0.0697803
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0951245,0.0763257
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0829102,0.0628906
gpu_array,4096,32,1,10,2,true,false,true,false,0.072041,0.0532422
gpu_array,4096,32,1,10,4,true,false,true,false,0.0656421,0.0470874
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0853613,0.0650977
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0743677,0.054104
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0731787,0.052915
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.148049,0.129495
gpu_array,4096,64,1,2,2,true,false,true,false,0.104814,0.0857715
gpu_array,4096,64,1,2,4,true,false,true,false,0.0832886,0.063269
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.151033,0.12906
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0888647,0.0695776
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0942627,0.075708
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0829077,0.0628882
gpu_array,4096,64,1,10,2,true,false,true,false,0.0720801,0.0532813
gpu_array,4096,64,1,10,4,true,false,true,false,0.0619409,0.0419214
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0850317,0.0652563
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0654028,0.046604
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0658643,0.0468213
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0588379,0.0412598
0.0412598
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0616235,0.0440454
0.0440454
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,0.0622363,0.0446582
0.0446582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,0.0670435,0.0492212
0.0492212
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.0711597,0.0533374
0.0533374
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.102991,0.0846802
0.0846802
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0412598
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.838543 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0466089,0.0187769
gpu_array,4096,32,1,2,2,true,false,true,false,0.0402612,0.0151147
gpu_array,4096,32,1,2,4,true,false,true,false,0.0393677,0.0142212
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0460547,0.0187109
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0382056,0.0103735
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0400903,0.0127466
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0358667,0.00925537
gpu_array,4096,32,1,10,2,true,false,true,false,0.0344775,0.00786621
gpu_array,4096,32,1,10,4,true,false,true,false,0.0321313,0.00771729
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0365674,0.00971191
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0328394,0.00696045
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0342578,0.00813477
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.044292,0.0186572
gpu_array,4096,64,1,2,2,true,false,true,false,0.0421265,0.0150269
gpu_array,4096,64,1,2,4,true,false,true,false,0.0421899,0.0141138
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0453491,0.0184937
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0357886,0.0103979
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0390747,0.0127075
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0342114,0.00930908
gpu_array,4096,64,1,10,2,true,false,true,false,0.0357666,0.00793457
gpu_array,4096,64,1,10,4,true,false,true,false,0.0339575,0.00783447
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0363647,0.00975342
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0332617,0.00713867
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0321606,0.00750244
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0284033,0.00691895
0.00691895
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0287231,0.00919189
0.00919189
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.028418,0.00717773
0.00717773
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0310132,0.00928467
0.00928467
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0315869,0.0103467
0.0103467
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0358057,0.0162744
0.0162744
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00691895
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.138303 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0451636,0.0173315
gpu_array,4096,32,1,2,2,true,false,true,false,0.040354,0.0139868
gpu_array,4096,32,1,2,4,true,false,true,false,0.0402686,0.0131689
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0448584,0.0172705
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0341089,0.00969482
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0370044,0.0118579
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0363696,0.00927002
gpu_array,4096,32,1,10,2,true,false,true,false,0.0340186,0.00789551
gpu_array,4096,32,1,10,4,true,false,true,false,0.0319214,0.00775146
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0392505,0.00970947
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0335986,0.0069873
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0352637,0.00816406
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0452686,0.0186572
gpu_array,4096,64,1,2,2,true,false,true,false,0.0409204,0.0150415
gpu_array,4096,64,1,2,4,true,false,true,false,0.0404907,0.0141235
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0436719,0.0185254
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0372729,0.0104175
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0388599,0.0127368
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0356396,0.00927246
gpu_array,4096,64,1,10,2,true,false,true,false,0.0362256,0.00790527
gpu_array,4096,64,1,10,4,true,false,true,false,0.0324805,0.00782227
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0363745,0.00976318
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0318359,0.00717773
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0333984,0.00751953
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0279565,0.00696045
0.00696045
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0300073,0.00925537
0.00925537
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.0284546,0.00721436
0.00721436
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0322754,0.00932617
0.00932617
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0313696,0.0103735
0.0103735
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0375049,0.0162646
0.0162646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00696045
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.13576 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.387,0.103308
gpu_array,4096,8,1,20,2,true,false,true,false,0.359233,0.0757861
gpu_array,4096,8,1,20,4,true,false,true,false,0.357664,0.0766577
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.399692,0.11063
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.340708,0.0626318
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.350996,0.0726758
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.377385,0.0792896
gpu_array,4096,8,1,50,2,true,false,true,false,0.356772,0.0574561
gpu_array,4096,8,1,50,4,true,false,true,false,0.410503,0.0660205
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.437217,0.0844336
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.366943,0.0703125
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.415137,0.0730957
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.343787,0.0644897
0.0644897
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.356907,0.0807837
0.0807837
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,true,false,true,true,0.330315,0.0546802
0.0546802
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,2,false,false,true,true,0.536501,0.258181
0.258181
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0546802
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.569521 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,false,0.387788,0.10312
gpu_array,4096,8,1,20,2,true,false,true,false,0.363696,0.0822021
gpu_array,4096,8,1,20,4,true,false,true,false,0.355396,0.0765869
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,false,0.395857,0.110701
gpu_sparse,4096,8,1,20,2,true,false,true,false,0.346584,0.0626489
gpu_sparse,4096,8,1,20,4,true,false,true,false,0.35688,0.0727002
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,false,0.424182,0.0792114
gpu_array,4096,8,1,50,2,true,false,true,false,0.359785,0.0575391
gpu_array,4096,8,1,50,4,true,false,true,false,0.368174,0.0659277
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,false,0.385103,0.0843213
gpu_sparse,4096,8,1,50,2,true,false,true,false,0.414875,0.0701489
gpu_sparse,4096,8,1,50,4,true,false,true,false,0.37595,0.0729712
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,true,0.344802,0.0645288
0.0645288
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,true,0.358572,0.0809839
0.0809839
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,true,false,true,true,0.356631,0.0809961
0.0809961
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,false,false,true,true,0.547356,0.2705
0.2705
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0575391
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 0.587812 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.157971,0.119885
gpu_array,4096,32,1,2,2,true,false,true,false,0.115859,0.0765527
gpu_array,4096,32,1,2,4,true,false,true,false,0.0966235,0.0590259
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.183352,0.125247
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.121631,0.0830566
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.11229,0.0729834
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.125884,0.0780322
gpu_array,4096,32,1,10,2,true,false,true,false,0.123521,0.0756689
gpu_array,4096,32,1,10,4,true,false,true,false,0.115554,0.0667261
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.153865,0.0752515
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.12127,0.073418
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.115581,0.0679736
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.17197,0.13364
gpu_array,4096,64,1,2,2,true,false,true,false,0.122349,0.0827979
gpu_array,4096,64,1,2,4,true,false,true,false,0.101626,0.0650049
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.189695,0.128171
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.120327,0.0834619
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.113916,0.0743652
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.128511,0.0787061
gpu_array,4096,64,1,10,2,true,false,true,false,0.123076,0.0752246
gpu_array,4096,64,1,10,4,true,false,true,false,0.111924,0.0630957
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.154761,0.0766357
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.126121,0.0758276
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.11366,0.0658081
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.114482,0.0785938
0.0785938
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.122974,0.0839111
0.0839111
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0768506,0.0409619
0.0409619
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0992896,0.0631567
0.0631567
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.114614,0.0782373
0.0782373
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.119976,0.0838428
0.0838428
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0409619
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.985196 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.158875,0.120056
gpu_array,4096,32,1,2,2,true,false,true,false,0.115227,0.0764087
gpu_array,4096,32,1,2,4,true,false,true,false,0.0992261,0.059187
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.182917,0.1253
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.120168,0.0830591
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.111255,0.0729248
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.125964,0.0778687
gpu_array,4096,32,1,10,2,true,false,true,false,0.128457,0.0759668
gpu_array,4096,32,1,10,4,true,false,true,false,0.118618,0.0666162
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.153354,0.0752295
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.123066,0.0735059
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.116106,0.0680103
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.1722,0.133381
gpu_array,4096,64,1,2,2,true,false,true,false,0.119329,0.0829517
gpu_array,4096,64,1,2,4,true,false,true,false,0.103416,0.0653296
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.189058,0.128267
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.12196,0.0833862
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.111504,0.0741504
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.126663,0.078811
gpu_array,4096,64,1,10,2,true,false,true,false,0.12303,0.0754224
gpu_array,4096,64,1,10,4,true,false,true,false,0.112517,0.0629565
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.154529,0.0768921
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.126179,0.0761304
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.113623,0.0657715
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,0.115139,0.0785181
0.0785181
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,0.121204,0.0838501
0.0838501
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,0.0776172,0.0409961
0.0409961
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,0.0982129,0.0630566
0.0630566
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,0.113433,0.0782764
0.0782764
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,0.120974,0.0838647
0.0838647
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0409961
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 0.985557 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.77009,0.0423071
gpu_array,4096,8,1,20,2,false,false,true,false,0.760029,0.0425
gpu_array,4096,8,1,20,4,false,false,true,false,0.770569,0.0484009
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.768884,0.0437866
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.772893,0.0438892
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.764417,0.0483521
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.793379,0.0397168
gpu_array,4096,8,1,50,2,false,false,true,false,0.796833,0.0402417
gpu_array,4096,8,1,50,4,false,false,true,false,0.786189,0.0403394
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.935579,0.0403149
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.936472,0.043894
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.795476,0.0440112
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.758118,0.0349731
gpu_array,4096,32,1,20,2,false,false,true,false,0.755369,0.0344214
gpu_array,4096,32,1,20,4,false,false,true,false,0.758755,0.0358545
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.749382,0.0350269
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.756008,0.0345728
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.755303,0.0360645
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.749546,0.0376318
0.0376318
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.754663,0.0354248
0.0354248
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.754741,0.0406299
0.0406299
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0344214
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.345028 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,false,0.761655,0.0394873
gpu_array,4096,8,1,20,2,false,false,true,false,0.760105,0.0398901
gpu_array,4096,8,1,20,4,false,false,true,false,0.771675,0.0451123
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,false,0.767964,0.0406689
gpu_sparse,4096,8,1,20,2,false,false,true,false,0.764248,0.0411035
gpu_sparse,4096,8,1,20,4,false,false,true,false,0.769895,0.0477271
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,false,0.789131,0.0398633
gpu_array,4096,8,1,50,2,false,false,true,false,0.933276,0.04021
gpu_array,4096,8,1,50,4,false,false,true,false,0.935129,0.040354
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,false,0.929575,0.040415
gpu_sparse,4096,8,1,50,2,false,false,true,false,0.934155,0.0440186
gpu_sparse,4096,8,1,50,4,false,false,true,false,0.798713,0.0440747
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,false,0.759282,0.034917
gpu_array,4096,32,1,20,2,false,false,true,false,0.759287,0.0344336
gpu_array,4096,32,1,20,4,false,false,true,false,0.752854,0.035813
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,false,0.753906,0.0351562
gpu_sparse,4096,32,1,20,2,false,false,true,false,0.753159,0.0346533
gpu_sparse,4096,32,1,20,4,false,false,true,false,0.754319,0.0363013
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,true,0.761387,0.0377539
0.0377539
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,true,0.75178,0.0405981
0.0405981
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,true,0.757654,0.0354858
0.0354858
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0344336
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.339164 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0530322,0.0188525
gpu_array,4096,32,1,2,2,true,false,true,false,0.0492773,0.0150977
gpu_array,4096,32,1,2,4,true,false,true,false,0.0504492,0.0143164
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0539722,0.0188159
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0458301,0.0106738
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0468262,0.0128906
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0440088,0.00958496
gpu_array,4096,32,1,10,2,true,false,true,false,0.0416162,0.00841309
gpu_array,4096,32,1,10,4,true,false,true,false,0.0420239,0.00833252
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0460352,0.0101465
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.044104,0.00845947
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0440137,0.00861328
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0545923,0.0189478
gpu_array,4096,64,1,2,2,true,false,true,false,0.0503003,0.015144
gpu_array,4096,64,1,2,4,true,false,true,false,0.0494971,0.0143408
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0534961,0.0188281
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0480542,0.0107007
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0471118,0.0129321
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0450806,0.00968018
gpu_array,4096,64,1,10,2,true,false,true,false,0.0462598,0.00841797
gpu_array,4096,64,1,10,4,true,false,true,false,0.0428223,0.00839844
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0463452,0.0102124
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.04177,0.00759033
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0424146,0.00823486
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.036604,0.00755127
0.00755127
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0377393,0.00966309
0.00966309
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0364673,0.00839111
0.00839111
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.038042,0.00996582
0.00996582
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0388843,0.010564
0.010564
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0452051,0.0168848
0.0168848
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00755127
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.143624 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.0529175,0.0175171
gpu_array,4096,32,1,2,2,true,false,true,false,0.048186,0.0140063
gpu_array,4096,32,1,2,4,true,false,true,false,0.0469556,0.0132642
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.0518604,0.0174365
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.0428247,0.00986572
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.0461499,0.0119702
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.0431616,0.00947021
gpu_array,4096,32,1,10,2,true,false,true,false,0.0420386,0.00834717
gpu_array,4096,32,1,10,4,true,false,true,false,0.0417334,0.00828613
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.0442432,0.0100635
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.0441089,0.00846436
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0437109,0.00855469
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.0530957,0.018916
gpu_array,4096,64,1,2,2,true,false,true,false,0.0488013,0.0151099
gpu_array,4096,64,1,2,4,true,false,true,false,0.0476807,0.0142334
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.0572534,0.0186792
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.0445117,0.0105762
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.0497437,0.0128784
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.0432642,0.00957275
gpu_array,4096,64,1,10,2,true,false,true,false,0.0421289,0.0084375
gpu_array,4096,64,1,10,4,true,false,true,false,0.0435352,0.00837891
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.0453198,0.0101636
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.0437061,0.00757324
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.0431543,0.00824219
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,true,0.036062,0.00749756
0.00749756
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,true,0.0372339,0.009646
0.009646
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,true,0.0364795,0.00840332
0.00840332
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,true,0.0382178,0.00989746
0.00989746
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.0386475,0.0105713
0.0105713
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.0447363,0.0169043
0.0169043
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00749756
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.140463 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.70203,4.65564
gpu_array,4096,32,1,2,2,true,false,true,false,3.165,3.12472
gpu_array,4096,32,1,2,4,true,false,true,false,3.11147,3.06948
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.50777,4.4692
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.3465,3.29792
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.56216,2.5209
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.5752,3.53345
gpu_array,4096,32,1,10,2,true,false,true,false,2.95504,2.91036
gpu_array,4096,32,1,10,4,true,false,true,false,2.78646,2.74568
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.09402,3.05472
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.99885,2.94587
gpu_sparse,4096,32,1,10,4,true,false,true,false,2.99468,2.94438
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,4.00534,3.96579
gpu_array,4096,64,1,2,2,true,false,true,false,3.08563,3.03437
gpu_array,4096,64,1,2,4,true,false,true,false,2.99456,2.94866
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.8495,3.81142
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.12013,3.08009
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.57791,2.52664
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.60039,3.54692
gpu_array,4096,64,1,10,2,true,false,true,false,2.90769,2.85593
gpu_array,4096,64,1,10,4,true,false,true,false,2.97975,2.93922
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.71485,2.67481
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.84165,2.79746
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.66812,2.6276
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,2.16743,2.14351
2.14351
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,1.97059,1.94861
1.94861
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,2.09342,2.07096
2.07096
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,1.93299,1.91175
1.91175
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.91175
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 135 seconds of which 8.61758 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,4.71663,4.66609
gpu_array,4096,32,1,2,2,true,false,true,false,3.17742,3.12762
gpu_array,4096,32,1,2,4,true,false,true,false,3.16746,3.12693
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,4.54816,4.51057
gpu_sparse,4096,32,1,2,2,true,false,true,false,3.28801,3.24919
gpu_sparse,4096,32,1,2,4,true,false,true,false,2.58144,2.54188
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,3.64282,3.60254
gpu_array,4096,32,1,10,2,true,false,true,false,2.88854,2.83653
gpu_array,4096,32,1,10,4,true,false,true,false,2.88566,2.83342
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,3.12318,3.08168
gpu_sparse,4096,32,1,10,2,true,false,true,false,2.92673,2.87741
gpu_sparse,4096,32,1,10,4,true,false,true,false,2.93646,2.89545
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,3.95555,3.9033
gpu_array,4096,64,1,2,2,true,false,true,false,3.06299,3.01025
gpu_array,4096,64,1,2,4,true,false,true,false,2.91487,2.86312
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,3.76552,3.72768
gpu_sparse,4096,64,1,2,2,true,false,true,false,3.06437,3.02408
gpu_sparse,4096,64,1,2,4,true,false,true,false,2.53209,2.49254
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,3.60304,3.55714
gpu_array,4096,64,1,10,2,true,false,true,false,2.88267,2.82969
gpu_array,4096,64,1,10,4,true,false,true,false,3.11605,3.06356
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,2.84102,2.80269
gpu_sparse,4096,64,1,10,2,true,false,true,false,2.86737,2.82685
gpu_sparse,4096,64,1,10,4,true,false,true,false,2.67666,2.62295
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,true,2.10059,2.07788
2.07788
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,true,2.01132,1.98959
1.98959
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,true,2.14397,2.12054
2.12054
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,true,2.00063,1.97964
1.97964
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.97964
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 132 seconds of which 8.62626 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.113176,0.0169849
gpu_array,4096,32,1,2,2,true,false,true,false,0.106074,0.0135449
gpu_array,4096,32,1,2,4,true,false,true,false,0.103425,0.0130933
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.111362,0.0168799
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.106587,0.0103955
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.108015,0.0115796
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.100752,0.00871094
gpu_array,4096,32,1,10,2,true,false,true,false,0.107212,0.00809082
gpu_array,4096,32,1,10,4,true,false,true,false,0.101863,0.00786865
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.106487,0.00907471
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.107534,0.00841309
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.0996851,0.00764404
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.108394,0.0168408
gpu_array,4096,64,1,2,2,true,false,true,false,0.112615,0.0134937
gpu_array,4096,64,1,2,4,true,false,true,false,0.116536,0.01302
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.119238,0.0166992
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.105046,0.0103198
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.113608,0.0115576
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.100608,0.00881104
gpu_array,4096,64,1,10,2,true,false,true,false,0.101069,0.0082959
gpu_array,4096,64,1,10,4,true,false,true,false,0.105332,0.00791992
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.105588,0.00915283
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.104128,0.00891357
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.105078,0.00766602
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.104836,0.00693604
0.00693604
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.107803,0.0103906
0.0103906
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,true,0.103962,0.00703857
0.00703857
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,true,0.108821,0.00994385
0.00994385
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,true,0.111414,0.0100952
0.0100952
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,true,0.112988,0.0160645
0.0160645
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00693604
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.1333 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,0.110559,0.0158325
gpu_array,4096,32,1,2,2,true,false,true,false,0.105081,0.0125513
gpu_array,4096,32,1,2,4,true,false,true,false,0.110703,0.0120703
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,0.110117,0.0156348
gpu_sparse,4096,32,1,2,2,true,false,true,false,0.10343,0.00968018
gpu_sparse,4096,32,1,2,4,true,false,true,false,0.109385,0.010752
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,0.104565,0.00812988
gpu_array,4096,32,1,10,2,true,false,true,false,0.100159,0.00811768
gpu_array,4096,32,1,10,4,true,false,true,false,0.10146,0.0079541
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,0.102266,0.00900391
gpu_sparse,4096,32,1,10,2,true,false,true,false,0.102622,0.00838379
gpu_sparse,4096,32,1,10,4,true,false,true,false,0.104531,0.00760742
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,0.116172,0.0168066
gpu_array,4096,64,1,2,2,true,false,true,false,0.105876,0.0135913
gpu_array,4096,64,1,2,4,true,false,true,false,0.103801,0.012981
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,0.113831,0.0166626
gpu_sparse,4096,64,1,2,2,true,false,true,false,0.114683,0.0104346
gpu_sparse,4096,64,1,2,4,true,false,true,false,0.103364,0.0115674
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,0.105107,0.00891602
gpu_array,4096,64,1,10,2,true,false,true,false,0.105393,0.0082251
gpu_array,4096,64,1,10,4,true,false,true,false,0.0983105,0.00797852
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,0.114832,0.00911865
gpu_sparse,4096,64,1,10,2,true,false,true,false,0.105286,0.0088501
gpu_sparse,4096,64,1,10,4,true,false,true,false,0.099375,0.00757812
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,true,0.101494,0.00701172
0.00701172
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,true,0.10175,0.00995361
0.00995361
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,true,0.100964,0.00697021
0.00697021
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,true,0.106575,0.0103833
0.0103833
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,true,0.106309,0.0101172
0.0101172
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,true,0.111284,0.01729
0.01729
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00697021
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.131135 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0754199,0.0629688
gpu_array,8192,32,1,2,2,true,false,true,false,0.0532715,0.0425293
gpu_array,8192,32,1,2,4,true,false,true,false,0.0477661,0.0369019
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0790259,0.0654761
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.057832,0.0453809
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0564233,0.0453149
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0595203,0.0471912
gpu_array,8192,32,1,10,2,true,false,true,false,0.0506763,0.0394458
gpu_array,8192,32,1,10,4,true,false,true,false,0.0482898,0.036449
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0610938,0.0490088
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0550293,0.0417236
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0532617,0.0411768
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0814929,0.0691638
gpu_array,8192,64,1,2,2,true,false,true,false,0.0594751,0.0473901
gpu_array,8192,64,1,2,4,true,false,true,false,0.0546411,0.0424341
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0858911,0.0734399
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0604993,0.0481702
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.059054,0.0480676
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0595972,0.0472681
gpu_array,8192,64,1,10,2,true,false,true,false,0.052312,0.0394946
gpu_array,8192,64,1,10,4,true,false,true,false,0.0507239,0.0397375
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0617859,0.0492126
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0567053,0.0442542
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0566626,0.0444556
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0483752,0.0370227
0.0370227
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0495422,0.0379456
0.0379456
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.055343,0.0437463
0.0437463
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0559265,0.0455505
0.0455505
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0508704,0.0392737
0.0392737
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0521558,0.0405591
0.0405591
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.036449
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 1.1393 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0750635,0.0629785
gpu_array,8192,32,1,2,2,true,false,true,false,0.054989,0.0425378
gpu_array,8192,32,1,2,4,true,false,true,false,0.0497253,0.036908
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0775952,0.0655103
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0570447,0.0453259
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0577173,0.0452661
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0593323,0.0471252
gpu_array,8192,32,1,10,2,true,false,true,false,0.0514209,0.039458
gpu_array,8192,32,1,10,4,true,false,true,false,0.0532385,0.0365149
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0613928,0.0489417
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0528455,0.0417371
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0536658,0.0410925
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0820215,0.069082
gpu_array,8192,64,1,2,2,true,false,true,false,0.0588123,0.0473376
gpu_array,8192,64,1,2,4,true,false,true,false,0.0547375,0.0424084
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0865649,0.0733813
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0607129,0.0483838
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0600623,0.0479773
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0579517,0.0472095
gpu_array,8192,64,1,10,2,true,false,true,false,0.0501379,0.0395178
gpu_array,8192,64,1,10,4,true,false,true,false,0.0513,0.0397034
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0600281,0.0491638
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0554907,0.0442603
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.056604,0.044397
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0484155,0.037063
0.037063
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0494141,0.0379395
0.0379395
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0551074,0.0437549
0.0437549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0570483,0.0454517
0.0454517
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0503674,0.039259
0.039259
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0511584,0.0405383
0.0405383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0365149
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 1.13887 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0290588,0.00952759
gpu_array,8192,32,1,2,2,true,false,true,false,0.0276257,0.0076062
gpu_array,8192,32,1,2,4,true,false,true,false,0.0269983,0.0072229
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0297241,0.00970459
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0255933,0.00593994
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0264404,0.00678711
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0260901,0.00655884
gpu_array,8192,32,1,10,2,true,false,true,false,0.0256226,0.00548096
gpu_array,8192,32,1,10,4,true,false,true,false,0.0246252,0.00533813
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0265662,0.00691284
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0253687,0.0058374
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0268152,0.00581909
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0299377,0.009552
gpu_array,8192,64,1,2,2,true,false,true,false,0.0284717,0.00759766
gpu_array,8192,64,1,2,4,true,false,true,false,0.0267114,0.00718018
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0283472,0.00979248
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0265076,0.0062439
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.025166,0.00697754
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0257715,0.00660645
gpu_array,8192,64,1,10,2,true,false,true,false,0.0254492,0.00555176
gpu_array,8192,64,1,10,4,true,false,true,false,0.0250623,0.00540894
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0265918,0.00693848
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0258936,0.00599609
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.025127,0.00608398
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0208777,0.00537476
0.00537476
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0218433,0.00585205
0.00585205
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0210657,0.00544067
0.00544067
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0211719,0.00579102
0.00579102
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,0.0245142,0.00754639
0.00754639
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,0.0232166,0.00759155
0.00759155
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00533813
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.167331 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0284827,0.00882935
gpu_array,8192,32,1,2,2,true,false,true,false,0.0261218,0.00707886
gpu_array,8192,32,1,2,4,true,false,true,false,0.0257153,0.00667236
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0308887,0.00903809
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0256396,0.00549805
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0244934,0.00630493
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.024751,0.0065625
gpu_array,8192,32,1,10,2,true,false,true,false,0.0254919,0.00547241
gpu_array,8192,32,1,10,4,true,false,true,false,0.025741,0.00535522
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0276526,0.00690063
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0252295,0.00582031
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0240955,0.00578491
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.030531,0.00953491
gpu_array,8192,64,1,2,2,true,false,true,false,0.0286011,0.00760498
gpu_array,8192,64,1,2,4,true,false,true,false,0.0281873,0.00719116
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0299182,0.00977661
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0255969,0.00618774
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0247668,0.00694458
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0269714,0.00658569
gpu_array,8192,64,1,10,2,true,false,true,false,0.0267346,0.00549438
gpu_array,8192,64,1,10,4,true,false,true,false,0.0241602,0.00536133
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0261633,0.00687622
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0253857,0.00597656
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0254846,0.00607544
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0208594,0.00535645
0.00535645
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0212183,0.0058374
0.0058374
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.020896,0.00539307
0.00539307
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0212634,0.0057605
0.0057605
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0232275,0.00748047
0.00748047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0242725,0.00754883
0.00754883
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.00535522
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.164089 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.369757,0.103522
gpu_array,8192,8,1,20,2,true,false,true,false,0.343677,0.0770752
gpu_array,8192,8,1,20,4,true,false,true,false,0.3392,0.0735754
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.373114,0.111517
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.323098,0.0601587
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.334614,0.0688672
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.339796,0.0763684
gpu_array,8192,8,1,50,2,true,false,true,false,0.321666,0.0549426
gpu_array,8192,8,1,50,4,true,false,true,false,0.330745,0.0641431
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.346072,0.0803247
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.336212,0.0733948
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.332938,0.0715857
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.327191,0.0670593
0.0670593
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.341178,0.0768958
0.0768958
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.33913,0.0770447
0.0770447
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.549008,0.289364
0.289364
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0549426
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 17 seconds of which 1.16805 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,false,0.368982,0.103601
gpu_array,8192,8,1,20,2,true,false,true,false,0.341882,0.0788208
gpu_array,8192,8,1,20,4,true,false,true,false,0.33677,0.0735864
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,false,0.376279,0.111509
gpu_sparse,8192,8,1,20,2,true,false,true,false,0.322493,0.0558911
gpu_sparse,8192,8,1,20,4,true,false,true,false,0.334983,0.0688696
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,false,0.340261,0.0762231
gpu_array,8192,8,1,50,2,true,false,true,false,0.323037,0.0549707
gpu_array,8192,8,1,50,4,true,false,true,false,0.327576,0.0639038
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,false,0.344095,0.0804236
gpu_sparse,8192,8,1,50,2,true,false,true,false,0.337013,0.0734631
gpu_sparse,8192,8,1,50,4,true,false,true,false,0.332782,0.0715515
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,true,0.328362,0.0670093
0.0670093
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,true,0.336366,0.0766003
0.0766003
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,true,0.338292,0.0770618
0.0770618
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,true,0.559384,0.298031
0.298031
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0549707
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 17 seconds of which 1.1727 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.118804,0.0772998
gpu_array,8192,32,1,2,2,true,false,true,false,0.0978918,0.0572424
gpu_array,8192,32,1,2,4,true,false,true,false,0.09375,0.0534668
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.1335,0.0803992
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.105651,0.0635364
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.107886,0.0641846
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.116069,0.0610156
gpu_array,8192,32,1,10,2,true,false,true,false,0.107766,0.0586938
gpu_array,8192,32,1,10,4,true,false,true,false,0.118434,0.0633801
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.124216,0.0586646
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.109087,0.0605029
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.11853,0.0633545
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.130652,0.0868286
gpu_array,8192,64,1,2,2,true,false,true,false,0.103293,0.0631323
gpu_array,8192,64,1,2,4,true,false,true,false,0.101418,0.0586938
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.138469,0.0847583
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.106893,0.0656335
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.10671,0.0648401
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.111306,0.0602808
gpu_array,8192,64,1,10,2,true,false,true,false,0.115068,0.0578174
gpu_array,8192,64,1,10,4,true,false,true,false,0.110138,0.0614319
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.125028,0.0583777
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.114398,0.0610535
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.117722,0.0630347
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.113677,0.0737598
0.0737598
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.139048,0.0997412
0.0997412
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0733655,0.0328381
0.0328381
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0965381,0.056377
0.056377
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,10,2,true,false,true,true,0.0706824,0.0310095
0.0310095
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,10,2,false,false,true,true,0.0938831,0.0546985
0.0546985
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0310095
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.55324 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.120352,0.0771387
gpu_array,8192,32,1,2,2,true,false,true,false,0.0986658,0.0572839
gpu_array,8192,32,1,2,4,true,false,true,false,0.0989148,0.0536267
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.134327,0.0804944
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.103431,0.0635144
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.105333,0.0641956
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.11646,0.060918
gpu_array,8192,32,1,10,2,true,false,true,false,0.107205,0.0587427
gpu_array,8192,32,1,10,4,true,false,true,false,0.116794,0.0633276
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.125995,0.0587341
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.110734,0.0604407
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.118291,0.0633594
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.129293,0.0868127
gpu_array,8192,64,1,2,2,true,false,true,false,0.103003,0.0629639
gpu_array,8192,64,1,2,4,true,false,true,false,0.100859,0.0587451
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.136709,0.0850732
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.108301,0.0658203
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.105297,0.0647693
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.114733,0.0602893
gpu_array,8192,64,1,10,2,true,false,true,false,0.106748,0.0577979
gpu_array,8192,64,1,10,4,true,false,true,false,0.112278,0.0613745
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.120255,0.0583655
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.11563,0.0610645
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.11343,0.0630151
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.112954,0.0734033
0.0734033
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.139843,0.0999255
0.0999255
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,true,0.0729089,0.0329919
0.0329919
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,true,0.0956958,0.0562671
0.0562671
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,10,2,true,false,true,true,0.0706213,0.0309485
0.0309485
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,10,2,false,false,true,true,0.0949683,0.0546851
0.0546851
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0309485
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.55328 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.708873,0.043468
gpu_array,8192,8,1,20,2,false,false,true,false,0.709518,0.0458215
gpu_array,8192,8,1,20,4,false,false,true,false,0.714374,0.0467712
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.709362,0.0466418
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.71682,0.0489734
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.713824,0.0493958
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.83974,0.0383484
gpu_array,8192,8,1,50,2,false,false,true,false,0.845244,0.041167
gpu_array,8192,8,1,50,4,false,false,true,false,0.72113,0.0411987
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.840164,0.0379175
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.843229,0.0430579
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.71937,0.0429785
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.707415,0.0426196
gpu_array,8192,32,1,20,2,false,false,true,false,0.713027,0.0424951
gpu_array,8192,32,1,20,4,false,false,true,false,0.707776,0.0391968
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.711104,0.0426465
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.707712,0.0424292
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.708673,0.038385
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.701968,0.0332666
0.0332666
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.704592,0.0395532
0.0395532
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.711763,0.0477002
0.0477002
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0332666
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.732391 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,false,0.714417,0.0435181
gpu_array,8192,8,1,20,2,false,false,true,false,0.711436,0.0457861
gpu_array,8192,8,1,20,4,false,false,true,false,0.710199,0.0467468
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,false,0.71921,0.0466028
gpu_sparse,8192,8,1,20,2,false,false,true,false,0.714911,0.0488953
gpu_sparse,8192,8,1,20,4,false,false,true,false,0.725562,0.0494141
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,false,0.841229,0.0383728
gpu_array,8192,8,1,50,2,false,false,true,false,0.719834,0.041123
gpu_array,8192,8,1,50,4,false,false,true,false,0.84036,0.0411658
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,false,0.838585,0.037926
gpu_sparse,8192,8,1,50,2,false,false,true,false,0.842494,0.0430554
gpu_sparse,8192,8,1,50,4,false,false,true,false,0.842477,0.0430383
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,false,0.71498,0.0426172
gpu_array,8192,32,1,20,2,false,false,true,false,0.709807,0.0424487
gpu_array,8192,32,1,20,4,false,false,true,false,0.705897,0.0391492
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,false,0.712938,0.0426501
gpu_sparse,8192,32,1,20,2,false,false,true,false,0.711246,0.0424231
gpu_sparse,8192,32,1,20,4,false,false,true,false,0.704674,0.0384143
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,true,0.701229,0.0332605
0.0332605
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,true,0.698634,0.0395764
0.0395764
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,true,0.711272,0.0476978
0.0476978
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0332605
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.732268 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0402747,0.00975708
gpu_array,8192,32,1,2,2,true,false,true,false,0.0412061,0.00775879
gpu_array,8192,32,1,2,4,true,false,true,false,0.0368225,0.00728149
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.046991,0.00988159
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0394446,0.00660767
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0374658,0.00707031
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0393152,0.00684448
gpu_array,8192,32,1,10,2,true,false,true,false,0.0366248,0.00586304
gpu_array,8192,32,1,10,4,true,false,true,false,0.0378088,0.00582642
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0467493,0.00719849
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0395374,0.00609009
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0381995,0.00621704
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0401562,0.00976074
gpu_array,8192,64,1,2,2,true,false,true,false,0.0410059,0.00780273
gpu_array,8192,64,1,2,4,true,false,true,false,0.0361438,0.00733521
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.039967,0.0100598
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0365979,0.00669067
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0372522,0.00734497
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0408728,0.00681519
gpu_array,8192,64,1,10,2,true,false,true,false,0.0367542,0.00587036
gpu_array,8192,64,1,10,4,true,false,true,false,0.0385193,0.00580444
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0415308,0.007229
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0401123,0.00629883
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0395532,0.00647217
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0316138,0.00585693
0.00585693
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0352441,0.0070459
0.0070459
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0323926,0.00578125
0.00578125
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0349207,0.00684448
0.00684448
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0338037,0.00768066
0.00768066
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.037583,0.00804199
0.00804199
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00578125
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.176236 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.038313,0.00901611
gpu_array,8192,32,1,2,2,true,false,true,false,0.041438,0.00713623
gpu_array,8192,32,1,2,4,true,false,true,false,0.0358008,0.00674805
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0412708,0.00916626
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.03599,0.00608276
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0364441,0.00653687
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0391199,0.00677124
gpu_array,8192,32,1,10,2,true,false,true,false,0.0376038,0.00586548
gpu_array,8192,32,1,10,4,true,false,true,false,0.0393384,0.00589111
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0472546,0.00721558
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.03875,0.00615723
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0382104,0.00622803
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0405811,0.00981934
gpu_array,8192,64,1,2,2,true,false,true,false,0.0417212,0.00778564
gpu_array,8192,64,1,2,4,true,false,true,false,0.0388525,0.0073584
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0475134,0.0100378
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.037417,0.00665527
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0374756,0.00732422
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0395361,0.00682129
gpu_array,8192,64,1,10,2,true,false,true,false,0.0360156,0.00586426
gpu_array,8192,64,1,10,4,true,false,true,false,0.0386499,0.00581299
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.046062,0.00724365
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0396863,0.00636108
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0386597,0.00643311
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.032052,0.00580688
0.00580688
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0359656,0.00703491
0.00703491
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,2,true,false,true,true,0.0312622,0.00562744
0.00562744
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,2,false,false,true,true,0.0363782,0.0070813
0.0070813
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0340747,0.00770752
0.00770752
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0366296,0.00806519
0.00806519
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00562744
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.173388 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.42858,3.40185
gpu_array,8192,32,1,2,2,true,false,true,false,2.5932,2.56756
gpu_array,8192,32,1,2,4,true,false,true,false,2.5725,2.54943
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.2768,3.25568
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.64678,2.62346
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.56026,2.53268
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.64125,2.61538
gpu_array,8192,32,1,10,2,true,false,true,false,2.75995,2.73358
gpu_array,8192,32,1,10,4,true,false,true,false,2.78476,2.75875
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.56641,2.54431
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.80818,2.78169
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.68845,2.66269
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.03673,3.01
gpu_array,8192,64,1,2,2,true,false,true,false,2.67186,2.64988
gpu_array,8192,64,1,2,4,true,false,true,false,2.71098,2.68839
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,2.97417,2.95232
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.74273,2.71966
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.56596,2.54387
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.74978,2.72439
gpu_array,8192,64,1,10,2,true,false,true,false,2.81164,2.78674
gpu_array,8192,64,1,10,4,true,false,true,false,3.05842,3.03352
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.64929,2.62646
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.81039,2.78524
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.61052,2.58513
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,true,false,true,true,2.12625,2.11074
2.11074
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,false,false,true,true,2.33678,2.32262
2.32262
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,true,false,true,true,2.2661,2.25219
2.25219
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,false,false,true,true,2.40281,2.38901
2.38901
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,true,false,false,true,1.90411,1.89068
1.89068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,false,false,false,true,2.02911,2.01495
2.01495
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.89068
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 137 seconds of which 16.2023 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,3.4325,3.40248
gpu_array,8192,32,1,2,2,true,false,true,false,2.55715,2.53457
gpu_array,8192,32,1,2,4,true,false,true,false,2.60701,2.57869
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,3.28834,3.26454
gpu_sparse,8192,32,1,2,2,true,false,true,false,2.69099,2.66779
gpu_sparse,8192,32,1,2,4,true,false,true,false,2.56642,2.54334
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,2.6309,2.60527
gpu_array,8192,32,1,10,2,true,false,true,false,2.76233,2.73328
gpu_array,8192,32,1,10,4,true,false,true,false,2.76979,2.74501
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,2.55936,2.53641
gpu_sparse,8192,32,1,10,2,true,false,true,false,2.79838,2.77299
gpu_sparse,8192,32,1,10,4,true,false,true,false,2.67043,2.64541
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,3.07356,3.05123
gpu_array,8192,64,1,2,2,true,false,true,false,2.6763,2.6525
gpu_array,8192,64,1,2,4,true,false,true,false,2.66124,2.63841
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,3.0012,2.97874
gpu_sparse,8192,64,1,2,2,true,false,true,false,2.70192,2.67946
gpu_sparse,8192,64,1,2,4,true,false,true,false,2.58072,2.55777
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,2.73521,2.70909
gpu_array,8192,64,1,10,2,true,false,true,false,2.83055,2.80638
gpu_array,8192,64,1,10,4,true,false,true,false,3.07938,3.05435
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,2.65394,2.6305
gpu_sparse,8192,64,1,10,2,true,false,true,false,2.76729,2.74239
gpu_sparse,8192,64,1,10,4,true,false,true,false,2.6406,2.61582
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,2,2,true,false,true,true,2.48246,2.46793
2.46793
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,2,2,false,false,true,true,2.22301,2.2091
2.2091
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,10,-1,true,false,false,true,1.96975,1.95449
1.95449
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,32,1,10,-1,false,false,false,true,2.10606,2.09166
2.09166
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,true,2.33549,2.31706
2.31706
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,true,2.0886,2.07493
2.07493
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.95449
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 128 seconds of which 16.2328 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0767114,0.0150659
gpu_array,8192,32,1,2,2,true,false,true,false,0.0751855,0.011709
gpu_array,8192,32,1,2,4,true,false,true,false,0.0747559,0.0111572
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0772229,0.0150891
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0727429,0.00914429
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0757227,0.0100488
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0709705,0.00627319
gpu_array,8192,32,1,10,2,true,false,true,false,0.0708887,0.00570312
gpu_array,8192,32,1,10,4,true,false,true,false,0.071593,0.00543091
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0714587,0.00639526
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0704749,0.00589966
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0714111,0.00585938
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.0785986,0.0151221
gpu_array,8192,64,1,2,2,true,false,true,false,0.0744543,0.0117102
gpu_array,8192,64,1,2,4,true,false,true,false,0.0732556,0.0112439
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0771362,0.0151245
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0728748,0.00915405
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.073855,0.0101343
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0697876,0.00631104
gpu_array,8192,64,1,10,2,true,false,true,false,0.069093,0.00573853
gpu_array,8192,64,1,10,4,true,false,true,false,0.0705481,0.00548462
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0715747,0.00651123
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0707007,0.00624756
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0704712,0.00601807
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0679468,0.00520264
0.00520264
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0697339,0.00747803
0.00747803
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0641492,0.00531128
0.00531128
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0690845,0.00792725
0.00792725
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0670532,0.00980225
0.00980225
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0797046,0.0156177
0.0156177
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00520264
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.219476 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,false,0.0761426,0.0140088
gpu_array,8192,32,1,2,2,true,false,true,false,0.07047,0.0108997
gpu_array,8192,32,1,2,4,true,false,true,false,0.0730383,0.0104163
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,false,0.0794043,0.0139746
gpu_sparse,8192,32,1,2,2,true,false,true,false,0.0716943,0.00846191
gpu_sparse,8192,32,1,2,4,true,false,true,false,0.0739514,0.00925415
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,false,0.0674854,0.00620605
gpu_array,8192,32,1,10,2,true,false,true,false,0.0704199,0.00572266
gpu_array,8192,32,1,10,4,true,false,true,false,0.0687048,0.00547241
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,false,0.0693054,0.00643921
gpu_sparse,8192,32,1,10,2,true,false,true,false,0.0694141,0.0059375
gpu_sparse,8192,32,1,10,4,true,false,true,false,0.0694214,0.00582275
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,false,0.077428,0.01505
gpu_array,8192,64,1,2,2,true,false,true,false,0.0733313,0.0116858
gpu_array,8192,64,1,2,4,true,false,true,false,0.0745825,0.011228
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,false,0.0794788,0.0150256
gpu_sparse,8192,64,1,2,2,true,false,true,false,0.0739343,0.00911499
gpu_sparse,8192,64,1,2,4,true,false,true,false,0.0733362,0.0101038
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,false,0.0686853,0.00630737
gpu_array,8192,64,1,10,2,true,false,true,false,0.0681702,0.00579224
gpu_array,8192,64,1,10,4,true,false,true,false,0.0705579,0.00549438
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,false,0.0713147,0.00649536
gpu_sparse,8192,64,1,10,2,true,false,true,false,0.0725464,0.00626221
gpu_sparse,8192,64,1,10,4,true,false,true,false,0.0713574,0.0060498
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,true,0.0703699,0.00518433
0.00518433
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,true,0.0692627,0.00749512
0.00749512
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,true,0.0632397,0.00525635
0.00525635
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,true,0.0706738,0.00792969
0.00792969
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,true,0.0668689,0.00986206
0.00986206
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,true,0.0799951,0.0156641
0.0156641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00518433
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 10 seconds of which 0.215136 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
