abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.415798,0.246713
gpu_array,256,8,1,20,2,true,false,true,false,0.284975,0.165555
gpu_array,256,8,1,20,4,true,false,true,false,0.350338,0.16507
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.393555,0.260184
gpu_sparse,256,8,1,20,2,true,false,true,false,0.260884,0.13421
gpu_sparse,256,8,1,20,4,true,false,true,false,0.288728,0.162612
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.443895,0.304386
gpu_reorg,256,8,1,20,2,true,false,true,false,0.302648,0.159791
gpu_reorg,256,8,1,20,4,true,false,true,false,0.275472,0.123128
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.259473,0.123312
gpu_array,256,8,1,50,2,true,false,true,false,0.231412,0.093019
gpu_array,256,8,1,50,4,true,false,true,false,0.21918,0.0869252
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.267129,0.131526
gpu_sparse,256,8,1,50,2,true,false,true,false,0.237492,0.105795
gpu_sparse,256,8,1,50,4,true,false,true,false,0.247288,0.107779
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.318259,0.172612
gpu_reorg,256,8,1,50,2,true,false,true,false,0.249224,0.102461
gpu_reorg,256,8,1,50,4,true,false,true,false,0.24736,0.0894364
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.361027,0.247746
gpu_array,256,32,1,20,2,true,false,true,false,0.291021,0.166021
gpu_array,256,32,1,20,4,true,false,true,false,0.283287,0.158845
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.362723,0.237723
gpu_sparse,256,32,1,20,2,true,false,true,false,0.2724,0.151864
gpu_sparse,256,32,1,20,4,true,false,true,false,0.298421,0.174537
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.452994,0.310137
gpu_reorg,256,32,1,20,2,true,false,true,false,0.311805,0.168948
gpu_reorg,256,32,1,20,4,true,false,true,false,0.297151,0.150388
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.198334,0.0817048
0.0817048
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.20385,0.0922433
0.0922433
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.290806,0.181431
0.181431
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.288996,0.17404
0.17404
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.302634,0.182098
0.182098
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.289526,0.17457
0.17457
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0817048
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 13 seconds of which 0.275805 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.373373,0.246141
gpu_array,256,8,1,20,2,true,false,true,false,0.288412,0.165645
gpu_array,256,8,1,20,4,true,false,true,false,0.279263,0.154263
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.37736,0.242316
gpu_sparse,256,8,1,20,2,true,false,true,false,0.3175,0.131116
gpu_sparse,256,8,1,20,4,true,false,true,false,0.287056,0.159824
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.443962,0.298873
gpu_reorg,256,8,1,20,2,true,false,true,false,0.299247,0.159738
gpu_reorg,256,8,1,20,4,true,false,true,false,0.282444,0.123404
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.25885,0.123248
gpu_array,256,8,1,50,2,true,false,true,false,0.243739,0.0947433
gpu_array,256,8,1,50,4,true,false,true,false,0.227193,0.0882422
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.273376,0.132193
gpu_sparse,256,8,1,50,2,true,false,true,false,0.237416,0.104604
gpu_sparse,256,8,1,50,4,true,false,true,false,0.249297,0.107556
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.324964,0.171504
gpu_reorg,256,8,1,50,2,true,false,true,false,0.249065,0.102302
gpu_reorg,256,8,1,50,4,true,false,true,false,0.2432,0.0902985
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.369227,0.247575
gpu_array,256,32,1,20,2,true,false,true,false,0.285218,0.161892
gpu_array,256,32,1,20,4,true,false,true,false,0.278457,0.155131
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.350929,0.230393
gpu_sparse,256,32,1,20,2,true,false,true,false,0.273284,0.147168
gpu_sparse,256,32,1,20,4,true,false,true,false,0.295525,0.174431
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.455354,0.310823
gpu_reorg,256,32,1,20,2,true,false,true,false,0.305354,0.168636
gpu_reorg,256,32,1,20,4,true,false,true,false,0.286186,0.149467
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.192006,0.0820731
0.0820731
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.199049,0.0924637
0.0924637
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.283184,0.168786
0.168786
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.281141,0.173998
0.173998
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.293368,0.181203
0.181203
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.280446,0.17442
0.17442
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0820731
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 12 seconds of which 0.272101 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.189448,0.0588672
gpu_array,256,8,1,20,2,true,false,true,false,0.188426,0.0533817
gpu_array,256,8,1,20,4,true,false,true,false,0.174855,0.0453906
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.195198,0.0584794
gpu_sparse,256,8,1,20,2,true,false,true,false,0.174082,0.047966
gpu_sparse,256,8,1,20,4,true,false,true,false,0.176071,0.0454911
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.227084,0.0725084
gpu_reorg,256,8,1,20,2,true,false,true,false,0.220868,0.0562472
gpu_reorg,256,8,1,20,4,true,false,true,false,0.204124,0.0534542
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.188348,0.0505134
gpu_array,256,8,1,50,2,true,false,true,false,0.189858,0.0470006
gpu_array,256,8,1,50,4,true,false,true,false,0.190985,0.0470117
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.189222,0.0508287
gpu_sparse,256,8,1,50,2,true,false,true,false,0.18738,0.0478711
gpu_sparse,256,8,1,50,4,true,false,true,false,0.173943,0.0478265
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.220965,0.0596931
gpu_reorg,256,8,1,50,2,true,false,true,false,0.215335,0.0523884
gpu_reorg,256,8,1,50,4,true,false,true,false,0.225745,0.0521959
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.199258,0.060865
gpu_array,256,32,1,20,2,true,false,true,false,0.207277,0.054933
gpu_array,256,32,1,20,4,true,false,true,false,0.192575,0.047486
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.192849,0.0600363
gpu_sparse,256,32,1,20,2,true,false,true,false,0.191585,0.0492857
gpu_sparse,256,32,1,20,4,true,false,true,false,0.184467,0.0483064
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.229238,0.0785686
gpu_reorg,256,32,1,20,2,true,false,true,false,0.209978,0.0565179
gpu_reorg,256,32,1,20,4,true,false,true,false,0.203619,0.0523912
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.164841,0.0459794
0.0459794
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.168915,0.0472628
0.0472628
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.160014,0.0445006
0.0445006
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.16933,0.0448884
0.0448884
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.165321,0.0459012
0.0459012
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.171839,0.0473968
0.0473968
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0445006
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0886494 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.200664,0.0622712
gpu_array,256,8,1,20,2,true,false,true,false,0.186328,0.0563058
gpu_array,256,8,1,20,4,true,false,true,false,0.187913,0.0472879
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.198599,0.0629967
gpu_sparse,256,8,1,20,2,true,false,true,false,0.178404,0.0500558
gpu_sparse,256,8,1,20,4,true,false,true,false,0.180393,0.0475809
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.244113,0.0783761
gpu_reorg,256,8,1,20,2,true,false,true,false,0.216334,0.0561775
gpu_reorg,256,8,1,20,4,true,false,true,false,0.211384,0.0534598
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.194568,0.0511523
gpu_array,256,8,1,50,2,true,false,true,false,0.181906,0.046861
gpu_array,256,8,1,50,4,true,false,true,false,0.18892,0.0471791
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.19135,0.0507254
gpu_sparse,256,8,1,50,2,true,false,true,false,0.187879,0.0478125
gpu_sparse,256,8,1,50,4,true,false,true,false,0.191565,0.0492662
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.217134,0.0597684
gpu_reorg,256,8,1,50,2,true,false,true,false,0.220991,0.0524637
gpu_reorg,256,8,1,50,4,true,false,true,false,0.219434,0.0525809
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.196819,0.0612165
gpu_array,256,32,1,20,2,true,false,true,false,0.207157,0.0559291
gpu_array,256,32,1,20,4,true,false,true,false,0.188078,0.0480106
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.208086,0.0607645
gpu_sparse,256,32,1,20,2,true,false,true,false,0.187034,0.0497573
gpu_sparse,256,32,1,20,4,true,false,true,false,0.171911,0.0485854
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.23584,0.0773577
gpu_reorg,256,32,1,20,2,true,false,true,false,0.22192,0.0572991
gpu_reorg,256,32,1,20,4,true,false,true,false,0.225176,0.0538588
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.163538,0.0452344
0.0452344
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.165762,0.044668
0.044668
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.158577,0.0464118
0.0464118
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.156906,0.0475307
0.0475307
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.158987,0.046264
0.046264
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.154688,0.0481027
0.0481027
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.044668
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0902816 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.786794,0.314696
gpu_array,256,8,1,20,2,true,false,true,false,0.725126,0.241309
gpu_array,256,8,1,20,4,true,false,true,false,0.699883,0.224994
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.813407,0.33238
gpu_sparse,256,8,1,20,2,true,false,true,false,0.643571,0.172031
gpu_sparse,256,8,1,20,4,true,false,true,false,0.703903,0.217854
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.2891,0.434743
gpu_reorg,256,8,1,20,2,true,false,true,false,1.06056,0.217366
gpu_reorg,256,8,1,20,4,true,false,true,false,1.05737,0.207486
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.662034,0.187146
gpu_array,256,8,1,50,2,true,false,true,false,0.612818,0.142952
gpu_array,256,8,1,50,4,true,false,true,false,0.606116,0.123973
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.668022,0.186437
gpu_sparse,256,8,1,50,2,true,false,true,false,0.622545,0.131473
gpu_sparse,256,8,1,50,4,true,false,true,false,0.620619,0.135686
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.07845,0.220753
gpu_reorg,256,8,1,50,2,true,false,true,false,0.986476,0.127101
gpu_reorg,256,8,1,50,4,true,false,true,false,0.978906,0.126228
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.582441,0.106995
0.106995
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.608775,0.145047
0.145047
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.716303,0.255366
0.255366
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.744369,0.28399
0.28399
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.106995
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.232244 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.790508,0.314503
gpu_array,256,8,1,20,2,true,false,true,false,0.725061,0.241802
gpu_array,256,8,1,20,4,true,false,true,false,0.692341,0.224707
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.870181,0.331677
gpu_sparse,256,8,1,20,2,true,false,true,false,0.696113,0.160399
gpu_sparse,256,8,1,20,4,true,false,true,false,0.686749,0.217999
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,1.30087,0.435357
gpu_reorg,256,8,1,20,2,true,false,true,false,1.07135,0.216995
gpu_reorg,256,8,1,20,4,true,false,true,false,1.06977,0.208167
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.655558,0.187366
gpu_array,256,8,1,50,2,true,false,true,false,0.612589,0.143839
gpu_array,256,8,1,50,4,true,false,true,false,0.622497,0.123613
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.675865,0.186468
gpu_sparse,256,8,1,50,2,true,false,true,false,0.617483,0.131992
gpu_sparse,256,8,1,50,4,true,false,true,false,0.62034,0.135965
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,1.08364,0.220921
gpu_reorg,256,8,1,50,2,true,false,true,false,0.988446,0.127955
gpu_reorg,256,8,1,50,4,true,false,true,false,1.11922,0.125354
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.561362,0.106563
0.106563
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.615656,0.144674
0.144674
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.719392,0.255106
0.255106
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.730603,0.271339
0.271339
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.106563
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.231053 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.422037,0.264113
gpu_array,256,8,1,20,2,true,false,true,false,0.318225,0.164208
gpu_array,256,8,1,20,4,true,false,true,false,0.290198,0.142877
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.406666,0.253764
gpu_sparse,256,8,1,20,2,true,false,true,false,0.334729,0.180711
gpu_sparse,256,8,1,20,4,true,false,true,false,0.335223,0.172835
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.510162,0.361166
gpu_reorg,256,8,1,20,2,true,false,true,false,0.372296,0.21772
gpu_reorg,256,8,1,20,4,true,false,true,false,0.357165,0.207054
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.659718,0.201013
gpu_array,256,8,1,50,2,true,false,true,false,0.584824,0.171878
gpu_array,256,8,1,50,4,true,false,true,false,0.59625,0.177723
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.349897,0.193647
gpu_sparse,256,8,1,50,2,true,false,true,false,0.608767,0.184102
gpu_sparse,256,8,1,50,4,true,false,true,false,0.592143,0.181429
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.384021,0.227213
gpu_reorg,256,8,1,50,2,true,false,true,false,0.362288,0.192645
gpu_reorg,256,8,1,50,4,true,false,true,false,0.350215,0.184478
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.429584,0.276124
gpu_array,256,32,1,20,2,true,false,true,false,0.330251,0.181814
gpu_array,256,32,1,20,4,true,false,true,false,0.314573,0.169484
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.39767,0.262068
gpu_sparse,256,32,1,20,2,true,false,true,false,0.333962,0.190547
gpu_sparse,256,32,1,20,4,true,false,true,false,0.332871,0.187224
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.482807,0.320977
gpu_reorg,256,32,1,20,2,true,false,true,false,0.376981,0.218499
gpu_reorg,256,32,1,20,4,true,false,true,false,0.371855,0.211699
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.314581,0.166144
0.166144
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.328571,0.180134
0.180134
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.314735,0.175226
0.175226
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.374023,0.231724
0.231724
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.265273,0.124648
0.124648
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.295084,0.153343
0.153343
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.124648
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.344485 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.414099,0.265103
gpu_array,256,8,1,20,2,true,false,true,false,0.313393,0.164955
gpu_array,256,8,1,20,4,true,false,true,false,0.297201,0.143184
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.460692,0.254219
gpu_sparse,256,8,1,20,2,true,false,true,false,0.317109,0.16923
gpu_sparse,256,8,1,20,4,true,false,true,false,0.317034,0.161342
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.493488,0.335006
gpu_reorg,256,8,1,20,2,true,false,true,false,0.359241,0.202991
gpu_reorg,256,8,1,20,4,true,false,true,false,0.359637,0.193901
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.62017,0.187693
gpu_array,256,8,1,50,2,true,false,true,false,0.594715,0.17284
gpu_array,256,8,1,50,4,true,false,true,false,0.611035,0.178557
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.348345,0.19377
gpu_sparse,256,8,1,50,2,true,false,true,false,0.603507,0.184422
gpu_sparse,256,8,1,50,4,true,false,true,false,0.608267,0.181928
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.387383,0.227785
gpu_reorg,256,8,1,50,2,true,false,true,false,0.3593,0.193563
gpu_reorg,256,8,1,50,4,true,false,true,false,0.344378,0.185896
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.434481,0.276557
gpu_array,256,32,1,20,2,true,false,true,false,0.339528,0.18272
gpu_array,256,32,1,20,4,true,false,true,false,0.313234,0.169819
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.42108,0.263156
gpu_sparse,256,32,1,20,2,true,false,true,false,0.3425,0.191272
gpu_sparse,256,32,1,20,4,true,false,true,false,0.339129,0.187902
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.483658,0.325176
gpu_reorg,256,32,1,20,2,true,false,true,false,0.387176,0.230368
gpu_reorg,256,32,1,20,4,true,false,true,false,0.400313,0.222857
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.297458,0.165204
0.165204
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.315689,0.180086
0.180086
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.31012,0.173959
0.173959
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.359955,0.226027
0.226027
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,0.268276,0.123744
0.123744
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,0.289679,0.151844
0.151844
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.123744
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 19 seconds of which 0.341354 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.39863,0.0788783
gpu_array,256,8,1,20,2,false,false,true,false,1.40016,0.0725893
gpu_array,256,8,1,20,4,false,false,true,false,1.39395,0.0580162
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.41819,0.077793
gpu_sparse,256,8,1,20,2,false,false,true,false,1.40278,0.0729855
gpu_sparse,256,8,1,20,4,false,false,true,false,1.43019,0.0635631
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.41363,0.0849442
gpu_reorg,256,8,1,20,2,false,false,true,false,1.43607,0.0772517
gpu_reorg,256,8,1,20,4,false,false,true,false,1.3873,0.0681027
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.40025,0.0648689
gpu_array,256,8,1,50,2,false,false,true,false,1.52605,0.0600893
gpu_array,256,8,1,50,4,false,false,true,false,1.40545,0.0600307
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.41903,0.065798
gpu_sparse,256,8,1,50,2,false,false,true,false,1.40851,0.0748047
gpu_sparse,256,8,1,50,4,false,false,true,false,1.41744,0.0748047
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.39215,0.0712807
gpu_reorg,256,8,1,50,2,false,false,true,false,1.40783,0.0668666
gpu_reorg,256,8,1,50,4,false,false,true,false,1.40253,0.0660296
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.42272,0.0856669
gpu_array,256,32,1,20,2,false,false,true,false,1.43494,0.0800335
gpu_array,256,32,1,20,4,false,false,true,false,1.3977,0.0740346
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.42699,0.0849163
gpu_sparse,256,32,1,20,2,false,false,true,false,1.42301,0.0803767
gpu_sparse,256,32,1,20,4,false,false,true,false,1.43244,0.0758538
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.61381,0.0898158
gpu_reorg,256,32,1,20,2,false,false,true,false,1.50876,0.0835407
gpu_reorg,256,32,1,20,4,false,false,true,false,1.43749,0.0770033
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.37462,0.0582115
0.0582115
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.46037,0.0557952
0.0557952
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.39322,0.071236
0.071236
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0557952
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.111369 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,1.36572,0.0788923
gpu_array,256,8,1,20,2,false,false,true,false,1.39527,0.0716099
gpu_array,256,8,1,20,4,false,false,true,false,1.37666,0.0574609
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,1.41405,0.0781166
gpu_sparse,256,8,1,20,2,false,false,true,false,1.41347,0.0713951
gpu_sparse,256,8,1,20,4,false,false,true,false,1.4234,0.0662584
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,1.41687,0.084841
gpu_reorg,256,8,1,20,2,false,false,true,false,1.42725,0.0773661
gpu_reorg,256,8,1,20,4,false,false,true,false,1.42216,0.0678041
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,1.4141,0.065332
gpu_array,256,8,1,50,2,false,false,true,false,1.38857,0.0604436
gpu_array,256,8,1,50,4,false,false,true,false,1.40545,0.0600251
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,1.3913,0.0659682
gpu_sparse,256,8,1,50,2,false,false,true,false,1.39892,0.0746987
gpu_sparse,256,8,1,50,4,false,false,true,false,1.42632,0.0753153
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,1.42778,0.0706334
gpu_reorg,256,8,1,50,2,false,false,true,false,1.43475,0.0664425
gpu_reorg,256,8,1,50,4,false,false,true,false,1.39975,0.0666071
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,1.43945,0.0850949
gpu_array,256,32,1,20,2,false,false,true,false,1.42206,0.0811021
gpu_array,256,32,1,20,4,false,false,true,false,1.41173,0.0735603
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,1.43481,0.0849219
gpu_sparse,256,32,1,20,2,false,false,true,false,1.42451,0.0801981
gpu_sparse,256,32,1,20,4,false,false,true,false,1.44393,0.0761858
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,1.63318,0.0902093
gpu_reorg,256,32,1,20,2,false,false,true,false,1.45986,0.0826283
gpu_reorg,256,32,1,20,4,false,false,true,false,1.45823,0.0765374
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,1.40315,0.0588449
0.0588449
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,1.38333,0.0563198
0.0563198
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,1.38979,0.0717104
0.0717104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0563198
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.111438 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.200756,0.0606892
gpu_array,256,8,1,20,2,true,false,true,false,0.199322,0.0542327
gpu_array,256,8,1,20,4,true,false,true,false,0.196085,0.0465318
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.20719,0.0604269
gpu_sparse,256,8,1,20,2,true,false,true,false,0.182229,0.0494169
gpu_sparse,256,8,1,20,4,true,false,true,false,0.190494,0.0470787
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.25656,0.0802204
gpu_reorg,256,8,1,20,2,true,false,true,false,0.236563,0.0579911
gpu_reorg,256,8,1,20,4,true,false,true,false,0.227478,0.0556027
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.202282,0.0516127
gpu_array,256,8,1,50,2,true,false,true,false,0.191772,0.0483566
gpu_array,256,8,1,50,4,true,false,true,false,0.190064,0.0483231
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.195505,0.0520898
gpu_sparse,256,8,1,50,2,true,false,true,false,0.191568,0.0487109
gpu_sparse,256,8,1,50,4,true,false,true,false,0.19154,0.048683
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.229074,0.0616629
gpu_reorg,256,8,1,50,2,true,false,true,false,0.231406,0.055067
gpu_reorg,256,8,1,50,4,true,false,true,false,0.231853,0.0549554
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.202207,0.061024
gpu_array,256,32,1,20,2,true,false,true,false,0.189964,0.0549191
gpu_array,256,32,1,20,4,true,false,true,false,0.184188,0.0485854
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.213502,0.0605999
gpu_sparse,256,32,1,20,2,true,false,true,false,0.182148,0.049894
gpu_sparse,256,32,1,20,4,true,false,true,false,0.189551,0.0489258
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.243114,0.0801674
gpu_reorg,256,32,1,20,2,true,false,true,false,0.2237,0.0579632
gpu_reorg,256,32,1,20,4,true,false,true,false,0.228744,0.0540792
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.171264,0.046264
0.046264
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.17103,0.0477037
0.0477037
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.168334,0.0450084
0.0450084
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.175547,0.0449665
0.0449665
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.170246,0.0469196
0.0469196
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.172489,0.050279
0.050279
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0449665
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0910823 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.199386,0.0632254
gpu_array,256,8,1,20,2,true,false,true,false,0.197838,0.0566546
gpu_array,256,8,1,20,4,true,false,true,false,0.181735,0.0478069
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.202467,0.0623996
gpu_sparse,256,8,1,20,2,true,false,true,false,0.18269,0.0504353
gpu_sparse,256,8,1,20,4,true,false,true,false,0.196646,0.0476507
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.25149,0.079615
gpu_reorg,256,8,1,20,2,true,false,true,false,0.226705,0.0570619
gpu_reorg,256,8,1,20,4,true,false,true,false,0.228753,0.0546456
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.199676,0.0512388
gpu_array,256,8,1,50,2,true,false,true,false,0.189157,0.0479743
gpu_array,256,8,1,50,4,true,false,true,false,0.18154,0.0476116
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.200935,0.0513811
gpu_sparse,256,8,1,50,2,true,false,true,false,0.186939,0.0479883
gpu_sparse,256,8,1,50,4,true,false,true,false,0.171044,0.0477176
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.229623,0.0622126
gpu_reorg,256,8,1,50,2,true,false,true,false,0.224986,0.0547852
gpu_reorg,256,8,1,50,4,true,false,true,false,0.230123,0.0548996
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.199515,0.0611217
gpu_array,256,32,1,20,2,true,false,true,false,0.213404,0.0549219
gpu_array,256,32,1,20,4,true,false,true,false,0.185703,0.0484263
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.2094,0.0604046
gpu_sparse,256,32,1,20,2,true,false,true,false,0.179113,0.0496484
gpu_sparse,256,32,1,20,4,true,false,true,false,0.187715,0.049322
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.246805,0.0782785
gpu_reorg,256,32,1,20,2,true,false,true,false,0.223504,0.0583259
gpu_reorg,256,32,1,20,4,true,false,true,false,0.228345,0.0542383
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,0.173251,0.0449023
0.0449023
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,0.164146,0.0447266
0.0447266
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,0.170477,0.0460352
0.0460352
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,0.173329,0.0477706
0.0477706
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,0.179099,0.0468443
0.0468443
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,0.175165,0.0501646
0.0501646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0447266
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0911583 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.88377,6.45632
gpu_array,256,8,1,20,2,true,false,true,false,13.9342,13.4565
gpu_array,256,8,1,20,4,true,false,true,false,13.4659,13.0229
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.4224,6.00499
gpu_sparse,256,8,1,20,2,true,false,true,false,13.5604,13.1056
gpu_sparse,256,8,1,20,4,true,false,true,false,9.68805,9.24887
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.71454,7.26532
gpu_reorg,256,8,1,20,2,true,false,true,false,11.3424,10.8742
gpu_reorg,256,8,1,20,4,true,false,true,false,8.64324,8.189
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.43009,3.99873
gpu_array,256,8,1,50,2,true,false,true,false,7.6593,7.20338
gpu_array,256,8,1,50,4,true,false,true,false,8.73839,8.29531
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,4.08191,3.64497
gpu_sparse,256,8,1,50,2,true,false,true,false,7.40632,6.9677
gpu_sparse,256,8,1,50,4,true,false,true,false,7.95984,7.51342
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,5.04391,4.58799
gpu_reorg,256,8,1,50,2,true,false,true,false,7.8222,7.36182
gpu_reorg,256,8,1,50,4,true,false,true,false,11.5909,11.107
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,7.14999,6.70579
gpu_array,256,32,1,20,2,true,false,true,false,5.79337,5.34471
gpu_array,256,32,1,20,4,true,false,true,false,6.43779,5.98411
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.58549,6.16027
gpu_sparse,256,32,1,20,2,true,false,true,false,5.88081,5.44945
gpu_sparse,256,32,1,20,4,true,false,true,false,5.85379,5.39397
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.96748,7.49761
gpu_reorg,256,32,1,20,2,true,false,true,false,6.93362,6.44701
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.86251,2.72802
2.72802
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,3.02817,2.88252
2.88252
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,6.01753,5.88919
5.88919
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.1699,6.03262
6.03262
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.72802
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 168 seconds of which 2.74969 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,6.8461,6.39689
gpu_array,256,8,1,20,2,true,false,true,false,13.8604,13.4235
gpu_array,256,8,1,20,4,true,false,true,false,13.3879,12.9359
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,6.61892,6.18365
gpu_sparse,256,8,1,20,2,true,false,true,false,13.5686,13.1294
gpu_sparse,256,8,1,20,4,true,false,true,false,9.71915,9.27328
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,7.74475,7.29554
gpu_reorg,256,8,1,20,2,true,false,true,false,11.3886,10.9299
gpu_reorg,256,8,1,20,4,true,false,true,false,8.72321,8.27176
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,4.45729,4.01477
gpu_array,256,8,1,50,2,true,false,true,false,7.70596,7.26065
gpu_array,256,8,1,50,4,true,false,true,false,8.69763,8.23502
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,4.28464,3.83375
gpu_sparse,256,8,1,50,2,true,false,true,false,7.49182,7.04818
gpu_sparse,256,8,1,50,4,true,false,true,false,7.9598,7.50779
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,5.05732,4.6042
gpu_reorg,256,8,1,50,2,true,false,true,false,7.82404,7.36366
gpu_reorg,256,8,1,50,4,true,false,true,false,11.746,11.2784
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,7.24528,6.80276
gpu_array,256,32,1,20,2,true,false,true,false,5.7949,5.36298
gpu_array,256,32,1,20,4,true,false,true,false,6.49185,6.03929
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,6.44354,6.00771
gpu_sparse,256,32,1,20,2,true,false,true,false,6.02174,5.57866
gpu_sparse,256,32,1,20,4,true,false,true,false,5.94387,5.50023
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,7.99234,7.54089
gpu_reorg,256,32,1,20,2,true,false,true,false,6.97933,6.52062
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,2.91773,2.79664
2.79664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,3.11411,2.97404
2.97404
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,5.94489,5.81208
5.81208
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,6.30964,6.17292
6.17292
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.79664
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 167 seconds of which 2.76602 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.268384,0.0591211
gpu_array,256,8,1,20,2,true,false,true,false,0.335879,0.103736
gpu_array,256,8,1,20,4,true,false,true,false,0.293652,0.0726702
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.301501,0.0615458
gpu_sparse,256,8,1,20,2,true,false,true,false,0.332673,0.0921596
gpu_sparse,256,8,1,20,4,true,false,true,false,0.313401,0.0873968
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.304827,0.0765904
gpu_reorg,256,8,1,20,2,true,false,true,false,0.354768,0.117045
gpu_reorg,256,8,1,20,4,true,false,true,false,0.344534,0.094534
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.273987,0.0546791
gpu_array,256,8,1,50,2,true,false,true,false,0.293504,0.0781027
gpu_array,256,8,1,50,4,true,false,true,false,0.294581,0.0791797
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.273834,0.0539676
gpu_sparse,256,8,1,50,2,true,false,true,false,0.314986,0.080611
gpu_sparse,256,8,1,50,4,true,false,true,false,0.302059,0.0794029
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.32267,0.0654157
gpu_reorg,256,8,1,50,2,true,false,true,false,0.319685,0.089774
gpu_reorg,256,8,1,50,4,true,false,true,false,0.317207,0.0895285
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.27221,0.0618304
gpu_array,256,32,1,20,2,true,false,true,false,0.275681,0.0580469
gpu_array,256,32,1,20,4,true,false,true,false,0.27019,0.0564621
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.272863,0.0596931
gpu_sparse,256,32,1,20,2,true,false,true,false,0.255594,0.0513532
gpu_sparse,256,32,1,20,4,true,false,true,false,0.26921,0.0549247
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.313245,0.0766378
gpu_reorg,256,32,1,20,2,true,false,true,false,0.313677,0.0636775
gpu_reorg,256,32,1,20,4,true,false,true,false,0.29668,0.067327
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.24957,0.0497935
0.0497935
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.259386,0.0596094
0.0596094
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.237776,0.0480441
0.0480441
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.241537,0.0490151
0.0490151
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.259908,0.0601311
0.0601311
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.276641,0.0623549
0.0623549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0480441
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.118495 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,0.281406,0.0626562
gpu_array,256,8,1,20,2,true,false,true,false,0.310594,0.110818
gpu_array,256,8,1,20,4,true,false,true,false,0.309456,0.0789872
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,0.266638,0.0618387
gpu_sparse,256,8,1,20,2,true,false,true,false,0.314763,0.0932227
gpu_sparse,256,8,1,20,4,true,false,true,false,0.307266,0.0873996
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,0.296624,0.0761998
gpu_reorg,256,8,1,20,2,true,false,true,false,0.366532,0.11709
gpu_reorg,256,8,1,20,4,true,false,true,false,0.338577,0.0941574
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,0.290642,0.0551507
gpu_array,256,8,1,50,2,true,false,true,false,0.288092,0.0782701
gpu_array,256,8,1,50,4,true,false,true,false,0.315047,0.0789983
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,0.263265,0.0534431
gpu_sparse,256,8,1,50,2,true,false,true,false,0.309319,0.0799665
gpu_sparse,256,8,1,50,4,true,false,true,false,0.296953,0.0793192
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,0.279339,0.064495
gpu_reorg,256,8,1,50,2,true,false,true,false,0.337232,0.0894643
gpu_reorg,256,8,1,50,4,true,false,true,false,0.337754,0.089428
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,0.275938,0.0616518
gpu_array,256,32,1,20,2,true,false,true,false,0.289252,0.0582254
gpu_array,256,32,1,20,4,true,false,true,false,0.289528,0.0562695
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,0.291456,0.0593136
gpu_sparse,256,32,1,20,2,true,false,true,false,0.272522,0.0515402
gpu_sparse,256,32,1,20,4,true,false,true,false,0.263809,0.0556613
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,0.334972,0.0754855
gpu_reorg,256,32,1,20,2,true,false,true,false,0.297885,0.0618359
gpu_reorg,256,32,1,20,4,true,false,true,false,0.315806,0.0680385
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,true,0.236847,0.0493471
0.0493471
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,true,0.267776,0.0590709
0.0590709
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,true,0.251381,0.0476981
0.0476981
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,true,0.233119,0.0484096
0.0484096
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,0.243343,0.0603069
0.0603069
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,0.247866,0.0620396
0.0620396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0476981
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.119081 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.21098,0.124391
gpu_array,512,8,1,20,2,true,false,true,false,0.175827,0.0840299
gpu_array,512,8,1,20,4,true,false,true,false,0.171989,0.07889
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.213385,0.123542
gpu_sparse,512,8,1,20,2,true,false,true,false,0.167441,0.0762956
gpu_sparse,512,8,1,20,4,true,false,true,false,0.179717,0.089222
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.273994,0.160713
gpu_reorg,512,8,1,20,2,true,false,true,false,0.193363,0.0865918
gpu_reorg,512,8,1,20,4,true,false,true,false,0.179124,0.0684473
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.150117,0.0706901
gpu_array,512,8,1,50,2,true,false,true,false,0.138304,0.0582259
gpu_array,512,8,1,50,4,true,false,true,false,0.141367,0.060638
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.15624,0.0729069
gpu_sparse,512,8,1,50,2,true,false,true,false,0.151989,0.0706087
gpu_sparse,512,8,1,50,4,true,false,true,false,0.153714,0.072985
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.19681,0.088737
gpu_reorg,512,8,1,50,2,true,false,true,false,0.167848,0.0552181
gpu_reorg,512,8,1,50,4,true,false,true,false,0.172487,0.0728776
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.216908,0.12446
gpu_array,512,32,1,20,2,true,false,true,false,0.176719,0.086875
gpu_array,512,32,1,20,4,true,false,true,false,0.175387,0.0842415
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.215498,0.125003
gpu_sparse,512,32,1,20,2,true,false,true,false,0.164967,0.079681
gpu_sparse,512,32,1,20,4,true,false,true,false,0.174053,0.0881152
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.269495,0.157516
gpu_reorg,512,32,1,20,2,true,false,true,false,0.195244,0.0910775
gpu_reorg,512,32,1,20,4,true,false,true,false,0.191663,0.0809863
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.155801,0.0542383
0.0542383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.168096,0.0645801
0.0645801
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.170036,0.0678223
0.0678223
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.17292,0.0772168
0.0772168
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.180355,0.0807454
0.0807454
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.184043,0.0857357
0.0857357
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0542383
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.293202 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.215042,0.124548
gpu_array,512,8,1,20,2,true,false,true,false,0.179238,0.0848372
gpu_array,512,8,1,20,4,true,false,true,false,0.170941,0.0797949
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.212402,0.12321
gpu_sparse,512,8,1,20,2,true,false,true,false,0.167451,0.0763053
gpu_sparse,512,8,1,20,4,true,false,true,false,0.182539,0.0894401
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.270762,0.160736
gpu_reorg,512,8,1,20,2,true,false,true,false,0.199303,0.0873242
gpu_reorg,512,8,1,20,4,true,false,true,false,0.179854,0.0685254
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.158324,0.0704329
gpu_array,512,8,1,50,2,true,false,true,false,0.139128,0.0583984
gpu_array,512,8,1,50,4,true,false,true,false,0.140768,0.0606901
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.160241,0.0730013
gpu_sparse,512,8,1,50,2,true,false,true,false,0.152054,0.0706738
gpu_sparse,512,8,1,50,4,true,false,true,false,0.164886,0.0737402
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.19085,0.0886361
gpu_reorg,512,8,1,50,2,true,false,true,false,0.154977,0.0553678
gpu_reorg,512,8,1,50,4,true,false,true,false,0.173988,0.0730762
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.216299,0.125153
gpu_array,512,32,1,20,2,true,false,true,false,0.175553,0.0870117
gpu_array,512,32,1,20,4,true,false,true,false,0.167884,0.0838997
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.216979,0.125182
gpu_sparse,512,32,1,20,2,true,false,true,false,0.16653,0.0799414
gpu_sparse,512,32,1,20,4,true,false,true,false,0.171979,0.0873437
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.269329,0.15735
gpu_reorg,512,32,1,20,2,true,false,true,false,0.203577,0.0909473
gpu_reorg,512,32,1,20,4,true,false,true,false,0.187865,0.0810938
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,0.153984,0.054375
0.054375
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,0.161022,0.064668
0.064668
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,true,false,true,true,0.167474,0.0678646
0.0678646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,0.179424,0.0772103
0.0772103
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,true,false,true,true,0.182747,0.0811849
0.0811849
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,512,32,1,20,4,false,false,true,true,0.189421,0.0852539
0.0852539
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.054375
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.293603 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.116715,0.0327311
gpu_array,512,8,1,20,2,true,false,true,false,0.118805,0.0302637
gpu_array,512,8,1,20,4,true,false,true,false,0.115671,0.0271289
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.120625,0.0327344
gpu_sparse,512,8,1,20,2,true,false,true,false,0.118164,0.0283203
gpu_sparse,512,8,1,20,4,true,false,true,false,0.125553,0.0278971
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.153304,0.0413249
gpu_reorg,512,8,1,20,2,true,false,true,false,0.145843,0.0319108
gpu_reorg,512,8,1,20,4,true,false,true,false,0.134837,0.0306706
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.116289,0.0290495
gpu_array,512,8,1,50,2,true,false,true,false,0.127305,0.0283464
gpu_array,512,8,1,50,4,true,false,true,false,0.122731,0.0283301
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.12998,0.029069
gpu_sparse,512,8,1,50,2,true,false,true,false,0.127432,0.0343327
gpu_sparse,512,8,1,50,4,true,false,true,false,0.122637,0.0340951
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.139398,0.0352311
gpu_reorg,512,8,1,50,2,true,false,true,false,0.152643,0.0367578
gpu_reorg,512,8,1,50,4,true,false,true,false,0.158604,0.0368587
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.124886,0.0311361
gpu_array,512,32,1,20,2,true,false,true,false,0.116807,0.028265
gpu_array,512,32,1,20,4,true,false,true,false,0.110368,0.0250814
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.127383,0.0310286
gpu_sparse,512,32,1,20,2,true,false,true,false,0.115195,0.0260026
gpu_sparse,512,32,1,20,4,true,false,true,false,0.117321,0.0255241
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.152204,0.0395736
gpu_reorg,512,32,1,20,2,true,false,true,false,0.144235,0.0303027
gpu_reorg,512,32,1,20,4,true,false,true,false,0.151468,0.0290723
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0949219,0.0239583
0.0239583
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.10137,0.0251986
0.0251986
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.10179,0.0256185
0.0256185
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.101992,0.0258203
0.0258203
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.100072,0.0252018
0.0252018
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.104482,0.0257064
0.0257064
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0239583
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.101636 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.127946,0.0328939
gpu_array,512,8,1,20,2,true,false,true,false,0.126012,0.0303092
gpu_array,512,8,1,20,4,true,false,true,false,0.121761,0.02736
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.133089,0.0328288
gpu_sparse,512,8,1,20,2,true,false,true,false,0.126449,0.0281413
gpu_sparse,512,8,1,20,4,true,false,true,false,0.124775,0.0277702
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.160563,0.0414225
gpu_reorg,512,8,1,20,2,true,false,true,false,0.151117,0.0319759
gpu_reorg,512,8,1,20,4,true,false,true,false,0.146403,0.0305176
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.120859,0.0290625
gpu_array,512,8,1,50,2,true,false,true,false,0.122679,0.028278
gpu_array,512,8,1,50,4,true,false,true,false,0.117445,0.028252
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.117399,0.0288574
gpu_sparse,512,8,1,50,2,true,false,true,false,0.127904,0.0341536
gpu_sparse,512,8,1,50,4,true,false,true,false,0.120055,0.0341178
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.157887,0.0354915
gpu_reorg,512,8,1,50,2,true,false,true,false,0.149876,0.0365951
gpu_reorg,512,8,1,50,4,true,false,true,false,0.150697,0.0367643
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.125394,0.0309928
gpu_array,512,32,1,20,2,true,false,true,false,0.122484,0.0280827
gpu_array,512,32,1,20,4,true,false,true,false,0.109518,0.0248828
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.119375,0.0308333
gpu_sparse,512,32,1,20,2,true,false,true,false,0.114424,0.0258822
gpu_sparse,512,32,1,20,4,true,false,true,false,0.115316,0.025472
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.15693,0.0397428
gpu_reorg,512,32,1,20,2,true,false,true,false,0.139635,0.0302604
gpu_reorg,512,32,1,20,4,true,false,true,false,0.144883,0.0289974
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.0943229,0.0240104
0.0240104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.0981185,0.0252018
0.0252018
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.103783,0.0256576
0.0256576
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.101364,0.0258431
0.0258431
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,0.100703,0.0251823
0.0251823
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,0.099873,0.0256543
0.0256543
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0240104
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.101528 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.744372,0.159736
gpu_array,512,8,1,20,2,true,false,true,false,0.724339,0.122777
gpu_array,512,8,1,20,4,true,false,true,false,0.733268,0.123242
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.762747,0.169648
gpu_sparse,512,8,1,20,2,true,false,true,false,0.681276,0.0907812
gpu_sparse,512,8,1,20,4,true,false,true,false,0.698792,0.111553
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.858258,0.22154
gpu_reorg,512,8,1,20,2,true,false,true,false,0.749938,0.119079
gpu_reorg,512,8,1,20,4,true,false,true,false,0.745348,0.114489
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.694886,0.102438
gpu_array,512,8,1,50,2,true,false,true,false,0.681852,0.0776855
gpu_array,512,8,1,50,4,true,false,true,false,0.659049,0.0822266
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.716774,0.105446
gpu_sparse,512,8,1,50,2,true,false,true,false,0.717139,0.103857
gpu_sparse,512,8,1,50,4,true,false,true,false,0.685667,0.103636
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.752077,0.117962
gpu_reorg,512,8,1,50,2,true,false,true,false,0.724147,0.0828711
gpu_reorg,512,8,1,50,4,true,false,true,false,0.759583,0.105286
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.665016,0.082985
0.082985
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.770654,0.100081
0.100081
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,0.661738,0.0888216
0.0888216
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,0.770303,0.192829
0.192829
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0776855
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.264087 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.738213,0.158786
gpu_array,512,8,1,20,2,true,false,true,false,0.715794,0.13181
gpu_array,512,8,1,20,4,true,false,true,false,0.709668,0.123079
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.762578,0.169479
gpu_sparse,512,8,1,20,2,true,false,true,false,0.668066,0.0905924
gpu_sparse,512,8,1,20,4,true,false,true,false,0.706758,0.111706
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.841117,0.221325
gpu_reorg,512,8,1,20,2,true,false,true,false,0.748503,0.119596
gpu_reorg,512,8,1,20,4,true,false,true,false,0.735993,0.114248
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.689593,0.102354
gpu_array,512,8,1,50,2,true,false,true,false,0.665173,0.0779329
gpu_array,512,8,1,50,4,true,false,true,false,0.678714,0.08236
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.703079,0.106725
gpu_sparse,512,8,1,50,2,true,false,true,false,0.717061,0.103779
gpu_sparse,512,8,1,50,4,true,false,true,false,0.697184,0.103434
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.74488,0.118577
gpu_reorg,512,8,1,50,2,true,false,true,false,0.728838,0.0830046
gpu_reorg,512,8,1,50,4,true,false,true,false,0.729147,0.1061
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.654027,0.0837142
0.0837142
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.679388,0.101263
0.101263
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.7079,0.129775
0.129775
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.727347,0.157035
0.157035
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0779329
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.2659 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.270719,0.141162
gpu_array,512,8,1,20,2,true,false,true,false,0.230687,0.10113
gpu_array,512,8,1,20,4,true,false,true,false,0.232865,0.098099
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.267061,0.145967
gpu_sparse,512,8,1,20,2,true,false,true,false,0.233704,0.113262
gpu_sparse,512,8,1,20,4,true,false,true,false,0.241901,0.115599
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.32445,0.196846
gpu_reorg,512,8,1,20,2,true,false,true,false,0.265635,0.132171
gpu_reorg,512,8,1,20,4,true,false,true,false,0.252471,0.130075
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.358099,0.122422
gpu_array,512,8,1,50,2,true,false,true,false,0.351934,0.11821
gpu_array,512,8,1,50,4,true,false,true,false,0.367295,0.130967
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.240426,0.119984
gpu_sparse,512,8,1,50,2,true,false,true,false,0.359756,0.125381
gpu_sparse,512,8,1,50,4,true,false,true,false,0.366914,0.135143
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.286641,0.139505
gpu_reorg,512,8,1,50,2,true,false,true,false,0.253617,0.128617
gpu_reorg,512,8,1,50,4,true,false,true,false,0.296973,0.168717
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.262165,0.146279
gpu_array,512,32,1,20,2,true,false,true,false,0.225296,0.110062
gpu_array,512,32,1,20,4,true,false,true,false,0.226615,0.109427
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.257669,0.139831
gpu_sparse,512,32,1,20,2,true,false,true,false,0.243994,0.113786
gpu_sparse,512,32,1,20,4,true,false,true,false,0.230176,0.116895
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.303219,0.174964
gpu_reorg,512,32,1,20,2,true,false,true,false,0.260309,0.137913
gpu_reorg,512,32,1,20,4,true,false,true,false,0.256159,0.137669
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.201172,0.0878906
0.0878906
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.196058,0.0918913
0.0918913
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.203193,0.0873079
0.0873079
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.229681,0.115098
0.115098
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.188193,0.0755632
0.0755632
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.199977,0.0834408
0.0834408
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0755632
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.418946 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.262197,0.141104
gpu_array,512,8,1,20,2,true,false,true,false,0.218597,0.100758
gpu_array,512,8,1,20,4,true,false,true,false,0.226224,0.0973177
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.263877,0.146038
gpu_sparse,512,8,1,20,2,true,false,true,false,0.24501,0.113499
gpu_sparse,512,8,1,20,4,true,false,true,false,0.245859,0.116302
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.314795,0.196956
gpu_reorg,512,8,1,20,2,true,false,true,false,0.267653,0.131585
gpu_reorg,512,8,1,20,4,true,false,true,false,0.24807,0.130231
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.357529,0.122503
gpu_array,512,8,1,50,2,true,false,true,false,0.357067,0.118786
gpu_array,512,8,1,50,4,true,false,true,false,0.37152,0.131286
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.244105,0.120407
gpu_sparse,512,8,1,50,2,true,false,true,false,0.357832,0.124759
gpu_sparse,512,8,1,50,4,true,false,true,false,0.373633,0.135352
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.265664,0.139362
gpu_reorg,512,8,1,50,2,true,false,true,false,0.251663,0.128617
gpu_reorg,512,8,1,50,4,true,false,true,false,0.293786,0.168786
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.274128,0.146523
gpu_array,512,32,1,20,2,true,false,true,false,0.240469,0.11026
gpu_array,512,32,1,20,4,true,false,true,false,0.238561,0.109004
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.256344,0.139808
gpu_sparse,512,32,1,20,2,true,false,true,false,0.242673,0.113115
gpu_sparse,512,32,1,20,4,true,false,true,false,0.236924,0.117783
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.306595,0.175736
gpu_reorg,512,32,1,20,2,true,false,true,false,0.261361,0.138314
gpu_reorg,512,32,1,20,4,true,false,true,false,0.276169,0.138148
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.200039,0.0874089
0.0874089
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.205094,0.0918132
0.0918132
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.202051,0.0874674
0.0874674
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.229652,0.115068
0.115068
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,0.18791,0.075931
0.075931
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,0.198184,0.0836003
0.0836003
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.075931
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.419188 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.13548,0.0449805
gpu_array,512,8,1,20,2,false,false,true,false,1.12387,0.0431445
gpu_array,512,8,1,20,4,false,false,true,false,1.12583,0.0418457
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.13892,0.0445182
gpu_sparse,512,8,1,20,2,false,false,true,false,1.15141,0.0433366
gpu_sparse,512,8,1,20,4,false,false,true,false,1.11405,0.0424316
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.17268,0.0554948
gpu_reorg,512,8,1,20,2,false,false,true,false,1.15985,0.050472
gpu_reorg,512,8,1,20,4,false,false,true,false,1.15779,0.0477637
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.13701,0.0458659
gpu_array,512,8,1,50,2,false,false,true,false,1.15506,0.0495866
gpu_array,512,8,1,50,4,false,false,true,false,1.15042,0.0495052
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.15205,0.0472298
gpu_sparse,512,8,1,50,2,false,false,true,false,1.16538,0.054707
gpu_sparse,512,8,1,50,4,false,false,true,false,1.14251,0.0552734
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.17465,0.0496452
gpu_reorg,512,8,1,50,2,false,false,true,false,1.16074,0.0546191
gpu_reorg,512,8,1,50,4,false,false,true,false,1.1653,0.0546224
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.16447,0.0466341
gpu_array,512,32,1,20,2,false,false,true,false,1.15026,0.0441374
gpu_array,512,32,1,20,4,false,false,true,false,1.13488,0.0424316
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.15877,0.0467871
gpu_sparse,512,32,1,20,2,false,false,true,false,1.14348,0.0445215
gpu_sparse,512,32,1,20,4,false,false,true,false,1.12928,0.0439974
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.17,0.0567187
gpu_reorg,512,32,1,20,2,false,false,true,false,1.15666,0.0518457
gpu_reorg,512,32,1,20,4,false,false,true,false,1.15607,0.0493001
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.13816,0.0424544
0.0424544
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.13304,0.0425456
0.0425456
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.12177,0.042347
0.042347
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0418457
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.146305 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,1.13883,0.0450814
gpu_array,512,8,1,20,2,false,false,true,false,1.13453,0.0433887
gpu_array,512,8,1,20,4,false,false,true,false,1.13424,0.0417871
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,1.1173,0.0443848
gpu_sparse,512,8,1,20,2,false,false,true,false,1.12459,0.0432096
gpu_sparse,512,8,1,20,4,false,false,true,false,1.12181,0.0423861
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,1.17779,0.0547461
gpu_reorg,512,8,1,20,2,false,false,true,false,1.18982,0.050498
gpu_reorg,512,8,1,20,4,false,false,true,false,1.17211,0.0477637
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,1.14222,0.0458626
gpu_array,512,8,1,50,2,false,false,true,false,1.14453,0.0494759
gpu_array,512,8,1,50,4,false,false,true,false,1.1393,0.0494531
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,1.14067,0.0469238
gpu_sparse,512,8,1,50,2,false,false,true,false,1.16631,0.0543262
gpu_sparse,512,8,1,50,4,false,false,true,false,1.13789,0.054554
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,1.16761,0.0491243
gpu_reorg,512,8,1,50,2,false,false,true,false,1.1661,0.0547689
gpu_reorg,512,8,1,50,4,false,false,true,false,1.18832,0.05486
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,1.15,0.0464811
gpu_array,512,32,1,20,2,false,false,true,false,1.13394,0.0440918
gpu_array,512,32,1,20,4,false,false,true,false,1.15102,0.0422949
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,1.1382,0.0463997
gpu_sparse,512,32,1,20,2,false,false,true,false,1.14457,0.0443066
gpu_sparse,512,32,1,20,4,false,false,true,false,1.15981,0.0445801
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,1.1765,0.0567122
gpu_reorg,512,32,1,20,2,false,false,true,false,1.16864,0.0520996
gpu_reorg,512,32,1,20,4,false,false,true,false,1.17247,0.0494206
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,1.13656,0.042806
0.042806
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,1.12799,0.0427051
0.0427051
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,1.11816,0.0426367
0.0426367
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0417871
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.146138 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.134378,0.0328158
gpu_array,512,8,1,20,2,true,false,true,false,0.124561,0.0301595
gpu_array,512,8,1,20,4,true,false,true,false,0.125218,0.0269108
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.121413,0.0328711
gpu_sparse,512,8,1,20,2,true,false,true,false,0.128402,0.0281413
gpu_sparse,512,8,1,20,4,true,false,true,false,0.126025,0.0277181
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.158659,0.0421224
gpu_reorg,512,8,1,20,2,true,false,true,false,0.156159,0.0324609
gpu_reorg,512,8,1,20,4,true,false,true,false,0.150391,0.03125
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.123073,0.0286719
gpu_array,512,8,1,50,2,true,false,true,false,0.120169,0.0296745
gpu_array,512,8,1,50,4,true,false,true,false,0.121361,0.0295638
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.119993,0.0288477
gpu_sparse,512,8,1,50,2,true,false,true,false,0.126357,0.0345605
gpu_sparse,512,8,1,50,4,true,false,true,false,0.124587,0.0347428
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.15724,0.0354948
gpu_reorg,512,8,1,50,2,true,false,true,false,0.159186,0.0380924
gpu_reorg,512,8,1,50,4,true,false,true,false,0.158076,0.0382845
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.126377,0.0313249
gpu_array,512,32,1,20,2,true,false,true,false,0.130762,0.0285482
gpu_array,512,32,1,20,4,true,false,true,false,0.124919,0.0253092
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.122832,0.0310352
gpu_sparse,512,32,1,20,2,true,false,true,false,0.122432,0.0260775
gpu_sparse,512,32,1,20,4,true,false,true,false,0.130801,0.0259831
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.165589,0.0405892
gpu_reorg,512,32,1,20,2,true,false,true,false,0.155866,0.0308659
gpu_reorg,512,32,1,20,4,true,false,true,false,0.154596,0.0295964
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.107327,0.0246452
0.0246452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.11028,0.0262956
0.0262956
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.104235,0.025459
0.025459
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.107878,0.0258464
0.0258464
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.110684,0.0266992
0.0266992
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.107653,0.0269238
0.0269238
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0246452
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103176 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.130111,0.0331055
gpu_array,512,8,1,20,2,true,false,true,false,0.130013,0.0304036
gpu_array,512,8,1,20,4,true,false,true,false,0.123519,0.0271647
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.133997,0.0330859
gpu_sparse,512,8,1,20,2,true,false,true,false,0.133197,0.0283789
gpu_sparse,512,8,1,20,4,true,false,true,false,0.121488,0.0277376
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.172435,0.0422266
gpu_reorg,512,8,1,20,2,true,false,true,false,0.16362,0.0327604
gpu_reorg,512,8,1,20,4,true,false,true,false,0.155075,0.031377
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.110794,0.028763
gpu_array,512,8,1,50,2,true,false,true,false,0.120055,0.0295605
gpu_array,512,8,1,50,4,true,false,true,false,0.12112,0.0293229
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.118822,0.0289779
gpu_sparse,512,8,1,50,2,true,false,true,false,0.12499,0.0344954
gpu_sparse,512,8,1,50,4,true,false,true,false,0.119033,0.0343978
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.149307,0.0353743
gpu_reorg,512,8,1,50,2,true,false,true,false,0.159036,0.0379427
gpu_reorg,512,8,1,50,4,true,false,true,false,0.153864,0.0379785
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.126198,0.0311458
gpu_array,512,32,1,20,2,true,false,true,false,0.1261,0.028444
gpu_array,512,32,1,20,4,true,false,true,false,0.115195,0.0253516
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.131416,0.0311556
gpu_sparse,512,32,1,20,2,true,false,true,false,0.123952,0.0262956
gpu_sparse,512,32,1,20,4,true,false,true,false,0.124225,0.025918
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.172106,0.0405957
gpu_reorg,512,32,1,20,2,true,false,true,false,0.154681,0.0309831
gpu_reorg,512,32,1,20,4,true,false,true,false,0.159036,0.0294792
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,0.104163,0.0247363
0.0247363
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,0.101136,0.0262663
0.0262663
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,0.106764,0.0253841
0.0253841
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,0.107454,0.0260742
0.0260742
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,0.111273,0.0266374
0.0266374
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,0.116064,0.0268717
0.0268717
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0247363
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103259 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,4.15353,3.884
gpu_array,512,8,1,20,2,true,false,true,false,7.98133,7.6799
gpu_array,512,8,1,20,4,true,false,true,false,7.46893,7.21958
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.69204,3.4479
gpu_sparse,512,8,1,20,2,true,false,true,false,7.80466,7.5449
gpu_sparse,512,8,1,20,4,true,false,true,false,5.51018,5.25107
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.5943,4.3137
gpu_reorg,512,8,1,20,2,true,false,true,false,5.91533,5.62822
gpu_reorg,512,8,1,20,4,true,false,true,false,5.41251,5.11954
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.79456,3.5068
gpu_array,512,8,1,50,2,true,false,true,false,4.58423,4.2828
gpu_array,512,8,1,50,4,true,false,true,false,9.09979,8.80422
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.64546,3.34142
gpu_sparse,512,8,1,50,2,true,false,true,false,4.61064,4.30921
gpu_sparse,512,8,1,50,4,true,false,true,false,8.06604,7.76526
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.96257,3.65202
gpu_reorg,512,8,1,50,2,true,false,true,false,8.49853,8.16975
gpu_reorg,512,8,1,50,4,true,false,true,false,9.50629,9.18467
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.17835,3.92184
gpu_array,512,32,1,20,2,true,false,true,false,3.68316,3.40582
gpu_array,512,32,1,20,4,true,false,true,false,3.74546,3.48309
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.62065,3.36154
gpu_sparse,512,32,1,20,2,true,false,true,false,3.62671,3.37345
gpu_sparse,512,32,1,20,4,true,false,true,false,3.72738,3.47283
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.53385,4.25
gpu_reorg,512,32,1,20,2,true,false,true,false,4.50026,4.20794
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.64168,2.54663
2.54663
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.85219,2.75714
2.75714
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.18441,3.09066
3.09066
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.29884,3.21355
3.21355
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.54663
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 151 seconds of which 3.69125 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,3.9848,3.70421
gpu_array,512,8,1,20,2,true,false,true,false,7.93561,7.65306
gpu_array,512,8,1,20,4,true,false,true,false,7.44361,7.19296
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,3.68931,3.44517
gpu_sparse,512,8,1,20,2,true,false,true,false,7.82102,7.53846
gpu_sparse,512,8,1,20,4,true,false,true,false,5.4663,5.2124
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,4.59874,4.32204
gpu_reorg,512,8,1,20,2,true,false,true,false,5.95635,5.67185
gpu_reorg,512,8,1,20,4,true,false,true,false,5.2851,4.99604
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,3.68898,3.39406
gpu_array,512,8,1,50,2,true,false,true,false,4.52695,4.22031
gpu_array,512,8,1,50,4,true,false,true,false,9.16754,8.87457
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,3.42943,3.14948
gpu_sparse,512,8,1,50,2,true,false,true,false,4.54495,4.24286
gpu_sparse,512,8,1,50,4,true,false,true,false,8.20621,7.90934
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,3.97017,3.66158
gpu_reorg,512,8,1,50,2,true,false,true,false,8.30018,7.98247
gpu_reorg,512,8,1,50,4,true,false,true,false,9.5299,9.22195
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,4.16422,3.91357
gpu_array,512,32,1,20,2,true,false,true,false,3.59169,3.34365
gpu_array,512,32,1,20,4,true,false,true,false,3.89001,3.62113
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,3.61203,3.37635
gpu_sparse,512,32,1,20,2,true,false,true,false,3.70895,3.45634
gpu_sparse,512,32,1,20,4,true,false,true,false,3.62743,3.37092
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,4.53595,4.26642
gpu_reorg,512,32,1,20,2,true,false,true,false,4.51529,4.23729
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,2.63486,2.5398
2.5398
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,2.741,2.65116
2.65116
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,3.09276,3.00096
3.00096
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,3.31917,3.22477
3.22477
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.5398
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 156 seconds of which 3.67092 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.162562,0.0317025
gpu_array,512,8,1,20,2,true,false,true,false,0.182288,0.0559863
gpu_array,512,8,1,20,4,true,false,true,false,0.177702,0.039681
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.156517,0.0315169
gpu_sparse,512,8,1,20,2,true,false,true,false,0.174785,0.047181
gpu_sparse,512,8,1,20,4,true,false,true,false,0.173415,0.0451595
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.202803,0.0393913
gpu_reorg,512,8,1,20,2,true,false,true,false,0.21804,0.0604883
gpu_reorg,512,8,1,20,4,true,false,true,false,0.204772,0.0491732
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.151559,0.0291634
gpu_array,512,8,1,50,2,true,false,true,false,0.172643,0.0424349
gpu_array,512,8,1,50,4,true,false,true,false,0.165495,0.0424479
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.156543,0.0289388
gpu_sparse,512,8,1,50,2,true,false,true,false,0.183525,0.0448535
gpu_sparse,512,8,1,50,4,true,false,true,false,0.16334,0.0448503
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.191198,0.035599
gpu_reorg,512,8,1,50,2,true,false,true,false,0.190439,0.0472103
gpu_reorg,512,8,1,50,4,true,false,true,false,0.197516,0.0471257
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.169336,0.0306641
gpu_array,512,32,1,20,2,true,false,true,false,0.165365,0.0292969
gpu_array,512,32,1,20,4,true,false,true,false,0.156702,0.0304004
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.161058,0.0295475
gpu_sparse,512,32,1,20,2,true,false,true,false,0.15791,0.0263997
gpu_sparse,512,32,1,20,4,true,false,true,false,0.156855,0.0292513
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.198079,0.0379232
gpu_reorg,512,32,1,20,2,true,false,true,false,0.187526,0.0351823
gpu_reorg,512,32,1,20,4,true,false,true,false,0.198942,0.0387858
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.138577,0.0252962
0.0252962
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.152881,0.029834
0.029834
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.137943,0.0253125
0.0253125
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.155908,0.0263509
0.0263509
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.155752,0.030752
0.030752
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.147881,0.0319954
0.0319954
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0252962
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.124917 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,0.175273,0.0320443
gpu_array,512,8,1,20,2,true,false,true,false,0.187461,0.0559505
gpu_array,512,8,1,20,4,true,false,true,false,0.179714,0.0397396
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,0.159339,0.031735
gpu_sparse,512,8,1,20,2,true,false,true,false,0.186634,0.0473112
gpu_sparse,512,8,1,20,4,true,false,true,false,0.183454,0.0454329
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,0.185791,0.0399577
gpu_reorg,512,8,1,20,2,true,false,true,false,0.226836,0.0608203
gpu_reorg,512,8,1,20,4,true,false,true,false,0.208102,0.049248
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,0.155156,0.0295052
gpu_array,512,8,1,50,2,true,false,true,false,0.177174,0.0424089
gpu_array,512,8,1,50,4,true,false,true,false,0.180426,0.0424056
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,0.156097,0.0291439
gpu_sparse,512,8,1,50,2,true,false,true,false,0.175944,0.0450846
gpu_sparse,512,8,1,50,4,true,false,true,false,0.177174,0.045013
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,0.190872,0.0359245
gpu_reorg,512,8,1,50,2,true,false,true,false,0.198311,0.0472689
gpu_reorg,512,8,1,50,4,true,false,true,false,0.198249,0.047207
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,0.165645,0.0308789
gpu_array,512,32,1,20,2,true,false,true,false,0.16112,0.0296094
gpu_array,512,32,1,20,4,true,false,true,false,0.165423,0.0306576
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,0.167715,0.029694
gpu_sparse,512,32,1,20,2,true,false,true,false,0.161416,0.0266504
gpu_sparse,512,32,1,20,4,true,false,true,false,0.162233,0.0294206
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,0.194326,0.0380762
gpu_reorg,512,32,1,20,2,true,false,true,false,0.190176,0.0352279
gpu_reorg,512,32,1,20,4,true,false,true,false,0.198522,0.0390169
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,true,0.149167,0.0254687
0.0254687
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,true,0.152419,0.0300228
0.0300228
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,0.14849,0.0254427
0.0254427
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,0.151227,0.0262272
0.0262272
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,0.153721,0.0306738
0.0306738
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,0.162031,0.0318229
0.0318229
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0254427
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.125449 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
