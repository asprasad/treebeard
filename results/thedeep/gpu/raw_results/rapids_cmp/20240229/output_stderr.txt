abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.402706,0.249805
gpu_array,256,8,1,20,2,true,false,true,0.289944,0.167734
gpu_array,256,8,1,20,4,true,false,true,0.284986,0.156638
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.366164,0.246744
gpu_sparse,256,8,1,20,2,true,false,true,0.261621,0.134947
gpu_sparse,256,8,1,20,4,true,false,true,0.289802,0.16257
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.438052,0.301892
gpu_reorg,256,8,1,20,2,true,false,true,0.302461,0.16072
gpu_reorg,256,8,1,20,4,true,false,true,0.265809,0.127416
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.2669,0.124601
gpu_array,256,8,1,50,2,true,false,true,0.230357,0.0986607
gpu_array,256,8,1,50,4,true,false,true,0.231526,0.0987137
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.27082,0.135218
gpu_sparse,256,8,1,50,2,true,false,true,0.250229,0.114068
gpu_sparse,256,8,1,50,4,true,false,true,0.261401,0.117985
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.306376,0.176353
gpu_reorg,256,8,1,50,2,true,false,true,0.259247,0.111367
gpu_reorg,256,8,1,50,4,true,false,true,0.242983,0.105148
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.37459,0.251264
gpu_array,256,32,1,20,2,true,false,true,0.297511,0.171395
gpu_array,256,32,1,20,4,true,false,true,0.293862,0.164955
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.373962,0.24952
gpu_sparse,256,32,1,20,2,true,false,true,0.268117,0.148697
gpu_sparse,256,32,1,20,4,true,false,true,0.292533,0.17144
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.454648,0.319604
gpu_reorg,256,32,1,20,2,true,false,true,0.32714,0.184283
gpu_reorg,256,32,1,20,4,true,false,true,0.312893,0.16334
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,0.203931,0.0951144
0.0951144
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,0.236219,0.116242
0.116242
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.295502,0.183895
0.183895
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.282871,0.176286
0.176286
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.282553,0.179874
0.179874
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.269431,0.171775
0.171775
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.0951144
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 13 seconds of which 0.283559 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.191744,0.0583733
gpu_array,256,8,1,20,2,true,false,true,0.178337,0.052779
gpu_array,256,8,1,20,4,true,false,true,0.167383,0.044615
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.185806,0.0580162
gpu_sparse,256,8,1,20,2,true,false,true,0.169021,0.0473689
gpu_sparse,256,8,1,20,4,true,false,true,0.169104,0.0452204
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.215064,0.071649
gpu_reorg,256,8,1,20,2,true,false,true,0.207673,0.0553292
gpu_reorg,256,8,1,20,4,true,false,true,0.202586,0.0524749
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.176696,0.0505804
gpu_array,256,8,1,50,2,true,false,true,0.174026,0.045678
gpu_array,256,8,1,50,4,true,false,true,0.174992,0.0460854
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.17305,0.0497238
gpu_sparse,256,8,1,50,2,true,false,true,0.183211,0.0476088
gpu_sparse,256,8,1,50,4,true,false,true,0.172556,0.0475558
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.207799,0.058245
gpu_reorg,256,8,1,50,2,true,false,true,0.199381,0.0509431
gpu_reorg,256,8,1,50,4,true,false,true,0.204891,0.0508733
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.183694,0.0603683
gpu_array,256,32,1,20,2,true,false,true,0.1819,0.0541099
gpu_array,256,32,1,20,4,true,false,true,0.165991,0.0460128
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.187227,0.0594364
gpu_sparse,256,32,1,20,2,true,false,true,0.177419,0.0485128
gpu_sparse,256,32,1,20,4,true,false,true,0.167489,0.0480692
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.23618,0.076024
gpu_reorg,256,32,1,20,2,true,false,true,0.206035,0.0553655
gpu_reorg,256,32,1,20,4,true,false,true,0.20793,0.0505636
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.151922,0.0453376
0.0453376
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.147185,0.0467383
0.0467383
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,0.153577,0.044202
0.044202
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,0.157213,0.0439314
0.0439314
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.168496,0.0446122
0.0446122
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.147458,0.0464537
0.0464537
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.0439314
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.0871863 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.77918,0.31043
gpu_array,256,8,1,20,2,true,false,true,0.715463,0.239459
gpu_array,256,8,1,20,4,true,false,true,0.694796,0.223256
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,1.13574,0.328259
gpu_sparse,256,8,1,20,2,true,false,true,0.623831,0.158429
gpu_sparse,256,8,1,20,4,true,false,true,0.698672,0.214855
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.89498,0.404467
gpu_reorg,256,8,1,20,2,true,false,true,0.703284,0.211097
gpu_reorg,256,8,1,20,4,true,false,true,0.691922,0.199177
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.651532,0.182224
gpu_array,256,8,1,50,2,true,false,true,0.61769,0.140011
gpu_array,256,8,1,50,4,true,false,true,0.588284,0.119534
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.978499,0.181066
gpu_sparse,256,8,1,50,2,true,false,true,0.60983,0.122665
gpu_sparse,256,8,1,50,4,true,false,true,0.601998,0.130458
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.692224,0.216219
gpu_reorg,256,8,1,50,2,true,false,true,0.614713,0.128105
gpu_reorg,256,8,1,50,4,true,false,true,0.611864,0.12135
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,0.554551,0.0997517
0.0997517
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,0.59815,0.142235
0.142235
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.71356,0.253181
0.253181
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.729314,0.279537
0.279537
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 0.0997517
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 22 seconds of which 0.225575 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.400045,0.252723
gpu_array,256,8,1,20,2,true,false,true,0.303717,0.160301
gpu_array,256,8,1,20,4,true,false,true,0.278993,0.13781
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.379849,0.241456
gpu_sparse,256,8,1,20,2,true,false,true,0.328432,0.176088
gpu_sparse,256,8,1,20,4,true,false,true,0.31255,0.166903
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.481549,0.331437
gpu_reorg,256,8,1,20,2,true,false,true,0.353234,0.202006
gpu_reorg,256,8,1,20,4,true,false,true,0.336705,0.189941
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.606699,0.189289
gpu_array,256,8,1,50,2,true,false,true,0.637017,0.166035
gpu_array,256,8,1,50,4,true,false,true,0.585287,0.171783
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.317397,0.181236
gpu_sparse,256,8,1,50,2,true,false,true,0.596387,0.17786
gpu_sparse,256,8,1,50,4,true,false,true,0.589688,0.171719
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.359807,0.205232
gpu_reorg,256,8,1,50,2,true,false,true,0.330711,0.175578
gpu_reorg,256,8,1,50,4,true,false,true,0.312522,0.167433
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.417188,0.264286
gpu_array,256,32,1,20,2,true,false,true,0.322815,0.167681
gpu_array,256,32,1,20,4,true,false,true,0.307121,0.154777
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.385226,0.233998
gpu_sparse,256,32,1,20,2,true,false,true,0.336189,0.188309
gpu_sparse,256,32,1,20,4,true,false,true,0.332958,0.183962
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.427531,0.290254
gpu_reorg,256,32,1,20,2,true,false,true,0.354601,0.199467
gpu_reorg,256,32,1,20,4,true,false,true,0.342257,0.1994
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.292427,0.154035
0.154035
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.309132,0.175204
0.175204
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.29594,0.171498
0.171498
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.346839,0.219607
0.219607
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,0.248775,0.115963
0.115963
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,0.281727,0.148915
0.148915
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 0.115963
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 18 seconds of which 0.324208 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,1.36175,0.0782673
gpu_array,256,8,1,20,2,false,false,true,1.34785,0.0716183
gpu_array,256,8,1,20,4,false,false,true,1.33848,0.0572266
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,1.36681,0.0777483
gpu_sparse,256,8,1,20,2,false,false,true,1.35554,0.0709431
gpu_sparse,256,8,1,20,4,false,false,true,1.34846,0.0621875
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,1.41554,0.0835045
gpu_reorg,256,8,1,20,2,false,false,true,1.40383,0.0762612
gpu_reorg,256,8,1,20,4,false,false,true,1.41489,0.0672377
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,1.34691,0.0634263
gpu_array,256,8,1,50,2,false,false,true,1.34105,0.0592439
gpu_array,256,8,1,50,4,false,false,true,1.33755,0.0590932
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,1.3604,0.0646429
gpu_sparse,256,8,1,50,2,false,false,true,1.36222,0.0731557
gpu_sparse,256,8,1,50,4,false,false,true,1.37336,0.0736998
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,1.5149,0.0690262
gpu_reorg,256,8,1,50,2,false,false,true,1.39703,0.0644364
gpu_reorg,256,8,1,50,4,false,false,true,1.38392,0.064721
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,1.38231,0.0843192
gpu_array,256,32,1,20,2,false,false,true,1.36707,0.0791211
gpu_array,256,32,1,20,4,false,false,true,1.35144,0.071861
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,1.37267,0.0836077
gpu_sparse,256,32,1,20,2,false,false,true,1.36903,0.0788477
gpu_sparse,256,32,1,20,4,false,false,true,1.48971,0.0739704
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,1.43787,0.089654
gpu_reorg,256,32,1,20,2,false,false,true,1.40304,0.0816099
gpu_reorg,256,32,1,20,4,false,false,true,1.39462,0.0748633
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,1.32939,0.0570647
0.0570647
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,1.31725,0.0549693
0.0549693
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,1.33606,0.0704381
0.0704381
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.0549693
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.109402 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.20091,0.0608426
gpu_array,256,8,1,20,2,true,false,true,0.191281,0.0545619
gpu_array,256,8,1,20,4,true,false,true,0.184062,0.0462277
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.20334,0.0604827
gpu_sparse,256,8,1,20,2,true,false,true,0.193943,0.0510854
gpu_sparse,256,8,1,20,4,true,false,true,0.201917,0.048457
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.236889,0.0789648
gpu_reorg,256,8,1,20,2,true,false,true,0.221381,0.0578767
gpu_reorg,256,8,1,20,4,true,false,true,0.216462,0.0540737
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.185873,0.0525028
gpu_array,256,8,1,50,2,true,false,true,0.182896,0.0484096
gpu_array,256,8,1,50,4,true,false,true,0.190854,0.0485547
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.199791,0.0519113
gpu_sparse,256,8,1,50,2,true,false,true,0.184403,0.0482422
gpu_sparse,256,8,1,50,4,true,false,true,0.176532,0.0481836
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.223602,0.0600977
gpu_reorg,256,8,1,50,2,true,false,true,0.221833,0.0521903
gpu_reorg,256,8,1,50,4,true,false,true,0.214721,0.0528906
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.200045,0.0622098
gpu_array,256,32,1,20,2,true,false,true,0.201911,0.0557059
gpu_array,256,32,1,20,4,true,false,true,0.180343,0.0486468
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.207288,0.0616406
gpu_sparse,256,32,1,20,2,true,false,true,0.183658,0.0502874
gpu_sparse,256,32,1,20,4,true,false,true,0.188292,0.0498996
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.246384,0.0784152
gpu_reorg,256,32,1,20,2,true,false,true,0.21865,0.0584933
gpu_reorg,256,32,1,20,4,true,false,true,0.216071,0.0547991
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,0.171403,0.0469615
0.0469615
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,0.172414,0.0485296
0.0485296
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,0.165399,0.0454213
0.0454213
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,0.17207,0.0453962
0.0453962
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,0.169562,0.0473521
0.0473521
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,0.175,0.050558
0.050558
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.0453962
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.0911294 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,6.51033,6.36636
gpu_array,256,8,1,20,2,true,false,true,14.3589,14.2126
gpu_array,256,8,1,20,4,true,false,true,13.5151,13.3829
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,6.18173,6.03162
gpu_sparse,256,8,1,20,2,true,false,true,13.9673,13.8278
gpu_sparse,256,8,1,20,4,true,false,true,9.70992,9.57432
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,7.4178,7.27215
gpu_reorg,256,8,1,20,2,true,false,true,11.0568,10.8967
gpu_reorg,256,8,1,20,4,true,false,true,8.19328,8.03647
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,4.39958,3.96542
gpu_array,256,8,1,50,2,true,false,true,7.90333,7.44964
gpu_array,256,8,1,50,4,true,false,true,9.00086,8.56615
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,4.0642,3.64344
gpu_sparse,256,8,1,50,2,true,false,true,7.66831,7.23193
gpu_sparse,256,8,1,50,4,true,false,true,8.03051,7.58632
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,5.03353,4.60775
gpu_reorg,256,8,1,50,2,true,false,true,8.06881,7.6341
gpu_reorg,256,8,1,50,4,true,false,true,11.6834,11.2431
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,6.78868,6.6542
gpu_array,256,32,1,20,2,true,false,true,5.62172,5.48779
gpu_array,256,32,1,20,4,true,false,true,6.19017,6.0568
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,6.08261,5.94087
gpu_sparse,256,32,1,20,2,true,false,true,5.65662,5.52325
gpu_sparse,256,32,1,20,4,true,false,true,5.58231,5.45396
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,7.64971,7.51076
gpu_reorg,256,32,1,20,2,true,false,true,6.66268,6.52205
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,2.92246,2.79299
2.79299
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,3.01424,2.87696
2.87696
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,5.96395,5.83002
5.83002
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,6.2617,6.13558
6.13558
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 2.79299
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 165 seconds of which 2.79442 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,0.266158,0.0585686
gpu_array,256,8,1,20,2,true,false,true,0.277319,0.10377
gpu_array,256,8,1,20,4,true,false,true,0.275854,0.0727288
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,0.260714,0.0575893
gpu_sparse,256,8,1,20,2,true,false,true,0.304941,0.0928878
gpu_sparse,256,8,1,20,4,true,false,true,0.263468,0.0876869
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,0.295335,0.0754688
gpu_reorg,256,8,1,20,2,true,false,true,0.323767,0.117294
gpu_reorg,256,8,1,20,4,true,false,true,0.312776,0.0940262
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,0.261353,0.0554381
gpu_array,256,8,1,50,2,true,false,true,0.283772,0.0795312
gpu_array,256,8,1,50,4,true,false,true,0.296423,0.0799051
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,0.239129,0.0538616
gpu_sparse,256,8,1,50,2,true,false,true,0.265539,0.0808287
gpu_sparse,256,8,1,50,4,true,false,true,0.267846,0.0797879
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,0.26123,0.0642439
gpu_reorg,256,8,1,50,2,true,false,true,0.32613,0.0895229
gpu_reorg,256,8,1,50,4,true,false,true,0.288954,0.0891769
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,0.242093,0.060731
gpu_array,256,32,1,20,2,true,false,true,0.259088,0.0581948
gpu_array,256,32,1,20,4,true,false,true,0.246917,0.0560686
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,0.267899,0.0591936
gpu_sparse,256,32,1,20,2,true,false,true,0.2407,0.0515262
gpu_sparse,256,32,1,20,4,true,false,true,0.244855,0.0545647
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,0.277508,0.0749414
gpu_reorg,256,32,1,20,2,true,false,true,0.29483,0.0626869
gpu_reorg,256,32,1,20,4,true,false,true,0.30947,0.0678404
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,true,false,true,0.23459,0.049322
0.049322
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,32,1,20,2,false,false,true,0.249425,0.059135
0.059135
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,true,false,false,0.22416,0.0478209
0.0478209
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,50,-1,false,false,false,0.244169,0.048298
0.048298
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,0.233256,0.059707
0.059707
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,0.253435,0.0620285
0.0620285
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.0478209
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 16 seconds of which 0.117984 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.209206,0.126523
gpu_array,512,8,1,20,2,true,false,true,0.167995,0.0853125
gpu_array,512,8,1,20,4,true,false,true,0.162601,0.0805697
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.213906,0.126016
gpu_sparse,512,8,1,20,2,true,false,true,0.162581,0.079248
gpu_sparse,512,8,1,20,4,true,false,true,0.175042,0.091709
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.268444,0.164277
gpu_reorg,512,8,1,20,2,true,false,true,0.182559,0.0881576
gpu_reorg,512,8,1,20,4,true,false,true,0.16834,0.0726367
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.145042,0.0721257
gpu_array,512,8,1,50,2,true,false,true,0.138945,0.0627734
gpu_array,512,8,1,50,4,true,false,true,0.145713,0.0656348
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.146878,0.0759147
gpu_sparse,512,8,1,50,2,true,false,true,0.164785,0.0768945
gpu_sparse,512,8,1,50,4,true,false,true,0.160023,0.0760384
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.190599,0.0916406
gpu_reorg,512,8,1,50,2,true,false,true,0.164421,0.0628581
gpu_reorg,512,8,1,50,4,true,false,true,0.183991,0.0882878
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.202467,0.125645
gpu_array,512,32,1,20,2,true,false,true,0.169365,0.0860319
gpu_array,512,32,1,20,4,true,false,true,0.166868,0.0822331
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.207285,0.125254
gpu_sparse,512,32,1,20,2,true,false,true,0.156751,0.0747201
gpu_sparse,512,32,1,20,4,true,false,true,0.170677,0.0860417
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.262617,0.159753
gpu_reorg,512,32,1,20,2,true,false,true,0.189414,0.0924089
gpu_reorg,512,32,1,20,4,true,false,true,0.193125,0.0817969
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,0.125996,0.0595898
0.0595898
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,0.128405,0.0633008
0.0633008
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.156709,0.0935579
0.0935579
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.160879,0.0899154
0.0899154
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.163698,0.0901302
0.0901302
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.157256,0.0869434
0.0869434
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.0595898
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.305555 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.118317,0.0323796
gpu_array,512,8,1,20,2,true,false,true,0.112012,0.0299805
gpu_array,512,8,1,20,4,true,false,true,0.11111,0.0264746
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.114479,0.0324479
gpu_sparse,512,8,1,20,2,true,false,true,0.112038,0.0280534
gpu_sparse,512,8,1,20,4,true,false,true,0.114867,0.027627
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.153838,0.0399056
gpu_reorg,512,8,1,20,2,true,false,true,0.136468,0.0303483
gpu_reorg,512,8,1,20,4,true,false,true,0.14126,0.0292806
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.11251,0.0278743
gpu_array,512,8,1,50,2,true,false,true,0.113939,0.0266992
gpu_array,512,8,1,50,4,true,false,true,0.120514,0.0267643
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.11389,0.0286035
gpu_sparse,512,8,1,50,2,true,false,true,0.127308,0.03486
gpu_sparse,512,8,1,50,4,true,false,true,0.131292,0.0349382
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.138249,0.033431
gpu_reorg,512,8,1,50,2,true,false,true,0.146058,0.0308236
gpu_reorg,512,8,1,50,4,true,false,true,0.141322,0.0306445
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.116846,0.0309082
gpu_array,512,32,1,20,2,true,false,true,0.122874,0.0278223
gpu_array,512,32,1,20,4,true,false,true,0.108574,0.0239388
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.119564,0.0303711
gpu_sparse,512,32,1,20,2,true,false,true,0.115547,0.0250521
gpu_sparse,512,32,1,20,4,true,false,true,0.108672,0.0246875
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.142601,0.0384342
gpu_reorg,512,32,1,20,2,true,false,true,0.137308,0.029235
gpu_reorg,512,32,1,20,4,true,false,true,0.136732,0.0273568
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.093584,0.0232715
0.0232715
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.0978255,0.0242578
0.0242578
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.0941699,0.0245085
0.0245085
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.0935677,0.0252083
0.0252083
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,0.095485,0.0245215
0.0245215
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,0.0991667,0.025599
0.025599
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.0232715
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.097926 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.566045,0.157191
gpu_array,512,8,1,20,2,true,false,true,0.532705,0.130361
gpu_array,512,8,1,20,4,true,false,true,0.527988,0.121738
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.769736,0.166221
gpu_sparse,512,8,1,20,2,true,false,true,0.482155,0.0882747
gpu_sparse,512,8,1,20,4,true,false,true,0.522432,0.109671
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.78513,0.193333
gpu_reorg,512,8,1,20,2,true,false,true,0.70541,0.11166
gpu_reorg,512,8,1,20,4,true,false,true,0.708776,0.107214
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.496572,0.0981348
gpu_array,512,8,1,50,2,true,false,true,0.479014,0.0753678
gpu_array,512,8,1,50,4,true,false,true,0.476533,0.0728874
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.667002,0.0999447
gpu_sparse,512,8,1,50,2,true,false,true,0.512995,0.0924219
gpu_sparse,512,8,1,50,4,true,false,true,0.494876,0.0879753
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.6996,0.111709
gpu_reorg,512,8,1,50,2,true,false,true,0.685495,0.080026
gpu_reorg,512,8,1,50,4,true,false,true,0.71791,0.100723
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,0.474632,0.0801009
0.0801009
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,0.49234,0.0997624
0.0997624
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.533818,0.128219
0.128219
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.558691,0.155046
0.155046
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.0728874
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.252721 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.254232,0.135742
gpu_array,512,8,1,20,2,true,false,true,0.227422,0.0972135
gpu_array,512,8,1,20,4,true,false,true,0.213717,0.0932747
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.262061,0.139014
gpu_sparse,512,8,1,20,2,true,false,true,0.230283,0.107887
gpu_sparse,512,8,1,20,4,true,false,true,0.240371,0.110814
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.291416,0.17488
gpu_reorg,512,8,1,20,2,true,false,true,0.240085,0.120944
gpu_reorg,512,8,1,20,4,true,false,true,0.239222,0.117477
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.354548,0.114964
gpu_array,512,8,1,50,2,true,false,true,0.347822,0.112145
gpu_array,512,8,1,50,4,true,false,true,0.362467,0.12679
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.225042,0.11111
gpu_sparse,512,8,1,50,2,true,false,true,0.349642,0.116569
gpu_sparse,512,8,1,50,4,true,false,true,0.362096,0.128372
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.239499,0.122311
gpu_reorg,512,8,1,50,2,true,false,true,0.244258,0.117305
gpu_reorg,512,8,1,50,4,true,false,true,0.273024,0.15193
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.333962,0.140602
gpu_array,512,32,1,20,2,true,false,true,0.227712,0.10792
gpu_array,512,32,1,20,4,true,false,true,0.230661,0.106312
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.258034,0.134336
gpu_sparse,512,32,1,20,2,true,false,true,0.238727,0.111774
gpu_sparse,512,32,1,20,4,true,false,true,0.22834,0.115059
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.278112,0.156367
gpu_reorg,512,32,1,20,2,true,false,true,0.24666,0.12752
gpu_reorg,512,32,1,20,4,true,false,true,0.254183,0.128532
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.19891,0.0862793
0.0862793
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.196143,0.0906738
0.0906738
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.198548,0.085918
0.085918
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.229945,0.11471
0.11471
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,0.191087,0.0725977
0.0725977
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,0.190492,0.0811165
0.0811165
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.0725977
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.395106 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,1.1011,0.0451139
gpu_array,512,8,1,20,2,false,false,true,1.13177,0.0432292
gpu_array,512,8,1,20,4,false,false,true,1.10521,0.0420573
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,1.11235,0.0439941
gpu_sparse,512,8,1,20,2,false,false,true,1.12951,0.0435677
gpu_sparse,512,8,1,20,4,false,false,true,1.11421,0.0425944
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,1.16409,0.0553613
gpu_reorg,512,8,1,20,2,false,false,true,1.16247,0.0504948
gpu_reorg,512,8,1,20,4,false,false,true,1.15638,0.0476562
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,1.12423,0.0461003
gpu_array,512,8,1,50,2,false,false,true,1.13244,0.0497591
gpu_array,512,8,1,50,4,false,false,true,1.1283,0.0495215
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,1.12523,0.0464551
gpu_sparse,512,8,1,50,2,false,false,true,1.12161,0.0545573
gpu_sparse,512,8,1,50,4,false,false,true,1.12598,0.0543652
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,1.16271,0.0494303
gpu_reorg,512,8,1,50,2,false,false,true,1.14879,0.054388
gpu_reorg,512,8,1,50,4,false,false,true,1.15121,0.0542025
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,1.13425,0.0463607
gpu_array,512,32,1,20,2,false,false,true,1.13711,0.0440072
gpu_array,512,32,1,20,4,false,false,true,1.11333,0.0423698
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,1.1272,0.0464714
gpu_sparse,512,32,1,20,2,false,false,true,1.15101,0.0442383
gpu_sparse,512,32,1,20,4,false,false,true,1.11544,0.0438249
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,1.15948,0.0559668
gpu_reorg,512,32,1,20,2,false,false,true,1.15597,0.0518034
gpu_reorg,512,32,1,20,4,false,false,true,1.15956,0.0495345
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,1.10738,0.0422754
0.0422754
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,1.11789,0.0423698
0.0423698
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,1.10596,0.0421615
0.0421615
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.0420573
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.145841 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.128411,0.0333594
gpu_array,512,8,1,20,2,true,false,true,0.125524,0.030472
gpu_array,512,8,1,20,4,true,false,true,0.119346,0.0275488
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.117786,0.033151
gpu_sparse,512,8,1,20,2,true,false,true,0.119352,0.0288574
gpu_sparse,512,8,1,20,4,true,false,true,0.114183,0.0282454
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.166471,0.0414714
gpu_reorg,512,8,1,20,2,true,false,true,0.151924,0.0321322
gpu_reorg,512,8,1,20,4,true,false,true,0.149736,0.0305957
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.115628,0.0296908
gpu_array,512,8,1,50,2,true,false,true,0.112152,0.0314225
gpu_array,512,8,1,50,4,true,false,true,0.113356,0.0313249
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.112581,0.0298991
gpu_sparse,512,8,1,50,2,true,false,true,0.116784,0.0354036
gpu_sparse,512,8,1,50,4,true,false,true,0.121927,0.0353385
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.157646,0.0352507
gpu_reorg,512,8,1,50,2,true,false,true,0.151836,0.0366016
gpu_reorg,512,8,1,50,4,true,false,true,0.148577,0.0365983
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.118594,0.0313542
gpu_array,512,32,1,20,2,true,false,true,0.120254,0.028457
gpu_array,512,32,1,20,4,true,false,true,0.125133,0.0255241
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.127617,0.031263
gpu_sparse,512,32,1,20,2,true,false,true,0.119977,0.0262272
gpu_sparse,512,32,1,20,4,true,false,true,0.123477,0.0258203
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.160495,0.0400521
gpu_reorg,512,32,1,20,2,true,false,true,0.153975,0.0309277
gpu_reorg,512,32,1,20,4,true,false,true,0.14444,0.0292057
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,0.107904,0.0245703
0.0245703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,0.10584,0.0264128
0.0264128
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,0.105335,0.0259082
0.0259082
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,0.100977,0.0261068
0.0261068
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,0.104209,0.0273861
0.0273861
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,0.103577,0.0274056
0.0274056
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.0245703
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.103832 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,3.94939,3.85889
gpu_array,512,8,1,20,2,true,false,true,8.02668,7.92121
gpu_array,512,8,1,20,4,true,false,true,7.42104,7.32404
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,3.55931,3.46426
gpu_sparse,512,8,1,20,2,true,false,true,7.87089,7.77453
gpu_sparse,512,8,1,20,4,true,false,true,5.50484,5.40654
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,4.46423,4.36918
gpu_reorg,512,8,1,20,2,true,false,true,5.74115,5.65065
gpu_reorg,512,8,1,20,4,true,false,true,5.28311,5.19848
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,3.75995,3.47674
gpu_array,512,8,1,50,2,true,false,true,4.55609,4.27159
gpu_array,512,8,1,50,4,true,false,true,9.14099,8.8643
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,3.38797,3.11323
gpu_sparse,512,8,1,50,2,true,false,true,4.49512,4.21061
gpu_sparse,512,8,1,50,4,true,false,true,8.1201,7.84341
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,3.95467,3.66887
gpu_reorg,512,8,1,50,2,true,false,true,8.94113,8.64621
gpu_reorg,512,8,1,50,4,true,false,true,9.63725,9.33908
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,3.96035,3.86855
gpu_array,512,32,1,20,2,true,false,true,3.51751,3.42246
gpu_array,512,32,1,20,4,true,false,true,3.70427,3.60531
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,3.46689,3.37704
gpu_sparse,512,32,1,20,2,true,false,true,3.53961,3.45497
gpu_sparse,512,32,1,20,4,true,false,true,3.50538,3.41684
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,4.43486,4.34046
gpu_reorg,512,32,1,20,2,true,false,true,4.39444,4.3072
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,2.66921,2.58132
2.58132
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,2.76552,2.67958
2.67958
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,3.05495,2.96901
2.96901
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,3.23841,3.15052
3.15052
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 2.58132
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 151 seconds of which 3.72672 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,0.162373,0.0321647
gpu_array,512,8,1,20,2,true,false,true,0.185462,0.056556
gpu_array,512,8,1,20,4,true,false,true,0.169723,0.040166
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,0.161963,0.0317546
gpu_sparse,512,8,1,20,2,true,false,true,0.177301,0.0477441
gpu_sparse,512,8,1,20,4,true,false,true,0.173105,0.0455013
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,0.183815,0.0399349
gpu_reorg,512,8,1,20,2,true,false,true,0.216696,0.061097
gpu_reorg,512,8,1,20,4,true,false,true,0.196973,0.0504883
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,0.167497,0.030127
gpu_array,512,8,1,50,2,true,false,true,0.178555,0.043138
gpu_array,512,8,1,50,4,true,false,true,0.175257,0.0430957
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,0.1554,0.0297493
gpu_sparse,512,8,1,50,2,true,false,true,0.178854,0.0453906
gpu_sparse,512,8,1,50,4,true,false,true,0.181966,0.0452474
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,0.185378,0.0369401
gpu_reorg,512,8,1,50,2,true,false,true,0.198574,0.0488346
gpu_reorg,512,8,1,50,4,true,false,true,0.212165,0.0487533
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,0.15875,0.0311458
gpu_array,512,32,1,20,2,true,false,true,0.159492,0.0299349
gpu_array,512,32,1,20,4,true,false,true,0.160277,0.0307194
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,0.158307,0.0300521
gpu_sparse,512,32,1,20,2,true,false,true,0.157165,0.0269564
gpu_sparse,512,32,1,20,4,true,false,true,0.155186,0.0295345
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,0.190843,0.0384993
gpu_reorg,512,32,1,20,2,true,false,true,0.189736,0.0354395
gpu_reorg,512,32,1,20,4,true,false,true,0.193011,0.0406673
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,true,false,true,0.146787,0.0256934
0.0256934
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,2,false,false,true,0.151191,0.0300977
0.0300977
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,0.149382,0.0256836
0.0256836
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,0.144313,0.0264746
0.0264746
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,0.144749,0.0308171
0.0308171
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,0.147298,0.0320638
0.0320638
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.0256836
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.127023 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.12165,0.0669629
gpu_array,1024,8,1,20,2,true,false,true,0.106899,0.0502588
gpu_array,1024,8,1,20,4,true,false,true,0.103916,0.0492285
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.124658,0.0689941
gpu_sparse,1024,8,1,20,2,true,false,true,0.126152,0.0704883
gpu_sparse,1024,8,1,20,4,true,false,true,0.124863,0.0633398
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.175625,0.0848047
gpu_reorg,1024,8,1,20,2,true,false,true,0.141636,0.0498389
gpu_reorg,1024,8,1,20,4,true,false,true,0.14397,0.054126
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.1152,0.0634424
gpu_array,1024,8,1,50,2,true,false,true,0.106167,0.0553857
gpu_array,1024,8,1,50,4,true,false,true,0.106616,0.0568115
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.119307,0.0675488
gpu_sparse,1024,8,1,50,2,true,false,true,0.120469,0.0687109
gpu_sparse,1024,8,1,50,4,true,false,true,0.117422,0.0676172
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.168892,0.081001
gpu_reorg,1024,8,1,50,2,true,false,true,0.145601,0.0547803
gpu_reorg,1024,8,1,50,4,true,false,true,0.155566,0.0657227
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.12708,0.0694629
gpu_array,1024,32,1,20,2,true,false,true,0.112451,0.0558105
gpu_array,1024,32,1,20,4,true,false,true,0.113276,0.0566357
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.129805,0.0721875
gpu_sparse,1024,32,1,20,2,true,false,true,0.121538,0.0639209
gpu_sparse,1024,32,1,20,4,true,false,true,0.120313,0.0626953
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.176963,0.0861426
gpu_reorg,1024,32,1,20,2,true,false,true,0.158125,0.0673047
gpu_reorg,1024,32,1,20,4,true,false,true,0.165059,0.0742383
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,0.100464,0.0535889
0.0535889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,0.0994531,0.0525781
0.0525781
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,0.10603,0.0523193
0.0523193
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,0.101367,0.0554687
0.0554687
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,0.100063,0.0551416
0.0551416
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,0.105464,0.0585889
0.0585889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.0492285
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.42499 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.0822363,0.0177832
gpu_array,1024,8,1,20,2,true,false,true,0.0793896,0.0168896
gpu_array,1024,8,1,20,4,true,false,true,0.0811914,0.0177148
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.0808447,0.0183447
gpu_sparse,1024,8,1,20,2,true,false,true,0.0813428,0.0188428
gpu_sparse,1024,8,1,20,4,true,false,true,0.0803027,0.0187793
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.12041,0.0217773
gpu_reorg,1024,8,1,20,2,true,false,true,0.114941,0.0172852
gpu_reorg,1024,8,1,20,4,true,false,true,0.11749,0.0178809
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.156895,0.0201758
gpu_array,1024,8,1,50,2,true,false,true,0.154868,0.0220557
gpu_array,1024,8,1,50,4,true,false,true,0.156797,0.0220312
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.15584,0.0210742
gpu_sparse,1024,8,1,50,2,true,false,true,0.160391,0.0246484
gpu_sparse,1024,8,1,50,4,true,false,true,0.160352,0.0246094
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.123403,0.0247705
gpu_reorg,1024,8,1,50,2,true,false,true,0.122002,0.0243457
gpu_reorg,1024,8,1,50,4,true,false,true,0.12981,0.0243408
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.0776855,0.0161621
gpu_array,1024,32,1,20,2,true,false,true,0.0743701,0.0147998
gpu_array,1024,32,1,20,4,true,false,true,0.0758252,0.0143018
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.0788721,0.0163721
gpu_sparse,1024,32,1,20,2,true,false,true,0.0769873,0.0154639
gpu_sparse,1024,32,1,20,4,true,false,true,0.0773486,0.0158252
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.118242,0.0205859
gpu_reorg,1024,32,1,20,2,true,false,true,0.116123,0.0165137
gpu_reorg,1024,32,1,20,4,true,false,true,0.116733,0.0161475
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,0.062334,0.0144824
0.0144824
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,0.0729687,0.0153516
0.0153516
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.0711719,0.0155078
0.0155078
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.0697412,0.0160303
0.0160303
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,0.0715967,0.0188623
0.0188623
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,0.0706445,0.0188867
0.0188867
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.0143018
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.126698 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.56085,0.139951
gpu_array,1024,8,1,20,2,true,false,true,0.538979,0.105386
gpu_array,1024,8,1,20,4,true,false,true,0.524888,0.105942
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.565581,0.149565
gpu_sparse,1024,8,1,20,2,true,false,true,0.496035,0.0849023
gpu_sparse,1024,8,1,20,4,true,false,true,0.511787,0.0996777
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.650996,0.168574
gpu_reorg,1024,8,1,20,2,true,false,true,0.566675,0.0989014
gpu_reorg,1024,8,1,20,4,true,false,true,0.556553,0.0946387
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.532729,0.087417
gpu_array,1024,8,1,50,2,true,false,true,0.508096,0.0637598
gpu_array,1024,8,1,50,4,true,false,true,0.490469,0.0685937
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.510435,0.0905127
gpu_sparse,1024,8,1,50,2,true,false,true,0.493677,0.0815674
gpu_sparse,1024,8,1,50,4,true,false,true,0.505024,0.0782666
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.582979,0.097627
gpu_reorg,1024,8,1,50,2,true,false,true,0.507188,0.0687109
gpu_reorg,1024,8,1,50,4,true,false,true,0.548569,0.07396
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,0.463315,0.0609717
0.0609717
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,0.492905,0.0886084
0.0886084
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.478364,0.0760205
0.0760205
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.594404,0.184248
0.184248
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.0609717
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 20 seconds of which 0.443966 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.213047,0.0782812
gpu_array,1024,8,1,20,2,true,false,true,0.204419,0.0696533
gpu_array,1024,8,1,20,4,true,false,true,0.214443,0.0806543
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.155195,0.0819531
gpu_sparse,1024,8,1,20,2,true,false,true,0.216963,0.0821973
gpu_sparse,1024,8,1,20,4,true,false,true,0.227163,0.0914209
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.194727,0.107813
gpu_reorg,1024,8,1,20,2,true,false,true,0.171787,0.0858496
gpu_reorg,1024,8,1,20,4,true,false,true,0.198613,0.114629
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.24708,0.102549
gpu_array,1024,8,1,50,2,true,false,true,0.245928,0.0984668
gpu_array,1024,8,1,50,4,true,false,true,0.24915,0.106572
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.260122,0.0999658
gpu_sparse,1024,8,1,50,2,true,false,true,0.245713,0.104111
gpu_sparse,1024,8,1,50,4,true,false,true,0.25749,0.112959
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.280103,0.108228
gpu_reorg,1024,8,1,50,2,true,false,true,0.279897,0.104116
gpu_reorg,1024,8,1,50,4,true,false,true,0.286514,0.114639
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.230161,0.0827002
gpu_array,1024,32,1,20,2,true,false,true,0.217363,0.0786914
gpu_array,1024,32,1,20,4,true,false,true,0.215811,0.082998
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.16374,0.081709
gpu_sparse,1024,32,1,20,2,true,false,true,0.221758,0.0840625
gpu_sparse,1024,32,1,20,4,true,false,true,0.227715,0.0870898
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.191499,0.106538
gpu_reorg,1024,32,1,20,2,true,false,true,0.181597,0.0956592
gpu_reorg,1024,32,1,20,4,true,false,true,0.199517,0.113579
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.127417,0.0502686
0.0502686
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.140776,0.0636279
0.0636279
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,0.129844,0.0546484
0.0546484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,0.170005,0.093833
0.093833
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,0.138506,0.062334
0.062334
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,0.13248,0.0699805
0.0699805
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.0502686
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 0.604524 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,0.945,0.0377734
gpu_array,1024,8,1,20,2,false,false,true,0.94417,0.0369434
gpu_array,1024,8,1,20,4,false,false,true,0.927803,0.0449902
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,0.946963,0.0377832
gpu_sparse,1024,8,1,20,2,false,false,true,0.928423,0.0368213
gpu_sparse,1024,8,1,20,4,false,false,true,0.952935,0.0447314
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,0.975039,0.0414453
gpu_reorg,1024,8,1,20,2,false,false,true,0.959077,0.042085
gpu_reorg,1024,8,1,20,4,false,false,true,0.963433,0.047417
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,0.942939,0.037666
gpu_array,1024,8,1,50,2,false,false,true,0.953652,0.0405664
gpu_array,1024,8,1,50,4,false,false,true,0.934058,0.0405029
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,0.935645,0.0391602
gpu_sparse,1024,8,1,50,2,false,false,true,0.959614,0.0455518
gpu_sparse,1024,8,1,50,4,false,false,true,0.939399,0.0458447
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,0.977925,0.0414014
gpu_reorg,1024,8,1,50,2,false,false,true,0.971875,0.0441406
gpu_reorg,1024,8,1,50,4,false,false,true,0.973813,0.044126
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,0.934131,0.0366699
gpu_array,1024,32,1,20,2,false,false,true,0.941592,0.0353418
gpu_array,1024,32,1,20,4,false,false,true,0.938018,0.0386035
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,0.930132,0.0365771
gpu_sparse,1024,32,1,20,2,false,false,true,0.939707,0.0354102
gpu_sparse,1024,32,1,20,4,false,false,true,0.927271,0.0385986
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,0.990503,0.0432373
gpu_reorg,1024,32,1,20,2,false,false,true,0.959272,0.0413037
gpu_reorg,1024,32,1,20,4,false,false,true,0.986191,0.0418555
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,0.911665,0.0347119
0.0347119
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.934043,0.0375586
0.0375586
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,0.936724,0.0353564
0.0353564
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.0347119
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.246615 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.0873633,0.0180273
gpu_array,1024,8,1,20,2,true,false,true,0.0818213,0.0173682
gpu_array,1024,8,1,20,4,true,false,true,0.0904883,0.0191992
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.0878223,0.0184863
gpu_sparse,1024,8,1,20,2,true,false,true,0.0885107,0.0191748
gpu_sparse,1024,8,1,20,4,true,false,true,0.0835107,0.0200342
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.134321,0.0229932
gpu_reorg,1024,8,1,20,2,true,false,true,0.130322,0.0189941
gpu_reorg,1024,8,1,20,4,true,false,true,0.131777,0.0214258
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.0917773,0.0214648
gpu_array,1024,8,1,50,2,true,false,true,0.0903271,0.0219678
gpu_array,1024,8,1,50,4,true,false,true,0.0933984,0.0221094
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.0908594,0.0215234
gpu_sparse,1024,8,1,50,2,true,false,true,0.0970654,0.0247998
gpu_sparse,1024,8,1,50,4,true,false,true,0.0950781,0.0247656
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.138882,0.0265771
gpu_reorg,1024,8,1,50,2,true,false,true,0.13751,0.0261816
gpu_reorg,1024,8,1,50,4,true,false,true,0.132441,0.0259961
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.0879346,0.0166455
gpu_array,1024,32,1,20,2,true,false,true,0.0830859,0.0157031
gpu_array,1024,32,1,20,4,true,false,true,0.0868506,0.0155615
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.0853174,0.016958
gpu_sparse,1024,32,1,20,2,true,false,true,0.0805273,0.0160742
gpu_sparse,1024,32,1,20,4,true,false,true,0.08396,0.0165771
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.132266,0.0219141
gpu_reorg,1024,32,1,20,2,true,false,true,0.128003,0.0186279
gpu_reorg,1024,32,1,20,4,true,false,true,0.12875,0.019375
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,0.0708984,0.0152344
0.0152344
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,0.0817139,0.0172607
0.0172607
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,0.0714258,0.0157617
0.0157617
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,0.0711377,0.0164502
0.0164502
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,0.0743359,0.0196484
0.0196484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,0.0745703,0.0198828
0.0198828
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.0152344
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.133686 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,3.24418,3.05961
gpu_array,1024,8,1,20,2,true,false,true,4.95598,4.76652
gpu_array,1024,8,1,20,4,true,false,true,4.77408,4.6315
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,2.86068,2.71908
gpu_sparse,1024,8,1,20,2,true,false,true,4.99006,4.83967
gpu_sparse,1024,8,1,20,4,true,false,true,4.75395,4.60453
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,3.63287,3.46295
gpu_reorg,1024,8,1,20,2,true,false,true,6.93275,6.76869
gpu_reorg,1024,8,1,20,4,true,false,true,5.21521,5.04822
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,3.87176,3.71844
gpu_array,1024,8,1,50,2,true,false,true,4.61121,4.45691
gpu_array,1024,8,1,50,4,true,false,true,6.86834,6.70525
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,3.36074,3.20742
gpu_sparse,1024,8,1,50,2,true,false,true,4.61117,4.45688
gpu_sparse,1024,8,1,50,4,true,false,true,6.37588,6.22256
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,4.11277,3.95164
gpu_reorg,1024,8,1,50,2,true,false,true,7.219,7.05006
gpu_reorg,1024,8,1,50,4,true,false,true,10.1583,9.98547
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,3.30738,3.16188
gpu_array,1024,32,1,20,2,true,false,true,3.4792,3.3415
gpu_array,1024,32,1,20,4,true,false,true,4.06598,3.92437
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,3.10758,2.97086
gpu_sparse,1024,32,1,20,2,true,false,true,3.52979,3.38623
gpu_sparse,1024,32,1,20,4,true,false,true,3.80879,3.67109
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,3.95625,3.7873
gpu_reorg,1024,32,1,20,2,true,false,true,4.76404,4.60193
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,2.86738,2.7834
2.7834
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,3.00158,2.92443
2.92443
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,2.07168,1.9916
1.9916
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,2.23424,2.13854
2.13854
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 1.9916
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 145 seconds of which 6.57093 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,0.114795,0.0171387
gpu_array,1024,8,1,20,2,true,false,true,0.122549,0.0297754
gpu_array,1024,8,1,20,4,true,false,true,0.125493,0.0268604
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,0.109219,0.0174219
gpu_sparse,1024,8,1,20,2,true,false,true,0.134946,0.0314307
gpu_sparse,1024,8,1,20,4,true,false,true,0.127095,0.0323682
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,0.154111,0.0222754
gpu_reorg,1024,8,1,20,2,true,false,true,0.163232,0.0343262
gpu_reorg,1024,8,1,20,4,true,false,true,0.148721,0.0334863
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,0.117021,0.0213184
gpu_array,1024,8,1,50,2,true,false,true,0.127539,0.0347656
gpu_array,1024,8,1,50,4,true,false,true,0.130522,0.0348193
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,0.110435,0.0215674
gpu_sparse,1024,8,1,50,2,true,false,true,0.126123,0.0362793
gpu_sparse,1024,8,1,50,4,true,false,true,0.130869,0.0361426
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,0.148623,0.0285059
gpu_reorg,1024,8,1,50,2,true,false,true,0.174365,0.0405762
gpu_reorg,1024,8,1,50,4,true,false,true,0.167329,0.040376
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,0.101279,0.0163184
gpu_array,1024,32,1,20,2,true,false,true,0.109146,0.0163721
gpu_array,1024,32,1,20,4,true,false,true,0.103389,0.0174512
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,0.109863,0.0161133
gpu_sparse,1024,32,1,20,2,true,false,true,0.10084,0.0168555
gpu_sparse,1024,32,1,20,4,true,false,true,0.106812,0.0179443
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,0.135376,0.0211182
gpu_reorg,1024,32,1,20,2,true,false,true,0.146304,0.0213037
gpu_reorg,1024,32,1,20,4,true,false,true,0.151426,0.0254492
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,0.103584,0.0156934
0.0156934
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,0.10603,0.0181396
0.0181396
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,0.104448,0.0165576
0.0165576
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,0.104321,0.0174072
0.0174072
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,0.105513,0.0185986
0.0185986
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,0.108999,0.0191553
0.0191553
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.0156934
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 14 seconds of which 0.166689 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.0957495,0.0669409
gpu_array,2048,8,1,20,2,true,false,true,0.0846167,0.0562964
gpu_array,2048,8,1,20,4,true,false,true,0.0855078,0.0552344
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.112668,0.0843481
gpu_sparse,2048,8,1,20,2,true,false,true,0.0960229,0.0667261
gpu_sparse,2048,8,1,20,4,true,false,true,0.0973877,0.0676025
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.124963,0.0776001
gpu_reorg,2048,8,1,20,2,true,false,true,0.101257,0.0548706
gpu_reorg,2048,8,1,20,4,true,false,true,0.0922192,0.0443677
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.0869702,0.0581616
gpu_array,2048,8,1,50,2,true,false,true,0.0787354,0.050415
gpu_array,2048,8,1,50,4,true,false,true,0.0808594,0.0520508
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.0915479,0.0627393
gpu_sparse,2048,8,1,50,2,true,false,true,0.0948389,0.0626123
gpu_sparse,2048,8,1,50,4,true,false,true,0.0929297,0.0626562
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.122627,0.0752637
gpu_reorg,2048,8,1,50,2,true,false,true,0.0959668,0.0486035
gpu_reorg,2048,8,1,50,4,true,false,true,0.105503,0.0566748
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.0905078,0.0626758
gpu_array,2048,32,1,20,2,true,false,true,0.083418,0.0511914
gpu_array,2048,32,1,20,4,true,false,true,0.0817358,0.0519507
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.0939551,0.0656348
gpu_sparse,2048,32,1,20,2,true,false,true,0.0774658,0.044751
gpu_sparse,2048,32,1,20,4,true,false,true,0.0795825,0.0483325
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.12283,0.0769312
gpu_reorg,2048,32,1,20,2,true,false,true,0.110688,0.0618604
gpu_reorg,2048,32,1,20,4,true,false,true,0.102781,0.0539526
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,true,false,true,0.0926709,0.0448193
0.0448193
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,20,4,false,false,true,0.0982129,0.053291
0.053291
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,0.0945776,0.0472144
0.0472144
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,0.0985913,0.0531812
0.0531812
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,true,false,true,0.0989966,0.0535864
0.0535864
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_reorg,2048,32,1,20,4,false,false,true,0.104324,0.0569604
0.0569604
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.0443677
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.790322 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline 13 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.0533716,0.0143091
gpu_array,2048,8,1,20,2,true,false,true,0.05021,0.0140771
gpu_array,2048,8,1,20,4,true,false,true,0.0544653,0.0149146
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.0526953,0.0150977
gpu_sparse,2048,8,1,20,2,true,false,true,0.049751,0.0141064
gpu_sparse,2048,8,1,20,4,true,false,true,0.0544653,0.0149146
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.0761572,0.0175635
gpu_reorg,2048,8,1,20,2,true,false,true,0.0779834,0.0135303
gpu_reorg,2048,8,1,20,4,true,false,true,0.0738452,0.0147632
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.0513599,0.0157153
gpu_array,2048,8,1,50,2,true,false,true,0.0553247,0.0162622
gpu_array,2048,8,1,50,4,true,false,true,0.0513623,0.0162061
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.0568579,0.0168188
gpu_sparse,2048,8,1,50,2,true,false,true,0.056062,0.0174878
gpu_sparse,2048,8,1,50,4,true,false,true,0.0532251,0.0175806
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.0744385,0.0192627
gpu_reorg,2048,8,1,50,2,true,false,true,0.0795972,0.018562
gpu_reorg,2048,8,1,50,4,true,false,true,0.0779321,0.0188501
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.0515308,0.01198
gpu_array,2048,32,1,20,2,true,false,true,0.0502295,0.0106787
gpu_array,2048,32,1,20,4,true,false,true,0.0469116,0.00980225
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.0528125,0.0122852
gpu_sparse,2048,32,1,20,2,true,false,true,0.0462891,0.0101563
gpu_sparse,2048,32,1,20,4,true,false,true,0.0514282,0.0118774
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.0759937,0.0159351
gpu_reorg,2048,32,1,20,2,true,false,true,0.0691626,0.012522
gpu_reorg,2048,32,1,20,4,true,false,true,0.0721436,0.0135498
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,0.0387915,0.00949463
0.00949463
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,0.0425122,0.00979736
0.00979736
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,0.0416187,0.0128101
0.0128101
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.0459912,0.0137646
0.0137646
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,0.0436914,0.0148828
0.0148828
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.0436279,0.0148193
0.0148193
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.00949463
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.194305 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.436426,0.106348
gpu_array,2048,8,1,20,2,true,false,true,0.418289,0.0799097
gpu_array,2048,8,1,20,4,true,false,true,0.411738,0.0801953
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.452915,0.11356
gpu_sparse,2048,8,1,20,2,true,false,true,0.398337,0.0619116
gpu_sparse,2048,8,1,20,4,true,false,true,0.409832,0.073894
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.493423,0.126724
gpu_reorg,2048,8,1,20,2,true,false,true,0.42585,0.0733105
gpu_reorg,2048,8,1,20,4,true,false,true,0.426726,0.0702808
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.417705,0.0812793
gpu_array,2048,8,1,50,2,true,false,true,0.394468,0.058042
gpu_array,2048,8,1,50,4,true,false,true,0.396221,0.0607715
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.414727,0.0846484
gpu_sparse,2048,8,1,50,2,true,false,true,0.405898,0.0684961
gpu_sparse,2048,8,1,50,4,true,false,true,0.40905,0.0706714
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.44845,0.0900513
gpu_reorg,2048,8,1,50,2,true,false,true,0.427178,0.0585254
gpu_reorg,2048,8,1,50,4,true,false,true,0.421367,0.0673633
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,0.389521,0.0540723
0.0540723
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,0.410774,0.0826489
0.0826489
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,0.379153,0.0563989
0.0563989
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.610759,0.286052
0.286052
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.0540723
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 21 seconds of which 0.780351 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.160415,0.0837549
gpu_array,2048,8,1,20,2,true,false,true,0.1652,0.0851221
gpu_array,2048,8,1,20,4,true,false,true,0.167393,0.0902441
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.175549,0.0920532
gpu_sparse,2048,8,1,20,2,true,false,true,0.213091,0.0983447
gpu_sparse,2048,8,1,20,4,true,false,true,0.167202,0.09396
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.200818,0.104626
gpu_reorg,2048,8,1,20,2,true,false,true,0.189407,0.0956567
gpu_reorg,2048,8,1,20,4,true,false,true,0.189817,0.0887427
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.174231,0.0946411
gpu_array,2048,8,1,50,2,true,false,true,0.173643,0.0930762
gpu_array,2048,8,1,50,4,true,false,true,0.174695,0.0975464
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.18512,0.0928345
gpu_sparse,2048,8,1,50,2,true,false,true,0.17644,0.0983154
gpu_sparse,2048,8,1,50,4,true,false,true,0.181963,0.106279
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.194224,0.0990088
gpu_reorg,2048,8,1,50,2,true,false,true,0.196509,0.0959229
gpu_reorg,2048,8,1,50,4,true,false,true,0.19926,0.105022
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.152644,0.0794019
gpu_array,2048,32,1,20,2,true,false,true,0.161008,0.0833716
gpu_array,2048,32,1,20,4,true,false,true,0.161365,0.087146
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.169629,0.0792969
gpu_sparse,2048,32,1,20,2,true,false,true,0.158391,0.0836841
gpu_sparse,2048,32,1,20,4,true,false,true,0.164028,0.0883447
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.186785,0.0910815
gpu_reorg,2048,32,1,20,2,true,false,true,0.189473,0.0908398
gpu_reorg,2048,32,1,20,4,true,false,true,0.184824,0.087168
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,0.10271,0.0548584
0.0548584
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,0.118677,0.0698486
0.0698486
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,0.112844,0.0640161
0.0640161
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,0.118728,0.0694116
0.0694116
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,0.111724,0.0638721
0.0638721
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,0.117798,0.0699463
0.0699463
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.0548584
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 1.1786 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,0.841475,0.0489941
gpu_array,2048,8,1,20,2,false,false,true,0.835242,0.0486206
gpu_array,2048,8,1,20,4,false,false,true,0.847568,0.0492285
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,0.84134,0.0493481
gpu_sparse,2048,8,1,20,2,false,false,true,0.839146,0.0471533
gpu_sparse,2048,8,1,20,4,false,false,true,0.841538,0.0495459
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,0.867766,0.0542896
gpu_reorg,2048,8,1,20,2,false,false,true,0.849971,0.0506543
gpu_reorg,2048,8,1,20,4,false,false,true,0.862187,0.0579883
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,0.81762,0.0334399
gpu_array,2048,8,1,50,2,false,false,true,0.822949,0.0353516
gpu_array,2048,8,1,50,4,false,false,true,0.865325,0.0352466
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,0.830891,0.0359692
gpu_sparse,2048,8,1,50,2,false,false,true,0.838894,0.0410425
gpu_sparse,2048,8,1,50,4,false,false,true,0.832561,0.0410571
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,1.00736,0.0391016
gpu_reorg,2048,8,1,50,2,false,false,true,0.876406,0.0399805
gpu_reorg,2048,8,1,50,4,false,false,true,0.875432,0.0385181
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,0.832061,0.042998
gpu_array,2048,32,1,20,2,false,false,true,0.820076,0.0417554
gpu_array,2048,32,1,20,4,false,false,true,0.811514,0.0331934
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,0.840039,0.0431641
gpu_sparse,2048,32,1,20,2,false,false,true,0.843303,0.0420337
gpu_sparse,2048,32,1,20,4,false,false,true,0.821838,0.0332642
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,0.863284,0.0498071
gpu_reorg,2048,32,1,20,2,false,false,true,0.855417,0.0482886
gpu_reorg,2048,32,1,20,4,false,false,true,0.83875,0.0389453
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,0.803965,0.0329687
0.0329687
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.80436,0.0314111
0.0314111
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.814832,0.0457886
0.0457886
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.0314111
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 7 seconds of which 0.523939 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.0615186,0.0146436
gpu_array,2048,8,1,20,2,true,false,true,0.0638525,0.0145361
gpu_array,2048,8,1,20,4,true,false,true,0.0626758,0.0153125
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.0638696,0.0160181
gpu_sparse,2048,8,1,20,2,true,false,true,0.0601367,0.0157031
gpu_sparse,2048,8,1,20,4,true,false,true,0.0641846,0.0158447
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.0837231,0.01927
gpu_reorg,2048,8,1,20,2,true,false,true,0.0774756,0.0159521
gpu_reorg,2048,8,1,20,4,true,false,true,0.0872925,0.0208862
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.0645752,0.0167236
gpu_array,2048,8,1,50,2,true,false,true,0.0660034,0.0171753
gpu_array,2048,8,1,50,4,true,false,true,0.064978,0.0171265
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.065686,0.0178345
gpu_sparse,2048,8,1,50,2,true,false,true,0.0691699,0.0179004
gpu_sparse,2048,8,1,50,4,true,false,true,0.0643042,0.0179175
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.12957,0.0211719
gpu_reorg,2048,8,1,50,2,true,false,true,0.130969,0.0201294
gpu_reorg,2048,8,1,50,4,true,false,true,0.129673,0.0202979
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.0611011,0.0127612
gpu_array,2048,32,1,20,2,true,false,true,0.0610425,0.0117261
gpu_array,2048,32,1,20,4,true,false,true,0.0620996,0.0122949
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.0625708,0.0132544
gpu_sparse,2048,32,1,20,2,true,false,true,0.0616553,0.0123389
gpu_sparse,2048,32,1,20,4,true,false,true,0.0620068,0.0122021
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.0860937,0.0187109
gpu_reorg,2048,32,1,20,2,true,false,true,0.0799927,0.0150513
gpu_reorg,2048,32,1,20,4,true,false,true,0.082561,0.0156665
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,0.0504663,0.0114038
0.0114038
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,0.0539063,0.0128906
0.0128906
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,true,false,true,0.0517139,0.0136279
0.0136279
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,2,false,false,true,0.0541309,0.0140918
0.0140918
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,0.0563794,0.0158521
0.0158521
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.0559521,0.0159131
0.0159131
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.0114038
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.213905 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,4.34122,4.26554
gpu_array,2048,8,1,20,2,true,false,true,5.09503,4.99786
gpu_array,2048,8,1,20,4,true,false,true,4.64488,4.54479
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,3.86032,3.78415
gpu_sparse,2048,8,1,20,2,true,false,true,5.07855,4.97992
gpu_sparse,2048,8,1,20,4,true,false,true,4.05697,3.98275
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,4.95341,4.86308
gpu_reorg,2048,8,1,20,2,true,false,true,5.4941,5.39791
gpu_reorg,2048,8,1,20,4,true,false,true,5.07185,4.97907
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,3.6495,3.5704
gpu_array,2048,8,1,50,2,true,false,true,4.48299,4.40145
gpu_array,2048,8,1,50,4,true,false,true,6.7738,6.69177
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,3.40215,3.31865
gpu_sparse,2048,8,1,50,2,true,false,true,4.47403,4.38956
gpu_sparse,2048,8,1,50,4,true,false,true,6.1364,6.04753
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,4.22292,4.12331
gpu_reorg,2048,8,1,50,2,true,false,true,7.83645,7.73879
gpu_reorg,2048,8,1,50,4,true,false,true,10.2513,10.1522
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,3.73113,3.65594
gpu_array,2048,32,1,20,2,true,false,true,3.02784,2.95021
gpu_array,2048,32,1,20,4,true,false,true,3.04819,2.973
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,3.21607,3.14381
gpu_sparse,2048,32,1,20,2,true,false,true,3.02147,2.94237
gpu_sparse,2048,32,1,20,4,true,false,true,2.89337,2.81671
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,4.17502,4.0632
gpu_reorg,2048,32,1,20,2,true,false,true,3.51743,3.41733
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,1.95819,1.92694
1.92694
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,2.07902,2.04533
2.04533
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,2.22026,2.18755
2.18755
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,2.21618,2.18151
2.18151
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 1.92694
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 157 seconds of which 12.9569 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,0.167832,0.0125586
gpu_array,2048,8,1,20,2,true,false,true,0.182336,0.0251099
gpu_array,2048,8,1,20,4,true,false,true,0.180862,0.0207056
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,0.158506,0.0144629
gpu_sparse,2048,8,1,20,2,true,false,true,0.185217,0.0245728
gpu_sparse,2048,8,1,20,4,true,false,true,0.16936,0.0243408
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,0.16738,0.0184546
gpu_reorg,2048,8,1,20,2,true,false,true,0.201201,0.0317676
gpu_reorg,2048,8,1,20,4,true,false,true,0.174915,0.0318481
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,0.14603,0.0166357
gpu_array,2048,8,1,50,2,true,false,true,0.179553,0.0291626
gpu_array,2048,8,1,50,4,true,false,true,0.160532,0.0291846
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,0.150127,0.0168262
gpu_sparse,2048,8,1,50,2,true,false,true,0.178596,0.0311353
gpu_sparse,2048,8,1,50,4,true,false,true,0.168682,0.0309863
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,0.168455,0.0234351
gpu_reorg,2048,8,1,50,2,true,false,true,0.201064,0.0345605
gpu_reorg,2048,8,1,50,4,true,false,true,0.193306,0.0346143
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,0.140042,0.0121118
gpu_array,2048,32,1,20,2,true,false,true,0.160977,0.0120508
gpu_array,2048,32,1,20,4,true,false,true,0.167041,0.0127441
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,0.141526,0.0121313
gpu_sparse,2048,32,1,20,2,true,false,true,0.171597,0.0129053
gpu_sparse,2048,32,1,20,4,true,false,true,0.177107,0.0135327
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,0.164277,0.0173047
gpu_reorg,2048,32,1,20,2,true,false,true,0.192041,0.0172363
gpu_reorg,2048,32,1,20,4,true,false,true,0.180215,0.0215234
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,0.142661,0.0108252
0.0108252
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,0.174358,0.0142017
0.0142017
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,0.162261,0.0128467
0.0128467
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,0.161431,0.0134814
0.0134814
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,0.16625,0.0143945
0.0143945
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,0.16054,0.0145435
0.0145435
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.0108252
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 15 seconds of which 0.271235 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,0.14115,0.122839
gpu_array,4096,32,1,2,2,true,false,true,0.100923,0.0816357
gpu_array,4096,32,1,2,4,true,false,true,0.0778076,0.0592529
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,0.154966,0.132261
gpu_sparse,4096,32,1,2,2,true,false,true,0.0904028,0.0701392
gpu_sparse,4096,32,1,2,4,true,false,true,0.0965308,0.0774878
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,0.0803125,0.0598047
gpu_array,4096,32,1,10,2,true,false,true,0.0692578,0.0480176
gpu_array,4096,32,1,10,4,true,false,true,0.0594189,0.0423291
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,0.08104,0.0622412
gpu_sparse,4096,32,1,10,2,true,false,true,0.0665112,0.0501538
gpu_sparse,4096,32,1,10,4,true,false,true,0.0670923,0.0485376
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,0.15104,0.132729
gpu_array,4096,64,1,2,2,true,false,true,0.107717,0.0874536
gpu_array,4096,64,1,2,4,true,false,true,0.081731,0.0634204
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,0.156492,0.132322
gpu_sparse,4096,64,1,2,2,true,false,true,0.0882837,0.0699731
gpu_sparse,4096,64,1,2,4,true,false,true,0.0957617,0.077207
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,0.076604,0.0600024
gpu_array,4096,64,1,10,2,true,false,true,0.0685986,0.048335
gpu_array,4096,64,1,10,4,true,false,true,0.0554663,0.0383765
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,0.0812646,0.0624658
gpu_sparse,4096,64,1,10,2,true,false,true,0.0600171,0.0431714
gpu_sparse,4096,64,1,10,4,true,false,true,0.0604102,0.0438086
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,0.0547681,0.0371899
0.0371899
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,0.0662671,0.0482007
0.0482007
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,0.0607886,0.0432104
0.0432104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,0.0627295,0.0444189
0.0444189
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,0.0687622,0.0524048
0.0524048
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,0.104722,0.0866553
0.0866553
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.0371899
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 0.829868 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,0.0460913,0.0187476
gpu_array,4096,32,1,2,2,true,false,true,0.0420166,0.0151611
gpu_array,4096,32,1,2,4,true,false,true,0.0413403,0.0142407
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,0.0452588,0.0186475
gpu_sparse,4096,32,1,2,2,true,false,true,0.0377686,0.0104248
gpu_sparse,4096,32,1,2,4,true,false,true,0.0401001,0.0127563
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,0.034021,0.00911865
gpu_array,4096,32,1,10,2,true,false,true,0.0331885,0.00779785
gpu_array,4096,32,1,10,4,true,false,true,0.0344604,0.00760498
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,0.0381104,0.0095459
gpu_sparse,4096,32,1,10,2,true,false,true,0.0324292,0.00703857
gpu_sparse,4096,32,1,10,4,true,false,true,0.0347974,0.00818604
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,0.0464893,0.0186572
gpu_array,4096,64,1,2,2,true,false,true,0.0424268,0.015083
gpu_array,4096,64,1,2,4,true,false,true,0.038811,0.0141528
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,0.0464624,0.0183862
gpu_sparse,4096,64,1,2,2,true,false,true,0.0374414,0.0103418
gpu_sparse,4096,64,1,2,4,true,false,true,0.0383838,0.012749
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,0.0358032,0.00919189
gpu_array,4096,64,1,10,2,true,false,true,0.0329932,0.00784668
gpu_array,4096,64,1,10,4,true,false,true,0.0350415,0.00769775
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,0.037478,0.009646
gpu_sparse,4096,64,1,10,2,true,false,true,0.0349927,0.00716064
gpu_sparse,4096,64,1,10,4,true,false,true,0.0318848,0.0074707
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,0.0279395,0.00694336
0.00694336
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,0.0303687,0.00912842
0.00912842
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,0.0285791,0.00709473
0.00709473
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,0.0304712,0.00923096
0.00923096
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,0.0315723,0.010332
0.010332
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,0.0383667,0.016394
0.016394
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.00694336
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.137944 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
airline-ohe 692 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,true,false,false,0.413286,0.109087
gpu_array,4096,8,1,20,2,true,false,true,0.377903,0.0807837
gpu_array,4096,8,1,20,4,true,false,true,0.377048,0.0750464
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,true,false,false,0.407551,0.107991
gpu_sparse,4096,8,1,20,2,true,false,true,0.359587,0.0588062
gpu_sparse,4096,8,1,20,4,true,false,true,0.368445,0.0696167
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,true,false,false,0.435159,0.074563
gpu_array,4096,8,1,50,2,true,false,true,0.370398,0.0535034
gpu_array,4096,8,1,50,4,true,false,true,0.420657,0.0588403
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,true,false,false,0.449727,0.0779004
gpu_sparse,4096,8,1,50,2,true,false,true,0.424485,0.0634009
gpu_sparse,4096,8,1,50,4,true,false,true,0.431016,0.0645605
4096 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
4096 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,true,false,true,0.346143,0.0521973
0.0521973
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,50,2,false,false,true,0.372185,0.0775073
0.0775073
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,true,false,true,0.372058,0.0798218
0.0798218
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,4096,8,1,20,4,false,false,true,0.560876,0.266687
0.266687
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	4096
Best kernel execution time: 0.0521973
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 15 seconds of which 0.56128 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,0.146436,0.111279
gpu_array,4096,32,1,2,2,true,false,true,0.111387,0.0730566
gpu_array,4096,32,1,2,4,true,false,true,0.0931885,0.0563232
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,0.16749,0.109629
gpu_sparse,4096,32,1,2,2,true,false,true,0.115703,0.0793262
gpu_sparse,4096,32,1,2,4,true,false,true,0.106321,0.0706763
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,0.120732,0.071416
gpu_array,4096,32,1,10,2,true,false,true,0.121606,0.073999
gpu_array,4096,32,1,10,4,true,false,true,0.112673,0.0643335
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,0.144165,0.0704346
gpu_sparse,4096,32,1,10,2,true,false,true,0.120054,0.0717139
gpu_sparse,4096,32,1,10,4,true,false,true,0.113562,0.0661987
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,0.159604,0.122739
gpu_array,4096,64,1,2,2,true,false,true,0.117668,0.0800708
gpu_array,4096,64,1,2,4,true,false,true,0.0996045,0.0624951
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,0.170562,0.114653
gpu_sparse,4096,64,1,2,2,true,false,true,0.118037,0.0806836
gpu_sparse,4096,64,1,2,4,true,false,true,0.109785,0.0714551
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,0.122117,0.0735327
gpu_array,4096,64,1,10,2,true,false,true,0.120435,0.0733154
gpu_array,4096,64,1,10,4,true,false,true,0.110359,0.0617749
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,0.145051,0.0735181
gpu_sparse,4096,64,1,10,2,true,false,true,0.120559,0.0722192
gpu_sparse,4096,64,1,10,4,true,false,true,0.11489,0.0645972
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,0.112773,0.0756641
0.0756641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,0.117595,0.0795093
0.0795093
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,0.0754102,0.0392773
0.0392773
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,0.098877,0.0622559
0.0622559
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,0.114011,0.075437
0.075437
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,0.118508,0.0823755
0.0823755
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	4096
Best kernel execution time: 0.0392773
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 16 seconds of which 0.93551 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
4096 8 1 20 gpu_array
gpu_array,4096,8,1,20,-1,false,false,false,0.756389,0.0398364
gpu_array,4096,8,1,20,2,false,false,true,0.752561,0.0401587
gpu_array,4096,8,1,20,4,false,false,true,0.762275,0.0457227
4096 8 1 20 gpu_sparse
gpu_sparse,4096,8,1,20,-1,false,false,false,0.754243,0.0406201
gpu_sparse,4096,8,1,20,2,false,false,true,0.748892,0.0411279
gpu_sparse,4096,8,1,20,4,false,false,true,0.760283,0.0456836
4096 8 1 50 gpu_array
gpu_array,4096,8,1,50,-1,false,false,false,0.91467,0.0396704
gpu_array,4096,8,1,50,2,false,false,true,0.77126,0.0405469
gpu_array,4096,8,1,50,4,false,false,true,0.770662,0.040437
4096 8 1 50 gpu_sparse
gpu_sparse,4096,8,1,50,-1,false,false,false,0.913459,0.0404126
gpu_sparse,4096,8,1,50,2,false,false,true,0.917517,0.0442261
gpu_sparse,4096,8,1,50,4,false,false,true,0.774431,0.0442065
4096 32 1 20 gpu_array
gpu_array,4096,32,1,20,-1,false,false,false,0.744639,0.0349219
gpu_array,4096,32,1,20,2,false,false,true,0.752344,0.0343262
gpu_array,4096,32,1,20,4,false,false,true,0.748777,0.0363745
4096 32 1 20 gpu_sparse
gpu_sparse,4096,32,1,20,-1,false,false,false,0.750596,0.0350195
gpu_sparse,4096,32,1,20,2,false,false,true,0.741919,0.0346436
gpu_sparse,4096,32,1,20,4,false,false,true,0.756182,0.0366992
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,32,1,20,2,false,false,true,0.740989,0.0381079
0.0381079
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,50,-1,false,false,false,0.743203,0.0349512
0.0349512
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,4096,8,1,20,-1,false,false,false,0.753157,0.0407544
0.0407544
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	4096
Best kernel execution time: 0.0343262
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 6 seconds of which 0.339332 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,0.0548047,0.0191602
gpu_array,4096,32,1,2,2,true,false,true,0.0528394,0.0152417
gpu_array,4096,32,1,2,4,true,false,true,0.0496094,0.0144531
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,0.0568945,0.0190527
gpu_sparse,4096,32,1,2,2,true,false,true,0.0461426,0.0107422
gpu_sparse,4096,32,1,2,4,true,false,true,0.047417,0.0129932
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,0.0450195,0.00961914
gpu_array,4096,32,1,10,2,true,false,true,0.0446069,0.00847412
gpu_array,4096,32,1,10,4,true,false,true,0.0441016,0.00845703
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,0.0455273,0.0103711
gpu_sparse,4096,32,1,10,2,true,false,true,0.0456299,0.00876465
gpu_sparse,4096,32,1,10,4,true,false,true,0.0442285,0.00882812
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,0.0540796,0.0189233
gpu_array,4096,64,1,2,2,true,false,true,0.0520337,0.0151685
gpu_array,4096,64,1,2,4,true,false,true,0.0509399,0.0143188
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,0.0553564,0.0189795
gpu_sparse,4096,64,1,2,2,true,false,true,0.045896,0.0107397
gpu_sparse,4096,64,1,2,4,true,false,true,0.0486133,0.0129687
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,0.0456226,0.00973389
gpu_array,4096,64,1,10,2,true,false,true,0.0442944,0.0086499
gpu_array,4096,64,1,10,4,true,false,true,0.0446655,0.00853271
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,0.0463184,0.0104297
gpu_sparse,4096,64,1,10,2,true,false,true,0.0441064,0.00772949
gpu_sparse,4096,64,1,10,4,true,false,true,0.0448218,0.00844482
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,true,false,true,0.036001,0.00768066
0.00768066
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,10,2,false,false,true,0.0375513,0.00971924
0.00971924
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,true,false,true,0.0369824,0.00866211
0.00866211
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,32,1,10,2,false,false,true,0.0383008,0.00998047
0.00998047
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,true,false,true,0.0390527,0.0107324
0.0107324
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_sparse,4096,64,1,2,2,false,false,true,0.044873,0.017041
0.017041
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	4096
Best kernel execution time: 0.00768066
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.145241 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,4.77226,4.72733
gpu_array,4096,32,1,2,2,true,false,true,3.52133,3.48031
gpu_array,4096,32,1,2,4,true,false,true,3.39396,3.35196
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,4.57834,4.53806
gpu_sparse,4096,32,1,2,2,true,false,true,3.60212,3.5611
gpu_sparse,4096,32,1,2,4,true,false,true,2.6183,2.57533
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,3.61521,3.55441
gpu_array,4096,32,1,10,2,true,false,true,2.94573,2.8681
gpu_array,4096,32,1,10,4,true,false,true,2.85145,2.77015
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,3.13256,3.07226
gpu_sparse,4096,32,1,10,2,true,false,true,3.04203,2.96293
gpu_sparse,4096,32,1,10,4,true,false,true,2.94616,2.88708
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,3.98227,3.93002
gpu_array,4096,64,1,2,2,true,false,true,3.36158,3.32032
gpu_array,4096,64,1,2,4,true,false,true,3.20645,3.16616
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,3.74616,3.70637
gpu_sparse,4096,64,1,2,2,true,false,true,3.45241,3.41091
gpu_sparse,4096,64,1,2,4,true,false,true,2.58499,2.54178
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,3.68064,3.62059
gpu_array,4096,64,1,10,2,true,false,true,2.90049,2.8231
gpu_array,4096,64,1,10,4,true,false,true,3.07576,2.99812
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,2.74757,2.67164
gpu_sparse,4096,64,1,10,2,true,false,true,2.86904,2.80947
gpu_sparse,4096,64,1,10,4,true,false,true,2.7192,2.64303
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,true,false,true,1.88105,1.83931
1.83931
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,64,1,2,4,false,false,true,1.99328,1.953
1.953
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,true,false,true,1.99687,1.95487
1.95487
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,4096,32,1,2,4,false,false,true,1.99746,1.95742
1.95742
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	4096
Best kernel execution time: 1.83931
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 130 seconds of which 8.77518 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,0.112319,0.0171045
gpu_array,4096,32,1,2,2,true,false,true,0.104758,0.0136938
gpu_array,4096,32,1,2,4,true,false,true,0.110811,0.0133984
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,0.113235,0.0170435
gpu_sparse,4096,32,1,2,2,true,false,true,0.10405,0.0105444
gpu_sparse,4096,32,1,2,4,true,false,true,0.107246,0.0117871
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,0.102175,0.00891357
gpu_array,4096,32,1,10,2,true,false,true,0.0958813,0.008479
gpu_array,4096,32,1,10,4,true,false,true,0.105107,0.00818359
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,0.106113,0.00918945
gpu_sparse,4096,32,1,10,2,true,false,true,0.104409,0.00870605
gpu_sparse,4096,32,1,10,4,true,false,true,0.105327,0.00815918
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,0.105256,0.0171216
gpu_array,4096,64,1,2,2,true,false,true,0.108149,0.013667
gpu_array,4096,64,1,2,4,true,false,true,0.109023,0.0133203
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,0.113406,0.0169702
gpu_sparse,4096,64,1,2,2,true,false,true,0.106563,0.0106152
gpu_sparse,4096,64,1,2,4,true,false,true,0.107161,0.0117017
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,0.101018,0.00897705
gpu_array,4096,64,1,10,2,true,false,true,0.102903,0.00842041
gpu_array,4096,64,1,10,4,true,false,true,0.102915,0.00818848
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,0.103479,0.00924072
gpu_sparse,4096,64,1,10,2,true,false,true,0.105959,0.00927979
gpu_sparse,4096,64,1,10,4,true,false,true,0.103203,0.00823242
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,true,false,true,0.0992432,0.00744629
0.00744629
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,10,4,false,false,true,0.106497,0.0110376
0.0110376
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,true,false,true,0.101982,0.0075
0.0075
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,64,1,10,4,false,false,true,0.106621,0.0101855
0.0101855
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,true,false,true,0.100815,0.0102393
0.0102393
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,4096,32,1,2,2,false,false,true,0.11374,0.017793
0.017793
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	4096
Best kernel execution time: 0.00744629
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.137273 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,0.0754834,0.0636426
gpu_array,8192,32,1,2,2,true,false,true,0.052832,0.0418457
gpu_array,8192,32,1,2,4,true,false,true,0.0464575,0.0344946
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,0.0770154,0.0651746
gpu_sparse,8192,32,1,2,2,true,false,true,0.0542383,0.0423975
gpu_sparse,8192,32,1,2,4,true,false,true,0.0555261,0.0436853
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,0.0633081,0.0452417
gpu_array,8192,32,1,10,2,true,false,true,0.0543091,0.0356323
gpu_array,8192,32,1,10,4,true,false,true,0.0506873,0.0326208
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,0.0580261,0.0470398
gpu_sparse,8192,32,1,10,2,true,false,true,0.0564368,0.0383704
gpu_sparse,8192,32,1,10,4,true,false,true,0.0566772,0.0375122
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,0.0815613,0.0697205
gpu_array,8192,64,1,2,2,true,false,true,0.0577258,0.0460071
gpu_array,8192,64,1,2,4,true,false,true,0.051748,0.039541
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,0.0837109,0.0727246
gpu_sparse,8192,64,1,2,2,true,false,true,0.0570801,0.0449951
gpu_sparse,8192,64,1,2,4,true,false,true,0.0579248,0.0459619
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,0.0636267,0.0453162
gpu_array,8192,64,1,10,2,true,false,true,0.0536011,0.0357788
gpu_array,8192,64,1,10,4,true,false,true,0.0537634,0.0358191
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,0.0589343,0.0472156
gpu_sparse,8192,64,1,10,2,true,false,true,0.058656,0.0405896
gpu_sparse,8192,64,1,10,4,true,false,true,0.0587805,0.0408362
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,0.0440674,0.0333252
0.0333252
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,0.044978,0.0341138
0.0341138
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,0.0515063,0.0400317
0.0400317
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,0.0567932,0.0453186
0.0453186
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,0.0463281,0.0355859
0.0355859
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,0.0492773,0.0380469
0.0380469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	8192
Best kernel execution time: 0.0326208
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 11 seconds of which 1.08019 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 1000 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,0.0291809,0.00952759
gpu_array,8192,32,1,2,2,true,false,true,0.027395,0.00761963
gpu_array,8192,32,1,2,4,true,false,true,0.0255945,0.00716187
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,0.02953,0.00963257
gpu_sparse,8192,32,1,2,2,true,false,true,0.0260962,0.00619873
gpu_sparse,8192,32,1,2,4,true,false,true,0.026416,0.0067627
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,0.0404102,0.00647461
gpu_array,8192,32,1,10,2,true,false,true,0.038988,0.0054187
gpu_array,8192,32,1,10,4,true,false,true,0.0375037,0.0052771
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,0.042196,0.00679565
gpu_sparse,8192,32,1,10,2,true,false,true,0.0410083,0.00560791
gpu_sparse,8192,32,1,10,4,true,false,true,0.0406079,0.00581787
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,0.0290466,0.00951538
gpu_array,8192,64,1,2,2,true,false,true,0.027373,0.00759766
gpu_array,8192,64,1,2,4,true,false,true,0.0271985,0.00717896
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,0.0294971,0.00972168
gpu_sparse,8192,64,1,2,2,true,false,true,0.0266956,0.00618774
gpu_sparse,8192,64,1,2,4,true,false,true,0.0268823,0.00698486
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,0.0394983,0.00653931
gpu_array,8192,64,1,10,2,true,false,true,0.0384131,0.0054541
gpu_array,8192,64,1,10,4,true,false,true,0.0387622,0.00531494
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,0.0396973,0.00686035
gpu_sparse,8192,64,1,10,2,true,false,true,0.0419128,0.0059021
gpu_sparse,8192,64,1,10,4,true,false,true,0.0390027,0.0060437
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,0.0200928,0.00532227
0.00532227
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,0.0203577,0.00570923
0.00570923
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,0.0206726,0.00541382
0.00541382
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,0.0205542,0.00566162
0.00566162
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,0.0224841,0.00759155
0.00759155
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,0.0222815,0.00763306
0.00763306
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	8192
Best kernel execution time: 0.0052771
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 7 seconds of which 0.166238 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,true,false,false,0.362261,0.10103
gpu_array,8192,8,1,20,2,true,false,true,0.335159,0.0723413
gpu_array,8192,8,1,20,4,true,false,true,0.328978,0.0673816
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,true,false,false,0.391426,0.107002
gpu_sparse,8192,8,1,20,2,true,false,true,0.316237,0.0534192
gpu_sparse,8192,8,1,20,4,true,false,true,0.334285,0.0669507
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,true,false,false,0.392734,0.0729102
gpu_array,8192,8,1,50,2,true,false,true,0.368611,0.0518384
gpu_array,8192,8,1,50,4,true,false,true,0.327809,0.0568127
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,true,false,false,0.394882,0.0753015
gpu_sparse,8192,8,1,50,2,true,false,true,0.384917,0.0675342
gpu_sparse,8192,8,1,50,4,true,false,true,0.338127,0.0639575
8192 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
8192 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,true,false,true,0.312257,0.0546887
0.0546887
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,50,2,false,false,true,0.333057,0.0745117
0.0745117
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,true,false,true,0.333506,0.0759375
0.0759375
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_array,8192,8,1,20,4,false,false,true,0.536547,0.279222
0.279222
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	8192
Best kernel execution time: 0.0518384
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 16 seconds of which 1.09842 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,0.114338,0.0752759
gpu_array,8192,32,1,2,2,true,false,true,0.0942712,0.0552087
gpu_array,8192,32,1,2,4,true,false,true,0.0908069,0.0522327
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,0.122312,0.0784888
gpu_sparse,8192,32,1,2,2,true,false,true,0.101561,0.0618884
gpu_sparse,8192,32,1,2,4,true,false,true,0.10189,0.0622168
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,0.10937,0.0599316
gpu_array,8192,32,1,10,2,true,false,true,0.111552,0.0574744
gpu_array,8192,32,1,10,4,true,false,true,0.114913,0.0616907
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,0.115481,0.0576196
gpu_sparse,8192,32,1,10,2,true,false,true,0.10879,0.0593518
gpu_sparse,8192,32,1,10,4,true,false,true,0.110424,0.0620837
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,0.123324,0.0836511
gpu_array,8192,64,1,2,2,true,false,true,0.101964,0.061925
gpu_array,8192,64,1,2,4,true,false,true,0.098147,0.0567651
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,0.124996,0.0805627
gpu_sparse,8192,64,1,2,2,true,false,true,0.103682,0.0641309
gpu_sparse,8192,64,1,2,4,true,false,true,0.102488,0.0626929
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,0.109369,0.0601746
gpu_array,8192,64,1,10,2,true,false,true,0.110571,0.0569824
gpu_array,8192,64,1,10,4,true,false,true,0.108877,0.0599268
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,0.109908,0.0577844
gpu_sparse,8192,64,1,10,2,true,false,true,0.114044,0.0597229
gpu_sparse,8192,64,1,10,4,true,false,true,0.114825,0.0616028
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,0.11056,0.0706433
0.0706433
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,0.118027,0.0788428
0.0788428
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,true,false,true,0.110626,0.0714417
0.0714417
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,2,4,false,false,true,0.121885,0.0824561
0.0824561
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,true,false,true,0.0716602,0.0321094
0.0321094
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,8192,64,1,10,2,false,false,true,0.0962817,0.0563647
0.0563647
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	8192
Best kernel execution time: 0.0321094
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 17 seconds of which 1.5575 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
8192 8 1 20 gpu_array
gpu_array,8192,8,1,20,-1,false,false,false,0.717823,0.0436292
gpu_array,8192,8,1,20,2,false,false,true,0.843127,0.0460083
gpu_array,8192,8,1,20,4,false,false,true,0.845354,0.0475024
8192 8 1 20 gpu_sparse
gpu_sparse,8192,8,1,20,-1,false,false,false,0.844063,0.0459668
gpu_sparse,8192,8,1,20,2,false,false,true,0.846964,0.0491125
gpu_sparse,8192,8,1,20,4,false,false,true,0.850306,0.0497693
8192 8 1 50 gpu_array
gpu_array,8192,8,1,50,-1,false,false,false,0.891846,0.0379639
gpu_array,8192,8,1,50,2,false,false,true,0.716831,0.0412939
gpu_array,8192,8,1,50,4,false,false,true,0.838101,0.0412256
8192 8 1 50 gpu_sparse
gpu_sparse,8192,8,1,50,-1,false,false,false,0.714728,0.0368713
gpu_sparse,8192,8,1,50,2,false,false,true,0.840308,0.0430664
gpu_sparse,8192,8,1,50,4,false,false,true,0.84454,0.0429041
8192 32 1 20 gpu_array
gpu_array,8192,32,1,20,-1,false,false,false,0.841907,0.0421021
gpu_array,8192,32,1,20,2,false,false,true,0.716895,0.0420898
gpu_array,8192,32,1,20,4,false,false,true,0.718007,0.0394177
8192 32 1 20 gpu_sparse
gpu_sparse,8192,32,1,20,-1,false,false,false,0.838866,0.0422351
gpu_sparse,8192,32,1,20,2,false,false,true,0.715898,0.0420703
gpu_sparse,8192,32,1,20,4,false,false,true,0.83788,0.038075
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,50,-1,false,false,false,0.693984,0.0310205
0.0310205
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,32,1,20,4,false,false,true,0.704417,0.0397437
0.0397437
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_sparse,8192,8,1,20,-1,false,false,false,0.710404,0.047074
0.047074
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	8192
Best kernel execution time: 0.0310205
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 8 seconds of which 0.728385 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
higgs 28 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,0.0373938,0.00968384
gpu_array,8192,32,1,2,2,true,false,true,0.0363879,0.00770142
gpu_array,8192,32,1,2,4,true,false,true,0.0350049,0.00729492
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,0.0387634,0.00995483
gpu_sparse,8192,32,1,2,2,true,false,true,0.0358228,0.00701416
gpu_sparse,8192,32,1,2,4,true,false,true,0.0361816,0.00712891
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,0.0364941,0.00683105
gpu_array,8192,32,1,10,2,true,false,true,0.0345178,0.00595337
gpu_array,8192,32,1,10,4,true,false,true,0.0349438,0.00589111
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,0.0363867,0.00733398
gpu_sparse,8192,32,1,10,2,true,false,true,0.0359717,0.00618652
gpu_sparse,8192,32,1,10,4,true,false,true,0.0363538,0.00632446
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,0.0375085,0.00967651
gpu_array,8192,64,1,2,2,true,false,true,0.03755,0.00776489
gpu_array,8192,64,1,2,4,true,false,true,0.0425525,0.00739624
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,0.0387891,0.0102246
gpu_sparse,8192,64,1,2,2,true,false,true,0.0369861,0.00683472
gpu_sparse,8192,64,1,2,4,true,false,true,0.0352014,0.00736938
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,0.035686,0.00687744
gpu_array,8192,64,1,10,2,true,false,true,0.0336548,0.00594482
gpu_array,8192,64,1,10,4,true,false,true,0.0350769,0.0059021
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,0.0432605,0.00737183
gpu_sparse,8192,64,1,10,2,true,false,true,0.0357739,0.00647705
gpu_sparse,8192,64,1,10,4,true,false,true,0.0363696,0.00658447
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,0.0280334,0.00581665
0.00581665
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,0.0299268,0.00685547
0.00685547
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,0.0281763,0.00595947
0.00595947
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,0.0293274,0.0071106
0.0071106
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,0.0305005,0.00767334
0.00767334
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,0.0299646,0.00799194
0.00799194
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	8192
Best kernel execution time: 0.00581665
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 7 seconds of which 0.177873 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,3.42318,3.40146
gpu_array,8192,32,1,2,2,true,false,true,2.58241,2.56007
gpu_array,8192,32,1,2,4,true,false,true,2.59571,2.57386
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,3.27905,3.25818
gpu_sparse,8192,32,1,2,2,true,false,true,2.66243,2.64045
gpu_sparse,8192,32,1,2,4,true,false,true,2.58831,2.56634
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,2.69215,2.66713
gpu_array,8192,32,1,10,2,true,false,true,2.76422,2.74078
gpu_array,8192,32,1,10,4,true,false,true,2.80931,2.78563
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,2.56426,2.54192
gpu_sparse,8192,32,1,10,2,true,false,true,2.76035,2.73679
gpu_sparse,8192,32,1,10,4,true,false,true,2.7158,2.69139
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,3.04457,3.02308
gpu_array,8192,64,1,2,2,true,false,true,2.64439,2.6223
gpu_array,8192,64,1,2,4,true,false,true,2.65269,2.63096
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,2.97394,2.95209
gpu_sparse,8192,64,1,2,2,true,false,true,2.74299,2.72138
gpu_sparse,8192,64,1,2,4,true,false,true,2.62252,2.60165
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,2.76718,2.74326
gpu_array,8192,64,1,10,2,true,false,true,2.82229,2.79836
gpu_array,8192,64,1,10,4,true,false,true,3.04881,3.02489
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,2.65071,2.62959
gpu_sparse,8192,64,1,10,2,true,false,true,2.80158,2.77827
gpu_sparse,8192,64,1,10,4,true,false,true,2.6357,2.61178
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,true,false,false,1.92245,1.90841
1.90841
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,10,-1,false,false,false,1.99756,1.98291
1.98291
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,true,false,true,2.08051,2.06635
2.06635
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,32,1,2,4,false,false,true,2.3618,2.34764
2.34764
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,true,false,true,2.08547,2.07106
2.07106
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,8192,64,1,2,4,false,false,true,2.46568,2.45079
2.45079
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	8192
Best kernel execution time: 1.90841
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 132 seconds of which 16.2056 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
8192 32 1 2 gpu_array
gpu_array,8192,32,1,2,-1,true,false,false,0.0745972,0.0139282
gpu_array,8192,32,1,2,2,true,false,true,0.074469,0.0118469
gpu_array,8192,32,1,2,4,true,false,true,0.0747253,0.0113708
8192 32 1 2 gpu_sparse
gpu_sparse,8192,32,1,2,-1,true,false,false,0.0766699,0.0151465
gpu_sparse,8192,32,1,2,2,true,false,true,0.0721973,0.00933105
gpu_sparse,8192,32,1,2,4,true,false,true,0.0726929,0.0101929
8192 32 1 10 gpu_array
gpu_array,8192,32,1,10,-1,true,false,false,0.0670557,0.00626465
gpu_array,8192,32,1,10,2,true,false,true,0.0689465,0.00583618
gpu_array,8192,32,1,10,4,true,false,true,0.0700354,0.00558228
8192 32 1 10 gpu_sparse
gpu_sparse,8192,32,1,10,-1,true,false,false,0.0690845,0.0064624
gpu_sparse,8192,32,1,10,2,true,false,true,0.0696301,0.00615356
gpu_sparse,8192,32,1,10,4,true,false,true,0.0697681,0.00592529
8192 64 1 2 gpu_array
gpu_array,8192,64,1,2,-1,true,false,false,0.0774902,0.0151123
gpu_array,8192,64,1,2,2,true,false,true,0.073313,0.0119116
gpu_array,8192,64,1,2,4,true,false,true,0.0731812,0.0114136
8192 64 1 2 gpu_sparse
gpu_sparse,8192,64,1,2,-1,true,false,false,0.0771802,0.0152905
gpu_sparse,8192,64,1,2,2,true,false,true,0.0719641,0.00934204
gpu_sparse,8192,64,1,2,4,true,false,true,0.0739954,0.0102747
8192 64 1 10 gpu_array
gpu_array,8192,64,1,10,-1,true,false,false,0.0689087,0.00628662
gpu_array,8192,64,1,10,2,true,false,true,0.0688672,0.00587891
gpu_array,8192,64,1,10,4,true,false,true,0.0704773,0.00565796
8192 64 1 10 gpu_sparse
gpu_sparse,8192,64,1,10,-1,true,false,false,0.069939,0.00658447
gpu_sparse,8192,64,1,10,2,true,false,true,0.0703418,0.00649902
gpu_sparse,8192,64,1,10,4,true,false,true,0.0715198,0.00633423
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,true,false,true,0.0694446,0.00547974
0.00547974
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,10,4,false,false,true,0.0710498,0.00757324
0.00757324
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,true,false,true,0.0642932,0.00545532
0.00545532
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,64,1,10,4,false,false,true,0.0695032,0.00797974
0.00797974
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,true,false,true,0.06479,0.00998047
0.00998047
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,8192,32,1,2,4,false,false,true,0.0784619,0.0159619
0.0159619
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	8192
Best kernel execution time: 0.00545532
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 9 seconds of which 0.22205 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 64
	numRowsPerThread: 1
	numTreeThreads: 10
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
