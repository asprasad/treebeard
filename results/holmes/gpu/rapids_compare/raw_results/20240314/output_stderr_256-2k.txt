abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-116.469,1.18397
gpu_array,256,8,1,20,2,true,false,true,false,-109.371,1.11099
gpu_array,256,8,1,20,4,true,false,true,false,-102.104,1.03845
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-145.552,1.47528
gpu_sparse,256,8,1,20,2,true,false,true,false,-133.918,1.35726
gpu_sparse,256,8,1,20,4,true,false,true,false,-127.757,1.29746
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-143.903,1.45929
gpu_reorg,256,8,1,20,2,true,false,true,false,-101.949,1.04006
gpu_reorg,256,8,1,20,4,true,false,true,false,-103.576,1.05159
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-147.79,1.49915
gpu_array,256,8,1,50,2,true,false,true,false,-113.742,1.15923
gpu_array,256,8,1,50,4,true,false,true,false,-113.699,1.15927
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-154.488,1.56581
gpu_sparse,256,8,1,50,2,true,false,true,false,-144.304,1.46603
gpu_sparse,256,8,1,50,4,true,false,true,false,-144.304,1.46537
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-211.984,2.14625
gpu_reorg,256,8,1,50,2,true,false,true,false,-117.193,1.19897
gpu_reorg,256,8,1,50,4,true,false,true,false,-122.101,1.2356
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-196.453,1.98992
gpu_array,256,32,1,20,2,true,false,true,false,-116.419,1.18214
gpu_array,256,32,1,20,4,true,false,true,false,-105.321,1.07147
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-197.358,1.99929
gpu_sparse,256,32,1,20,2,true,false,true,false,-125.226,1.27041
gpu_sparse,256,32,1,20,4,true,false,true,false,-111.527,1.13732
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-267.943,2.71129
gpu_reorg,256,32,1,20,2,true,false,true,false,-150.177,1.52302
gpu_reorg,256,32,1,20,4,true,false,true,false,-157.763,1.59855
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,-100.12,1.0195
1.0195
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-109.218,1.11227
1.11227
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-105.627,1.07259
1.07259
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-111.857,1.14003
1.14003
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-108.74,1.10684
1.10684
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-109.592,1.11367
1.11367
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 1.0195
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 31 seconds of which 2.30187 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-116.788,1.18696
gpu_array,256,8,1,20,2,true,false,true,false,-110.239,1.11843
gpu_array,256,8,1,20,4,true,false,true,false,-102.213,1.04279
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-145.716,1.47719
gpu_sparse,256,8,1,20,2,true,false,true,false,-134.801,1.36732
gpu_sparse,256,8,1,20,4,true,false,true,false,-128.097,1.30332
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-144.397,1.46658
gpu_reorg,256,8,1,20,2,true,false,true,false,-102.782,1.04815
gpu_reorg,256,8,1,20,4,true,false,true,false,-104.272,1.06012
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-148.657,1.50676
gpu_array,256,8,1,50,2,true,false,true,false,-114.577,1.16544
gpu_array,256,8,1,50,4,true,false,true,false,-114.388,1.16294
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-155.555,1.5776
gpu_sparse,256,8,1,50,2,true,false,true,false,-145.476,1.4737
gpu_sparse,256,8,1,50,4,true,false,true,false,-145.375,1.47641
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-212.54,2.15284
gpu_reorg,256,8,1,50,2,true,false,true,false,-118.458,1.20676
gpu_reorg,256,8,1,50,4,true,false,true,false,-122.069,1.24039
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-196.429,1.99133
gpu_array,256,32,1,20,2,true,false,true,false,-116.29,1.18107
gpu_array,256,32,1,20,4,true,false,true,false,-105.728,1.0748
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-197.504,2.01207
gpu_sparse,256,32,1,20,2,true,false,true,false,-124.982,1.26939
gpu_sparse,256,32,1,20,4,true,false,true,false,-112.026,1.13771
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-267.939,2.71125
gpu_reorg,256,32,1,20,2,true,false,true,false,-150.615,1.52604
gpu_reorg,256,32,1,20,4,true,false,true,false,-157.845,1.59937
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,-100.997,1.03319
1.03319
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-110.167,1.11743
1.11743
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-105.561,1.07326
1.07326
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-113.422,1.14956
1.14956
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,-105.763,1.07888
1.07888
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,-120.387,1.2245
1.2245
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 1.03319
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 30 seconds of which 2.31493 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-22.0149,0.22841
gpu_array,256,8,1,20,2,true,false,true,false,-20.8786,0.217972
gpu_array,256,8,1,20,4,true,false,true,false,-21.201,0.218613
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-26.9564,0.28639
gpu_sparse,256,8,1,20,2,true,false,true,false,-28.8346,0.297068
gpu_sparse,256,8,1,20,4,true,false,true,false,-26.691,0.275505
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-24.0988,0.251088
gpu_reorg,256,8,1,20,2,true,false,true,false,-23.9707,0.248622
gpu_reorg,256,8,1,20,4,true,false,true,false,-24.0146,0.251063
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-29.6231,0.306607
gpu_array,256,8,1,50,2,true,false,true,false,-28.4715,0.295229
gpu_array,256,8,1,50,4,true,false,true,false,-28.5288,0.295405
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-33.8444,0.35207
gpu_sparse,256,8,1,50,2,true,false,true,false,-34.181,0.351911
gpu_sparse,256,8,1,50,4,true,false,true,false,-33.9684,0.351336
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-28.3746,0.294517
gpu_reorg,256,8,1,50,2,true,false,true,false,-31.4164,0.325201
gpu_reorg,256,8,1,50,4,true,false,true,false,-31.1892,0.323661
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-21.5627,0.222469
gpu_array,256,32,1,20,2,true,false,true,false,-17.3477,0.179626
gpu_array,256,32,1,20,4,true,false,true,false,-17.4675,0.179791
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-22.0905,0.226507
gpu_sparse,256,32,1,20,2,true,false,true,false,-19.4377,0.199581
gpu_sparse,256,32,1,20,4,true,false,true,false,-25.2805,0.26137
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-39.165,0.402545
gpu_reorg,256,32,1,20,2,true,false,true,false,-22.4079,0.233814
gpu_reorg,256,32,1,20,4,true,false,true,false,-23.5537,0.238703
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-17.148,0.17514
0.17514
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-21.1972,0.219634
0.219634
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,true,-20.8123,0.216133
0.216133
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,true,-26.8934,0.280117
0.280117
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-31.3726,0.326582
0.326582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-28.0499,0.291027
0.291027
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.17514
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 0.451774 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-35.3121,0.361448
gpu_array,256,8,1,20,2,true,false,true,false,-26.5477,0.272567
gpu_array,256,8,1,20,4,true,false,true,false,-26.0252,0.269481
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-34.6533,0.355619
gpu_sparse,256,8,1,20,2,true,false,true,false,-25.6594,0.265778
gpu_sparse,256,8,1,20,4,true,false,true,false,-25.2575,0.261501
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-22.7641,0.237584
gpu_reorg,256,8,1,20,2,true,false,true,false,-22.5697,0.237241
gpu_reorg,256,8,1,20,4,true,false,true,false,-22.6588,0.238549
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-34.3838,0.354481
gpu_array,256,8,1,50,2,true,false,true,false,-28.5612,0.2937
gpu_array,256,8,1,50,4,true,false,true,false,-28.7349,0.295282
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-34.0615,0.352578
gpu_sparse,256,8,1,50,2,true,false,true,false,-33.9932,0.351677
gpu_sparse,256,8,1,50,4,true,false,true,false,-34.3742,0.351267
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-28.5456,0.293733
gpu_reorg,256,8,1,50,2,true,false,true,false,-31.2607,0.327461
gpu_reorg,256,8,1,50,4,true,false,true,false,-31.4451,0.324989
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-21.6668,0.223797
gpu_array,256,32,1,20,2,true,false,true,false,-16.7848,0.177815
gpu_array,256,32,1,20,4,true,false,true,false,-17.2822,0.177609
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-22.0442,0.226995
gpu_sparse,256,32,1,20,2,true,false,true,false,-19.2681,0.198376
gpu_sparse,256,32,1,20,4,true,false,true,false,-27.0268,0.277324
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-38.9511,0.409944
gpu_reorg,256,32,1,20,2,true,false,true,false,-29.0816,0.301222
gpu_reorg,256,32,1,20,4,true,false,true,false,-29.8852,0.30678
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-21.5767,0.222927
0.222927
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-26.4982,0.275778
0.275778
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,-27.548,0.290723
0.290723
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-29.7045,0.310564
0.310564
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-33.555,0.352944
0.352944
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-36.3089,0.378555
0.378555
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.177609
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 0.490306 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-382.468,3.87657
gpu_array,256,8,1,20,2,true,false,true,false,-210.476,2.13866
gpu_array,256,8,1,20,4,true,false,true,false,-135.852,1.38651
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-374.892,3.80031
gpu_sparse,256,8,1,20,2,true,false,true,false,-211.102,2.14567
gpu_sparse,256,8,1,20,4,true,false,true,false,-146.077,1.48926
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-371.959,3.7817
gpu_reorg,256,8,1,20,2,true,false,true,false,-197.973,2.02439
gpu_reorg,256,8,1,20,4,true,false,true,false,-224.297,2.29274
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-184.093,1.87363
gpu_array,256,8,1,50,2,true,false,true,false,-120.098,1.22847
gpu_array,256,8,1,50,4,true,false,true,false,-150.624,1.53499
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-187.764,1.91081
gpu_sparse,256,8,1,50,2,true,false,true,false,-139.393,1.42313
gpu_sparse,256,8,1,50,4,true,false,true,false,-155.452,1.58212
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-213.665,2.18417
gpu_reorg,256,8,1,50,2,true,false,true,false,-101.381,1.05558
gpu_reorg,256,8,1,50,4,true,false,true,false,-129.915,1.33201
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,true,false,true,true,-218.068,1.66181
1.66181
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,false,false,true,true,-188.884,1.93645
1.93645
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,true,false,true,true,-184.793,1.89023
1.89023
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,false,false,true,true,-494.813,5.0259
5.0259
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 1.05558
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 46 seconds of which 2.43585 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-382.318,3.87533
gpu_array,256,8,1,20,2,true,false,true,false,-210.357,2.13798
gpu_array,256,8,1,20,4,true,false,true,false,-135.501,1.38214
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-374.589,3.79727
gpu_sparse,256,8,1,20,2,true,false,true,false,-211.041,2.14419
gpu_sparse,256,8,1,20,4,true,false,true,false,-145.38,1.48083
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-371.78,3.77948
gpu_reorg,256,8,1,20,2,true,false,true,false,-197.685,2.02333
gpu_reorg,256,8,1,20,4,true,false,true,false,-224.476,2.2905
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-183.38,1.86469
gpu_array,256,8,1,50,2,true,false,true,false,-119.428,1.22191
gpu_array,256,8,1,50,4,true,false,true,false,-150.401,1.53206
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-186.691,1.90195
gpu_sparse,256,8,1,50,2,true,false,true,false,-138.576,1.41637
gpu_sparse,256,8,1,50,4,true,false,true,false,-154.283,1.57314
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-213.573,2.18306
gpu_reorg,256,8,1,50,2,true,false,true,false,-101.447,1.0527
gpu_reorg,256,8,1,50,4,true,false,true,false,-128.337,1.32114
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,true,false,true,true,-212.889,1.64439
1.64439
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,false,false,true,true,-188.669,1.92878
1.92878
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,true,false,true,true,-184.639,1.88964
1.88964
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,false,false,true,true,-495.097,5.02604
5.02604
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 1.0527
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 46 seconds of which 2.43031 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-113.394,1.15414
gpu_array,256,8,1,20,2,true,false,true,false,-120.886,1.22772
gpu_array,256,8,1,20,4,true,false,true,false,-130.143,1.32285
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-112.289,1.14245
gpu_sparse,256,8,1,20,2,true,false,true,false,-143.243,1.45479
gpu_sparse,256,8,1,20,4,true,false,true,false,-148.448,1.50427
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-144.637,1.46847
gpu_reorg,256,8,1,20,2,true,false,true,false,-117.141,1.19188
gpu_reorg,256,8,1,20,4,true,false,true,false,-157.332,1.59552
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-181.749,1.85362
gpu_array,256,8,1,50,2,true,false,true,false,-148.054,1.51444
gpu_array,256,8,1,50,4,true,false,true,false,-194.392,1.98277
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-180.245,1.82797
gpu_sparse,256,8,1,50,2,true,false,true,false,-168.597,1.72156
gpu_sparse,256,8,1,50,4,true,false,true,false,-205.643,2.09578
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-213.693,2.16283
gpu_reorg,256,8,1,50,2,true,false,true,false,-147.631,1.50242
gpu_reorg,256,8,1,50,4,true,false,true,false,-264.597,2.67952
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-183.325,1.85759
gpu_array,256,32,1,20,2,true,false,true,false,-139.001,1.41181
gpu_array,256,32,1,20,4,true,false,true,false,-108.68,1.1061
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-177.632,1.79969
gpu_sparse,256,32,1,20,2,true,false,true,false,-140.946,1.42914
gpu_sparse,256,32,1,20,4,true,false,true,false,-114.623,1.16492
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-197.074,1.99751
gpu_reorg,256,32,1,20,2,true,false,true,false,-146.984,1.49185
gpu_reorg,256,32,1,20,4,true,false,true,false,-152.025,1.54295
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-121.456,1.23208
1.23208
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-186.119,1.88405
1.88405
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-102.181,1.03451
1.03451
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-105.809,1.07565
1.07565
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-115.756,1.17473
1.17473
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-135.399,1.37665
1.37665
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 1.03451
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 42 seconds of which 2.61029 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-113.394,1.15441
gpu_array,256,8,1,20,2,true,false,true,false,-120.982,1.22865
gpu_array,256,8,1,20,4,true,false,true,false,-130.182,1.32215
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-112.153,1.14126
gpu_sparse,256,8,1,20,2,true,false,true,false,-143.149,1.45584
gpu_sparse,256,8,1,20,4,true,false,true,false,-148.224,1.50561
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-145.107,1.47027
gpu_reorg,256,8,1,20,2,true,false,true,false,-117.558,1.1925
gpu_reorg,256,8,1,20,4,true,false,true,false,-157.314,1.59592
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-181.807,1.85589
gpu_array,256,8,1,50,2,true,false,true,false,-148.011,1.51229
gpu_array,256,8,1,50,4,true,false,true,false,-194.153,1.98095
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-180.543,1.82879
gpu_sparse,256,8,1,50,2,true,false,true,false,-168.764,1.72299
gpu_sparse,256,8,1,50,4,true,false,true,false,-205.181,2.09352
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-213.566,2.16275
gpu_reorg,256,8,1,50,2,true,false,true,false,-147.962,1.50228
gpu_reorg,256,8,1,50,4,true,false,true,false,-264.811,2.68042
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-183.299,1.85865
gpu_array,256,32,1,20,2,true,false,true,false,-139.41,1.41357
gpu_array,256,32,1,20,4,true,false,true,false,-108.982,1.10687
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-177.46,1.80093
gpu_sparse,256,32,1,20,2,true,false,true,false,-140.67,1.42782
gpu_sparse,256,32,1,20,4,true,false,true,false,-114.696,1.1648
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-196.964,1.99574
gpu_reorg,256,32,1,20,2,true,false,true,false,-146.778,1.4907
gpu_reorg,256,32,1,20,4,true,false,true,false,-151.964,1.54265
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-121.187,1.23007
1.23007
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-182.11,1.84564
1.84564
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-102.474,1.03888
1.03888
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-106.525,1.08413
1.08413
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-115.836,1.17547
1.17547
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-136.289,1.38409
1.38409
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 1.03888
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 42 seconds of which 2.60948 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,-136.814,1.40344
gpu_array,256,8,1,20,2,false,false,true,false,-132.22,1.35886
gpu_array,256,8,1,20,4,false,false,true,false,-126.17,1.29783
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,-140.92,1.44617
gpu_sparse,256,8,1,20,2,false,false,true,false,-135.712,1.39213
gpu_sparse,256,8,1,20,4,false,false,true,false,-126.821,1.30396
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,-164.905,1.68764
gpu_reorg,256,8,1,20,2,false,false,true,false,-145.544,1.49196
gpu_reorg,256,8,1,20,4,false,false,true,false,-134.958,1.40734
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,-72.9606,0.763131
gpu_array,256,8,1,50,2,false,false,true,false,-75.6779,0.784752
gpu_array,256,8,1,50,4,false,false,true,false,-75.3884,0.783451
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,-76.0097,0.790499
gpu_sparse,256,8,1,50,2,false,false,true,false,-85.9399,0.891063
gpu_sparse,256,8,1,50,4,false,false,true,false,-85.7251,0.889283
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,-77.3056,0.804355
gpu_reorg,256,8,1,50,2,false,false,true,false,-75.6147,0.786565
gpu_reorg,256,8,1,50,4,false,false,true,false,-75.7202,0.788131
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,-114.109,1.17514
gpu_array,256,32,1,20,2,false,false,true,false,-105.094,1.08544
gpu_array,256,32,1,20,4,false,false,true,false,-107.613,1.10914
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,-115.99,1.19611
gpu_sparse,256,32,1,20,2,false,false,true,false,-108.755,1.12035
gpu_sparse,256,32,1,20,4,false,false,true,false,-113.935,1.17523
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,-128.068,1.31641
gpu_reorg,256,32,1,20,2,false,false,true,false,-118.205,1.2162
gpu_reorg,256,32,1,20,4,false,false,true,false,-119.673,1.23146
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-69.3699,0.725502
0.725502
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-104.236,1.07669
1.07669
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-100.399,1.03726
1.03726
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.725502
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 21 seconds of which 1.71702 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,-136.803,1.40502
gpu_array,256,8,1,20,2,false,false,true,false,-132.517,1.35996
gpu_array,256,8,1,20,4,false,false,true,false,-126.225,1.29876
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,-140.48,1.44374
gpu_sparse,256,8,1,20,2,false,false,true,false,-135.593,1.3928
gpu_sparse,256,8,1,20,4,false,false,true,false,-126.799,1.30472
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,-164.842,1.68643
gpu_reorg,256,8,1,20,2,false,false,true,false,-145.365,1.49059
gpu_reorg,256,8,1,20,4,false,false,true,false,-134.746,1.38465
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,-73.1859,0.762201
gpu_array,256,8,1,50,2,false,false,true,false,-75.3678,0.782899
gpu_array,256,8,1,50,4,false,false,true,false,-74.929,0.784687
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,-75.8661,0.79067
gpu_sparse,256,8,1,50,2,false,false,true,false,-85.5905,0.887751
gpu_sparse,256,8,1,50,4,false,false,true,false,-85.9682,0.891205
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,-77.3938,0.80541
gpu_reorg,256,8,1,50,2,false,false,true,false,-75.6343,0.787606
gpu_reorg,256,8,1,50,4,false,false,true,false,-75.6786,0.789068
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,-114.049,1.17386
gpu_array,256,32,1,20,2,false,false,true,false,-104.976,1.08346
gpu_array,256,32,1,20,4,false,false,true,false,-107.57,1.1096
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,-115.962,1.19376
gpu_sparse,256,32,1,20,2,false,false,true,false,-108.68,1.11974
gpu_sparse,256,32,1,20,4,false,false,true,false,-113.776,1.17246
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,-128.261,1.31859
gpu_reorg,256,32,1,20,2,false,false,true,false,-117.895,1.21406
gpu_reorg,256,32,1,20,4,false,false,true,false,-119.411,1.22869
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-69.545,0.726727
0.726727
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-104.41,1.07594
1.07594
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-100.372,1.03705
1.03705
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.726727
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 21 seconds of which 1.71531 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-22.7196,0.237985
gpu_array,256,8,1,20,2,true,false,true,false,-20.9862,0.222467
gpu_array,256,8,1,20,4,true,false,true,false,-21.2606,0.222076
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-27.9496,0.287595
gpu_sparse,256,8,1,20,2,true,false,true,false,-26.1572,0.268039
gpu_sparse,256,8,1,20,4,true,false,true,false,-25.4597,0.265765
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-24.2812,0.252263
gpu_reorg,256,8,1,20,2,true,false,true,false,-23.5836,0.247355
gpu_reorg,256,8,1,20,4,true,false,true,false,-29.0143,0.298189
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-32.8914,0.339104
gpu_array,256,8,1,50,2,true,false,true,false,-28.3752,0.293345
gpu_array,256,8,1,50,4,true,false,true,false,-28.2219,0.293175
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-34.1622,0.350622
gpu_sparse,256,8,1,50,2,true,false,true,false,-32.7881,0.339701
gpu_sparse,256,8,1,50,4,true,false,true,false,-32.8091,0.340424
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-30.8553,0.31606
gpu_reorg,256,8,1,50,2,true,false,true,false,-32.9321,0.341342
gpu_reorg,256,8,1,50,4,true,false,true,false,-33.1341,0.341323
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-22.9534,0.241348
gpu_array,256,32,1,20,2,true,false,true,false,-19.7563,0.204076
gpu_array,256,32,1,20,4,true,false,true,false,-20.0897,0.207709
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-33.713,0.346727
gpu_sparse,256,32,1,20,2,true,false,true,false,-24.0961,0.251016
gpu_sparse,256,32,1,20,4,true,false,true,false,-24.9707,0.257506
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-36.5099,0.377411
gpu_reorg,256,32,1,20,2,true,false,true,false,-29.3376,0.301875
gpu_reorg,256,32,1,20,4,true,false,true,false,-29.1221,0.301998
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-19.3458,0.202734
0.202734
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-25.2983,0.260324
0.260324
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,-20.2259,0.211579
0.211579
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-22.1241,0.22639
0.22639
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,-25.0072,0.269542
0.269542
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,-30.0446,0.31649
0.31649
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.202734
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 12 seconds of which 0.472758 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-35.1012,0.360329
gpu_array,256,8,1,20,2,true,false,true,false,-24.9744,0.259378
gpu_array,256,8,1,20,4,true,false,true,false,-25.3599,0.260586
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-33.1973,0.343982
gpu_sparse,256,8,1,20,2,true,false,true,false,-26.1315,0.269704
gpu_sparse,256,8,1,20,4,true,false,true,false,-25.5075,0.266473
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-23.9618,0.25024
gpu_reorg,256,8,1,20,2,true,false,true,false,-24.0073,0.24935
gpu_reorg,256,8,1,20,4,true,false,true,false,-23.9091,0.281702
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-38.9014,0.402134
gpu_array,256,8,1,50,2,true,false,true,false,-41.163,0.420739
gpu_array,256,8,1,50,4,true,false,true,false,-41.5926,0.432475
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-41.5197,0.425605
gpu_sparse,256,8,1,50,2,true,false,true,false,-33.018,0.340212
gpu_sparse,256,8,1,50,4,true,false,true,false,-33.0835,0.339489
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-30.2136,0.31262
gpu_reorg,256,8,1,50,2,true,false,true,false,-33.0393,0.341861
gpu_reorg,256,8,1,50,4,true,false,true,false,-33.2888,0.34067
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-23.02,0.240592
gpu_array,256,32,1,20,2,true,false,true,false,-19.7069,0.205485
gpu_array,256,32,1,20,4,true,false,true,false,-19.937,0.208664
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-24.3365,0.254495
gpu_sparse,256,32,1,20,2,true,false,true,false,-22.1487,0.229679
gpu_sparse,256,32,1,20,4,true,false,true,false,-27.6988,0.287254
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-40.8994,0.421448
gpu_reorg,256,32,1,20,2,true,false,true,false,-29.4297,0.298538
gpu_reorg,256,32,1,20,4,true,false,true,false,-29.2566,0.30315
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-19.5183,0.201049
0.201049
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-25.0875,0.260131
0.260131
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,true,-20.6594,0.213345
0.213345
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,true,-21.6258,0.226908
0.226908
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-25.9352,0.267921
0.267921
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-29.9683,0.310134
0.310134
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.201049
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 12 seconds of which 0.503109 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-1710.07,69.4695
gpu_array,256,8,1,20,2,true,false,true,false,-2025.29,81.753
gpu_array,256,8,1,20,4,true,false,true,false,-2109.17,85.4045
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-1710.11,69.4835
gpu_sparse,256,8,1,20,2,true,false,true,false,-2299.04,93.4729
gpu_sparse,256,8,1,20,4,true,false,true,false,-2418.55,98.3164
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-2728.62,111.908
gpu_reorg,256,8,1,20,2,true,false,true,false,-2914.25,118.7
gpu_reorg,256,8,1,20,4,true,false,true,false,-3747.45,153.931
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-3387.17,139.904
gpu_array,256,8,1,50,2,true,false,true,false,-2559.62,104.297
gpu_array,256,8,1,50,4,true,false,true,false,-3860.36,158.46
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-2802.63,115.042
gpu_sparse,256,8,1,50,2,true,false,true,false,-2625.04,105.703
gpu_sparse,256,8,1,50,4,true,false,true,false,-3943.81,162.106
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-4171.58,172.619
gpu_reorg,256,8,1,50,2,true,false,true,false,-9469.59,395.153
gpu_reorg,256,8,1,50,4,true,false,true,false,-10156.3,422.293
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-1982.26,79.9831
gpu_array,256,32,1,20,2,true,false,true,false,-1781.85,72.2598
gpu_array,256,32,1,20,4,true,false,true,false,-1772.69,71.2993
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-1732.72,69.7073
gpu_sparse,256,32,1,20,2,true,false,true,false,-1798.13,72.59
gpu_sparse,256,32,1,20,4,true,false,true,false,-1778.42,71.9036
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-2166.51,87.4835
gpu_reorg,256,32,1,20,2,true,false,true,false,-4280.33,177.21
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-1367.38,54.5511
54.5511
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-1388.97,55.7961
55.7961
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-3188.61,130.22
130.22
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-3344.5,137.034
137.034
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 54.5511
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 595 seconds of which 47.8471 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-1711.38,69.4852
gpu_array,256,8,1,20,2,true,false,true,false,-2033.17,81.9829
gpu_array,256,8,1,20,4,true,false,true,false,-2139.35,86.0705
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-1705.48,69.4602
gpu_sparse,256,8,1,20,2,true,false,true,false,-2327.37,94.0794
gpu_sparse,256,8,1,20,4,true,false,true,false,-2414.34,98.1938
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-2717.71,111.553
gpu_reorg,256,8,1,20,2,true,false,true,false,-2921.01,118.885
gpu_reorg,256,8,1,20,4,true,false,true,false,-3775.2,153.939
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-3373.95,139.66
gpu_array,256,8,1,50,2,true,false,true,false,-2569.45,104.253
gpu_array,256,8,1,50,4,true,false,true,false,-3857.34,158.394
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-2788.02,114.869
gpu_sparse,256,8,1,50,2,true,false,true,false,-2573.88,105.039
gpu_sparse,256,8,1,50,4,true,false,true,false,-3923.71,161.662
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-4145.78,172.039
gpu_reorg,256,8,1,50,2,true,false,true,false,-9425.06,389.049
gpu_reorg,256,8,1,50,4,true,false,true,false,-10175.3,421.58
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-1952.87,79.3608
gpu_array,256,32,1,20,2,true,false,true,false,-1764.57,71.731
gpu_array,256,32,1,20,4,true,false,true,false,-1749.24,71.1898
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-1731.17,69.7257
gpu_sparse,256,32,1,20,2,true,false,true,false,-1779.22,72.0565
gpu_sparse,256,32,1,20,4,true,false,true,false,-1788.33,72.0831
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-2138.97,86.8062
gpu_reorg,256,32,1,20,2,true,false,true,false,-4262.95,177.581
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,-1298.06,51.9026
51.9026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,-1354.61,53.9105
53.9105
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,true,false,true,true,-3151.61,129.236
129.236
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,false,false,true,true,-3475.59,142.836
142.836
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 51.9026
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 596 seconds of which 47.7263 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-20.1207,0.209057
gpu_array,256,8,1,20,2,true,false,true,false,-31.9811,0.332475
gpu_array,256,8,1,20,4,true,false,true,false,-31.4343,0.325745
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-24.619,0.25656
gpu_sparse,256,8,1,20,2,true,false,true,false,-36.1161,0.37382
gpu_sparse,256,8,1,20,4,true,false,true,false,-37.2647,0.384255
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-24.5289,0.253984
gpu_reorg,256,8,1,20,2,true,false,true,false,-102.998,0.829922
gpu_reorg,256,8,1,20,4,true,false,true,false,-100.334,0.840326
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-30.3031,0.314598
gpu_array,256,8,1,50,2,true,false,true,false,-63.745,0.665117
gpu_array,256,8,1,50,4,true,false,true,false,-60.3247,0.615008
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-31.1563,0.322469
gpu_sparse,256,8,1,50,2,true,false,true,false,-59.4885,0.608052
gpu_sparse,256,8,1,50,4,true,false,true,false,-59.5574,0.610605
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-31.0147,0.323443
gpu_reorg,256,8,1,50,2,true,false,true,false,-61.8891,0.633825
gpu_reorg,256,8,1,50,4,true,false,true,false,-62.0056,0.633954
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-21.3005,0.219021
gpu_array,256,32,1,20,2,true,false,true,false,-24.3904,0.253535
gpu_array,256,32,1,20,4,true,false,true,false,-43.8401,0.448443
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-24.1943,0.250421
gpu_sparse,256,32,1,20,2,true,false,true,false,-27.4773,0.284436
gpu_sparse,256,32,1,20,4,true,false,true,false,-49.9427,0.50933
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-59.1308,0.589595
gpu_reorg,256,32,1,20,2,true,false,true,false,-49.0413,0.504414
gpu_reorg,256,32,1,20,4,true,false,true,false,-95.6051,0.769944
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-26.9225,0.277235
0.277235
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-33.7484,0.347542
0.347542
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,true,false,false,true,-28.8399,0.298491
0.298491
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,false,false,false,true,-35.5887,0.364933
0.364933
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-23.5633,0.241434
0.241434
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-26.809,0.272506
0.272506
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.209057
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 32 seconds of which 0.725222 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-29.8452,0.315516
gpu_array,256,8,1,20,2,true,false,true,false,-62.4886,0.557196
gpu_array,256,8,1,20,4,true,false,true,false,-45.6929,0.467288
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-24.7944,0.256403
gpu_sparse,256,8,1,20,2,true,false,true,false,-36.2966,0.374127
gpu_sparse,256,8,1,20,4,true,false,true,false,-64.1465,0.569983
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-27.1593,0.282101
gpu_reorg,256,8,1,20,2,true,false,true,false,-43.7752,0.44966
gpu_reorg,256,8,1,20,4,true,false,true,false,-129.279,0.999632
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-28.0341,0.291833
gpu_array,256,8,1,50,2,true,false,true,false,-60.2744,0.616253
gpu_array,256,8,1,50,4,true,false,true,false,-60.2892,0.615326
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-31.2527,0.321515
gpu_sparse,256,8,1,50,2,true,false,true,false,-59.4534,0.609626
gpu_sparse,256,8,1,50,4,true,false,true,false,-59.5381,0.609185
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-30.9037,0.322832
gpu_reorg,256,8,1,50,2,true,false,true,false,-62.0569,0.633912
gpu_reorg,256,8,1,50,4,true,false,true,false,-62.0388,0.634701
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-21.1407,0.220921
gpu_array,256,32,1,20,2,true,false,true,false,-24.3369,0.250159
gpu_array,256,32,1,20,4,true,false,true,false,-51.4573,0.530385
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-34.8141,0.359403
gpu_sparse,256,32,1,20,2,true,false,true,false,-30.9001,0.3181
gpu_sparse,256,32,1,20,4,true,false,true,false,-55.0326,0.542695
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-37.7721,0.386989
gpu_reorg,256,32,1,20,2,true,false,true,false,-31.3323,0.32567
gpu_reorg,256,32,1,20,4,true,false,true,false,-36.9804,0.379556
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,true,false,false,true,-20.5594,0.214623
0.214623
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,false,false,false,true,-26.9335,0.277997
0.277997
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-23.0288,0.240137
0.240137
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-25.7187,0.271769
0.271769
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-18.456,0.19137
0.19137
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-23.5355,0.242414
0.242414
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.19137
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 31 seconds of which 0.700379 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-114.643,1.16173
gpu_array,512,8,1,20,2,true,false,true,false,-97.1397,0.985957
gpu_array,512,8,1,20,4,true,false,true,false,-92.4798,0.945973
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-126.768,1.28441
gpu_sparse,512,8,1,20,2,true,false,true,false,-122.111,1.24117
gpu_sparse,512,8,1,20,4,true,false,true,false,-118.756,1.20323
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-141.375,1.43277
gpu_reorg,512,8,1,20,2,true,false,true,false,-96.8583,0.986084
gpu_reorg,512,8,1,20,4,true,false,true,false,-93.3714,0.951543
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-144.635,1.46507
gpu_array,512,8,1,50,2,true,false,true,false,-109.811,1.11514
gpu_array,512,8,1,50,4,true,false,true,false,-110.032,1.11818
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-151.297,1.53272
gpu_sparse,512,8,1,50,2,true,false,true,false,-140.215,1.42141
gpu_sparse,512,8,1,50,4,true,false,true,false,-140.208,1.42085
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-207.146,2.10369
gpu_reorg,512,8,1,50,2,true,false,true,false,-111.884,1.14877
gpu_reorg,512,8,1,50,4,true,false,true,false,-115.98,1.1873
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-144.647,1.46402
gpu_array,512,32,1,20,2,true,false,true,false,-86.1145,0.875059
gpu_array,512,32,1,20,4,true,false,true,false,-79.8565,0.812731
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-144.978,1.46838
gpu_sparse,512,32,1,20,2,true,false,true,false,-92.555,0.939818
gpu_sparse,512,32,1,20,4,true,false,true,false,-89.375,0.908883
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-195.466,1.97777
gpu_reorg,512,32,1,20,2,true,false,true,false,-111.309,1.12895
gpu_reorg,512,32,1,20,4,true,false,true,false,-116.458,1.17906
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-79.8526,0.813415
0.813415
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-88.2754,0.898424
0.898424
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-91.0181,0.930452
0.930452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-101.25,1.03166
1.03166
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-101.134,1.02866
1.02866
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-104.321,1.06102
1.06102
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.812731
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 27 seconds of which 4.01657 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-114.53,1.16113
gpu_array,512,8,1,20,2,true,false,true,false,-97.0071,0.98569
gpu_array,512,8,1,20,4,true,false,true,false,-93.2674,0.95069
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-126.657,1.28367
gpu_sparse,512,8,1,20,2,true,false,true,false,-122.222,1.24205
gpu_sparse,512,8,1,20,4,true,false,true,false,-117.937,1.20071
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-141.421,1.43298
gpu_reorg,512,8,1,20,2,true,false,true,false,-96.0781,0.98306
gpu_reorg,512,8,1,20,4,true,false,true,false,-93.8444,0.956419
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-144.588,1.46508
gpu_array,512,8,1,50,2,true,false,true,false,-109.813,1.11968
gpu_array,512,8,1,50,4,true,false,true,false,-110.174,1.11793
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-151.315,1.53262
gpu_sparse,512,8,1,50,2,true,false,true,false,-140.791,1.42552
gpu_sparse,512,8,1,50,4,true,false,true,false,-140.131,1.42077
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-207.193,2.10357
gpu_reorg,512,8,1,50,2,true,false,true,false,-111.362,1.1447
gpu_reorg,512,8,1,50,4,true,false,true,false,-116.081,1.18656
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-144.601,1.46409
gpu_array,512,32,1,20,2,true,false,true,false,-86.1931,0.875254
gpu_array,512,32,1,20,4,true,false,true,false,-80.5496,0.819538
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-144.969,1.46718
gpu_sparse,512,32,1,20,2,true,false,true,false,-92.5249,0.939935
gpu_sparse,512,32,1,20,4,true,false,true,false,-90.1271,0.912614
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-195.591,1.97919
gpu_reorg,512,32,1,20,2,true,false,true,false,-111.396,1.12707
gpu_reorg,512,32,1,20,4,true,false,true,false,-116.087,1.17641
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-80.0101,0.814766
0.814766
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-88.2583,0.899222
0.899222
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-90.9598,0.928919
0.928919
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-100.922,1.03011
1.03011
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,-94.9419,0.968923
0.968923
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,-109.228,1.11068
1.11068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.814766
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 27 seconds of which 4.01682 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-19.1732,0.19792
gpu_array,512,8,1,20,2,true,false,true,false,-17.8675,0.187197
gpu_array,512,8,1,20,4,true,false,true,false,-17.2088,0.181842
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-23.3459,0.241979
gpu_sparse,512,8,1,20,2,true,false,true,false,-28.8461,0.319307
gpu_sparse,512,8,1,20,4,true,false,true,false,-35.7439,0.366742
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-27.5049,0.281585
gpu_reorg,512,8,1,20,2,true,false,true,false,-24.1552,0.248408
gpu_reorg,512,8,1,20,4,true,false,true,false,-24.425,0.250794
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-34.1807,0.348636
gpu_array,512,8,1,50,2,true,false,true,false,-29.9094,0.34321
gpu_array,512,8,1,50,4,true,false,true,false,-39.6258,0.408714
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-58.4703,0.600638
gpu_sparse,512,8,1,50,2,true,false,true,false,-30.2534,0.308473
gpu_sparse,512,8,1,50,4,true,false,true,false,-28.4894,0.293115
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-25.5364,0.26501
gpu_reorg,512,8,1,50,2,true,false,true,false,-25.6385,0.26583
gpu_reorg,512,8,1,50,4,true,false,true,false,-25.5755,0.264984
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-14.8755,0.152533
gpu_array,512,32,1,20,2,true,false,true,false,-11.4845,0.119014
gpu_array,512,32,1,20,4,true,false,true,false,-18.4139,0.19222
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-27.0515,0.278529
gpu_sparse,512,32,1,20,2,true,false,true,false,-25.1591,0.260833
gpu_sparse,512,32,1,20,4,true,false,true,false,-27.6758,0.286455
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-44.7648,0.456536
gpu_reorg,512,32,1,20,2,true,false,true,false,-23.7204,0.245065
gpu_reorg,512,32,1,20,4,true,false,true,false,-24.0432,0.245869
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,true,-16.6347,0.17195
0.17195
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,true,-21.5766,0.222191
0.222191
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-32.8378,0.336725
0.336725
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-28.7754,0.294961
0.294961
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-29.5598,0.301549
0.301549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-28.1994,0.290856
0.290856
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.119014
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 0.945118 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-24.6039,0.259375
gpu_array,512,8,1,20,2,true,false,true,false,-24.2076,0.248805
gpu_array,512,8,1,20,4,true,false,true,false,-26.0598,0.267643
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-39.1998,0.389352
gpu_sparse,512,8,1,20,2,true,false,true,false,-29.1349,0.299974
gpu_sparse,512,8,1,20,4,true,false,true,false,-28.9217,0.297673
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-27.7076,0.28391
gpu_reorg,512,8,1,20,2,true,false,true,false,-24.4178,0.249551
gpu_reorg,512,8,1,20,4,true,false,true,false,-29.3014,0.300124
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-43.9041,0.433779
gpu_array,512,8,1,50,2,true,false,true,false,-28.4847,0.293304
gpu_array,512,8,1,50,4,true,false,true,false,-26.8467,0.277012
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-37.4198,0.382314
gpu_sparse,512,8,1,50,2,true,false,true,false,-28.4328,0.291803
gpu_sparse,512,8,1,50,4,true,false,true,false,-28.3384,0.29248
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-25.3218,0.263486
gpu_reorg,512,8,1,50,2,true,false,true,false,-25.7184,0.264694
gpu_reorg,512,8,1,50,4,true,false,true,false,-25.9547,0.28554
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-17.4231,0.179128
gpu_array,512,32,1,20,2,true,false,true,false,-14.7065,0.152201
gpu_array,512,32,1,20,4,true,false,true,false,-16.859,0.172894
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-24.6593,0.255417
gpu_sparse,512,32,1,20,2,true,false,true,false,-22.8048,0.237555
gpu_sparse,512,32,1,20,4,true,false,true,false,-25.5842,0.264756
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-38.8726,0.393005
gpu_reorg,512,32,1,20,2,true,false,true,false,-30.0757,0.308402
gpu_reorg,512,32,1,20,4,true,false,true,false,-30.3251,0.310924
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,true,-21.0807,0.21484
0.21484
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,true,-27.3591,0.280205
0.280205
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,-41.5284,0.424121
0.424121
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,-43.8727,0.447617
0.447617
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,-48.2559,0.497962
0.497962
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,-37.5514,0.382822
0.382822
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.152201
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 1.01403 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-377.546,3.82975
gpu_array,512,8,1,20,2,true,false,true,false,-205.828,2.09556
gpu_array,512,8,1,20,4,true,false,true,false,-131.571,1.34632
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-370.299,3.75623
gpu_sparse,512,8,1,20,2,true,false,true,false,-206.588,2.10299
gpu_sparse,512,8,1,20,4,true,false,true,false,-140.06,1.43063
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-357.643,3.627
gpu_reorg,512,8,1,20,2,true,false,true,false,-189.23,1.92767
gpu_reorg,512,8,1,20,4,true,false,true,false,-214.018,2.17777
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-179.755,1.82843
gpu_array,512,8,1,50,2,true,false,true,false,-114.082,1.1692
gpu_array,512,8,1,50,4,true,false,true,false,-128.834,1.31802
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-183.493,1.86959
gpu_sparse,512,8,1,50,2,true,false,true,false,-131.694,1.34849
gpu_sparse,512,8,1,50,4,true,false,true,false,-133.753,1.36704
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-201.324,2.05078
gpu_reorg,512,8,1,50,2,true,false,true,false,-96.1681,0.989479
gpu_reorg,512,8,1,50,4,true,false,true,false,-122.466,1.2545
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,-215.81,1.66431
1.66431
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,-179.13,1.82856
1.82856
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,true,false,true,true,-176.484,1.79716
1.79716
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,false,false,true,true,-455.049,4.62129
4.62129
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.989479
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 44 seconds of which 4.64904 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-377.496,3.82869
gpu_array,512,8,1,20,2,true,false,true,false,-205.941,2.09641
gpu_array,512,8,1,20,4,true,false,true,false,-131.391,1.34445
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-370.197,3.75595
gpu_sparse,512,8,1,20,2,true,false,true,false,-206.564,2.1021
gpu_sparse,512,8,1,20,4,true,false,true,false,-139.74,1.4301
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-357.76,3.62885
gpu_reorg,512,8,1,20,2,true,false,true,false,-191.897,1.94041
gpu_reorg,512,8,1,20,4,true,false,true,false,-213.897,2.17691
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-179.205,1.82656
gpu_array,512,8,1,50,2,true,false,true,false,-114.046,1.16912
gpu_array,512,8,1,50,4,true,false,true,false,-128.942,1.31773
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-183.677,1.87131
gpu_sparse,512,8,1,50,2,true,false,true,false,-131.368,1.34542
gpu_sparse,512,8,1,50,4,true,false,true,false,-133.582,1.36615
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-201.461,2.05174
gpu_reorg,512,8,1,50,2,true,false,true,false,-96.2364,0.990186
gpu_reorg,512,8,1,50,4,true,false,true,false,-122.423,1.25294
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,-197.689,1.53854
1.53854
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,-178.175,1.81598
1.81598
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,true,false,true,true,-175.616,1.7889
1.7889
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,false,false,true,true,-455.114,4.62054
4.62054
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.990186
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 44 seconds of which 4.63452 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-119.246,1.20841
gpu_array,512,8,1,20,2,true,false,true,false,-121.337,1.23036
gpu_array,512,8,1,20,4,true,false,true,false,-128.6,1.30248
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-117.327,1.18924
gpu_sparse,512,8,1,20,2,true,false,true,false,-135.538,1.37116
gpu_sparse,512,8,1,20,4,true,false,true,false,-144.572,1.47018
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-157.661,1.59763
gpu_reorg,512,8,1,20,2,true,false,true,false,-114.88,1.16788
gpu_reorg,512,8,1,20,4,true,false,true,false,-121.521,1.23522
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-177.663,1.80496
gpu_array,512,8,1,50,2,true,false,true,false,-147.528,1.50176
gpu_array,512,8,1,50,4,true,false,true,false,-195.708,1.99039
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-176.408,1.78606
gpu_sparse,512,8,1,50,2,true,false,true,false,-177.504,1.80214
gpu_sparse,512,8,1,50,4,true,false,true,false,-206.447,2.09587
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-208.04,2.10543
gpu_reorg,512,8,1,50,2,true,false,true,false,-141.618,1.4425
gpu_reorg,512,8,1,50,4,true,false,true,false,-249.85,2.52862
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-138.903,1.40918
gpu_array,512,32,1,20,2,true,false,true,false,-107.008,1.08724
gpu_array,512,32,1,20,4,true,false,true,false,-87.42,0.886595
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-133.131,1.34896
gpu_sparse,512,32,1,20,2,true,false,true,false,-108.238,1.09871
gpu_sparse,512,32,1,20,4,true,false,true,false,-91.9466,0.934928
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-167.914,1.70253
gpu_reorg,512,32,1,20,2,true,false,true,false,-116.18,1.17599
gpu_reorg,512,32,1,20,4,true,false,true,false,-119.747,1.21517
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-91.1922,0.926986
0.926986
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-141.492,1.43228
1.43228
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,-95.6332,0.97222
0.97222
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,-103.343,1.04944
1.04944
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-109.871,1.11278
1.11278
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-132.457,1.34201
1.34201
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.886595
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 38 seconds of which 4.76419 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-118.67,1.20073
gpu_array,512,8,1,20,2,true,false,true,false,-120.711,1.22673
gpu_array,512,8,1,20,4,true,false,true,false,-128.276,1.30185
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-116.71,1.1863
gpu_sparse,512,8,1,20,2,true,false,true,false,-134.477,1.38992
gpu_sparse,512,8,1,20,4,true,false,true,false,-144.051,1.46147
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-157.063,1.59028
gpu_reorg,512,8,1,20,2,true,false,true,false,-113.888,1.15844
gpu_reorg,512,8,1,20,4,true,false,true,false,-121.254,1.23117
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-176.802,1.7974
gpu_array,512,8,1,50,2,true,false,true,false,-146.738,1.49204
gpu_array,512,8,1,50,4,true,false,true,false,-195.586,1.98488
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-175.504,1.77731
gpu_sparse,512,8,1,50,2,true,false,true,false,-177.274,1.79793
gpu_sparse,512,8,1,50,4,true,false,true,false,-205.623,2.08916
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-207.119,2.09638
gpu_reorg,512,8,1,50,2,true,false,true,false,-142.147,1.44098
gpu_reorg,512,8,1,50,4,true,false,true,false,-248.761,2.5167
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-138.675,1.40601
gpu_array,512,32,1,20,2,true,false,true,false,-106.982,1.08423
gpu_array,512,32,1,20,4,true,false,true,false,-86.6013,0.880456
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-132.644,1.34646
gpu_sparse,512,32,1,20,2,true,false,true,false,-108.175,1.09685
gpu_sparse,512,32,1,20,4,true,false,true,false,-91.5242,0.932793
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-167.278,1.69604
gpu_reorg,512,32,1,20,2,true,false,true,false,-115.708,1.17457
gpu_reorg,512,32,1,20,4,true,false,true,false,-119.365,1.2106
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-91.1962,0.924857
0.924857
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-141.708,1.43387
1.43387
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,-95.9277,0.973346
0.973346
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,-103.333,1.05005
1.05005
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-110.04,1.11452
1.11452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-132.406,1.34191
1.34191
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.880456
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 38 seconds of which 4.752 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,-136.278,1.40133
gpu_array,512,8,1,20,2,false,false,true,false,-127.111,1.30936
gpu_array,512,8,1,20,4,false,false,true,false,-123.033,1.26674
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,-140.618,1.44548
gpu_sparse,512,8,1,20,2,false,false,true,false,-132.741,1.36611
gpu_sparse,512,8,1,20,4,false,false,true,false,-124.801,1.28702
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,-162.324,1.66519
gpu_reorg,512,8,1,20,2,false,false,true,false,-139.537,1.43354
gpu_reorg,512,8,1,20,4,false,false,true,false,-138.129,1.42151
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,-70.6729,0.73984
gpu_array,512,8,1,50,2,false,false,true,false,-70.5296,0.737946
gpu_array,512,8,1,50,4,false,false,true,false,-70.4404,0.737331
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,-73.3989,0.767116
gpu_sparse,512,8,1,50,2,false,false,true,false,-81.2938,0.84555
gpu_sparse,512,8,1,50,4,false,false,true,false,-81.4975,0.848171
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,-73.963,0.772682
gpu_reorg,512,8,1,50,2,false,false,true,false,-70.1165,0.733073
gpu_reorg,512,8,1,50,4,false,false,true,false,-70.0876,0.732757
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,-105.77,1.09183
gpu_array,512,32,1,20,2,false,false,true,false,-98.2813,1.01754
gpu_array,512,32,1,20,4,false,false,true,false,-100.365,1.0383
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,-107.339,1.1098
gpu_sparse,512,32,1,20,2,false,false,true,false,-100.903,1.04514
gpu_sparse,512,32,1,20,4,false,false,true,false,-106.246,1.09781
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,-117.398,1.2118
gpu_reorg,512,32,1,20,2,false,false,true,false,-109.703,1.1338
gpu_reorg,512,32,1,20,4,false,false,true,false,-111.029,1.14678
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,50,4,false,false,true,true,-59.7272,0.628896
0.628896
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,32,1,20,2,false,false,true,true,-108.081,1.1166
1.1166
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,-125.537,1.29326
1.29326
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.628896
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 19 seconds of which 3.32209 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_reorg
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,-136.282,1.40429
gpu_array,512,8,1,20,2,false,false,true,false,-127.226,1.30979
gpu_array,512,8,1,20,4,false,false,true,false,-122.821,1.26594
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,-140.805,1.44584
gpu_sparse,512,8,1,20,2,false,false,true,false,-132.564,1.36297
gpu_sparse,512,8,1,20,4,false,false,true,false,-124.799,1.28567
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,-162.069,1.66434
gpu_reorg,512,8,1,20,2,false,false,true,false,-139.172,1.42981
gpu_reorg,512,8,1,20,4,false,false,true,false,-138.257,1.4228
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,-70.4093,0.737161
gpu_array,512,8,1,50,2,false,false,true,false,-70.082,0.734388
gpu_array,512,8,1,50,4,false,false,true,false,-70.4199,0.741514
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,-73.3421,0.765365
gpu_sparse,512,8,1,50,2,false,false,true,false,-81.1683,0.845417
gpu_sparse,512,8,1,50,4,false,false,true,false,-81.3988,0.845355
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,-74.0701,0.771699
gpu_reorg,512,8,1,50,2,false,false,true,false,-70.1933,0.733145
gpu_reorg,512,8,1,50,4,false,false,true,false,-70.077,0.73486
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,-105.301,1.09008
gpu_array,512,32,1,20,2,false,false,true,false,-98.3645,1.01771
gpu_array,512,32,1,20,4,false,false,true,false,-100.242,1.0393
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,-107.454,1.10951
gpu_sparse,512,32,1,20,2,false,false,true,false,-101.035,1.04591
gpu_sparse,512,32,1,20,4,false,false,true,false,-106.563,1.09883
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,-117.078,1.20935
gpu_reorg,512,32,1,20,2,false,false,true,false,-109.642,1.13321
gpu_reorg,512,32,1,20,4,false,false,true,false,-111.172,1.14811
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,-59.7485,0.629072
0.629072
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,32,1,20,2,false,false,true,true,-107.983,1.11485
1.11485
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,-125.472,1.29342
1.29342
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.629072
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 19 seconds of which 3.3208 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-19.6638,0.205319
gpu_array,512,8,1,20,2,true,false,true,false,-17.6852,0.183913
gpu_array,512,8,1,20,4,true,false,true,false,-17.1795,0.181836
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-23.9404,0.24641
gpu_sparse,512,8,1,20,2,true,false,true,false,-27.6454,0.286263
gpu_sparse,512,8,1,20,4,true,false,true,false,-29.4276,0.308057
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-32.4862,0.330169
gpu_reorg,512,8,1,20,2,true,false,true,false,-24.8698,0.255892
gpu_reorg,512,8,1,20,4,true,false,true,false,-25.0488,0.257191
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-35.1444,0.358848
gpu_array,512,8,1,50,2,true,false,true,false,-25.0842,0.256966
gpu_array,512,8,1,50,4,true,false,true,false,-25.1082,0.257718
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-34.156,0.349248
gpu_sparse,512,8,1,50,2,true,false,true,false,-27.301,0.280404
gpu_sparse,512,8,1,50,4,true,false,true,false,-27.0733,0.280199
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-27.556,0.283154
gpu_reorg,512,8,1,50,2,true,false,true,false,-28.1991,0.28792
gpu_reorg,512,8,1,50,4,true,false,true,false,-27.6282,0.283893
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-17.2741,0.182314
gpu_array,512,32,1,20,2,true,false,true,false,-15.7298,0.161452
gpu_array,512,32,1,20,4,true,false,true,false,-17.8488,0.185026
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-25.2907,0.260072
gpu_sparse,512,32,1,20,2,true,false,true,false,-24.1308,0.247477
gpu_sparse,512,32,1,20,4,true,false,true,false,-26.7635,0.276839
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-41.9785,0.435612
gpu_reorg,512,32,1,20,2,true,false,true,false,-32.6401,0.33584
gpu_reorg,512,32,1,20,4,true,false,true,false,-28.7153,0.295775
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,true,-18.2622,0.187699
0.187699
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,true,-24.226,0.247344
0.247344
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-23.2156,0.23625
0.23625
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-25.1128,0.258949
0.258949
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-23.6191,0.244801
0.244801
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-31.1306,0.318594
0.318594
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.161452
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 12 seconds of which 0.897786 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-19.8117,0.20585
gpu_array,512,8,1,20,2,true,false,true,false,-17.6788,0.186403
gpu_array,512,8,1,20,4,true,false,true,false,-17.2172,0.180609
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-23.8075,0.246501
gpu_sparse,512,8,1,20,2,true,false,true,false,-26.9932,0.2789
gpu_sparse,512,8,1,20,4,true,false,true,false,-29.7226,0.304098
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-28.3022,0.290915
gpu_reorg,512,8,1,20,2,true,false,true,false,-25.0163,0.255192
gpu_reorg,512,8,1,20,4,true,false,true,false,-25.1886,0.258639
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-35.1534,0.358926
gpu_array,512,8,1,50,2,true,false,true,false,-25.9479,0.261045
gpu_array,512,8,1,50,4,true,false,true,false,-24.7865,0.255814
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-34.0207,0.349756
gpu_sparse,512,8,1,50,2,true,false,true,false,-28.9088,0.296283
gpu_sparse,512,8,1,50,4,true,false,true,false,-32.7249,0.33498
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-28.4988,0.292848
gpu_reorg,512,8,1,50,2,true,false,true,false,-28.3266,0.292581
gpu_reorg,512,8,1,50,4,true,false,true,false,-28.2219,0.289176
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-17.1294,0.177256
gpu_array,512,32,1,20,2,true,false,true,false,-14.0777,0.147516
gpu_array,512,32,1,20,4,true,false,true,false,-14.2356,0.146523
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-18.0647,0.186618
gpu_sparse,512,32,1,20,2,true,false,true,false,-25.6273,0.264661
gpu_sparse,512,32,1,20,4,true,false,true,false,-28.6044,0.297992
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-46.6036,0.457607
gpu_reorg,512,32,1,20,2,true,false,true,false,-29.076,0.299036
gpu_reorg,512,32,1,20,4,true,false,true,false,-29.216,0.300895
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-18.7254,0.193232
0.193232
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-25.0861,0.258265
0.258265
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-29.238,0.299102
0.299102
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-31.4728,0.323421
0.323421
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,-27.9738,0.287285
0.287285
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,-30.366,0.310452
0.310452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.146523
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 12 seconds of which 0.91017 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-2504.37,102.632
gpu_array,512,8,1,20,2,true,false,true,false,-1812.03,72.135
gpu_array,512,8,1,20,4,true,false,true,false,-1943.02,77.9501
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-2332.96,95.445
gpu_sparse,512,8,1,20,2,true,false,true,false,-1992.29,80.1097
gpu_sparse,512,8,1,20,4,true,false,true,false,-2475.84,100.659
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-3272.41,134.596
gpu_reorg,512,8,1,20,2,true,false,true,false,-2668.69,106.874
gpu_reorg,512,8,1,20,4,true,false,true,false,-6588.75,274.016
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-3956.82,163.65
gpu_array,512,8,1,50,2,true,false,true,false,-3714.89,152.17
gpu_array,512,8,1,50,4,true,false,true,false,-4727.68,194.021
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-3206.88,132.411
gpu_sparse,512,8,1,50,2,true,false,true,false,-3629.79,148.744
gpu_sparse,512,8,1,50,4,true,false,true,false,-4556.15,187.478
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-4803.71,199.747
gpu_reorg,512,8,1,50,2,true,false,true,false,-11901.8,498.295
gpu_reorg,512,8,1,50,4,true,false,true,false,-11358.5,472
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-1946.22,78.6295
gpu_array,512,32,1,20,2,true,false,true,false,-1797.78,73.0215
gpu_array,512,32,1,20,4,true,false,true,false,-1632.88,66.0384
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-1653.71,66.344
gpu_sparse,512,32,1,20,2,true,false,true,false,-1837.2,73.9618
gpu_sparse,512,32,1,20,4,true,false,true,false,-1679.62,67.7609
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-1893.77,76.3329
gpu_reorg,512,32,1,20,2,true,false,true,false,-4727.7,196.864
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,-2381.89,96.2745
96.2745
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,-2454.62,99.8615
99.8615
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-2913.39,118.94
118.94
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-3074.16,125.52
125.52
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 66.0384
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 602 seconds of which 110.911 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-2483.35,102.856
gpu_array,512,8,1,20,2,true,false,true,false,-1835.43,72.8201
gpu_array,512,8,1,20,4,true,false,true,false,-1968,78.8672
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-2310.73,94.9001
gpu_sparse,512,8,1,20,2,true,false,true,false,-2018.19,80.6542
gpu_sparse,512,8,1,20,4,true,false,true,false,-2499.91,101.038
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-3262.4,134.582
gpu_reorg,512,8,1,20,2,true,false,true,false,-2619.41,106.204
gpu_reorg,512,8,1,20,4,true,false,true,false,-6614.34,273.066
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-3961.57,163.891
gpu_array,512,8,1,50,2,true,false,true,false,-3709.4,152.098
gpu_array,512,8,1,50,4,true,false,true,false,-4715.1,194.197
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-3220.22,132.73
gpu_sparse,512,8,1,50,2,true,false,true,false,-3620.61,148.11
gpu_sparse,512,8,1,50,4,true,false,true,false,-4555.24,187.236
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-4808.2,199.694
gpu_reorg,512,8,1,50,2,true,false,true,false,-11976.6,501.1
gpu_reorg,512,8,1,50,4,true,false,true,false,-11360.1,472.98
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-1937.22,78.2431
gpu_array,512,32,1,20,2,true,false,true,false,-1808.96,73.3133
gpu_array,512,32,1,20,4,true,false,true,false,-1654.91,66.3826
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-1651.51,66.3067
gpu_sparse,512,32,1,20,2,true,false,true,false,-1825.58,73.779
gpu_sparse,512,32,1,20,4,true,false,true,false,-1677.31,67.69
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-1904.43,76.6166
gpu_reorg,512,32,1,20,2,true,false,true,false,-4739.08,196.439
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,2,true,false,true,true,-2366.64,96.1352
96.1352
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,20,2,false,false,true,true,-2542.78,102.857
102.857
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,-1509.87,60.5045
60.5045
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,-1572.78,62.9141
62.9141
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 60.5045
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 581 seconds of which 107.986 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-17.3309,0.18015
gpu_array,512,8,1,20,2,true,false,true,false,-30.7896,0.314541
gpu_array,512,8,1,20,4,true,false,true,false,-43.9438,0.448102
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-22.1353,0.227992
gpu_sparse,512,8,1,20,2,true,false,true,false,-35.4814,0.363685
gpu_sparse,512,8,1,20,4,true,false,true,false,-61.3042,0.566888
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-25.4728,0.26224
gpu_reorg,512,8,1,20,2,true,false,true,false,-117.018,0.952943
gpu_reorg,512,8,1,20,4,true,false,true,false,-143.369,1.17747
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-26.7677,0.276602
gpu_array,512,8,1,50,2,true,false,true,false,-59.8965,0.608076
gpu_array,512,8,1,50,4,true,false,true,false,-59.6898,0.607038
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-29.4299,0.301178
gpu_sparse,512,8,1,50,2,true,false,true,false,-59.0062,0.600524
gpu_sparse,512,8,1,50,4,true,false,true,false,-58.9448,0.60012
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-31.4137,0.322653
gpu_reorg,512,8,1,50,2,true,false,true,false,-59.814,0.606546
gpu_reorg,512,8,1,50,4,true,false,true,false,-59.2371,0.60404
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-15.747,0.164427
gpu_array,512,32,1,20,2,true,false,true,false,-18.5478,0.191813
gpu_array,512,32,1,20,4,true,false,true,false,-36.4765,0.373128
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-33.4538,0.3411
gpu_sparse,512,32,1,20,2,true,false,true,false,-35.5821,0.366507
gpu_sparse,512,32,1,20,4,true,false,true,false,-30.5919,0.313714
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-36.2781,0.369714
gpu_reorg,512,32,1,20,2,true,false,true,false,-37.7394,0.411683
gpu_reorg,512,32,1,20,4,true,false,true,false,-82.7586,0.758932
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,32,1,20,-1,true,false,false,true,-28.8062,0.295371
0.295371
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,32,1,20,-1,false,false,false,true,-41.6752,0.425023
0.425023
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,-33.4249,0.34068
0.34068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,-39.9544,0.407604
0.407604
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,-29.6915,0.30457
0.30457
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,-32.8894,0.337806
0.337806
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.164427
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 32 seconds of which 1.4769 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-17.4216,0.181927
gpu_array,512,8,1,20,2,true,false,true,false,-30.6096,0.313564
gpu_array,512,8,1,20,4,true,false,true,false,-47.5163,0.483682
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-21.87,0.225075
gpu_sparse,512,8,1,20,2,true,false,true,false,-34.8811,0.357201
gpu_sparse,512,8,1,20,4,true,false,true,false,-65.3358,0.594515
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-30.0725,0.308372
gpu_reorg,512,8,1,20,2,true,false,true,false,-48.7633,0.497142
gpu_reorg,512,8,1,20,4,true,false,true,false,-41.7017,0.455225
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-30.7155,0.314408
gpu_array,512,8,1,50,2,true,false,true,false,-63.9882,0.630244
gpu_array,512,8,1,50,4,true,false,true,false,-59.7164,0.606533
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-29.285,0.300902
gpu_sparse,512,8,1,50,2,true,false,true,false,-59.1248,0.600495
gpu_sparse,512,8,1,50,4,true,false,true,false,-59.1317,0.600771
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-31.4399,0.322461
gpu_reorg,512,8,1,50,2,true,false,true,false,-59.6447,0.605267
gpu_reorg,512,8,1,50,4,true,false,true,false,-59.5687,0.606416
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-15.6813,0.163089
gpu_array,512,32,1,20,2,true,false,true,false,-19.4875,0.196133
gpu_array,512,32,1,20,4,true,false,true,false,-36.5255,0.37361
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-25.7538,0.26446
gpu_sparse,512,32,1,20,2,true,false,true,false,-29.2479,0.299639
gpu_sparse,512,32,1,20,4,true,false,true,false,-28.449,0.290547
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-34.738,0.355098
gpu_reorg,512,32,1,20,2,true,false,true,false,-67.0833,0.609382
gpu_reorg,512,32,1,20,4,true,false,true,false,-85.4166,0.748096
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,32,1,20,-1,true,false,false,true,-24.7054,0.253548
0.253548
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,32,1,20,-1,false,false,false,true,-35.0527,0.357419
0.357419
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,-23.0191,0.237419
0.237419
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,-28.4919,0.293245
0.293245
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,true,-26.92,0.276641
0.276641
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,true,-31.0971,0.320179
0.320179
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.163089
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 30 seconds of which 1.33557 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-114.999,1.16582
gpu_array,1024,8,1,20,2,true,false,true,false,-92.1999,0.944668
gpu_array,1024,8,1,20,4,true,false,true,false,-89.1661,0.915942
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-129.353,1.31067
gpu_sparse,1024,8,1,20,2,true,false,true,false,-117.677,1.19854
gpu_sparse,1024,8,1,20,4,true,false,true,false,-114.954,1.1708
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-139.971,1.41774
gpu_reorg,1024,8,1,20,2,true,false,true,false,-94.2116,0.964189
gpu_reorg,1024,8,1,20,4,true,false,true,false,-89.8423,0.921396
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-131.162,1.32852
gpu_array,1024,8,1,50,2,true,false,true,false,-101.979,1.03658
gpu_array,1024,8,1,50,4,true,false,true,false,-100.05,1.02521
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-137.965,1.39547
gpu_sparse,1024,8,1,50,2,true,false,true,false,-126.737,1.28525
gpu_sparse,1024,8,1,50,4,true,false,true,false,-127.224,1.28856
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-188.835,1.9107
gpu_reorg,1024,8,1,50,2,true,false,true,false,-103.876,1.06563
gpu_reorg,1024,8,1,50,4,true,false,true,false,-107.079,1.08693
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-142.933,1.44595
gpu_array,1024,32,1,20,2,true,false,true,false,-84.3256,0.856084
gpu_array,1024,32,1,20,4,true,false,true,false,-77.4335,0.78814
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-143.289,1.4503
gpu_sparse,1024,32,1,20,2,true,false,true,false,-90.8098,0.921689
gpu_sparse,1024,32,1,20,4,true,false,true,false,-82.7451,0.839888
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-194.175,1.96353
gpu_reorg,1024,32,1,20,2,true,false,true,false,-109.667,1.11118
gpu_reorg,1024,32,1,20,4,true,false,true,false,-114.389,1.15891
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-77.0727,0.786699
0.786699
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-84.3177,0.861035
0.861035
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-87.3778,0.900542
0.900542
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-99.7845,1.02315
1.02315
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-92.4692,0.949722
0.949722
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-107.349,1.09631
1.09631
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.786699
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 23 seconds of which 7.69756 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-114.956,1.16438
gpu_array,1024,8,1,20,2,true,false,true,false,-92.3986,0.945132
gpu_array,1024,8,1,20,4,true,false,true,false,-89.0949,0.91584
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-129.28,1.30856
gpu_sparse,1024,8,1,20,2,true,false,true,false,-118.09,1.20157
gpu_sparse,1024,8,1,20,4,true,false,true,false,-114.335,1.16744
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-139.754,1.41685
gpu_reorg,1024,8,1,20,2,true,false,true,false,-92.5941,0.957686
gpu_reorg,1024,8,1,20,4,true,false,true,false,-90.0078,0.92291
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-131.144,1.32898
gpu_array,1024,8,1,50,2,true,false,true,false,-101.746,1.03735
gpu_array,1024,8,1,50,4,true,false,true,false,-100.128,1.02472
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-138.037,1.39562
gpu_sparse,1024,8,1,50,2,true,false,true,false,-127.174,1.29157
gpu_sparse,1024,8,1,50,4,true,false,true,false,-126.681,1.28889
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-188.91,1.91097
gpu_reorg,1024,8,1,50,2,true,false,true,false,-103.546,1.06253
gpu_reorg,1024,8,1,50,4,true,false,true,false,-107.139,1.08891
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-142.828,1.44401
gpu_array,1024,32,1,20,2,true,false,true,false,-84.0236,0.855269
gpu_array,1024,32,1,20,4,true,false,true,false,-77.1227,0.787407
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-143.368,1.45095
gpu_sparse,1024,32,1,20,2,true,false,true,false,-90.5548,0.918804
gpu_sparse,1024,32,1,20,4,true,false,true,false,-82.2439,0.838096
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-194.12,1.96324
gpu_reorg,1024,32,1,20,2,true,false,true,false,-109.806,1.11143
gpu_reorg,1024,32,1,20,4,true,false,true,false,-114.402,1.15947
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-77.4283,0.788525
0.788525
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-84.6841,0.864712
0.864712
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-88.4043,0.905249
0.905249
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-100.212,1.02519
1.02519
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-93.1591,0.952275
0.952275
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-107.5,1.09578
1.09578
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.787407
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 23 seconds of which 7.6985 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-17.6473,0.181753
gpu_array,1024,8,1,20,2,true,false,true,false,-15.7959,0.161084
gpu_array,1024,8,1,20,4,true,false,true,false,-15.6337,0.159243
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-21.4319,0.219434
gpu_sparse,1024,8,1,20,2,true,false,true,false,-20.0183,0.20438
gpu_sparse,1024,8,1,20,4,true,false,true,false,-33.7277,0.341665
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-33.2585,0.346021
gpu_reorg,1024,8,1,20,2,true,false,true,false,-31.0262,0.323403
gpu_reorg,1024,8,1,20,4,true,false,true,false,-34.1334,0.357822
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-52.0545,0.519727
gpu_array,1024,8,1,50,2,true,false,true,false,-42.8351,0.43248
gpu_array,1024,8,1,50,4,true,false,true,false,-39.3137,0.399204
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-51.7503,0.524155
gpu_sparse,1024,8,1,50,2,true,false,true,false,-37.642,0.381455
gpu_sparse,1024,8,1,50,4,true,false,true,false,-37.6823,0.383159
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-33.4619,0.339814
gpu_reorg,1024,8,1,50,2,true,false,true,false,-32.4516,0.328716
gpu_reorg,1024,8,1,50,4,true,false,true,false,-32.5601,0.32957
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-19.3913,0.198545
gpu_array,1024,32,1,20,2,true,false,true,false,-14.5544,0.147749
gpu_array,1024,32,1,20,4,true,false,true,false,-20.5407,0.210234
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-31.7654,0.322485
gpu_sparse,1024,32,1,20,2,true,false,true,false,-29.0432,0.295684
gpu_sparse,1024,32,1,20,4,true,false,true,false,-32.8904,0.33418
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-53.4494,0.542817
gpu_reorg,1024,32,1,20,2,true,false,true,false,-32.9661,0.334727
gpu_reorg,1024,32,1,20,4,true,false,true,false,-33.8125,0.342734
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,-22.4002,0.227729
0.227729
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-29.9604,0.304253
0.304253
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-35.3163,0.426851
0.426851
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-53.5228,0.549434
0.549434
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-60.6107,0.617817
0.617817
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-50.2587,0.510786
0.510786
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.147749
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 2.31406 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-17.5452,0.179443
gpu_array,1024,8,1,20,2,true,false,true,false,-15.6883,0.16127
gpu_array,1024,8,1,20,4,true,false,true,false,-15.5034,0.159731
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-21.3175,0.218584
gpu_sparse,1024,8,1,20,2,true,false,true,false,-30.9684,0.329453
gpu_sparse,1024,8,1,20,4,true,false,true,false,-36.6842,0.374404
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-35.5297,0.360918
gpu_reorg,1024,8,1,20,2,true,false,true,false,-33.2025,0.337559
gpu_reorg,1024,8,1,20,4,true,false,true,false,-37.0093,0.375479
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-54.9409,0.557109
gpu_array,1024,8,1,50,2,true,false,true,false,-35.9233,0.364751
gpu_array,1024,8,1,50,4,true,false,true,false,-35.9112,0.36521
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-50.3217,0.509316
gpu_sparse,1024,8,1,50,2,true,false,true,false,-48.4155,0.490723
gpu_sparse,1024,8,1,50,4,true,false,true,false,-46.3343,0.469419
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-35.5469,0.360371
gpu_reorg,1024,8,1,50,2,true,false,true,false,-34.5855,0.350981
gpu_reorg,1024,8,1,50,4,true,false,true,false,-34.4909,0.349932
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-20.5981,0.210464
gpu_array,1024,32,1,20,2,true,false,true,false,-15.3071,0.156738
gpu_array,1024,32,1,20,4,true,false,true,false,-21.2712,0.217129
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-30.3824,0.315879
gpu_sparse,1024,32,1,20,2,true,false,true,false,-27.9292,0.287568
gpu_sparse,1024,32,1,20,4,true,false,true,false,-31.4966,0.324697
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-51.2463,0.519302
gpu_reorg,1024,32,1,20,2,true,false,true,false,-32.8902,0.334395
gpu_reorg,1024,32,1,20,4,true,false,true,false,-33.7698,0.341553
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,-22.3388,0.227593
0.227593
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-29.8885,0.303848
0.303848
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-35.9425,0.441289
0.441289
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-53.7765,0.551597
0.551597
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-60.5223,0.617373
0.617373
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-51.4807,0.521255
0.521255
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.156738
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 2.39316 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-344.103,3.4865
gpu_array,1024,8,1,20,2,true,false,true,false,-187.849,1.9084
gpu_array,1024,8,1,20,4,true,false,true,false,-119.772,1.22274
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-337.283,3.41823
gpu_sparse,1024,8,1,20,2,true,false,true,false,-188.361,1.91293
gpu_sparse,1024,8,1,20,4,true,false,true,false,-129.505,1.32274
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-336.841,3.41371
gpu_reorg,1024,8,1,20,2,true,false,true,false,-177.021,1.79903
gpu_reorg,1024,8,1,20,4,true,false,true,false,-199.121,2.02189
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-169.6,1.73212
gpu_array,1024,8,1,50,2,true,false,true,false,-107.928,1.10498
gpu_array,1024,8,1,50,4,true,false,true,false,-123.038,1.25413
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-178.306,1.80716
gpu_sparse,1024,8,1,50,2,true,false,true,false,-123.358,1.26061
gpu_sparse,1024,8,1,50,4,true,false,true,false,-129.121,1.31758
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-193.323,1.97006
gpu_reorg,1024,8,1,50,2,true,false,true,false,-92.2646,0.933691
gpu_reorg,1024,8,1,50,4,true,false,true,false,-114.087,1.16638
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,true,false,true,true,-264.473,1.96493
1.96493
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,false,false,true,true,-196.6,1.91983
1.91983
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,true,false,true,true,-165.109,1.67849
1.67849
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,false,false,true,true,-447.401,4.53738
4.53738
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.933691
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 39 seconds of which 8.83784 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-343.948,3.48459
gpu_array,1024,8,1,20,2,true,false,true,false,-187.85,1.90796
gpu_array,1024,8,1,20,4,true,false,true,false,-119.893,1.22322
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-341.178,3.43772
gpu_sparse,1024,8,1,20,2,true,false,true,false,-188.335,1.91358
gpu_sparse,1024,8,1,20,4,true,false,true,false,-129.465,1.32141
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-337.043,3.41467
gpu_reorg,1024,8,1,20,2,true,false,true,false,-177.13,1.79947
gpu_reorg,1024,8,1,20,4,true,false,true,false,-199.266,2.02273
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-171.385,1.73831
gpu_array,1024,8,1,50,2,true,false,true,false,-107.778,1.10376
gpu_array,1024,8,1,50,4,true,false,true,false,-122.59,1.2528
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-175.822,1.79568
gpu_sparse,1024,8,1,50,2,true,false,true,false,-123.134,1.25989
gpu_sparse,1024,8,1,50,4,true,false,true,false,-129.267,1.31862
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-192.84,1.96048
gpu_reorg,1024,8,1,50,2,true,false,true,false,-89.1887,0.918765
gpu_reorg,1024,8,1,50,4,true,false,true,false,-114.071,1.16756
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,true,false,true,true,-264.403,1.96426
1.96426
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,false,false,true,true,-195.064,1.91817
1.91817
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,true,false,true,true,-165.142,1.6784
1.6784
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,false,false,true,true,-447.302,4.53512
4.53512
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.918765
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 39 seconds of which 8.8345 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-110.147,1.12074
gpu_array,1024,8,1,20,2,true,false,true,false,-132.261,1.33588
gpu_array,1024,8,1,20,4,true,false,true,false,-134.619,1.36446
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-107.369,1.09579
gpu_sparse,1024,8,1,20,2,true,false,true,false,-143.096,1.45065
gpu_sparse,1024,8,1,20,4,true,false,true,false,-145.153,1.46927
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-151.941,1.53902
gpu_reorg,1024,8,1,20,2,true,false,true,false,-126.562,1.28686
gpu_reorg,1024,8,1,20,4,true,false,true,false,-117.123,1.19238
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-161.719,1.63893
gpu_array,1024,8,1,50,2,true,false,true,false,-149.522,1.52206
gpu_array,1024,8,1,50,4,true,false,true,false,-195.755,1.98495
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-157.979,1.60231
gpu_sparse,1024,8,1,50,2,true,false,true,false,-184.509,1.88043
gpu_sparse,1024,8,1,50,4,true,false,true,false,-204.793,2.07523
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-186.904,1.8946
gpu_reorg,1024,8,1,50,2,true,false,true,false,-135.669,1.38022
gpu_reorg,1024,8,1,50,4,true,false,true,false,-243.758,2.46752
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-134.139,1.35894
gpu_array,1024,32,1,20,2,true,false,true,false,-104.729,1.06208
gpu_array,1024,32,1,20,4,true,false,true,false,-82.06,0.837412
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-124.635,1.26568
gpu_sparse,1024,32,1,20,2,true,false,true,false,-105.293,1.06637
gpu_sparse,1024,32,1,20,4,true,false,true,false,-87.3098,0.888398
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-146.807,1.49069
gpu_reorg,1024,32,1,20,2,true,false,true,false,-109.757,1.11725
gpu_reorg,1024,32,1,20,4,true,false,true,false,-113.379,1.15562
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-87.8627,0.892158
0.892158
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-135.662,1.37302
1.37302
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-93.6668,0.950356
0.950356
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-101.207,1.02837
1.02837
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-100.677,1.02148
1.02148
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-131.874,1.33856
1.33856
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.837412
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 33 seconds of which 9.24625 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-110.116,1.11681
gpu_array,1024,8,1,20,2,true,false,true,false,-133.192,1.35128
gpu_array,1024,8,1,20,4,true,false,true,false,-133.734,1.35764
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-106.928,1.09012
gpu_sparse,1024,8,1,20,2,true,false,true,false,-141.462,1.43401
gpu_sparse,1024,8,1,20,4,true,false,true,false,-144.41,1.46264
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-150.792,1.53146
gpu_reorg,1024,8,1,20,2,true,false,true,false,-125.789,1.28212
gpu_reorg,1024,8,1,20,4,true,false,true,false,-116.402,1.18437
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-160.988,1.63176
gpu_array,1024,8,1,50,2,true,false,true,false,-149.171,1.51722
gpu_array,1024,8,1,50,4,true,false,true,false,-194.849,1.98137
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-157.328,1.59497
gpu_sparse,1024,8,1,50,2,true,false,true,false,-183.948,1.85972
gpu_sparse,1024,8,1,50,4,true,false,true,false,-204.501,2.07124
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-186.043,1.88583
gpu_reorg,1024,8,1,50,2,true,false,true,false,-134.898,1.37269
gpu_reorg,1024,8,1,50,4,true,false,true,false,-242.643,2.45627
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-133.478,1.35313
gpu_array,1024,32,1,20,2,true,false,true,false,-104.227,1.05604
gpu_array,1024,32,1,20,4,true,false,true,false,-81.5925,0.832271
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-124.147,1.25942
gpu_sparse,1024,32,1,20,2,true,false,true,false,-104.533,1.05944
gpu_sparse,1024,32,1,20,4,true,false,true,false,-86.681,0.881514
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-146.059,1.48195
gpu_reorg,1024,32,1,20,2,true,false,true,false,-109.787,1.11622
gpu_reorg,1024,32,1,20,4,true,false,true,false,-113.548,1.154
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-87.7565,0.890981
0.890981
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-135.696,1.37275
1.37275
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-93.6937,0.950825
0.950825
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-101.014,1.02774
1.02774
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-100.549,1.02058
1.02058
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-131.743,1.33818
1.33818
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.832271
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 33 seconds of which 9.2112 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,-144.389,1.48037
gpu_array,1024,8,1,20,2,false,false,true,false,-129.505,1.331
gpu_array,1024,8,1,20,4,false,false,true,false,-125.72,1.29334
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,-147.157,1.5095
gpu_sparse,1024,8,1,20,2,false,false,true,false,-139.038,1.42687
gpu_sparse,1024,8,1,20,4,false,false,true,false,-126.934,1.30281
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,-173.492,1.77464
gpu_reorg,1024,8,1,20,2,false,false,true,false,-141.051,1.44954
gpu_reorg,1024,8,1,20,4,false,false,true,false,-146.115,1.49754
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,-65.9654,0.687944
gpu_array,1024,8,1,50,2,false,false,true,false,-68.553,0.715513
gpu_array,1024,8,1,50,4,false,false,true,false,-68.5021,0.714736
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,-67.9001,0.708262
gpu_sparse,1024,8,1,50,2,false,false,true,false,-79.4106,0.823779
gpu_sparse,1024,8,1,50,4,false,false,true,false,-79.3397,0.823369
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,-69.2156,0.72187
gpu_reorg,1024,8,1,50,2,false,false,true,false,-67.1758,0.702129
gpu_reorg,1024,8,1,50,4,false,false,true,false,-67.3588,0.703696
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,-105.943,1.09303
gpu_array,1024,32,1,20,2,false,false,true,false,-99.8819,1.03117
gpu_array,1024,32,1,20,4,false,false,true,false,-101.773,1.05013
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,-108.111,1.11537
gpu_sparse,1024,32,1,20,2,false,false,true,false,-102.539,1.05774
gpu_sparse,1024,32,1,20,4,false,false,true,false,-107.852,1.11061
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,-118.722,1.2202
gpu_reorg,1024,32,1,20,2,false,false,true,false,-112.801,1.16156
gpu_reorg,1024,32,1,20,4,false,false,true,false,-115.565,1.18772
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-62.6847,0.655137
0.655137
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-97.9399,1.0113
1.0113
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-96.4918,0.994492
0.994492
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.655137
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 16 seconds of which 6.62638 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,-144.196,1.47852
gpu_array,1024,8,1,20,2,false,false,true,false,-130.4,1.33519
gpu_array,1024,8,1,20,4,false,false,true,false,-126.018,1.2972
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,-147.049,1.51051
gpu_sparse,1024,8,1,20,2,false,false,true,false,-138.709,1.42383
gpu_sparse,1024,8,1,20,4,false,false,true,false,-126.896,1.30281
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,-173.382,1.77323
gpu_reorg,1024,8,1,20,2,false,false,true,false,-141.527,1.45262
gpu_reorg,1024,8,1,20,4,false,false,true,false,-146.328,1.49839
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,-65.9222,0.688154
gpu_array,1024,8,1,50,2,false,false,true,false,-68.3304,0.712559
gpu_array,1024,8,1,50,4,false,false,true,false,-68.555,0.713564
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,-67.9437,0.708613
gpu_sparse,1024,8,1,50,2,false,false,true,false,-79.1877,0.822017
gpu_sparse,1024,8,1,50,4,false,false,true,false,-79.229,0.821743
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,-69.2817,0.721245
gpu_reorg,1024,8,1,50,2,false,false,true,false,-67.2597,0.70127
gpu_reorg,1024,8,1,50,4,false,false,true,false,-67.3704,0.703813
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,-105.815,1.09217
gpu_array,1024,32,1,20,2,false,false,true,false,-99.9304,1.03148
gpu_array,1024,32,1,20,4,false,false,true,false,-101.775,1.05005
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,-108.012,1.1137
gpu_sparse,1024,32,1,20,2,false,false,true,false,-102.9,1.05641
gpu_sparse,1024,32,1,20,4,false,false,true,false,-107.935,1.11152
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,-118.784,1.2204
gpu_reorg,1024,32,1,20,2,false,false,true,false,-113.206,1.16433
gpu_reorg,1024,32,1,20,4,false,false,true,false,-115.572,1.18853
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-62.437,0.653838
0.653838
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-98.0535,1.01198
1.01198
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-96.3336,0.994551
0.994551
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.653838
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 16 seconds of which 6.62615 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-18.2141,0.187271
gpu_array,1024,8,1,20,2,true,false,true,false,-15.7207,0.161113
gpu_array,1024,8,1,20,4,true,false,true,false,-15.4855,0.159028
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-21.6735,0.223003
gpu_sparse,1024,8,1,20,2,true,false,true,false,-19.4376,0.200137
gpu_sparse,1024,8,1,20,4,true,false,true,false,-31.9387,0.324971
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-34.9477,0.361899
gpu_reorg,1024,8,1,20,2,true,false,true,false,-31.3285,0.323877
gpu_reorg,1024,8,1,20,4,true,false,true,false,-35.0807,0.356812
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-50.8484,0.515874
gpu_array,1024,8,1,50,2,true,false,true,false,-33.7267,0.343662
gpu_array,1024,8,1,50,4,true,false,true,false,-33.54,0.34187
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-47.4213,0.481084
gpu_sparse,1024,8,1,50,2,true,false,true,false,-33.5246,0.342573
gpu_sparse,1024,8,1,50,4,true,false,true,false,-33.623,0.341841
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-36.0912,0.366763
gpu_reorg,1024,8,1,50,2,true,false,true,false,-35.3813,0.358945
gpu_reorg,1024,8,1,50,4,true,false,true,false,-35.3795,0.35978
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-25.944,0.26499
gpu_array,1024,32,1,20,2,true,false,true,false,-22.7432,0.232393
gpu_array,1024,32,1,20,4,true,false,true,false,-25.7964,0.26416
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-34.9908,0.364624
gpu_sparse,1024,32,1,20,2,true,false,true,false,-32.779,0.34019
gpu_sparse,1024,32,1,20,4,true,false,true,false,-37.2558,0.384863
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-61.6978,0.626411
gpu_reorg,1024,32,1,20,2,true,false,true,false,-33.4826,0.34165
gpu_reorg,1024,32,1,20,4,true,false,true,false,-34.9204,0.353979
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-26.8808,0.273452
0.273452
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-29.7017,0.302163
0.302163
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,-29.1121,0.296104
0.296104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-40.7202,0.421431
0.421431
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-41.1959,0.422305
0.422305
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-48.9022,0.486504
0.486504
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.159028
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 11 seconds of which 2.27855 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-18.2839,0.186821
gpu_array,1024,8,1,20,2,true,false,true,false,-15.7354,0.161094
gpu_array,1024,8,1,20,4,true,false,true,false,-15.4684,0.157568
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-21.8162,0.222861
gpu_sparse,1024,8,1,20,2,true,false,true,false,-30.7449,0.311782
gpu_sparse,1024,8,1,20,4,true,false,true,false,-33.9517,0.345181
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-36.3,0.368921
gpu_reorg,1024,8,1,20,2,true,false,true,false,-33.3129,0.339443
gpu_reorg,1024,8,1,20,4,true,false,true,false,-36.8824,0.374414
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-52.6894,0.534253
gpu_array,1024,8,1,50,2,true,false,true,false,-35.3946,0.359277
gpu_array,1024,8,1,50,4,true,false,true,false,-35.2446,0.358955
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-49.8439,0.50665
gpu_sparse,1024,8,1,50,2,true,false,true,false,-42.077,0.426895
gpu_sparse,1024,8,1,50,4,true,false,true,false,-49.2733,0.515723
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-47.9175,0.482866
gpu_reorg,1024,8,1,50,2,true,false,true,false,-42.9566,0.435967
gpu_reorg,1024,8,1,50,4,true,false,true,false,-39.5534,0.401675
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-24.7226,0.252017
gpu_array,1024,32,1,20,2,true,false,true,false,-19.5365,0.198867
gpu_array,1024,32,1,20,4,true,false,true,false,-19.9582,0.203887
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-26.0229,0.265195
gpu_sparse,1024,32,1,20,2,true,false,true,false,-32.9561,0.334893
gpu_sparse,1024,32,1,20,4,true,false,true,false,-36.7638,0.373848
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-58.1444,0.572417
gpu_reorg,1024,32,1,20,2,true,false,true,false,-38.8117,0.39437
gpu_reorg,1024,32,1,20,4,true,false,true,false,-40.1245,0.407764
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-29.9747,0.305547
0.305547
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-33.0007,0.335254
0.335254
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,-24.1493,0.244253
0.244253
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-32.8662,0.334946
0.334946
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-31.2174,0.322656
0.322656
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-45.7588,0.463867
0.463867
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.157568
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 11 seconds of which 2.35523 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-3064.1,125.972
gpu_array,1024,8,1,20,2,true,false,true,false,-1848.68,71.3028
gpu_array,1024,8,1,20,4,true,false,true,false,-2542.73,101.412
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-2796.3,114.852
gpu_sparse,1024,8,1,20,2,true,false,true,false,-2111.68,83.8356
gpu_sparse,1024,8,1,20,4,true,false,true,false,-2947.32,118.829
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-3895.19,160.744
gpu_reorg,1024,8,1,20,2,true,false,true,false,-3911.53,154.121
gpu_reorg,1024,8,1,20,4,true,false,true,false,-9738.01,403.406
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-4251.15,176.474
gpu_array,1024,8,1,50,2,true,false,true,false,-4621.37,188.756
gpu_array,1024,8,1,50,4,true,false,true,false,-5326.79,220.736
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-3349.92,138.044
gpu_sparse,1024,8,1,50,2,true,false,true,false,-4516.85,185.127
gpu_sparse,1024,8,1,50,4,true,false,true,false,-4999.4,205.981
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-5085.07,210.63
gpu_reorg,1024,8,1,50,2,true,false,true,false,-13646.4,568.726
gpu_reorg,1024,8,1,50,4,true,false,true,false,-12205.7,508.758
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-2036.13,81.15
gpu_array,1024,32,1,20,2,true,false,true,false,-2027.61,81.5328
gpu_array,1024,32,1,20,4,true,false,true,false,-1783.22,71.0768
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-1737.36,67.666
gpu_sparse,1024,32,1,20,2,true,false,true,false,-2025.45,81.4445
gpu_sparse,1024,32,1,20,4,true,false,true,false,-1824.42,72.3011
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-2018.77,78.7332
gpu_reorg,1024,32,1,20,2,true,false,true,false,-5498.62,227.733
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,true,false,true,true,-2427.99,97.3094
97.3094
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,false,false,true,true,-2590.95,103.76
103.76
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,-1586.9,61.9296
61.9296
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,-1615.36,63.6621
63.6621
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 61.9296
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 500 seconds of which 247.091 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-3086.44,126.664
gpu_array,1024,8,1,20,2,true,false,true,false,-1801.89,70.3133
gpu_array,1024,8,1,20,4,true,false,true,false,-2553.88,101.91
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-2792.32,114.783
gpu_sparse,1024,8,1,20,2,true,false,true,false,-2144.22,84.6208
gpu_sparse,1024,8,1,20,4,true,false,true,false,-2941.36,118.5
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-3886.68,160.599
gpu_reorg,1024,8,1,20,2,true,false,true,false,-3844.13,153.529
gpu_reorg,1024,8,1,20,4,true,false,true,false,-9697.56,403.041
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-4258.98,176.411
gpu_array,1024,8,1,50,2,true,false,true,false,-4594.45,189.188
gpu_array,1024,8,1,50,4,true,false,true,false,-5411,220.488
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-3366.35,138.847
gpu_sparse,1024,8,1,50,2,true,false,true,false,-4481.88,184.621
gpu_sparse,1024,8,1,50,4,true,false,true,false,-4995.81,205.508
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-5058.87,210.186
gpu_reorg,1024,8,1,50,2,true,false,true,false,-13831.9,570.649
gpu_reorg,1024,8,1,50,4,true,false,true,false,-12285.2,509.184
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-2054.93,81.6952
gpu_array,1024,32,1,20,2,true,false,true,false,-2009.86,81.1002
gpu_array,1024,32,1,20,4,true,false,true,false,-1774.58,70.8275
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-1705.74,67.1403
gpu_sparse,1024,32,1,20,2,true,false,true,false,-2045.61,81.7632
gpu_sparse,1024,32,1,20,4,true,false,true,false,-1822.33,72.1554
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-1984,78.3878
gpu_reorg,1024,32,1,20,2,true,false,true,false,-5454.02,228.306
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,true,false,true,true,-2446.16,97.6999
97.6999
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,false,false,true,true,-2610.79,104.191
104.191
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,-1563.97,61.4811
61.4811
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,-1613.89,63.6606
63.6606
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 61.4811
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 502 seconds of which 247.166 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-16.4708,0.168887
gpu_array,1024,8,1,20,2,true,false,true,false,-29.1581,0.296953
gpu_array,1024,8,1,20,4,true,false,true,false,-52.2557,0.529443
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-29.762,0.303389
gpu_sparse,1024,8,1,20,2,true,false,true,false,-44.9266,0.457173
gpu_sparse,1024,8,1,20,4,true,false,true,false,-41.4958,0.421143
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-27.7263,0.282441
gpu_reorg,1024,8,1,20,2,true,false,true,false,-148.481,1.16185
gpu_reorg,1024,8,1,20,4,true,false,true,false,-90.2439,0.834263
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-37.7275,0.386724
gpu_array,1024,8,1,50,2,true,false,true,false,-77.2823,0.786025
gpu_array,1024,8,1,50,4,true,false,true,false,-105.292,1.05278
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-29.792,0.306631
gpu_sparse,1024,8,1,50,2,true,false,true,false,-59.3009,0.603359
gpu_sparse,1024,8,1,50,4,true,false,true,false,-92.9404,0.939507
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-40.9955,0.419512
gpu_reorg,1024,8,1,50,2,true,false,true,false,-75.4169,0.764702
gpu_reorg,1024,8,1,50,4,true,false,true,false,-116.671,1.15327
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-18.7972,0.192021
gpu_array,1024,32,1,20,2,true,false,true,false,-20.8731,0.212793
gpu_array,1024,32,1,20,4,true,false,true,false,-49.0878,0.497183
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-36.7177,0.37314
gpu_sparse,1024,32,1,20,2,true,false,true,false,-39.5199,0.400967
gpu_sparse,1024,32,1,20,4,true,false,true,false,-55.0695,0.558413
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-74.054,0.730171
gpu_reorg,1024,32,1,20,2,true,false,true,false,-74.5458,0.768638
gpu_reorg,1024,32,1,20,4,true,false,true,false,-60.5599,0.616812
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-42.7435,0.434219
0.434219
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-46.0863,0.469336
0.469336
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,true,false,false,true,-28.0573,0.285464
0.285464
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,false,false,false,true,-40.6526,0.412793
0.412793
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,-36.0234,0.366284
0.366284
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-42.0105,0.427017
0.427017
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.168887
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 30 seconds of which 3.6072 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-16.3231,0.167158
gpu_array,1024,8,1,20,2,true,false,true,false,-28.8373,0.293545
gpu_array,1024,8,1,20,4,true,false,true,false,-51.2225,0.51874
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-30.1277,0.306865
gpu_sparse,1024,8,1,20,2,true,false,true,false,-45.5504,0.461357
gpu_sparse,1024,8,1,20,4,true,false,true,false,-85.1919,0.803218
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-33.4118,0.339204
gpu_reorg,1024,8,1,20,2,true,false,true,false,-153.364,1.43297
gpu_reorg,1024,8,1,20,4,true,false,true,false,-81.7066,0.94479
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-30.7986,0.316675
gpu_array,1024,8,1,50,2,true,false,true,false,-66.0562,0.672349
gpu_array,1024,8,1,50,4,true,false,true,false,-92.3839,0.943208
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-39.9467,0.409751
gpu_sparse,1024,8,1,50,2,true,false,true,false,-74.1858,0.732129
gpu_sparse,1024,8,1,50,4,true,false,true,false,-52.7179,0.536997
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-27.2177,0.282251
gpu_reorg,1024,8,1,50,2,true,false,true,false,-52.023,0.530679
gpu_reorg,1024,8,1,50,4,true,false,true,false,-87.2783,0.816416
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-16.8914,0.173013
gpu_array,1024,32,1,20,2,true,false,true,false,-19.095,0.194028
gpu_array,1024,32,1,20,4,true,false,true,false,-53.6561,0.542144
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-49.9547,0.515
gpu_sparse,1024,32,1,20,2,true,false,true,false,-55.1206,0.559102
gpu_sparse,1024,32,1,20,4,true,false,true,false,-41.3268,0.419287
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-54.9328,0.556499
gpu_reorg,1024,32,1,20,2,true,false,true,false,-42.9883,0.435537
gpu_reorg,1024,32,1,20,4,true,false,true,false,-83.5132,0.845225
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-30.1607,0.307036
0.307036
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-37.5012,0.381572
0.381572
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,true,false,false,true,-26.5138,0.270381
0.270381
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,false,false,false,true,-38.0994,0.386978
0.386978
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,-37.1446,0.377847
0.377847
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-42.6471,0.43396
0.43396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.167158
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 30 seconds of which 3.46233 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-114.593,1.15885
gpu_array,2048,8,1,20,2,true,false,true,false,-90.8359,0.920486
gpu_array,2048,8,1,20,4,true,false,true,false,-90.2235,0.917092
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-128.786,1.3011
gpu_sparse,2048,8,1,20,2,true,false,true,false,-114.953,1.16433
gpu_sparse,2048,8,1,20,4,true,false,true,false,-113.516,1.15061
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-139.301,1.409
gpu_reorg,2048,8,1,20,2,true,false,true,false,-94.7244,0.964531
gpu_reorg,2048,8,1,20,4,true,false,true,false,-92.1944,0.936011
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-130.374,1.31973
gpu_array,2048,8,1,50,2,true,false,true,false,-100.083,1.01369
gpu_array,2048,8,1,50,4,true,false,true,false,-100.3,1.01642
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-137.334,1.38703
gpu_sparse,2048,8,1,50,2,true,false,true,false,-126.707,1.28377
gpu_sparse,2048,8,1,50,4,true,false,true,false,-127.809,1.29709
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-187.952,1.90015
gpu_reorg,2048,8,1,50,2,true,false,true,false,-102.884,1.04692
gpu_reorg,2048,8,1,50,4,true,false,true,false,-105.671,1.07066
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-130.196,1.31658
gpu_array,2048,32,1,20,2,true,false,true,false,-77.2028,0.781101
gpu_array,2048,32,1,20,4,true,false,true,false,-71.6722,0.727705
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-130.417,1.31944
gpu_sparse,2048,32,1,20,2,true,false,true,false,-82.978,0.839851
gpu_sparse,2048,32,1,20,4,true,false,true,false,-80.0569,0.812263
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-176.731,1.78626
gpu_reorg,2048,32,1,20,2,true,false,true,false,-99.9722,1.01364
gpu_reorg,2048,32,1,20,4,true,false,true,false,-104.306,1.05779
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-71.8553,0.728721
0.728721
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-79.1292,0.803459
0.803459
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-87.126,0.885198
0.885198
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-99.251,1.0078
1.0078
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-93.0578,0.94759
0.94759
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-101.534,1.03296
1.03296
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.727705
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 30 seconds of which 14.8758 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-114.474,1.15904
gpu_array,2048,8,1,20,2,true,false,true,false,-90.9934,0.922117
gpu_array,2048,8,1,20,4,true,false,true,false,-89.532,0.914294
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-128.707,1.3016
gpu_sparse,2048,8,1,20,2,true,false,true,false,-115.254,1.16592
gpu_sparse,2048,8,1,20,4,true,false,true,false,-113.693,1.15487
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-139.508,1.40986
gpu_reorg,2048,8,1,20,2,true,false,true,false,-94.6734,0.966284
gpu_reorg,2048,8,1,20,4,true,false,true,false,-91.9239,0.935442
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-130.748,1.32468
gpu_array,2048,8,1,50,2,true,false,true,false,-100.462,1.01545
gpu_array,2048,8,1,50,4,true,false,true,false,-100.376,1.01869
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-137.216,1.38625
gpu_sparse,2048,8,1,50,2,true,false,true,false,-127.139,1.28641
gpu_sparse,2048,8,1,50,4,true,false,true,false,-128.095,1.29695
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-187.958,1.90018
gpu_reorg,2048,8,1,50,2,true,false,true,false,-103.206,1.04989
gpu_reorg,2048,8,1,50,4,true,false,true,false,-106.085,1.07316
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-130.248,1.3172
gpu_array,2048,32,1,20,2,true,false,true,false,-77.1071,0.780569
gpu_array,2048,32,1,20,4,true,false,true,false,-72.1238,0.730164
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-130.327,1.31901
gpu_sparse,2048,32,1,20,2,true,false,true,false,-83.1785,0.843962
gpu_sparse,2048,32,1,20,4,true,false,true,false,-79.9064,0.811853
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-176.713,1.78647
gpu_reorg,2048,32,1,20,2,true,false,true,false,-100.057,1.01408
gpu_reorg,2048,32,1,20,4,true,false,true,false,-104.649,1.05992
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-71.9994,0.729141
0.729141
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-79.6628,0.805964
0.805964
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-87.007,0.884558
0.884558
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-99.3581,1.00813
1.00813
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-93.281,0.948469
0.948469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-101.661,1.03295
1.03295
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.729141
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 30 seconds of which 14.8904 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-17.2553,0.177854
gpu_array,2048,8,1,20,2,true,false,true,false,-15.1193,0.157603
gpu_array,2048,8,1,20,4,true,false,true,false,-14.9297,0.15572
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-21.2516,0.217107
gpu_sparse,2048,8,1,20,2,true,false,true,false,-19.6205,0.201777
gpu_sparse,2048,8,1,20,4,true,false,true,false,-19.543,0.201616
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-18.472,0.190095
gpu_reorg,2048,8,1,20,2,true,false,true,false,-15.4119,0.164241
gpu_reorg,2048,8,1,20,4,true,false,true,false,-15.6918,0.166636
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-29.0571,0.294485
gpu_array,2048,8,1,50,2,true,false,true,false,-19.6495,0.202581
gpu_array,2048,8,1,50,4,true,false,true,false,-19.7301,0.203479
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-27.4802,0.279524
gpu_sparse,2048,8,1,50,2,true,false,true,false,-25.795,0.262104
gpu_sparse,2048,8,1,50,4,true,false,true,false,-25.6266,0.262522
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-23.8643,0.245598
gpu_reorg,2048,8,1,50,2,true,false,true,false,-22.2001,0.230059
gpu_reorg,2048,8,1,50,4,true,false,true,false,-22.2703,0.231616
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-13.125,0.134768
gpu_array,2048,32,1,20,2,true,false,true,false,-9.3221,0.0958667
gpu_array,2048,32,1,20,4,true,false,true,false,-13.8391,0.14093
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-21.5165,0.218867
gpu_sparse,2048,32,1,20,2,true,false,true,false,-16.4379,0.167053
gpu_sparse,2048,32,1,20,4,true,false,true,false,-16.5755,0.169102
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-25.7055,0.260786
gpu_reorg,2048,32,1,20,2,true,false,true,false,-20.1583,0.204485
gpu_reorg,2048,32,1,20,4,true,false,true,false,-23.534,0.257961
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,-16.7084,0.168589
0.168589
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-22.0204,0.22324
0.22324
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-28.0663,0.284307
0.284307
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-20.6621,0.209475
0.209475
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-20.54,0.209512
0.209512
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-20.7673,0.210684
0.210684
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0958667
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 2.78538 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-17.2461,0.177285
gpu_array,2048,8,1,20,2,true,false,true,false,-15.2331,0.157964
gpu_array,2048,8,1,20,4,true,false,true,false,-14.8648,0.155747
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-21.1502,0.216538
gpu_sparse,2048,8,1,20,2,true,false,true,false,-19.6525,0.202029
gpu_sparse,2048,8,1,20,4,true,false,true,false,-19.5145,0.200806
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-18.2761,0.188752
gpu_reorg,2048,8,1,20,2,true,false,true,false,-15.7584,0.166392
gpu_reorg,2048,8,1,20,4,true,false,true,false,-20.3463,0.205984
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-28.9971,0.293896
gpu_array,2048,8,1,50,2,true,false,true,false,-20.0094,0.203508
gpu_array,2048,8,1,50,4,true,false,true,false,-19.7344,0.202598
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-27.4806,0.279617
gpu_sparse,2048,8,1,50,2,true,false,true,false,-25.7001,0.261819
gpu_sparse,2048,8,1,50,4,true,false,true,false,-25.7486,0.261697
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-23.9247,0.244717
gpu_reorg,2048,8,1,50,2,true,false,true,false,-22.2804,0.230298
gpu_reorg,2048,8,1,50,4,true,false,true,false,-22.1819,0.229695
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-13.1021,0.13469
gpu_array,2048,32,1,20,2,true,false,true,false,-9.34988,0.0968945
gpu_array,2048,32,1,20,4,true,false,true,false,-9.22741,0.0943628
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-20.3666,0.207659
gpu_sparse,2048,32,1,20,2,true,false,true,false,-18.1845,0.185129
gpu_sparse,2048,32,1,20,4,true,false,true,false,-19.9059,0.2049
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-33.0982,0.335359
gpu_reorg,2048,32,1,20,2,true,false,true,false,-16.0592,0.163416
gpu_reorg,2048,32,1,20,4,true,false,true,false,-16.1696,0.16438
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-10.7671,0.109348
0.109348
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-14.253,0.144412
0.144412
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-25.3226,0.256963
0.256963
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-20.4301,0.207144
0.207144
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,true,-20.6928,0.209507
0.209507
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,true,-20.4892,0.208582
0.208582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0943628
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 12 seconds of which 2.70421 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-342.83,3.47078
gpu_array,2048,8,1,20,2,true,false,true,false,-186.787,1.89448
gpu_array,2048,8,1,20,4,true,false,true,false,-119.358,1.21394
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-336.389,3.40558
gpu_sparse,2048,8,1,20,2,true,false,true,false,-187.443,1.90089
gpu_sparse,2048,8,1,20,4,true,false,true,false,-133.289,1.36044
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-340.368,3.44886
gpu_reorg,2048,8,1,20,2,true,false,true,false,-175.978,1.78458
gpu_reorg,2048,8,1,20,4,true,false,true,false,-197.634,2.0039
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-173.633,1.75931
gpu_array,2048,8,1,50,2,true,false,true,false,-109.37,1.11505
gpu_array,2048,8,1,50,4,true,false,true,false,-118.029,1.20055
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-179.672,1.82489
gpu_sparse,2048,8,1,50,2,true,false,true,false,-122.008,1.24215
gpu_sparse,2048,8,1,50,4,true,false,true,false,-124.563,1.26611
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-193.799,1.9654
gpu_reorg,2048,8,1,50,2,true,false,true,false,-89.0897,0.909822
gpu_reorg,2048,8,1,50,4,true,false,true,false,-113.112,1.15336
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,-177.692,1.36654
1.36654
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,-173.72,1.76453
1.76453
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,true,false,true,true,-164.889,1.67267
1.67267
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,false,false,true,true,-457.016,4.62785
4.62785
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.909822
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 48 seconds of which 17.3473 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-342.971,3.47135
gpu_array,2048,8,1,20,2,true,false,true,false,-186.811,1.89462
gpu_array,2048,8,1,20,4,true,false,true,false,-119.408,1.21449
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-336.481,3.40557
gpu_sparse,2048,8,1,20,2,true,false,true,false,-187.352,1.90056
gpu_sparse,2048,8,1,20,4,true,false,true,false,-133.075,1.35403
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-340.306,3.44802
gpu_reorg,2048,8,1,20,2,true,false,true,false,-176.014,1.78458
gpu_reorg,2048,8,1,20,4,true,false,true,false,-197.603,2.00339
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-172.698,1.75325
gpu_array,2048,8,1,50,2,true,false,true,false,-109.224,1.11318
gpu_array,2048,8,1,50,4,true,false,true,false,-117.906,1.2004
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-179.967,1.82954
gpu_sparse,2048,8,1,50,2,true,false,true,false,-121.835,1.24124
gpu_sparse,2048,8,1,50,4,true,false,true,false,-124.675,1.26687
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-193.846,1.96488
gpu_reorg,2048,8,1,50,2,true,false,true,false,-88.7347,0.906418
gpu_reorg,2048,8,1,50,4,true,false,true,false,-113.146,1.15095
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,-175.084,1.32162
1.32162
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,-173.953,1.76629
1.76629
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,true,false,true,true,-164.925,1.67284
1.67284
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,false,false,true,true,-456.965,4.62687
4.62687
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.906418
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 48 seconds of which 17.3224 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-110.24,1.12205
gpu_array,2048,8,1,20,2,true,false,true,false,-149.775,1.51096
gpu_array,2048,8,1,20,4,true,false,true,false,-146.836,1.4906
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-108.611,1.10341
gpu_sparse,2048,8,1,20,2,true,false,true,false,-151.152,1.52848
gpu_sparse,2048,8,1,20,4,true,false,true,false,-150.061,1.52359
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-157.761,1.59499
gpu_reorg,2048,8,1,20,2,true,false,true,false,-139.867,1.41319
gpu_reorg,2048,8,1,20,4,true,false,true,false,-116.211,1.1737
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-160.61,1.62649
gpu_array,2048,8,1,50,2,true,false,true,false,-167.965,1.69483
gpu_array,2048,8,1,50,4,true,false,true,false,-199.229,2.01535
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-157.015,1.58898
gpu_sparse,2048,8,1,50,2,true,false,true,false,-200.545,2.03172
gpu_sparse,2048,8,1,50,4,true,false,true,false,-205.655,2.0808
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-183.992,1.86145
gpu_reorg,2048,8,1,50,2,true,false,true,false,-144.144,1.46051
gpu_reorg,2048,8,1,50,4,true,false,true,false,-237.916,2.40603
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-124.828,1.26604
gpu_array,2048,32,1,20,2,true,false,true,false,-96.4732,0.97894
gpu_array,2048,32,1,20,4,true,false,true,false,-77.4451,0.787297
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-116.8,1.1834
gpu_sparse,2048,32,1,20,2,true,false,true,false,-97.0085,0.983655
gpu_sparse,2048,32,1,20,4,true,false,true,false,-82.1034,0.833584
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-141.98,1.43637
gpu_reorg,2048,32,1,20,2,true,false,true,false,-106.658,1.0825
gpu_reorg,2048,32,1,20,4,true,false,true,false,-109.179,1.11202
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-80.5926,0.817605
0.817605
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-126.701,1.28555
1.28555
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,-94.379,0.95647
0.95647
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,-101.234,1.02448
1.02448
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,-130.076,1.31552
1.31552
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-139.212,1.4076
1.4076
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.787297
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 42 seconds of which 18.718 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-110.204,1.11906
gpu_array,2048,8,1,20,2,true,false,true,false,-149.775,1.5171
gpu_array,2048,8,1,20,4,true,false,true,false,-147.218,1.49089
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-108.887,1.10268
gpu_sparse,2048,8,1,20,2,true,false,true,false,-149.518,1.51917
gpu_sparse,2048,8,1,20,4,true,false,true,false,-148.747,1.5147
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-157.153,1.59345
gpu_reorg,2048,8,1,20,2,true,false,true,false,-138.915,1.40807
gpu_reorg,2048,8,1,20,4,true,false,true,false,-116.811,1.17626
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-160.285,1.62446
gpu_array,2048,8,1,50,2,true,false,true,false,-168.616,1.69676
gpu_array,2048,8,1,50,4,true,false,true,false,-199.773,2.01649
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-157.072,1.58917
gpu_sparse,2048,8,1,50,2,true,false,true,false,-200.996,2.03656
gpu_sparse,2048,8,1,50,4,true,false,true,false,-205.433,2.07881
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-183.782,1.86064
gpu_reorg,2048,8,1,50,2,true,false,true,false,-144.127,1.45766
gpu_reorg,2048,8,1,50,4,true,false,true,false,-237.912,2.40568
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-125.228,1.27199
gpu_array,2048,32,1,20,2,true,false,true,false,-96.5398,0.979238
gpu_array,2048,32,1,20,4,true,false,true,false,-77.5436,0.787947
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-116.765,1.18352
gpu_sparse,2048,32,1,20,2,true,false,true,false,-96.9798,0.984114
gpu_sparse,2048,32,1,20,4,true,false,true,false,-81.8697,0.832446
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-142.119,1.43875
gpu_reorg,2048,32,1,20,2,true,false,true,false,-106.566,1.08265
gpu_reorg,2048,32,1,20,4,true,false,true,false,-109.614,1.1129
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-80.5781,0.815923
0.815923
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-126.808,1.28612
1.28612
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,-94.4076,0.956169
0.956169
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,-101.151,1.02429
1.02429
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,-129.892,1.31474
1.31474
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-139.192,1.40767
1.40767
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.787947
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 42 seconds of which 18.713 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,-155.823,1.58805
gpu_array,2048,8,1,20,2,false,false,true,false,-140.25,1.43279
gpu_array,2048,8,1,20,4,false,false,true,false,-127.929,1.31026
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,-158.979,1.62073
gpu_sparse,2048,8,1,20,2,false,false,true,false,-150.085,1.53573
gpu_sparse,2048,8,1,20,4,false,false,true,false,-128.708,1.31691
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,-183.725,1.87397
gpu_reorg,2048,8,1,20,2,false,false,true,false,-144.572,1.47785
gpu_reorg,2048,8,1,20,4,false,false,true,false,-150.548,1.53861
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,-65.7165,0.680986
gpu_array,2048,8,1,50,2,false,false,true,false,-67.9651,0.703804
gpu_array,2048,8,1,50,4,false,false,true,false,-67.9276,0.703276
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,-67.8463,0.702532
gpu_sparse,2048,8,1,50,2,false,false,true,false,-77.1373,0.796287
gpu_sparse,2048,8,1,50,4,false,false,true,false,-76.9636,0.79467
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,-68.7412,0.713408
gpu_reorg,2048,8,1,50,2,false,false,true,false,-65.8537,0.684392
gpu_reorg,2048,8,1,50,4,false,false,true,false,-65.9335,0.684707
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,-104.582,1.07268
gpu_array,2048,32,1,20,2,false,false,true,false,-98.9574,1.01623
gpu_array,2048,32,1,20,4,false,false,true,false,-100.71,1.0341
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,-106.488,1.0923
gpu_sparse,2048,32,1,20,2,false,false,true,false,-101.533,1.04269
gpu_sparse,2048,32,1,20,4,false,false,true,false,-106.312,1.0912
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,-117.569,1.20298
gpu_reorg,2048,32,1,20,2,false,false,true,false,-114.227,1.1698
gpu_reorg,2048,32,1,20,4,false,false,true,false,-118.413,1.21041
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-62.1378,0.645452
0.645452
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-96.6974,0.994021
0.994021
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-97.6539,1.00431
1.00431
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.645452
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 23 seconds of which 13.4083 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,-155.873,1.59036
gpu_array,2048,8,1,20,2,false,false,true,false,-140.384,1.43442
gpu_array,2048,8,1,20,4,false,false,true,false,-127.196,1.30597
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,-158.768,1.61726
gpu_sparse,2048,8,1,20,2,false,false,true,false,-150.35,1.53574
gpu_sparse,2048,8,1,20,4,false,false,true,false,-128.72,1.31802
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,-183.369,1.87146
gpu_reorg,2048,8,1,20,2,false,false,true,false,-144.601,1.4768
gpu_reorg,2048,8,1,20,4,false,false,true,false,-150.666,1.53849
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,-65.8241,0.681724
gpu_array,2048,8,1,50,2,false,false,true,false,-67.9386,0.703489
gpu_array,2048,8,1,50,4,false,false,true,false,-67.9146,0.703579
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,-67.8038,0.702505
gpu_sparse,2048,8,1,50,2,false,false,true,false,-77.2163,0.79594
gpu_sparse,2048,8,1,50,4,false,false,true,false,-77.169,0.796323
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,-68.8443,0.713804
gpu_reorg,2048,8,1,50,2,false,false,true,false,-65.9227,0.684685
gpu_reorg,2048,8,1,50,4,false,false,true,false,-65.9426,0.683909
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,-104.456,1.07137
gpu_array,2048,32,1,20,2,false,false,true,false,-99.0082,1.01719
gpu_array,2048,32,1,20,4,false,false,true,false,-100.598,1.03232
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,-106.427,1.09157
gpu_sparse,2048,32,1,20,2,false,false,true,false,-101.522,1.04251
gpu_sparse,2048,32,1,20,4,false,false,true,false,-106.346,1.09138
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,-117.67,1.20423
gpu_reorg,2048,32,1,20,2,false,false,true,false,-113.849,1.16813
gpu_reorg,2048,32,1,20,4,false,false,true,false,-118.166,1.21046
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-62.1858,0.645212
0.645212
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-96.6531,0.993418
0.993418
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-97.4259,1.00184
1.00184
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.645212
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 23 seconds of which 13.4038 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-17.2392,0.177837
gpu_array,2048,8,1,20,2,true,false,true,false,-14.7466,0.153765
gpu_array,2048,8,1,20,4,true,false,true,false,-14.2999,0.149788
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-20.757,0.214192
gpu_sparse,2048,8,1,20,2,true,false,true,false,-18.7738,0.193469
gpu_sparse,2048,8,1,20,4,true,false,true,false,-18.5867,0.192124
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-19.7087,0.203862
gpu_reorg,2048,8,1,20,2,true,false,true,false,-16.6335,0.176062
gpu_reorg,2048,8,1,20,4,true,false,true,false,-16.7774,0.178147
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-27.9545,0.283298
gpu_array,2048,8,1,50,2,true,false,true,false,-18.6705,0.193318
gpu_array,2048,8,1,50,4,true,false,true,false,-18.7399,0.193728
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-27.648,0.280732
gpu_sparse,2048,8,1,50,2,true,false,true,false,-22.4019,0.230413
gpu_sparse,2048,8,1,50,4,true,false,true,false,-22.6266,0.231848
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-25.2863,0.262551
gpu_reorg,2048,8,1,50,2,true,false,true,false,-24.0818,0.249265
gpu_reorg,2048,8,1,50,4,true,false,true,false,-23.9735,0.249646
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-14.2998,0.146938
gpu_array,2048,32,1,20,2,true,false,true,false,-10.9934,0.114019
gpu_array,2048,32,1,20,4,true,false,true,false,-11.2011,0.114863
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-14.9481,0.152532
gpu_sparse,2048,32,1,20,2,true,false,true,false,-12.4726,0.128972
gpu_sparse,2048,32,1,20,4,true,false,true,false,-19.2229,0.194536
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-30.3725,0.314531
gpu_reorg,2048,32,1,20,2,true,false,true,false,-28.1051,0.288923
gpu_reorg,2048,32,1,20,4,true,false,true,false,-25.0309,0.253723
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,-12.4129,0.126646
0.126646
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-16.9977,0.172681
0.172681
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-16.1957,0.164648
0.164648
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-18.1317,0.184192
0.184192
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-16.6035,0.168958
0.168958
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-23.4017,0.23697
0.23697
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.114019
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 12 seconds of which 2.69401 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-17.0653,0.176355
gpu_array,2048,8,1,20,2,true,false,true,false,-14.7324,0.153809
gpu_array,2048,8,1,20,4,true,false,true,false,-14.435,0.150464
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-20.8114,0.214028
gpu_sparse,2048,8,1,20,2,true,false,true,false,-18.3883,0.189846
gpu_sparse,2048,8,1,20,4,true,false,true,false,-18.2965,0.189355
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-19.6691,0.202969
gpu_reorg,2048,8,1,20,2,true,false,true,false,-16.3965,0.175308
gpu_reorg,2048,8,1,20,4,true,false,true,false,-16.4464,0.180054
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-30.478,0.303767
gpu_array,2048,8,1,50,2,true,false,true,false,-18.5188,0.191692
gpu_array,2048,8,1,50,4,true,false,true,false,-18.5648,0.192007
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-27.3111,0.278286
gpu_sparse,2048,8,1,50,2,true,false,true,false,-22.3804,0.229976
gpu_sparse,2048,8,1,50,4,true,false,true,false,-22.3869,0.230293
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-25.1327,0.260864
gpu_reorg,2048,8,1,50,2,true,false,true,false,-23.6997,0.247593
gpu_reorg,2048,8,1,50,4,true,false,true,false,-23.7532,0.247239
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-14.0634,0.146084
gpu_array,2048,32,1,20,2,true,false,true,false,-10.8966,0.112212
gpu_array,2048,32,1,20,4,true,false,true,false,-11.0291,0.113987
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-14.8699,0.153003
gpu_sparse,2048,32,1,20,2,true,false,true,false,-20.1789,0.210767
gpu_sparse,2048,32,1,20,4,true,false,true,false,-23.8873,0.244043
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-32.4434,0.319819
gpu_reorg,2048,32,1,20,2,true,false,true,false,-25.2983,0.256846
gpu_reorg,2048,32,1,20,4,true,false,true,false,-25.1903,0.255527
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,-15.499,0.157727
0.157727
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-21.1748,0.215298
0.215298
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-27.0618,0.279026
0.279026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-33.2278,0.340601
0.340601
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-20.7327,0.210706
0.210706
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-22.788,0.231514
0.231514
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.112212
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 12 seconds of which 2.89221 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-3185.05,132.372
gpu_array,2048,8,1,20,2,true,false,true,false,-1800.76,73.891
gpu_array,2048,8,1,20,4,true,false,true,false,-2823.97,115.441
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-2861.1,118.044
gpu_sparse,2048,8,1,20,2,true,false,true,false,-2343.92,94.367
gpu_sparse,2048,8,1,20,4,true,false,true,false,-3360.48,138.432
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-4230.05,175.761
gpu_reorg,2048,8,1,20,2,true,false,true,false,-5352.07,214.853
gpu_reorg,2048,8,1,20,4,true,false,true,false,-11384,474.261
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-4343.29,180.242
gpu_array,2048,8,1,50,2,true,false,true,false,-5110.09,212.011
gpu_array,2048,8,1,50,4,true,false,true,false,-5478.67,225.536
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-3387.03,140.196
gpu_sparse,2048,8,1,50,2,true,false,true,false,-4924.34,206.236
gpu_sparse,2048,8,1,50,4,true,false,true,false,-5137.77,213.119
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-5166.56,214.54
gpu_reorg,2048,8,1,50,2,true,false,true,false,-14354.5,599.06
gpu_reorg,2048,8,1,50,4,true,false,true,false,-12606.2,524.856
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-1982.14,80.7819
gpu_array,2048,32,1,20,2,true,false,true,false,-1922.34,78.9149
gpu_array,2048,32,1,20,4,true,false,true,false,-1696.29,69.0373
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-1680.74,68.3154
gpu_sparse,2048,32,1,20,2,true,false,true,false,-1924.22,78.966
gpu_sparse,2048,32,1,20,4,true,false,true,false,-1742.54,70.467
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-1938.03,79.0589
gpu_reorg,2048,32,1,20,2,true,false,true,false,-5715.44,237.561
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,-2228.75,90.4044
90.4044
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,-2359.47,95.98
95.98
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,-1466.5,58.8629
58.8629
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,-1504.06,60.8183
60.8183
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 58.8629
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 778 seconds of which 524.532 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-3191.43,132.4
gpu_array,2048,8,1,20,2,true,false,true,false,-1792.99,71.8939
gpu_array,2048,8,1,20,4,true,false,true,false,-2790.41,115.885
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-2845.93,117.733
gpu_sparse,2048,8,1,20,2,true,false,true,false,-2294.62,93.8618
gpu_sparse,2048,8,1,20,4,true,false,true,false,-3333.98,137.402
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-4240.1,176.438
gpu_reorg,2048,8,1,20,2,true,false,true,false,-5380.17,216.259
gpu_reorg,2048,8,1,20,4,true,false,true,false,-11330.1,471.893
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-4346.82,180.402
gpu_array,2048,8,1,50,2,true,false,true,false,-5119.27,210.722
gpu_array,2048,8,1,50,4,true,false,true,false,-5532.15,228.761
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-3402.07,140.527
gpu_sparse,2048,8,1,50,2,true,false,true,false,-4972.47,206.439
gpu_sparse,2048,8,1,50,4,true,false,true,false,-5061.72,212.548
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-5174.92,214.726
gpu_reorg,2048,8,1,50,2,true,false,true,false,-14366.5,598.84
gpu_reorg,2048,8,1,50,4,true,false,true,false,-12681.2,526.042
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-1977.13,80.7638
gpu_array,2048,32,1,20,2,true,false,true,false,-1920.58,78.842
gpu_array,2048,32,1,20,4,true,false,true,false,-1708.37,69.3412
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-1682.61,67.843
gpu_sparse,2048,32,1,20,2,true,false,true,false,-1939.61,79.2528
gpu_sparse,2048,32,1,20,4,true,false,true,false,-1735.64,70.3357
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-1898.73,79.1384
gpu_reorg,2048,32,1,20,2,true,false,true,false,-5604.28,235.285
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,-2215.53,90.1587
90.1587
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,-2341.89,95.6298
95.6298
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,-1447.88,58.5068
58.5068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,-1515.13,61.0467
61.0467
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 58.5068
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 778 seconds of which 524.177 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-14.5794,0.152549
gpu_array,2048,8,1,20,2,true,false,true,false,-27.7523,0.28387
gpu_array,2048,8,1,20,4,true,false,true,false,-24.4513,0.251299
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-17.35,0.180244
gpu_sparse,2048,8,1,20,2,true,false,true,false,-28.3311,0.290969
gpu_sparse,2048,8,1,20,4,true,false,true,false,-26.92,0.278208
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-18.3905,0.192068
gpu_reorg,2048,8,1,20,2,true,false,true,false,-111.716,0.867908
gpu_reorg,2048,8,1,20,4,true,false,true,false,-116.258,0.877585
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-21.7574,0.223569
gpu_array,2048,8,1,50,2,true,false,true,false,-52.3936,0.532136
gpu_array,2048,8,1,50,4,true,false,true,false,-52.1873,0.530503
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-24.1008,0.247791
gpu_sparse,2048,8,1,50,2,true,false,true,false,-51.4741,0.522507
gpu_sparse,2048,8,1,50,4,true,false,true,false,-51.4421,0.52271
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-26.804,0.276123
gpu_reorg,2048,8,1,50,2,true,false,true,false,-51.6078,0.524084
gpu_reorg,2048,8,1,50,4,true,false,true,false,-51.6482,0.524646
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-12.9001,0.135044
gpu_array,2048,32,1,20,2,true,false,true,false,-14.9135,0.153918
gpu_array,2048,32,1,20,4,true,false,true,false,-27.122,0.280859
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-24.9141,0.25676
gpu_sparse,2048,32,1,20,2,true,false,true,false,-35.126,0.358416
gpu_sparse,2048,32,1,20,4,true,false,true,false,-22.0245,0.225999
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-25.8137,0.260962
gpu_reorg,2048,32,1,20,2,true,false,true,false,-23.962,0.244558
gpu_reorg,2048,32,1,20,4,true,false,true,false,-22.9607,0.234651
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,true,false,false,true,-11.9067,0.124585
0.124585
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,false,false,false,true,-16.9287,0.175288
0.175288
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,-13.2327,0.13843
0.13843
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,-16.8789,0.177251
0.177251
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,-16.8514,0.175947
0.175947
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-23.1972,0.237322
0.237322
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.124585
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 30 seconds of which 4.28391 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-14.5679,0.151804
gpu_array,2048,8,1,20,2,true,false,true,false,-27.2797,0.278894
gpu_array,2048,8,1,20,4,true,false,true,false,-24.6923,0.253015
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-17.2152,0.178879
gpu_sparse,2048,8,1,20,2,true,false,true,false,-28.3911,0.290999
gpu_sparse,2048,8,1,20,4,true,false,true,false,-26.7536,0.275701
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-18.4757,0.192715
gpu_reorg,2048,8,1,20,2,true,false,true,false,-82.6197,0.762104
gpu_reorg,2048,8,1,20,4,true,false,true,false,-42.0599,0.430383
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-21.7237,0.223521
gpu_array,2048,8,1,50,2,true,false,true,false,-51.6231,0.52481
gpu_array,2048,8,1,50,4,true,false,true,false,-51.9524,0.528108
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-24.114,0.247844
gpu_sparse,2048,8,1,50,2,true,false,true,false,-51.605,0.523918
gpu_sparse,2048,8,1,50,4,true,false,true,false,-51.4975,0.523484
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-26.7227,0.275835
gpu_reorg,2048,8,1,50,2,true,false,true,false,-51.5917,0.524502
gpu_reorg,2048,8,1,50,4,true,false,true,false,-51.5909,0.523853
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-12.9484,0.134116
gpu_array,2048,32,1,20,2,true,false,true,false,-14.9826,0.154143
gpu_array,2048,32,1,20,4,true,false,true,false,-27.7794,0.283591
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-18.3108,0.188213
gpu_sparse,2048,32,1,20,2,true,false,true,false,-20.1055,0.207468
gpu_sparse,2048,32,1,20,4,true,false,true,false,-38.6765,0.393818
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-28.3176,0.289814
gpu_reorg,2048,32,1,20,2,true,false,true,false,-21.236,0.217566
gpu_reorg,2048,32,1,20,4,true,false,true,false,-50.6938,0.476135
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,true,false,false,true,-22.4162,0.229771
0.229771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,false,false,false,true,-32.2245,0.313145
0.313145
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,-21.2536,0.218127
0.218127
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,-24.2798,0.249033
0.249033
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,-20.2254,0.207727
0.207727
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-23.555,0.24188
0.24188
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.134116
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 30 seconds of which 4.30691 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,-56.3724,1.15125
gpu_array,4096,32,1,2,2,true,false,true,false,-37.4767,0.770393
gpu_array,4096,32,1,2,4,true,false,true,false,-33.6625,0.688323
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,-56.9395,1.16259
gpu_sparse,4096,32,1,2,2,true,false,true,false,-41.7308,0.852678
gpu_sparse,4096,32,1,2,4,true,false,true,false,-38.2007,0.782988
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,-46.6406,0.953896
gpu_array,4096,32,1,10,2,true,false,true,false,-34.7308,0.713274
gpu_array,4096,32,1,10,4,true,false,true,false,-33.9306,0.695334
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,-47.2802,0.966389
gpu_sparse,4096,32,1,10,2,true,false,true,false,-38.7742,0.7946
gpu_sparse,4096,32,1,10,4,true,false,true,false,-38.2439,0.783894
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,-56.8078,1.16066
gpu_array,4096,64,1,2,2,true,false,true,false,-38.2307,0.776899
gpu_array,4096,64,1,2,4,true,false,true,false,-33.9714,0.695859
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,-57.7982,1.18008
gpu_sparse,4096,64,1,2,2,true,false,true,false,-41.7743,0.850911
gpu_sparse,4096,64,1,2,4,true,false,true,false,-38.5311,0.788928
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,-61.2581,1.25047
gpu_array,4096,64,1,10,2,true,false,true,false,-39.108,0.798987
gpu_array,4096,64,1,10,4,true,false,true,false,-34.6904,0.710496
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,-61.2676,1.25123
gpu_sparse,4096,64,1,10,2,true,false,true,false,-42.1804,0.863035
gpu_sparse,4096,64,1,10,4,true,false,true,false,-38.8016,0.794622
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,-34.8392,0.713289
0.713289
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,-37.964,0.777664
0.777664
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,-33.8335,0.692881
0.692881
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,-37.1158,0.760684
0.760684
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,-33.921,0.695232
0.695232
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,-37.2924,0.761804
0.761804
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.688323
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 25 seconds of which 10.5838 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,-56.3796,1.15136
gpu_array,4096,32,1,2,2,true,false,true,false,-37.8586,0.769841
gpu_array,4096,32,1,2,4,true,false,true,false,-33.8121,0.690068
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,-56.8919,1.16229
gpu_sparse,4096,32,1,2,2,true,false,true,false,-41.7775,0.855308
gpu_sparse,4096,32,1,2,4,true,false,true,false,-38.2657,0.795562
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,-46.6073,0.953518
gpu_array,4096,32,1,10,2,true,false,true,false,-34.775,0.713975
gpu_array,4096,32,1,10,4,true,false,true,false,-33.9974,0.695964
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,-47.2588,0.966035
gpu_sparse,4096,32,1,10,2,true,false,true,false,-38.7879,0.794866
gpu_sparse,4096,32,1,10,4,true,false,true,false,-38.1178,0.782341
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,-56.9932,1.16404
gpu_array,4096,64,1,2,2,true,false,true,false,-37.5505,0.76833
gpu_array,4096,64,1,2,4,true,false,true,false,-33.9509,0.69584
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,-57.9725,1.18152
gpu_sparse,4096,64,1,2,2,true,false,true,false,-41.5618,0.849546
gpu_sparse,4096,64,1,2,4,true,false,true,false,-38.5594,0.78948
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,-61.2066,1.25065
gpu_array,4096,64,1,10,2,true,false,true,false,-39.1021,0.798779
gpu_array,4096,64,1,10,4,true,false,true,false,-34.6392,0.710173
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,-61.2751,1.25201
gpu_sparse,4096,64,1,10,2,true,false,true,false,-42.2054,0.863176
gpu_sparse,4096,64,1,10,4,true,false,true,false,-38.7184,0.793821
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,-34.4434,0.705515
0.705515
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,-36.7691,0.754329
0.754329
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,-33.8965,0.695085
0.695085
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,-37.2484,0.761604
0.761604
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,true,false,true,true,-33.8353,0.692578
0.692578
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,4096,32,1,10,4,false,false,true,true,-37.1805,0.76137
0.76137
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	4096
Best kernel execution time: 0.690068
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 25 seconds of which 10.5755 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,-6.19677,0.127935
gpu_array,4096,32,1,2,2,true,false,true,false,-3.86481,0.0802539
gpu_array,4096,32,1,2,4,true,false,true,false,-3.57572,0.0744238
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,-6.29062,0.129307
gpu_sparse,4096,32,1,2,2,true,false,true,false,-4.65542,0.0967822
gpu_sparse,4096,32,1,2,4,true,false,true,false,-7.05928,0.145801
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,-8.20283,0.168755
gpu_array,4096,32,1,10,2,true,false,true,false,-6.80942,0.140044
gpu_array,4096,32,1,10,4,true,false,true,false,-7.4755,0.153894
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,-11.6093,0.238162
gpu_sparse,4096,32,1,10,2,true,false,true,false,-8.63554,0.177446
gpu_sparse,4096,32,1,10,4,true,false,true,false,-8.58662,0.176804
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,-11.0519,0.226914
gpu_array,4096,64,1,2,2,true,false,true,false,-6.83605,0.140022
gpu_array,4096,64,1,2,4,true,false,true,false,-6.41851,0.132271
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,-10.4958,0.21561
gpu_sparse,4096,64,1,2,2,true,false,true,false,-7.72593,0.159084
gpu_sparse,4096,64,1,2,4,true,false,true,false,-7.33273,0.150664
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,-8.78411,0.180491
gpu_array,4096,64,1,10,2,true,false,true,false,-6.34915,0.130588
gpu_array,4096,64,1,10,4,true,false,true,false,-6.28516,0.129148
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,-11.916,0.244399
gpu_sparse,4096,64,1,10,2,true,false,true,false,-7.78191,0.159985
gpu_sparse,4096,64,1,10,4,true,false,true,false,-7.68725,0.157969
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,-5.81977,0.11968
0.11968
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,-8.81388,0.18075
0.18075
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,64,1,10,4,true,false,true,true,-7.12847,0.146433
0.146433
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,64,1,10,4,false,false,true,true,-11.0061,0.225376
0.225376
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,-6.52861,0.134229
0.134229
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,-9.84811,0.201938
0.201938
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.0744238
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 11 seconds of which 1.94362 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
4096 32 1 2 gpu_array
gpu_array,4096,32,1,2,-1,true,false,false,false,-6.20205,0.127786
gpu_array,4096,32,1,2,2,true,false,true,false,-3.84734,0.0796655
gpu_array,4096,32,1,2,4,true,false,true,false,-3.5872,0.0739307
4096 32 1 2 gpu_sparse
gpu_sparse,4096,32,1,2,-1,true,false,false,false,-6.29054,0.129377
gpu_sparse,4096,32,1,2,2,true,false,true,false,-4.66352,0.0959985
gpu_sparse,4096,32,1,2,4,true,false,true,false,-6.62716,0.135537
4096 32 1 10 gpu_array
gpu_array,4096,32,1,10,-1,true,false,false,false,-7.7006,0.158291
gpu_array,4096,32,1,10,2,true,false,true,false,-6.01345,0.125952
gpu_array,4096,32,1,10,4,true,false,true,false,-6.38667,0.131394
4096 32 1 10 gpu_sparse
gpu_sparse,4096,32,1,10,-1,true,false,false,false,-10.4749,0.215044
gpu_sparse,4096,32,1,10,2,true,false,true,false,-7.63017,0.156697
gpu_sparse,4096,32,1,10,4,true,false,true,false,-7.57779,0.155857
4096 64 1 2 gpu_array
gpu_array,4096,64,1,2,-1,true,false,false,false,-10.113,0.207322
gpu_array,4096,64,1,2,2,true,false,true,false,-6.58532,0.135627
gpu_array,4096,64,1,2,4,true,false,true,false,-6.09672,0.125444
4096 64 1 2 gpu_sparse
gpu_sparse,4096,64,1,2,-1,true,false,false,false,-10.1054,0.207363
gpu_sparse,4096,64,1,2,2,true,false,true,false,-8.00322,0.164504
gpu_sparse,4096,64,1,2,4,true,false,true,false,-8.70927,0.208459
4096 64 1 10 gpu_array
gpu_array,4096,64,1,10,-1,true,false,false,false,-13.231,0.271165
gpu_array,4096,64,1,10,2,true,false,true,false,-10.5253,0.217876
gpu_array,4096,64,1,10,4,true,false,true,false,-11.3373,0.235491
4096 64 1 10 gpu_sparse
gpu_sparse,4096,64,1,10,-1,true,false,false,false,-16.9692,0.350093
gpu_sparse,4096,64,1,10,2,true,false,true,false,-11.4589,0.235164
gpu_sparse,4096,64,1,10,4,true,false,true,false,-9.75494,0.200381
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,32,1,2,4,true,false,true,true,-7.38942,0.151841
0.151841
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,32,1,2,4,false,false,true,true,-11.213,0.230122
0.230122
Trying shared reduce for config
numRowsPerTB: 64
numRowsPerThread: 1
numTreeThreads: 2
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,64,1,2,4,true,false,true,true,-7.42243,0.152524
0.152524
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,64,1,2,4,false,false,true,true,-13.5215,0.271245
0.271245
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 10
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,32,1,10,2,true,false,true,true,-7.17281,0.1475
0.1475
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,4096,32,1,10,2,false,false,true,true,-10.6331,0.218188
0.218188
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	4096
Best kernel execution time: 0.0739307
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 11 seconds of which 2.17737 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 2
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
error: cuCtxCreate(&context, 0, device) failed with error code out of memory[]
error: cuCtxCreate(&context, 0, device) failed with error code out of memory[]
Lowering to LLVM failed.
error: cannot be converted to LLVM IR: missing `LLVMTranslationDialectInterface` registration for dialect for op: func.func
python: /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/src/gpu/GPUExecutionHelper.cpp:114: llvm::Expected<std::unique_ptr<mlir::ExecutionEngine> > mlir::decisionforest::GPUInferenceRunner::CreateExecutionEngine(mlir::ModuleOp): Assertion `maybeEngine && "failed to construct an execution engine"' failed.
