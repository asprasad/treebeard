abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-113.503,1.14785
gpu_array,256,8,1,20,2,true,false,true,-106.89,1.07963
gpu_array,256,8,1,20,4,true,false,true,-99.5363,1.01054
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-142.132,1.43584
gpu_sparse,256,8,1,20,2,true,false,true,-131.304,1.32779
gpu_sparse,256,8,1,20,4,true,false,true,-124.677,1.26295
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-141.159,1.42766
gpu_reorg,256,8,1,20,2,true,false,true,-99.7489,1.01056
gpu_reorg,256,8,1,20,4,true,false,true,-101.218,1.02402
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-144.722,1.46335
gpu_array,256,8,1,50,2,true,false,true,-111.472,1.12862
gpu_array,256,8,1,50,4,true,false,true,-111.408,1.12871
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-151.628,1.53268
gpu_sparse,256,8,1,50,2,true,false,true,-141.459,1.43464
gpu_sparse,256,8,1,50,4,true,false,true,-141.637,1.43372
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-208.15,2.10349
gpu_reorg,256,8,1,50,2,true,false,true,-115.431,1.17362
gpu_reorg,256,8,1,50,4,true,false,true,-118.758,1.20164
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,-192.501,1.94515
gpu_array,256,32,1,20,2,true,false,true,-113.117,1.1433
gpu_array,256,32,1,20,4,true,false,true,-102.295,1.03238
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,-193.238,1.95243
gpu_sparse,256,32,1,20,2,true,false,true,-121.545,1.22809
gpu_sparse,256,32,1,20,4,true,false,true,-107.668,1.08803
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,-263.219,2.65931
gpu_reorg,256,32,1,20,2,true,false,true,-146.999,1.48479
gpu_reorg,256,32,1,20,4,true,false,true,-154.307,1.55896
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,-97.9224,0.992254
0.992254
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,-106.752,1.0822
1.0822
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,-102.71,1.0365
1.0365
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,-109.341,1.10698
1.10698
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,-105.793,1.07369
1.07369
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,-106.864,1.08439
1.08439
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 0.992254
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 27 seconds of which 2.24234 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-22.1105,0.223744
gpu_array,256,8,1,20,2,true,false,true,-20.6347,0.209004
gpu_array,256,8,1,20,4,true,false,true,-20.5626,0.210237
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-27.0707,0.273577
gpu_sparse,256,8,1,20,2,true,false,true,-25.4155,0.257999
gpu_sparse,256,8,1,20,4,true,false,true,-24.9777,0.254475
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-21.6157,0.220218
gpu_reorg,256,8,1,20,2,true,false,true,-21.4238,0.219023
gpu_reorg,256,8,1,20,4,true,false,true,-21.6129,0.221925
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-27.4003,0.277123
gpu_array,256,8,1,50,2,true,false,true,-27.8128,0.282609
gpu_array,256,8,1,50,4,true,false,true,-27.8839,0.282377
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-33.6924,0.341083
gpu_sparse,256,8,1,50,2,true,false,true,-33.5911,0.339718
gpu_sparse,256,8,1,50,4,true,false,true,-33.4817,0.339138
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-27.4386,0.277952
gpu_reorg,256,8,1,50,2,true,false,true,-30.023,0.303474
gpu_reorg,256,8,1,50,4,true,false,true,-30.118,0.30502
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,-20.0662,0.204978
gpu_array,256,32,1,20,2,true,false,true,-15.9875,0.162595
gpu_array,256,32,1,20,4,true,false,true,-16.0253,0.164964
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,-20.8543,0.212093
gpu_sparse,256,32,1,20,2,true,false,true,-18.0773,0.183887
gpu_sparse,256,32,1,20,4,true,false,true,-22.0912,0.225248
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,-33.5678,0.342902
gpu_reorg,256,32,1,20,2,true,false,true,-25.9031,0.26264
gpu_reorg,256,32,1,20,4,true,false,true,-26.4142,0.267701
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,-18.5364,0.187977
0.187977
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,-23.447,0.237148
0.237148
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,-23.6599,0.240257
0.240257
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,-23.587,0.23885
0.23885
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,-29.3593,0.294729
0.294729
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,-26.4567,0.267595
0.267595
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.162595
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 9 seconds of which 0.426612 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-376.615,3.81268
gpu_array,256,8,1,20,2,true,false,true,-206.418,2.09307
gpu_array,256,8,1,20,4,true,false,true,-132.451,1.34751
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-369.774,3.76087
gpu_sparse,256,8,1,20,2,true,false,true,-206.86,2.09779
gpu_sparse,256,8,1,20,4,true,false,true,-141.897,1.4455
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-372.487,3.76681
gpu_reorg,256,8,1,20,2,true,false,true,-195.226,1.97645
gpu_reorg,256,8,1,20,4,true,false,true,-220.927,2.23622
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-180.38,1.83419
gpu_array,256,8,1,50,2,true,false,true,-117.048,1.19241
gpu_array,256,8,1,50,4,true,false,true,-147.172,1.49576
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-183.699,1.8647
gpu_sparse,256,8,1,50,2,true,false,true,-135.877,1.3844
gpu_sparse,256,8,1,50,4,true,false,true,-151.645,1.54163
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-213.415,2.15999
gpu_reorg,256,8,1,50,2,true,false,true,-101.076,1.02708
gpu_reorg,256,8,1,50,4,true,false,true,-126.959,1.28751
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,true,false,true,-204.397,1.55285
1.55285
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,false,false,true,-188.215,1.90586
1.90586
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,true,false,true,-183.076,1.85389
1.85389
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,false,false,true,-491.896,4.97704
4.97704
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 1.02708
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 41 seconds of which 2.38665 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-110.962,1.12514
gpu_array,256,8,1,20,2,true,false,true,-118.351,1.19683
gpu_array,256,8,1,20,4,true,false,true,-127.39,1.28946
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-109.961,1.112
gpu_sparse,256,8,1,20,2,true,false,true,-140.533,1.42161
gpu_sparse,256,8,1,20,4,true,false,true,-146.068,1.47711
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-141.85,1.43477
gpu_reorg,256,8,1,20,2,true,false,true,-115.18,1.16713
gpu_reorg,256,8,1,20,4,true,false,true,-153.989,1.55575
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-179.774,1.82024
gpu_array,256,8,1,50,2,true,false,true,-146.195,1.48178
gpu_array,256,8,1,50,4,true,false,true,-192.083,1.94479
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-177.138,1.79078
gpu_sparse,256,8,1,50,2,true,false,true,-166.963,1.69052
gpu_sparse,256,8,1,50,4,true,false,true,-202.739,2.05359
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-210.314,2.12497
gpu_reorg,256,8,1,50,2,true,false,true,-145.56,1.47114
gpu_reorg,256,8,1,50,4,true,false,true,-261.036,2.63723
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,-180.329,1.8223
gpu_array,256,32,1,20,2,true,false,true,-136.412,1.37767
gpu_array,256,32,1,20,4,true,false,true,-106.304,1.07443
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,-174.484,1.76321
gpu_sparse,256,32,1,20,2,true,false,true,-137.951,1.39393
gpu_sparse,256,32,1,20,4,true,false,true,-112.179,1.13342
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,-194.029,1.95968
gpu_reorg,256,32,1,20,2,true,false,true,-144.116,1.45645
gpu_reorg,256,32,1,20,4,true,false,true,-149.204,1.50797
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,-120.307,1.21605
1.21605
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,-183.31,1.85217
1.85217
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,-99.3935,1.00494
1.00494
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,-103.224,1.04479
1.04479
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,-112.91,1.14115
1.14115
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,-134.054,1.35714
1.35714
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 1.00494
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 37 seconds of which 2.55489 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,-133.88,1.36371
gpu_array,256,8,1,20,2,false,false,true,-129.832,1.32525
gpu_array,256,8,1,20,4,false,false,true,-123.61,1.26125
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,-137.926,1.40561
gpu_sparse,256,8,1,20,2,false,false,true,-132.599,1.35278
gpu_sparse,256,8,1,20,4,false,false,true,-124.227,1.26736
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,-161.024,1.6404
gpu_reorg,256,8,1,20,2,false,false,true,-142.448,1.45141
gpu_reorg,256,8,1,20,4,false,false,true,-131.648,1.34321
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,-71.2205,0.732028
gpu_array,256,8,1,50,2,false,false,true,-72.6842,0.74719
gpu_array,256,8,1,50,4,false,false,true,-72.6504,0.747483
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,-73.8178,0.760329
gpu_sparse,256,8,1,50,2,false,false,true,-83.187,0.854308
gpu_sparse,256,8,1,50,4,false,false,true,-83.1605,0.854026
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,-75.3493,0.775126
gpu_reorg,256,8,1,50,2,false,false,true,-74.0785,0.762497
gpu_reorg,256,8,1,50,4,false,false,true,-73.9389,0.760896
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,-111.626,1.14045
gpu_array,256,32,1,20,2,false,false,true,-102.546,1.04912
gpu_array,256,32,1,20,4,false,false,true,-105.005,1.07393
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,-113.647,1.16138
gpu_sparse,256,32,1,20,2,false,false,true,-106.211,1.0862
gpu_sparse,256,32,1,20,4,false,false,true,-111.616,1.14072
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,-125.569,1.28231
gpu_reorg,256,32,1,20,2,false,false,true,-115.337,1.17981
gpu_reorg,256,32,1,20,4,false,false,true,-116.427,1.18991
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,-67.495,0.695315
0.695315
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,-102.107,1.04434
1.04434
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,-98.4015,1.00703
1.00703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.695315
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 18 seconds of which 1.66172 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-20.7573,0.210371
gpu_array,256,8,1,20,2,true,false,true,-19.6822,0.200589
gpu_array,256,8,1,20,4,true,false,true,-19.7495,0.201373
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-26.6862,0.269665
gpu_sparse,256,8,1,20,2,true,false,true,-23.7257,0.240271
gpu_sparse,256,8,1,20,4,true,false,true,-27.081,0.273343
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-25.0678,0.254169
gpu_reorg,256,8,1,20,2,true,false,true,-24.4252,0.24832
gpu_reorg,256,8,1,20,4,true,false,true,-24.6427,0.249559
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-29.7485,0.301152
gpu_array,256,8,1,50,2,true,false,true,-26.5818,0.269199
gpu_array,256,8,1,50,4,true,false,true,-26.669,0.269607
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-32.9215,0.333518
gpu_sparse,256,8,1,50,2,true,false,true,-30.7062,0.310589
gpu_sparse,256,8,1,50,4,true,false,true,-30.6469,0.310103
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-29.184,0.297056
gpu_reorg,256,8,1,50,2,true,false,true,-31.6462,0.320901
gpu_reorg,256,8,1,50,4,true,false,true,-31.7228,0.321814
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,-22.2178,0.224676
gpu_array,256,32,1,20,2,true,false,true,-18.6936,0.189261
gpu_array,256,32,1,20,4,true,false,true,-18.9408,0.193092
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,-23.4947,0.237969
gpu_sparse,256,32,1,20,2,true,false,true,-20.9515,0.212001
gpu_sparse,256,32,1,20,4,true,false,true,-26.2272,0.264941
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,-38.8994,0.378477
gpu_reorg,256,32,1,20,2,true,false,true,-28.2701,0.286825
gpu_reorg,256,32,1,20,4,true,false,true,-28.0191,0.283343
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,-18.4689,0.187863
0.187863
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,-23.9803,0.24291
0.24291
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,-19.1494,0.195488
0.195488
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,-20.357,0.20661
0.20661
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,-20.6535,0.21036
0.21036
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,-22.0015,0.224503
0.224503
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.187863
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 10 seconds of which 0.4311 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-1672.13,67.9919
gpu_array,256,8,1,20,2,true,false,true,-2031.38,81.8126
gpu_array,256,8,1,20,4,true,false,true,-2125.91,85.7505
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-1639.65,66.4675
gpu_sparse,256,8,1,20,2,true,false,true,-2313.32,93.3373
gpu_sparse,256,8,1,20,4,true,false,true,-2396.08,97.3529
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-2618.51,108.758
gpu_reorg,256,8,1,20,2,true,false,true,-2932.23,118.912
gpu_reorg,256,8,1,20,4,true,false,true,-3665.03,150.461
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-3337.21,138.17
gpu_array,256,8,1,50,2,true,false,true,-2586.4,105.12
gpu_array,256,8,1,50,4,true,false,true,-3835.28,157.08
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-2801.19,115.603
gpu_sparse,256,8,1,50,2,true,false,true,-2646.41,107.812
gpu_sparse,256,8,1,50,4,true,false,true,-3941.84,162.003
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-4168.48,173.678
gpu_reorg,256,8,1,50,2,true,false,true,-9838.48,408.612
gpu_reorg,256,8,1,50,4,true,false,true,-9871.2,408.728
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,-2002.31,81.3997
gpu_array,256,32,1,20,2,true,false,true,-1779.37,72.2726
gpu_array,256,32,1,20,4,true,false,true,-1760.1,71.1464
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,-1736.37,70.1988
gpu_sparse,256,32,1,20,2,true,false,true,-1787.28,72.4636
gpu_sparse,256,32,1,20,4,true,false,true,-1805.09,72.3812
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,-2076.27,86.4528
gpu_reorg,256,32,1,20,2,true,false,true,-4313.78,177.911
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,-1305.27,52.0653
52.0653
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,-1331.09,53.3966
53.3966
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,true,false,true,-3156.82,129.466
129.466
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,false,false,true,-3457.68,141.74
141.74
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 52.0653
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 530 seconds of which 47.7254 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,-19.7734,0.202009
gpu_array,256,8,1,20,2,true,false,true,-29.1335,0.295589
gpu_array,256,8,1,20,4,true,false,true,-30.1214,0.305508
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,-23.4194,0.237977
gpu_sparse,256,8,1,20,2,true,false,true,-34.5749,0.35029
gpu_sparse,256,8,1,20,4,true,false,true,-35.0994,0.354816
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,-23.1748,0.236501
gpu_reorg,256,8,1,20,2,true,false,true,-38.2561,0.38952
gpu_reorg,256,8,1,20,4,true,false,true,-45.5785,0.462221
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,-27.1556,0.275159
gpu_array,256,8,1,50,2,true,false,true,-58.5851,0.592916
gpu_array,256,8,1,50,4,true,false,true,-58.6122,0.59264
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,-29.6876,0.301752
gpu_sparse,256,8,1,50,2,true,false,true,-57.823,0.58488
gpu_sparse,256,8,1,50,4,true,false,true,-57.8405,0.584746
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,-29.7721,0.302634
gpu_reorg,256,8,1,50,2,true,false,true,-60.1442,0.60803
gpu_reorg,256,8,1,50,4,true,false,true,-60.0972,0.607564
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,-20.0596,0.204911
gpu_array,256,32,1,20,2,true,false,true,-23.2896,0.23719
gpu_array,256,32,1,20,4,true,false,true,-37.128,0.378108
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,-32.5755,0.330737
gpu_sparse,256,32,1,20,2,true,false,true,-28.689,0.290896
gpu_sparse,256,32,1,20,4,true,false,true,-29.8697,0.302132
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,-32.5531,0.330293
gpu_reorg,256,32,1,20,2,true,false,true,-35.4917,0.359894
gpu_reorg,256,32,1,20,4,true,false,true,-38.3229,0.388008
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,-18.5313,0.188527
0.188527
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,-22.9673,0.233078
0.233078
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,true,false,false,-19.4141,0.19755
0.19755
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,false,false,false,-25.8057,0.261236
0.261236
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,-22.2709,0.225723
0.225723
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,-25.1718,0.255681
0.255681
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.188527
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 22 seconds of which 0.587198 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-113.001,1.1442
gpu_array,512,8,1,20,2,true,false,true,-95.3466,0.966523
gpu_array,512,8,1,20,4,true,false,true,-91.6091,0.932536
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-124.738,1.26434
gpu_sparse,512,8,1,20,2,true,false,true,-120.421,1.21859
gpu_sparse,512,8,1,20,4,true,false,true,-116.499,1.17917
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-139.563,1.41001
gpu_reorg,512,8,1,20,2,true,false,true,-95.4388,0.973981
gpu_reorg,512,8,1,20,4,true,false,true,-92.5024,0.938314
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-142.205,1.43739
gpu_array,512,8,1,50,2,true,false,true,-110.369,1.11859
gpu_array,512,8,1,50,4,true,false,true,-109.233,1.10494
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-149.624,1.51219
gpu_sparse,512,8,1,50,2,true,false,true,-137.713,1.3942
gpu_sparse,512,8,1,50,4,true,false,true,-135.923,1.37593
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-205.583,2.07725
gpu_reorg,512,8,1,50,2,true,false,true,-111.603,1.13306
gpu_reorg,512,8,1,50,4,true,false,true,-116.844,1.18165
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,-142.737,1.44245
gpu_array,512,32,1,20,2,true,false,true,-84.6961,0.858617
gpu_array,512,32,1,20,4,true,false,true,-78.9566,0.799886
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,-142.55,1.44048
gpu_sparse,512,32,1,20,2,true,false,true,-91.135,0.922926
gpu_sparse,512,32,1,20,4,true,false,true,-88.0413,0.891654
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,-193.054,1.95169
gpu_reorg,512,32,1,20,2,true,false,true,-109.497,1.10821
gpu_reorg,512,32,1,20,4,true,false,true,-114.672,1.15966
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,-78.563,0.7957
0.7957
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,-87.1215,0.884408
0.884408
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,-89.2644,0.908763
0.908763
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,-99.7394,1.01514
1.01514
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,-93.6359,0.956566
0.956566
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,-107.726,1.09549
1.09549
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.7957
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 23 seconds of which 3.95208 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-18.8569,0.19126
gpu_array,512,8,1,20,2,true,false,true,-17.1255,0.175306
gpu_array,512,8,1,20,4,true,false,true,-16.86,0.173818
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-22.9259,0.232275
gpu_sparse,512,8,1,20,2,true,false,true,-21.4108,0.218148
gpu_sparse,512,8,1,20,4,true,false,true,-21.2371,0.216631
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-23.8154,0.241221
gpu_reorg,512,8,1,20,2,true,false,true,-23.1065,0.23401
gpu_reorg,512,8,1,20,4,true,false,true,-23.6269,0.238372
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-34.9358,0.357217
gpu_array,512,8,1,50,2,true,false,true,-29.3437,0.296898
gpu_array,512,8,1,50,4,true,false,true,-26.4237,0.267077
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-36.4735,0.360514
gpu_sparse,512,8,1,50,2,true,false,true,-28.5608,0.288138
gpu_sparse,512,8,1,50,4,true,false,true,-28.1445,0.284564
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-24.7246,0.252611
gpu_reorg,512,8,1,50,2,true,false,true,-24.5641,0.251611
gpu_reorg,512,8,1,50,4,true,false,true,-24.6753,0.252435
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,-14.5119,0.148281
gpu_array,512,32,1,20,2,true,false,true,-11.0496,0.112516
gpu_array,512,32,1,20,4,true,false,true,-11.0784,0.112969
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,-21.308,0.216058
gpu_sparse,512,32,1,20,2,true,false,true,-18.3292,0.185736
gpu_sparse,512,32,1,20,4,true,false,true,-20.6323,0.208887
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,-31.7251,0.319827
gpu_reorg,512,32,1,20,2,true,false,true,-21.7447,0.22084
gpu_reorg,512,32,1,20,4,true,false,true,-22.2172,0.224876
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,-15.2108,0.155101
0.155101
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,-19.7763,0.200924
0.200924
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,-23.4569,0.237113
0.237113
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,-24.025,0.243232
0.243232
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,-26.2109,0.265042
0.265042
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,-27.0182,0.272816
0.272816
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.112516
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 9 seconds of which 0.784008 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-374.066,3.78436
gpu_array,512,8,1,20,2,true,false,true,-204.22,2.06922
gpu_array,512,8,1,20,4,true,false,true,-130.346,1.32326
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-366.868,3.7121
gpu_sparse,512,8,1,20,2,true,false,true,-204.78,2.07453
gpu_sparse,512,8,1,20,4,true,false,true,-138.5,1.40578
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-355.083,3.58904
gpu_reorg,512,8,1,20,2,true,false,true,-188.125,1.90689
gpu_reorg,512,8,1,20,4,true,false,true,-213.394,2.16084
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-177.63,1.80119
gpu_array,512,8,1,50,2,true,false,true,-113.061,1.14925
gpu_array,512,8,1,50,4,true,false,true,-127.205,1.29201
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-181.504,1.84283
gpu_sparse,512,8,1,50,2,true,false,true,-130.431,1.32491
gpu_sparse,512,8,1,50,4,true,false,true,-132.087,1.34174
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-201.838,2.04578
gpu_reorg,512,8,1,50,2,true,false,true,-95.6217,0.974658
gpu_reorg,512,8,1,50,4,true,false,true,-121.886,1.23678
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,-198.94,1.51556
1.51556
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,-178.204,1.80801
1.80801
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,true,false,true,-176.459,1.78858
1.78858
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,false,false,true,-451.894,4.58224
4.58224
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 0.974658
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 38 seconds of which 4.58031 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-117.078,1.18457
gpu_array,512,8,1,20,2,true,false,true,-118.342,1.20245
gpu_array,512,8,1,20,4,true,false,true,-126.433,1.27747
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-115.886,1.17305
gpu_sparse,512,8,1,20,2,true,false,true,-133.587,1.35293
gpu_sparse,512,8,1,20,4,true,false,true,-142.464,1.43825
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-156.294,1.58448
gpu_reorg,512,8,1,20,2,true,false,true,-112.577,1.13982
gpu_reorg,512,8,1,20,4,true,false,true,-119.444,1.2072
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-175.157,1.77356
gpu_array,512,8,1,50,2,true,false,true,-145.723,1.47221
gpu_array,512,8,1,50,4,true,false,true,-192.881,1.95079
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-173.86,1.75805
gpu_sparse,512,8,1,50,2,true,false,true,-173.974,1.76322
gpu_sparse,512,8,1,50,4,true,false,true,-203.512,2.05719
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-205.071,2.07194
gpu_reorg,512,8,1,50,2,true,false,true,-140.215,1.41922
gpu_reorg,512,8,1,50,4,true,false,true,-246.328,2.48897
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,-137.021,1.38161
gpu_array,512,32,1,20,2,true,false,true,-105.381,1.06482
gpu_array,512,32,1,20,4,true,false,true,-85.925,0.868649
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,-130.609,1.32106
gpu_sparse,512,32,1,20,2,true,false,true,-106.478,1.07706
gpu_sparse,512,32,1,20,4,true,false,true,-90.8458,0.918571
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,-168.004,1.69814
gpu_reorg,512,32,1,20,2,true,false,true,-114.545,1.15959
gpu_reorg,512,32,1,20,4,true,false,true,-117.771,1.19216
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,-89.3445,0.902913
0.902913
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,-138.249,1.39698
1.39698
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,-94.4491,0.955169
0.955169
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,-102.507,1.0379
1.0379
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,-108.423,1.09888
1.09888
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,-131.047,1.32372
1.32372
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.868649
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 33 seconds of which 4.68097 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,-134.753,1.37149
gpu_array,512,8,1,20,2,false,false,true,-126.309,1.28559
gpu_array,512,8,1,20,4,false,false,true,-122.077,1.24276
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,-138.996,1.41464
gpu_sparse,512,8,1,20,2,false,false,true,-131.858,1.34132
gpu_sparse,512,8,1,20,4,false,false,true,-124.315,1.2654
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,-161.358,1.63997
gpu_reorg,512,8,1,20,2,false,false,true,-138.781,1.41064
gpu_reorg,512,8,1,20,4,false,false,true,-137.918,1.40343
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,-71.1935,0.729017
gpu_array,512,8,1,50,2,false,false,true,-70.3726,0.720485
gpu_array,512,8,1,50,4,false,false,true,-70.4885,0.721165
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,-73.7299,0.755107
gpu_sparse,512,8,1,50,2,false,false,true,-81.7477,0.834303
gpu_sparse,512,8,1,50,4,false,false,true,-81.5652,0.833877
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,-73.8737,0.757155
gpu_reorg,512,8,1,50,2,false,false,true,-71.2137,0.729707
gpu_reorg,512,8,1,50,4,false,false,true,-71.2444,0.728893
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,-104.743,1.06774
gpu_array,512,32,1,20,2,false,false,true,-97.8069,0.997764
gpu_array,512,32,1,20,4,false,false,true,-99.6525,1.01678
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,-106.527,1.08678
gpu_sparse,512,32,1,20,2,false,false,true,-100.474,1.02493
gpu_sparse,512,32,1,20,4,false,false,true,-105.646,1.07684
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,-117.752,1.19987
gpu_reorg,512,32,1,20,2,false,false,true,-109.532,1.11622
gpu_reorg,512,32,1,20,4,false,false,true,-110.454,1.12501
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,-60.4901,0.620547
0.620547
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,-96.3379,0.983047
0.983047
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,-96.1587,0.980612
0.980612
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.620547
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 16 seconds of which 3.22366 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-18.8431,0.192682
gpu_array,512,8,1,20,2,true,false,true,-16.9076,0.172471
gpu_array,512,8,1,20,4,true,false,true,-16.5817,0.170283
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-23.0823,0.234137
gpu_sparse,512,8,1,20,2,true,false,true,-21.0852,0.214977
gpu_sparse,512,8,1,20,4,true,false,true,-20.8994,0.213271
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-25.1878,0.256172
gpu_reorg,512,8,1,20,2,true,false,true,-24.1963,0.243835
gpu_reorg,512,8,1,20,4,true,false,true,-24.5269,0.252393
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-36.8913,0.371051
gpu_array,512,8,1,50,2,true,false,true,-24.4111,0.247122
gpu_array,512,8,1,50,4,true,false,true,-24.4124,0.247148
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-33.6936,0.340918
gpu_sparse,512,8,1,50,2,true,false,true,-27.8608,0.281745
gpu_sparse,512,8,1,50,4,true,false,true,-26.1609,0.264883
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-27.0428,0.274255
gpu_reorg,512,8,1,50,2,true,false,true,-27.5511,0.278298
gpu_reorg,512,8,1,50,4,true,false,true,-27.6313,0.278835
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,-16.2574,0.164453
gpu_array,512,32,1,20,2,true,false,true,-13.4078,0.135771
gpu_array,512,32,1,20,4,true,false,true,-15.862,0.160752
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,-20.8389,0.211273
gpu_sparse,512,32,1,20,2,true,false,true,-19.9833,0.202272
gpu_sparse,512,32,1,20,4,true,false,true,-20.8953,0.216663
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,-34.7658,0.353314
gpu_reorg,512,32,1,20,2,true,false,true,-25.5247,0.257845
gpu_reorg,512,32,1,20,4,true,false,true,-25.6073,0.259238
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,-16.2517,0.164977
0.164977
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,-21.7182,0.219925
0.219925
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,-20.5493,0.208477
0.208477
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,-22.5147,0.228177
0.228177
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,-23.4969,0.238154
0.238154
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,-28.1458,0.286497
0.286497
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.135771
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 9 seconds of which 0.803048 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-2491.54,101.712
gpu_array,512,8,1,20,2,true,false,true,-1813.49,72.1623
gpu_array,512,8,1,20,4,true,false,true,-1965.32,78.8875
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-2311.77,94.9267
gpu_sparse,512,8,1,20,2,true,false,true,-2021.89,80.7306
gpu_sparse,512,8,1,20,4,true,false,true,-2481.66,100.662
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-3195.62,133.087
gpu_reorg,512,8,1,20,2,true,false,true,-2604.16,105.545
gpu_reorg,512,8,1,20,4,true,false,true,-6533.42,272.682
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-4024.9,166.519
gpu_array,512,8,1,50,2,true,false,true,-3802.11,154.724
gpu_array,512,8,1,50,4,true,false,true,-4729.51,194.006
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-3231.1,133.219
gpu_sparse,512,8,1,50,2,true,false,true,-3698.66,150.386
gpu_sparse,512,8,1,50,4,true,false,true,-4536.13,186.565
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-4736.39,197.271
gpu_reorg,512,8,1,50,2,true,false,true,-12359.8,509.348
gpu_reorg,512,8,1,50,4,true,false,true,-11336.4,471.037
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,-1927.13,78.2091
gpu_array,512,32,1,20,2,true,false,true,-1820.95,73.6365
gpu_array,512,32,1,20,4,true,false,true,-1636.03,65.9453
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,-1647.48,66.2246
gpu_sparse,512,32,1,20,2,true,false,true,-1802.28,73.264
gpu_sparse,512,32,1,20,4,true,false,true,-1682.72,67.7405
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,-1771.76,73.3588
gpu_reorg,512,32,1,20,2,true,false,true,-4725.99,197.571
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,-2346.35,95.4642
95.4642
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,-2481.07,100.331
100.331
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,-2904.86,118.716
118.716
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,-3079.45,125.658
125.658
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 65.9453
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 543 seconds of which 111.093 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,-16.5292,0.168747
gpu_array,512,8,1,20,2,true,false,true,-29.7618,0.3014
gpu_array,512,8,1,20,4,true,false,true,-27.1122,0.275153
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,-19.5424,0.197855
gpu_sparse,512,8,1,20,2,true,false,true,-35.7641,0.383008
gpu_sparse,512,8,1,20,4,true,false,true,-35.8171,0.361986
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,-23.4038,0.237461
gpu_reorg,512,8,1,20,2,true,false,true,-69.5561,0.660033
gpu_reorg,512,8,1,20,4,true,false,true,-42.6693,0.433581
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,-25.9636,0.262959
gpu_array,512,8,1,50,2,true,false,true,-55.8658,0.564538
gpu_array,512,8,1,50,4,true,false,true,-55.8634,0.564352
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,-28.5081,0.288158
gpu_sparse,512,8,1,50,2,true,false,true,-55.5688,0.561364
gpu_sparse,512,8,1,50,4,true,false,true,-55.4757,0.560758
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,-30.6993,0.311751
gpu_reorg,512,8,1,50,2,true,false,true,-58.102,0.586839
gpu_reorg,512,8,1,50,4,true,false,true,-58.0183,0.587126
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,-15.1666,0.154987
gpu_array,512,32,1,20,2,true,false,true,-17.9737,0.181934
gpu_array,512,32,1,20,4,true,false,true,-24.6227,0.284212
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,-27.0598,0.27417
gpu_sparse,512,32,1,20,2,true,false,true,-28.7303,0.291204
gpu_sparse,512,32,1,20,4,true,false,true,-29.0716,0.294248
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,-34.1642,0.344951
gpu_reorg,512,32,1,20,2,true,false,true,-36.0339,0.363906
gpu_reorg,512,32,1,20,4,true,false,true,-65.4836,0.654469
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,32,1,20,-1,true,false,false,-18.2978,0.186533
0.186533
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,32,1,20,-1,false,false,false,-25.9628,0.2625
0.2625
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,-20.5852,0.208415
0.208415
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,-25.651,0.259785
0.259785
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,50,-1,true,false,false,-26.8073,0.270837
0.270837
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,512,8,1,50,-1,false,false,false,-31.0012,0.313861
0.313861
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.154987
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 22 seconds of which 1.19328 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-113.973,1.15123
gpu_array,1024,8,1,20,2,true,false,true,-91.3699,0.930864
gpu_array,1024,8,1,20,4,true,false,true,-87.8219,0.903691
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-128.107,1.2937
gpu_sparse,1024,8,1,20,2,true,false,true,-116.738,1.18351
gpu_sparse,1024,8,1,20,4,true,false,true,-113.213,1.15471
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-138.754,1.40201
gpu_reorg,1024,8,1,20,2,true,false,true,-92.0023,0.948896
gpu_reorg,1024,8,1,20,4,true,false,true,-88.645,0.911616
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-129.913,1.3149
gpu_array,1024,8,1,50,2,true,false,true,-100.114,1.01638
gpu_array,1024,8,1,50,4,true,false,true,-99.7333,1.01667
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-136.762,1.38443
gpu_sparse,1024,8,1,50,2,true,false,true,-126.735,1.28636
gpu_sparse,1024,8,1,50,4,true,false,true,-127.605,1.29281
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-186.604,1.88615
gpu_reorg,1024,8,1,50,2,true,false,true,-102.644,1.05031
gpu_reorg,1024,8,1,50,4,true,false,true,-105.693,1.0729
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,-141.198,1.4288
gpu_array,1024,32,1,20,2,true,false,true,-82.9065,0.842476
gpu_array,1024,32,1,20,4,true,false,true,-75.7628,0.772363
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,-141.574,1.43022
gpu_sparse,1024,32,1,20,2,true,false,true,-89.4292,0.907749
gpu_sparse,1024,32,1,20,4,true,false,true,-81.4612,0.830752
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,-192.689,1.94597
gpu_reorg,1024,32,1,20,2,true,false,true,-108.084,1.09653
gpu_reorg,1024,32,1,20,4,true,false,true,-113.285,1.14681
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,-76.4155,0.777813
0.777813
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,-83.7148,0.851631
0.851631
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,-86.7794,0.88957
0.88957
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,-99.4567,1.01499
1.01499
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,-92.6341,0.946958
0.946958
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,-100.386,1.02685
1.02685
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.772363
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 19 seconds of which 7.60025 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-17.3371,0.176528
gpu_array,1024,8,1,20,2,true,false,true,-15.5973,0.158555
gpu_array,1024,8,1,20,4,true,false,true,-15.3864,0.15562
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-21.4224,0.217285
gpu_sparse,1024,8,1,20,2,true,false,true,-19.9402,0.202363
gpu_sparse,1024,8,1,20,4,true,false,true,-19.7498,0.200376
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-30.2624,0.305977
gpu_reorg,1024,8,1,20,2,true,false,true,-26.2598,0.26563
gpu_reorg,1024,8,1,20,4,true,false,true,-29.4518,0.298159
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-42.151,0.426162
gpu_array,1024,8,1,50,2,true,false,true,-31.9551,0.323262
gpu_array,1024,8,1,50,4,true,false,true,-31.8821,0.322036
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-43.8281,0.443359
gpu_sparse,1024,8,1,50,2,true,false,true,-42.1493,0.425884
gpu_sparse,1024,8,1,50,4,true,false,true,-36.2684,0.366318
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-31.4652,0.318008
gpu_reorg,1024,8,1,50,2,true,false,true,-30.9095,0.312207
gpu_reorg,1024,8,1,50,4,true,false,true,-30.7434,0.311265
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,-18.7422,0.189404
gpu_array,1024,32,1,20,2,true,false,true,-13.6175,0.138369
gpu_array,1024,32,1,20,4,true,false,true,-13.619,0.137856
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,-27.5814,0.280879
gpu_sparse,1024,32,1,20,2,true,false,true,-23.9361,0.241602
gpu_sparse,1024,32,1,20,4,true,false,true,-26.8416,0.271704
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,-40.9574,0.413711
gpu_reorg,1024,32,1,20,2,true,false,true,-31.9736,0.323301
gpu_reorg,1024,32,1,20,4,true,false,true,-32.7412,0.33105
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,-21.5528,0.217686
0.217686
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,-28.5832,0.288896
0.288896
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,-34.4188,0.347837
0.347837
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,-35.036,0.353677
0.353677
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,-40.9824,0.414116
0.414116
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,-38.8583,0.392637
0.392637
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.137856
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 9 seconds of which 1.96029 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-346.23,3.48624
gpu_array,1024,8,1,20,2,true,false,true,-186.946,1.89247
gpu_array,1024,8,1,20,4,true,false,true,-119.335,1.21127
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-336.612,3.40416
gpu_sparse,1024,8,1,20,2,true,false,true,-187.551,1.8986
gpu_sparse,1024,8,1,20,4,true,false,true,-129.093,1.31167
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-339.592,3.43119
gpu_reorg,1024,8,1,20,2,true,false,true,-176.367,1.7855
gpu_reorg,1024,8,1,20,4,true,false,true,-198.532,2.01016
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-171.371,1.73163
gpu_array,1024,8,1,50,2,true,false,true,-107.025,1.09068
gpu_array,1024,8,1,50,4,true,false,true,-121.893,1.23809
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-176.184,1.78418
gpu_sparse,1024,8,1,50,2,true,false,true,-122.034,1.24104
gpu_sparse,1024,8,1,50,4,true,false,true,-127.886,1.29745
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-193.06,1.95626
gpu_reorg,1024,8,1,50,2,true,false,true,-88.6682,0.907007
gpu_reorg,1024,8,1,50,4,true,false,true,-113.041,1.14928
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,true,false,true,-242.107,1.80753
1.80753
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,false,false,true,-174.744,1.77045
1.77045
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,true,false,true,-164.497,1.6655
1.6655
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,false,false,true,-446.4,4.51187
4.51187
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.907007
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 33 seconds of which 8.72085 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-107.475,1.0912
gpu_array,1024,8,1,20,2,true,false,true,-132.876,1.34737
gpu_array,1024,8,1,20,4,true,false,true,-129.642,1.31055
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-109.089,1.10653
gpu_sparse,1024,8,1,20,2,true,false,true,-141.247,1.4268
gpu_sparse,1024,8,1,20,4,true,false,true,-139.304,1.41263
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-149.805,1.5132
gpu_reorg,1024,8,1,20,2,true,false,true,-125.066,1.26834
gpu_reorg,1024,8,1,20,4,true,false,true,-116.408,1.1796
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-160.696,1.62476
gpu_array,1024,8,1,50,2,true,false,true,-150.163,1.5162
gpu_array,1024,8,1,50,4,true,false,true,-195.146,1.97396
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-157.371,1.58813
gpu_sparse,1024,8,1,50,2,true,false,true,-183.492,1.85663
gpu_sparse,1024,8,1,50,4,true,false,true,-202.383,2.04724
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-184.305,1.86446
gpu_reorg,1024,8,1,50,2,true,false,true,-132.894,1.35351
gpu_reorg,1024,8,1,50,4,true,false,true,-240.51,2.43074
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,-128.599,1.30155
gpu_array,1024,32,1,20,2,true,false,true,-102.102,1.03401
gpu_array,1024,32,1,20,4,true,false,true,-81.4055,0.82981
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,-125.232,1.26569
gpu_sparse,1024,32,1,20,2,true,false,true,-103.218,1.04475
gpu_sparse,1024,32,1,20,4,true,false,true,-85.9867,0.874609
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,-146.859,1.48562
gpu_reorg,1024,32,1,20,2,true,false,true,-113.372,1.14979
gpu_reorg,1024,32,1,20,4,true,false,true,-115.488,1.16972
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,-87.081,0.881899
0.881899
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,-134.446,1.35851
1.35851
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,-93.0478,0.942441
0.942441
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,-100.442,1.02042
1.02042
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,-99.4238,1.01078
1.01078
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,-130.191,1.31838
1.31838
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.82981
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 28 seconds of which 9.13404 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,-144.41,1.46583
gpu_array,1024,8,1,20,2,false,false,true,-128.932,1.31086
gpu_array,1024,8,1,20,4,false,false,true,-125.211,1.2723
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,-146.376,1.48849
gpu_sparse,1024,8,1,20,2,false,false,true,-138.609,1.40732
gpu_sparse,1024,8,1,20,4,false,false,true,-126.202,1.28338
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,-171.681,1.74533
gpu_reorg,1024,8,1,20,2,false,false,true,-140.208,1.42601
gpu_reorg,1024,8,1,20,4,false,false,true,-145.156,1.47504
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,-66.3486,0.679678
gpu_array,1024,8,1,50,2,false,false,true,-69.0888,0.706162
gpu_array,1024,8,1,50,4,false,false,true,-69.1529,0.706465
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,-68.357,0.700586
gpu_sparse,1024,8,1,50,2,false,false,true,-79.1964,0.81042
gpu_sparse,1024,8,1,50,4,false,false,true,-79.0291,0.809746
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,-68.8829,0.706924
gpu_reorg,1024,8,1,50,2,false,false,true,-66.8122,0.686846
gpu_reorg,1024,8,1,50,4,false,false,true,-66.8304,0.686177
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,-105.733,1.07696
gpu_array,1024,32,1,20,2,false,false,true,-99.7398,1.01605
gpu_array,1024,32,1,20,4,false,false,true,-101.673,1.0349
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,-107.968,1.09875
gpu_sparse,1024,32,1,20,2,false,false,true,-102.338,1.04224
gpu_sparse,1024,32,1,20,4,false,false,true,-107.595,1.09522
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,-118.329,1.20368
gpu_reorg,1024,32,1,20,2,false,false,true,-112.68,1.1476
gpu_reorg,1024,32,1,20,4,false,false,true,-114.832,1.16674
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,-62.3486,0.64064
0.64064
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,-97.5628,0.993833
0.993833
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,-96.2848,0.98083
0.98083
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.64064
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 13 seconds of which 6.52595 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-17.5864,0.178218
gpu_array,1024,8,1,20,2,true,false,true,-15.3181,0.155522
gpu_array,1024,8,1,20,4,true,false,true,-15.0265,0.152202
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-21.097,0.214502
gpu_sparse,1024,8,1,20,2,true,false,true,-19.0224,0.194351
gpu_sparse,1024,8,1,20,4,true,false,true,-18.9607,0.193599
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-32.7524,0.329634
gpu_reorg,1024,8,1,20,2,true,false,true,-27.5605,0.28519
gpu_reorg,1024,8,1,20,4,true,false,true,-30.8933,0.312793
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-41.9848,0.424346
gpu_array,1024,8,1,50,2,true,false,true,-38.2925,0.388198
gpu_array,1024,8,1,50,4,true,false,true,-38.4196,0.389009
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-57.4523,0.580874
gpu_sparse,1024,8,1,50,2,true,false,true,-33.6761,0.340542
gpu_sparse,1024,8,1,50,4,true,false,true,-33.5802,0.339771
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-36.381,0.368042
gpu_reorg,1024,8,1,50,2,true,false,true,-35.8192,0.362461
gpu_reorg,1024,8,1,50,4,true,false,true,-35.6919,0.360879
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,-21.8117,0.220576
gpu_array,1024,32,1,20,2,true,false,true,-20.2549,0.205039
gpu_array,1024,32,1,20,4,true,false,true,-21.4431,0.21709
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,-31.1324,0.314858
gpu_sparse,1024,32,1,20,2,true,false,true,-27.3374,0.276895
gpu_sparse,1024,32,1,20,4,true,false,true,-31.0366,0.31394
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,-49.236,0.497383
gpu_reorg,1024,32,1,20,2,true,false,true,-32.1995,0.325937
gpu_reorg,1024,32,1,20,4,true,false,true,-33.3034,0.337227
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,-25.5785,0.258398
0.258398
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,-28.361,0.286465
0.286465
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,-20.7229,0.209761
0.209761
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,-28.1673,0.284854
0.284854
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,-34.3248,0.347075
0.347075
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,-41.1332,0.415664
0.415664
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.152202
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 9 seconds of which 2.06465 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-3058.45,126.41
gpu_array,1024,8,1,20,2,true,false,true,-1814.96,70.7598
gpu_array,1024,8,1,20,4,true,false,true,-2539.59,101.664
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-2798.61,114.757
gpu_sparse,1024,8,1,20,2,true,false,true,-2174.84,84.6573
gpu_sparse,1024,8,1,20,4,true,false,true,-2932.73,118.48
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-3812.53,159.012
gpu_reorg,1024,8,1,20,2,true,false,true,-3590.19,143.344
gpu_reorg,1024,8,1,20,4,true,false,true,-9818.47,405.969
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-4244.62,177.348
gpu_array,1024,8,1,50,2,true,false,true,-4626.65,186.021
gpu_array,1024,8,1,50,4,true,false,true,-5320.75,220.087
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-3344.32,137.874
gpu_sparse,1024,8,1,50,2,true,false,true,-4522.16,183.454
gpu_sparse,1024,8,1,50,4,true,false,true,-4977.8,205.756
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-5055.25,212.258
gpu_reorg,1024,8,1,50,2,true,false,true,-13697.3,570.701
gpu_reorg,1024,8,1,50,4,true,false,true,-12235.2,509.412
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,-2009.83,80.531
gpu_array,1024,32,1,20,2,true,false,true,-2014.69,81.3445
gpu_array,1024,32,1,20,4,true,false,true,-1812,71.9988
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,-1717.75,67.6212
gpu_sparse,1024,32,1,20,2,true,false,true,-2015.78,81.5269
gpu_sparse,1024,32,1,20,4,true,false,true,-1811.92,72.3051
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,-1773.08,73.7816
gpu_reorg,1024,32,1,20,2,true,false,true,-5548.13,230.939
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,true,false,true,-2461.65,97.9714
97.9714
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,false,false,true,-2597.79,103.931
103.931
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,-1562.45,61.4068
61.4068
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,-1630.32,63.9858
63.9858
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 61.4068
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 440 seconds of which 246.544 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,-15.694,0.160454
gpu_array,1024,8,1,20,2,true,false,true,-28.1486,0.286909
gpu_array,1024,8,1,20,4,true,false,true,-42.8815,0.434917
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,-29.536,0.299976
gpu_sparse,1024,8,1,20,2,true,false,true,-44.9713,0.45354
gpu_sparse,1024,8,1,20,4,true,false,true,-43.1693,0.437173
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,-26.8634,0.273276
gpu_reorg,1024,8,1,20,2,true,false,true,-48.7529,0.492217
gpu_reorg,1024,8,1,20,4,true,false,true,-46.2328,0.46937
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,-22.3788,0.228672
gpu_array,1024,8,1,50,2,true,false,true,-50.9742,0.517041
gpu_array,1024,8,1,50,4,true,false,true,-50.8919,0.516304
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,-24.9296,0.253965
gpu_sparse,1024,8,1,50,2,true,false,true,-50.4872,0.511826
gpu_sparse,1024,8,1,50,4,true,false,true,-50.4577,0.51207
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,-27.1087,0.278955
gpu_reorg,1024,8,1,50,2,true,false,true,-51.3045,0.520684
gpu_reorg,1024,8,1,50,4,true,false,true,-51.3293,0.521284
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,-14.1229,0.144629
gpu_array,1024,32,1,20,2,true,false,true,-16.246,0.165142
gpu_array,1024,32,1,20,4,true,false,true,-16.8785,0.172266
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,-23.7803,0.242168
gpu_sparse,1024,32,1,20,2,true,false,true,-30.2748,0.311123
gpu_sparse,1024,32,1,20,4,true,false,true,-41.4236,0.420146
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,-51.3346,0.518921
gpu_reorg,1024,32,1,20,2,true,false,true,-42.7422,0.432593
gpu_reorg,1024,32,1,20,4,true,false,true,-41.9459,0.425215
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,true,false,false,-24.6724,0.251396
0.251396
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,false,false,false,-35.2651,0.35792
0.35792
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,-29.5978,0.300659
0.300659
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,-36.452,0.370288
0.370288
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,-38.1213,0.391362
0.391362
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,-45.832,0.464897
0.464897
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.144629
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 20 seconds of which 2.48573 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
