abalone 8 1000 0
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-112.587,1.13905
gpu_array,2048,8,1,20,2,true,false,true,-89.0914,0.901301
gpu_array,2048,8,1,20,4,true,false,true,-88.4378,0.899636
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-126.149,1.27508
gpu_sparse,2048,8,1,20,2,true,false,true,-112.922,1.1437
gpu_sparse,2048,8,1,20,4,true,false,true,-112.123,1.13489
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-137.302,1.38745
gpu_reorg,2048,8,1,20,2,true,false,true,-92.7132,0.941611
gpu_reorg,2048,8,1,20,4,true,false,true,-90.4664,0.915925
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-128.202,1.2953
gpu_array,2048,8,1,50,2,true,false,true,-99.1558,1.00629
gpu_array,2048,8,1,50,4,true,false,true,-98.4809,0.998621
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-134.89,1.36505
gpu_sparse,2048,8,1,50,2,true,false,true,-123.192,1.24658
gpu_sparse,2048,8,1,50,4,true,false,true,-123.415,1.24997
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-185.865,1.8788
gpu_reorg,2048,8,1,50,2,true,false,true,-101.222,1.02766
gpu_reorg,2048,8,1,50,4,true,false,true,-104.966,1.0618
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,-128.257,1.29642
gpu_array,2048,32,1,20,2,true,false,true,-75.6519,0.767576
gpu_array,2048,32,1,20,4,true,false,true,-70.3199,0.712339
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,-128.642,1.29974
gpu_sparse,2048,32,1,20,2,true,false,true,-81.4499,0.82354
gpu_sparse,2048,32,1,20,4,true,false,true,-78.4647,0.793647
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,-174.377,1.76187
gpu_reorg,2048,32,1,20,2,true,false,true,-98.4505,0.995305
gpu_reorg,2048,32,1,20,4,true,false,true,-102.687,1.0372
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,-69.8641,0.710654
0.710654
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,-77.7098,0.789746
0.789746
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,-85.8847,0.872161
0.872161
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,-98.2433,0.996973
0.996973
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,-89.9329,0.912834
0.912834
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,-103.587,1.051
1.051
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.710654
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 26 seconds of which 14.6185 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-16.6834,0.171121
gpu_array,2048,8,1,20,2,true,false,true,-14.6863,0.152104
gpu_array,2048,8,1,20,4,true,false,true,-14.4329,0.151121
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-20.6913,0.211035
gpu_sparse,2048,8,1,20,2,true,false,true,-19.0345,0.195522
gpu_sparse,2048,8,1,20,4,true,false,true,-19.0232,0.195593
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-18.0079,0.185439
gpu_reorg,2048,8,1,20,2,true,false,true,-15.2229,0.160901
gpu_reorg,2048,8,1,20,4,true,false,true,-15.5539,0.165334
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-22.5995,0.229614
gpu_array,2048,8,1,50,2,true,false,true,-19.3101,0.198206
gpu_array,2048,8,1,50,4,true,false,true,-19.3015,0.197969
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-27.3509,0.277056
gpu_sparse,2048,8,1,50,2,true,false,true,-25.3439,0.257683
gpu_sparse,2048,8,1,50,4,true,false,true,-25.3678,0.257686
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-23.5333,0.240637
gpu_reorg,2048,8,1,50,2,true,false,true,-21.736,0.224436
gpu_reorg,2048,8,1,50,4,true,false,true,-22.0116,0.227178
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,-12.7912,0.131177
gpu_array,2048,32,1,20,2,true,false,true,-9.02851,0.0925854
gpu_array,2048,32,1,20,4,true,false,true,-8.96971,0.0922974
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,-12.8269,0.131616
gpu_sparse,2048,32,1,20,2,true,false,true,-10.4117,0.106338
gpu_sparse,2048,32,1,20,4,true,false,true,-10.4836,0.107209
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,-16.127,0.167478
gpu_reorg,2048,32,1,20,2,true,false,true,-15.1129,0.155164
gpu_reorg,2048,32,1,20,4,true,false,true,-16.2226,0.164072
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,-10.7923,0.11293
0.11293
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,-16.2141,0.163867
0.163867
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,-20.5245,0.207483
0.207483
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,-22.9517,0.231401
0.231401
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,-20.5607,0.207839
0.207839
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,-21.326,0.215457
0.215457
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0922974
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 9 seconds of which 2.45168 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-341.038,3.44799
gpu_array,2048,8,1,20,2,true,false,true,-185.46,1.87646
gpu_array,2048,8,1,20,4,true,false,true,-118.73,1.20359
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-334.705,3.38424
gpu_sparse,2048,8,1,20,2,true,false,true,-186.066,1.88268
gpu_sparse,2048,8,1,20,4,true,false,true,-132.382,1.3436
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-342.598,3.46459
gpu_reorg,2048,8,1,20,2,true,false,true,-174.915,1.77167
gpu_reorg,2048,8,1,20,4,true,false,true,-196.355,1.98998
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-172.774,1.74765
gpu_array,2048,8,1,50,2,true,false,true,-109.157,1.10757
gpu_array,2048,8,1,50,4,true,false,true,-117.28,1.18838
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-177.878,1.80254
gpu_sparse,2048,8,1,50,2,true,false,true,-121.328,1.22912
gpu_sparse,2048,8,1,50,4,true,false,true,-124.041,1.25663
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-194.261,1.96644
gpu_reorg,2048,8,1,50,2,true,false,true,-88.1049,0.896108
gpu_reorg,2048,8,1,50,4,true,false,true,-112.398,1.14065
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,-182.31,1.39846
1.39846
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,-173.146,1.75333
1.75333
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,true,false,true,-163.806,1.65866
1.65866
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,false,false,true,-457.047,4.62165
4.62165
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.896108
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 42 seconds of which 17.2573 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-109.214,1.10504
gpu_array,2048,8,1,20,2,true,false,true,-150.439,1.51662
gpu_array,2048,8,1,20,4,true,false,true,-146.031,1.47948
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-108.749,1.10065
gpu_sparse,2048,8,1,20,2,true,false,true,-147.581,1.49985
gpu_sparse,2048,8,1,20,4,true,false,true,-149.724,1.51285
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-157.433,1.59092
gpu_reorg,2048,8,1,20,2,true,false,true,-137.228,1.38518
gpu_reorg,2048,8,1,20,4,true,false,true,-114.001,1.15798
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-159.003,1.60733
gpu_array,2048,8,1,50,2,true,false,true,-164.624,1.66958
gpu_array,2048,8,1,50,4,true,false,true,-196.935,1.99065
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-155.822,1.575
gpu_sparse,2048,8,1,50,2,true,false,true,-200.042,2.02719
gpu_sparse,2048,8,1,50,4,true,false,true,-203.755,2.06306
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-182.232,1.84166
gpu_reorg,2048,8,1,50,2,true,false,true,-143.968,1.45406
gpu_reorg,2048,8,1,50,4,true,false,true,-238.676,2.40336
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,-123.055,1.25002
gpu_array,2048,32,1,20,2,true,false,true,-95.5508,0.966792
gpu_array,2048,32,1,20,4,true,false,true,-76.7388,0.778284
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,-115.461,1.16813
gpu_sparse,2048,32,1,20,2,true,false,true,-96.1335,0.971978
gpu_sparse,2048,32,1,20,4,true,false,true,-81.0727,0.820901
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,-142.71,1.44484
gpu_reorg,2048,32,1,20,2,true,false,true,-104.909,1.06164
gpu_reorg,2048,32,1,20,4,true,false,true,-108.219,1.0999
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,-79.8894,0.806858
0.806858
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,-125.239,1.26562
1.26562
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,-93.7068,0.946555
0.946555
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,-99.7498,1.01049
1.01049
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,-128.242,1.2953
1.2953
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,-137.666,1.39206
1.39206
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.778284
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 37 seconds of which 18.5384 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,-154.363,1.5653
gpu_array,2048,8,1,20,2,false,false,true,-139.752,1.41953
gpu_array,2048,8,1,20,4,false,false,true,-127.315,1.29415
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,-158.025,1.60286
gpu_sparse,2048,8,1,20,2,false,false,true,-149.359,1.51551
gpu_sparse,2048,8,1,20,4,false,false,true,-127.936,1.29948
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,-182.52,1.84943
gpu_reorg,2048,8,1,20,2,false,false,true,-144.114,1.46371
gpu_reorg,2048,8,1,20,4,false,false,true,-149.772,1.52027
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,-65.9908,0.675254
gpu_array,2048,8,1,50,2,false,false,true,-67.3889,0.689666
gpu_array,2048,8,1,50,4,false,false,true,-67.4242,0.690569
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,-67.7225,0.693035
gpu_sparse,2048,8,1,50,2,false,false,true,-76.5167,0.7821
gpu_sparse,2048,8,1,50,4,false,false,true,-76.6342,0.782307
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,-69.0107,0.704675
gpu_reorg,2048,8,1,50,2,false,false,true,-66.4074,0.6805
gpu_reorg,2048,8,1,50,4,false,false,true,-66.5339,0.680483
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,-104.238,1.06076
gpu_array,2048,32,1,20,2,false,false,true,-98.4899,1.0033
gpu_array,2048,32,1,20,4,false,false,true,-100.494,1.02392
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,-106.185,1.08066
gpu_sparse,2048,32,1,20,2,false,false,true,-101.02,1.03021
gpu_sparse,2048,32,1,20,4,false,false,true,-106.13,1.08056
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,-117.074,1.19173
gpu_reorg,2048,32,1,20,2,false,false,true,-113.542,1.15587
gpu_reorg,2048,32,1,20,4,false,false,true,-117.501,1.19628
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,-62.7257,0.642979
0.642979
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,-96.2383,0.980974
0.980974
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,-97.1805,0.990413
0.990413
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.642979
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 20 seconds of which 13.2491 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-16.823,0.173081
gpu_array,2048,8,1,20,2,true,false,true,-14.4246,0.150115
gpu_array,2048,8,1,20,4,true,false,true,-14.1,0.148562
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-20.8172,0.213025
gpu_sparse,2048,8,1,20,2,true,false,true,-18.0502,0.18709
gpu_sparse,2048,8,1,20,4,true,false,true,-18.1693,0.188081
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-19.254,0.199648
gpu_reorg,2048,8,1,20,2,true,false,true,-16.1713,0.173892
gpu_reorg,2048,8,1,20,4,true,false,true,-16.3329,0.175928
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-22.9651,0.235132
gpu_array,2048,8,1,50,2,true,false,true,-18.3011,0.190076
gpu_array,2048,8,1,50,4,true,false,true,-18.5143,0.191218
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-27.4018,0.278354
gpu_sparse,2048,8,1,50,2,true,false,true,-22.1583,0.227468
gpu_sparse,2048,8,1,50,4,true,false,true,-22.3527,0.228384
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-24.7593,0.255339
gpu_reorg,2048,8,1,50,2,true,false,true,-23.4739,0.242375
gpu_reorg,2048,8,1,50,4,true,false,true,-23.2651,0.241211
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,-13.8636,0.14375
gpu_array,2048,32,1,20,2,true,false,true,-10.6845,0.109971
gpu_array,2048,32,1,20,4,true,false,true,-10.8804,0.111833
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,-14.5797,0.149768
gpu_sparse,2048,32,1,20,2,true,false,true,-12.1326,0.125203
gpu_sparse,2048,32,1,20,4,true,false,true,-12.4515,0.127585
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,-22.4129,0.261453
gpu_reorg,2048,32,1,20,2,true,false,true,-23.8776,0.24106
gpu_reorg,2048,32,1,20,4,true,false,true,-21.2725,0.21533
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,-12.0958,0.122458
0.122458
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,-16.485,0.16688
0.16688
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,-15.8239,0.159944
0.159944
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,-17.7163,0.17925
0.17925
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,-16.1834,0.163777
0.163777
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,-18.6706,0.188765
0.188765
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.109971
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 9 seconds of which 2.5256 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-3220.55,133.859
gpu_array,2048,8,1,20,2,true,false,true,-1816.03,71.8889
gpu_array,2048,8,1,20,4,true,false,true,-2881.62,116.14
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-2867.14,118.733
gpu_sparse,2048,8,1,20,2,true,false,true,-2278.89,92.9964
gpu_sparse,2048,8,1,20,4,true,false,true,-3370.16,138.769
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-4325.1,177.786
gpu_reorg,2048,8,1,20,2,true,false,true,-5053.29,206.107
gpu_reorg,2048,8,1,20,4,true,false,true,-11312.7,469.086
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-4340.64,181.408
gpu_array,2048,8,1,50,2,true,false,true,-5121.81,214.31
gpu_array,2048,8,1,50,4,true,false,true,-5447.41,224.892
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-3390.67,141.232
gpu_sparse,2048,8,1,50,2,true,false,true,-4971.77,206.248
gpu_sparse,2048,8,1,50,4,true,false,true,-5112.06,212.153
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-5129.68,214.965
gpu_reorg,2048,8,1,50,2,true,false,true,-14325.6,597.947
gpu_reorg,2048,8,1,50,4,true,false,true,-12669.6,529.715
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,-2001.96,80.9608
gpu_array,2048,32,1,20,2,true,false,true,-1920.36,78.976
gpu_array,2048,32,1,20,4,true,false,true,-1692.96,69.151
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,-1670.73,67.7442
gpu_sparse,2048,32,1,20,2,true,false,true,-1941.53,79.2903
gpu_sparse,2048,32,1,20,4,true,false,true,-1724.89,70.11
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,-2036.98,84.3079
gpu_reorg,2048,32,1,20,2,true,false,true,-5857.59,243.387
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,-2224.41,90.3224
90.3224
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,-2360.41,95.8999
95.8999
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,-1455.39,58.6333
58.6333
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,-1508.19,60.9377
60.9377
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 58.6333
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 720 seconds of which 525.103 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,-14.6076,0.150234
gpu_array,2048,8,1,20,2,true,false,true,-27.3219,0.277241
gpu_array,2048,8,1,20,4,true,false,true,-24.1213,0.245378
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,-17.4122,0.178096
gpu_sparse,2048,8,1,20,2,true,false,true,-35.184,0.355085
gpu_sparse,2048,8,1,20,4,true,false,true,-26.9003,0.275039
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,-18.4254,0.191313
gpu_reorg,2048,8,1,20,2,true,false,true,-38.0323,0.388567
gpu_reorg,2048,8,1,20,4,true,false,true,-41.9331,0.426248
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,-21.8026,0.222292
gpu_array,2048,8,1,50,2,true,false,true,-50.828,0.513833
gpu_array,2048,8,1,50,4,true,false,true,-51.5577,0.521436
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,-24.4301,0.248145
gpu_sparse,2048,8,1,50,2,true,false,true,-51.7009,0.522727
gpu_sparse,2048,8,1,50,4,true,false,true,-51.0212,0.51592
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,-26.6963,0.272905
gpu_reorg,2048,8,1,50,2,true,false,true,-51.6034,0.522529
gpu_reorg,2048,8,1,50,4,true,false,true,-51.6462,0.522732
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,-12.7921,0.13127
gpu_array,2048,32,1,20,2,true,false,true,-14.561,0.148
gpu_array,2048,32,1,20,4,true,false,true,-15.3318,0.182812
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,-20.7583,0.20999
gpu_sparse,2048,32,1,20,2,true,false,true,-21.2313,0.214971
gpu_sparse,2048,32,1,20,4,true,false,true,-19.642,0.19887
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,-24.7248,0.249805
gpu_reorg,2048,32,1,20,2,true,false,true,-20.5535,0.208186
gpu_reorg,2048,32,1,20,4,true,false,true,-22.2022,0.224526
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,true,false,false,-11.8807,0.121719
0.121719
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,32,1,20,-1,false,false,false,-16.7851,0.171953
0.171953
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,-13.071,0.133635
0.133635
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,-16.8059,0.174084
0.174084
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,-16.6444,0.171479
0.171479
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,-19.5568,0.20104
0.20104
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.121719
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 22 seconds of which 3.72411 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
