abalone 8 1000 0
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-353.549,1.19188
gpu_array,256,8,1,20,2,true,false,true,false,-333.775,1.13026
gpu_array,256,8,1,20,4,true,false,true,false,-311.001,1.05552
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-441.871,1.48466
gpu_sparse,256,8,1,20,2,true,false,true,false,-409.472,1.38055
gpu_sparse,256,8,1,20,4,true,false,true,false,-389.554,1.32019
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-437.09,1.47266
gpu_reorg,256,8,1,20,2,true,false,true,false,-313.277,1.06635
gpu_reorg,256,8,1,20,4,true,false,true,false,-316.032,1.07588
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-449.311,1.51035
gpu_array,256,8,1,50,2,true,false,true,false,-346.867,1.17479
gpu_array,256,8,1,50,4,true,false,true,false,-356.164,1.19498
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-472.055,1.58892
gpu_sparse,256,8,1,50,2,true,false,true,false,-441.06,1.49063
gpu_sparse,256,8,1,50,4,true,false,true,false,-439.606,1.48533
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-643.008,2.15191
gpu_reorg,256,8,1,50,2,true,false,true,false,-364.595,1.23526
gpu_reorg,256,8,1,50,4,true,false,true,false,-370.257,1.2523
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-595.109,1.99192
gpu_array,256,32,1,20,2,true,false,true,false,-352.837,1.18681
gpu_array,256,32,1,20,4,true,false,true,false,-318.775,1.07464
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-597.586,1.99945
gpu_sparse,256,32,1,20,2,true,false,true,false,-378.504,1.26673
gpu_sparse,256,32,1,20,4,true,false,true,false,-335.936,1.13299
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-810.084,2.71158
gpu_reorg,256,32,1,20,2,true,false,true,false,-456.154,1.52736
gpu_reorg,256,32,1,20,4,true,false,true,false,-478.407,1.60108
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,-306.329,1.04165
1.04165
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-333.518,1.13345
1.13345
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-321.056,1.0804
1.0804
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-342.26,1.15752
1.15752
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-334.529,1.13032
1.13032
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-335.414,1.13748
1.13748
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 1.04165
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 63 seconds of which 6.97893 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-354.988,1.19621
gpu_array,256,8,1,20,2,true,false,true,false,-338.783,1.13919
gpu_array,256,8,1,20,4,true,false,true,false,-312.19,1.06146
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-441.73,1.48678
gpu_sparse,256,8,1,20,2,true,false,true,false,-409.768,1.38672
gpu_sparse,256,8,1,20,4,true,false,true,false,-390.063,1.32539
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-437.696,1.47427
gpu_reorg,256,8,1,20,2,true,false,true,false,-314.073,1.07074
gpu_reorg,256,8,1,20,4,true,false,true,false,-317.781,1.07903
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-448.362,1.51179
gpu_array,256,8,1,50,2,true,false,true,false,-348.237,1.17969
gpu_array,256,8,1,50,4,true,false,true,false,-350.504,1.18715
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-472.825,1.59165
gpu_sparse,256,8,1,50,2,true,false,true,false,-441.698,1.49468
gpu_sparse,256,8,1,50,4,true,false,true,false,-439.912,1.48948
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-643.256,2.15287
gpu_reorg,256,8,1,50,2,true,false,true,false,-365.046,1.23862
gpu_reorg,256,8,1,50,4,true,false,true,false,-369.675,1.25407
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-594.704,1.99103
gpu_array,256,32,1,20,2,true,false,true,false,-352.621,1.18437
gpu_array,256,32,1,20,4,true,false,true,false,-319.617,1.07728
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-597.985,2.00191
gpu_sparse,256,32,1,20,2,true,false,true,false,-378.021,1.2672
gpu_sparse,256,32,1,20,4,true,false,true,false,-337.963,1.13732
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-810.177,2.71121
gpu_reorg,256,32,1,20,2,true,false,true,false,-455.803,1.5272
gpu_reorg,256,32,1,20,4,true,false,true,false,-478.377,1.60099
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,true,false,true,true,-306.044,1.04334
1.04334
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-333.734,1.13488
1.13488
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-321.68,1.08148
1.08148
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-343.105,1.15876
1.15876
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-337.421,1.13581
1.13581
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-336.257,1.14077
1.14077
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	256
Best kernel execution time: 1.04334
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 63 seconds of which 6.99085 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-72.3547,0.244655
gpu_array,256,8,1,20,2,true,false,true,false,-67.7441,0.228538
gpu_array,256,8,1,20,4,true,false,true,false,-67.8622,0.229363
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-87.0039,0.293567
gpu_sparse,256,8,1,20,2,true,false,true,false,-83.0535,0.28025
gpu_sparse,256,8,1,20,4,true,false,true,false,-82.2818,0.277945
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-70.4407,0.23844
gpu_reorg,256,8,1,20,2,true,false,true,false,-69.9972,0.237715
gpu_reorg,256,8,1,20,4,true,false,true,false,-70.3218,0.238515
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-90.0612,0.30377
gpu_array,256,8,1,50,2,true,false,true,false,-90.8903,0.306102
gpu_array,256,8,1,50,4,true,false,true,false,-90.5202,0.306258
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-107.737,0.362013
gpu_sparse,256,8,1,50,2,true,false,true,false,-108.101,0.363144
gpu_sparse,256,8,1,50,4,true,false,true,false,-108.408,0.365261
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-88.0151,0.297374
gpu_reorg,256,8,1,50,2,true,false,true,false,-96.6711,0.326103
gpu_reorg,256,8,1,50,4,true,false,true,false,-96.8468,0.32615
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-65.6102,0.222378
gpu_array,256,32,1,20,2,true,false,true,false,-52.0952,0.178278
gpu_array,256,32,1,20,4,true,false,true,false,-52.6224,0.179537
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-67.6501,0.228257
gpu_sparse,256,32,1,20,2,true,false,true,false,-59.3413,0.201073
gpu_sparse,256,32,1,20,4,true,false,true,false,-59.4234,0.20218
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-84.6752,0.286269
gpu_reorg,256,32,1,20,2,true,false,true,false,-70.6185,0.23804
gpu_reorg,256,32,1,20,4,true,false,true,false,-70.7899,0.239645
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-52.5003,0.178808
0.178808
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-64.7519,0.218012
0.218012
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,true,-66.5295,0.225528
0.225528
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,true,-66.7008,0.226082
0.226082
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-81.0409,0.272757
0.272757
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-80.4018,0.270071
0.270071
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.178278
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 18 seconds of which 1.31974 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-112.808,0.318728
gpu_array,256,8,1,20,2,true,false,true,false,-67.8793,0.229529
gpu_array,256,8,1,20,4,true,false,true,false,-67.7473,0.23039
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-87.2644,0.294167
gpu_sparse,256,8,1,20,2,true,false,true,false,-83.2612,0.28125
gpu_sparse,256,8,1,20,4,true,false,true,false,-82.0619,0.276805
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-70.2958,0.238256
gpu_reorg,256,8,1,20,2,true,false,true,false,-69.818,0.236125
gpu_reorg,256,8,1,20,4,true,false,true,false,-70.6509,0.238598
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-89.7203,0.302578
gpu_array,256,8,1,50,2,true,false,true,false,-91.213,0.306566
gpu_array,256,8,1,50,4,true,false,true,false,-90.6473,0.306387
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-107.978,0.363201
gpu_sparse,256,8,1,50,2,true,false,true,false,-108.048,0.363907
gpu_sparse,256,8,1,50,4,true,false,true,false,-108.009,0.363889
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-88.0166,0.297561
gpu_reorg,256,8,1,50,2,true,false,true,false,-97.2818,0.32815
gpu_reorg,256,8,1,50,4,true,false,true,false,-97.3895,0.32814
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-65.62,0.223148
gpu_array,256,32,1,20,2,true,false,true,false,-52.5413,0.178002
gpu_array,256,32,1,20,4,true,false,true,false,-53.302,0.180168
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-68.2363,0.230222
gpu_sparse,256,32,1,20,2,true,false,true,false,-59.1297,0.201179
gpu_sparse,256,32,1,20,4,true,false,true,false,-60.0992,0.203827
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-85.0475,0.286174
gpu_reorg,256,32,1,20,2,true,false,true,false,-70.1187,0.236784
gpu_reorg,256,32,1,20,4,true,false,true,false,-71.4591,0.241747
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-52.426,0.178331
0.178331
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-64.9673,0.219682
0.219682
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,true,-67.2088,0.225897
0.225897
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,true,-66.1862,0.224519
0.224519
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-81.2217,0.273228
0.273228
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-80.4871,0.272386
0.272386
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	256
Best kernel execution time: 0.178002
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 18 seconds of which 1.33317 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-1158.22,3.87815
gpu_array,256,8,1,20,2,true,false,true,false,-639.282,2.1426
gpu_array,256,8,1,20,4,true,false,true,false,-414.234,1.39501
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-1134.85,3.80361
gpu_sparse,256,8,1,20,2,true,false,true,false,-641.156,2.14869
gpu_sparse,256,8,1,20,4,true,false,true,false,-443.775,1.49693
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-1115.24,3.73441
gpu_reorg,256,8,1,20,2,true,false,true,false,-601.977,2.01655
gpu_reorg,256,8,1,20,4,true,false,true,false,-683.121,2.28915
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-563.31,1.88778
gpu_array,256,8,1,50,2,true,false,true,false,-366.244,1.24029
gpu_array,256,8,1,50,4,true,false,true,false,-461.252,1.55056
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-571.653,1.92004
gpu_sparse,256,8,1,50,2,true,false,true,false,-424.001,1.43216
gpu_sparse,256,8,1,50,4,true,false,true,false,-473.903,1.59437
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-648.346,2.17396
gpu_reorg,256,8,1,50,2,true,false,true,false,-314.69,1.06802
gpu_reorg,256,8,1,50,4,true,false,true,false,-393.674,1.32902
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,true,false,true,true,-410.469,1.18703
1.18703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,false,false,true,true,-587.638,1.96948
1.96948
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,true,false,true,true,-562.243,1.88521
1.88521
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,false,false,true,true,-1506.37,5.04582
5.04582
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 1.06802
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 80 seconds of which 7.2482 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-1157.33,3.87543
gpu_array,256,8,1,20,2,true,false,true,false,-639.253,2.14169
gpu_array,256,8,1,20,4,true,false,true,false,-413.191,1.39259
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-1134.74,3.80301
gpu_sparse,256,8,1,20,2,true,false,true,false,-641.659,2.14963
gpu_sparse,256,8,1,20,4,true,false,true,false,-444.228,1.49656
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-1115.34,3.73452
gpu_reorg,256,8,1,20,2,true,false,true,false,-601.352,2.01463
gpu_reorg,256,8,1,20,4,true,false,true,false,-682.719,2.28807
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-562.539,1.88634
gpu_array,256,8,1,50,2,true,false,true,false,-366.552,1.24032
gpu_array,256,8,1,50,4,true,false,true,false,-459.45,1.54899
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-571.527,1.9206
gpu_sparse,256,8,1,50,2,true,false,true,false,-424.677,1.43392
gpu_sparse,256,8,1,50,4,true,false,true,false,-473.971,1.59517
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-648.62,2.17332
gpu_reorg,256,8,1,50,2,true,false,true,false,-314.669,1.06826
gpu_reorg,256,8,1,50,4,true,false,true,false,-394.085,1.33028
256 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
256 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,true,false,true,true,-413.404,1.19341
1.19341
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,50,2,false,false,true,true,-587.693,1.96952
1.96952
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,true,false,true,true,-562.457,1.88551
1.88551
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,256,8,1,20,2,false,false,true,true,-1507.09,5.04632
5.04632
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	256
Best kernel execution time: 1.06826
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 80 seconds of which 7.24809 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-337.987,1.14137
gpu_array,256,8,1,20,2,true,false,true,false,-362.872,1.22532
gpu_array,256,8,1,20,4,true,false,true,false,-388.613,1.31357
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-334.31,1.1304
gpu_sparse,256,8,1,20,2,true,false,true,false,-428.449,1.44899
gpu_sparse,256,8,1,20,4,true,false,true,false,-445.138,1.5018
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-439.568,1.48153
gpu_reorg,256,8,1,20,2,true,false,true,false,-354.695,1.20536
gpu_reorg,256,8,1,20,4,true,false,true,false,-479.145,1.60822
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-556.015,1.86487
gpu_array,256,8,1,50,2,true,false,true,false,-451.548,1.52709
gpu_array,256,8,1,50,4,true,false,true,false,-592.522,1.98955
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-547.717,1.83502
gpu_sparse,256,8,1,50,2,true,false,true,false,-518.716,1.74632
gpu_sparse,256,8,1,50,4,true,false,true,false,-628.864,2.10961
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-648.81,2.17146
gpu_reorg,256,8,1,50,2,true,false,true,false,-451.519,1.51884
gpu_reorg,256,8,1,50,4,true,false,true,false,-801.442,2.68185
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-558.193,1.86916
gpu_array,256,32,1,20,2,true,false,true,false,-420.134,1.40804
gpu_array,256,32,1,20,4,true,false,true,false,-329.5,1.10984
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-537.984,1.80101
gpu_sparse,256,32,1,20,2,true,false,true,false,-424.376,1.42072
gpu_sparse,256,32,1,20,4,true,false,true,false,-346.416,1.16866
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-604.23,2.02291
gpu_reorg,256,32,1,20,2,true,false,true,false,-443.444,1.49143
gpu_reorg,256,32,1,20,4,true,false,true,false,-462.507,1.5523
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-367.128,1.2293
1.2293
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-546.092,1.82823
1.82823
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-311.447,1.04784
1.04784
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-324.08,1.09811
1.09811
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-351.995,1.18643
1.18643
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-415.67,1.4044
1.4044
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 1.04784
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 79 seconds of which 7.85503 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
covtype 54 800 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-338.626,1.14563
gpu_array,256,8,1,20,2,true,false,true,false,-363.078,1.22769
gpu_array,256,8,1,20,4,true,false,true,false,-388.913,1.31434
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-334.841,1.12911
gpu_sparse,256,8,1,20,2,true,false,true,false,-428.918,1.44963
gpu_sparse,256,8,1,20,4,true,false,true,false,-444.727,1.49853
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-439.871,1.48151
gpu_reorg,256,8,1,20,2,true,false,true,false,-354.396,1.20459
gpu_reorg,256,8,1,20,4,true,false,true,false,-479.07,1.60831
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-555.972,1.86468
gpu_array,256,8,1,50,2,true,false,true,false,-451.746,1.52706
gpu_array,256,8,1,50,4,true,false,true,false,-593.103,1.99177
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-547.346,1.83299
gpu_sparse,256,8,1,50,2,true,false,true,false,-519.164,1.74401
gpu_sparse,256,8,1,50,4,true,false,true,false,-627.93,2.10838
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-648.944,2.1718
gpu_reorg,256,8,1,50,2,true,false,true,false,-448.721,1.51539
gpu_reorg,256,8,1,50,4,true,false,true,false,-800.898,2.68007
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-558.071,1.86817
gpu_array,256,32,1,20,2,true,false,true,false,-420.189,1.40782
gpu_array,256,32,1,20,4,true,false,true,false,-328.878,1.10825
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-538.069,1.80083
gpu_sparse,256,32,1,20,2,true,false,true,false,-424.367,1.42258
gpu_sparse,256,32,1,20,4,true,false,true,false,-346.097,1.16711
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-604.688,2.02387
gpu_reorg,256,32,1,20,2,true,false,true,false,-442.294,1.489
gpu_reorg,256,32,1,20,4,true,false,true,false,-462.686,1.55376
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,true,false,true,true,-366.83,1.22846
1.22846
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,32,1,20,4,false,false,true,true,-545.916,1.82806
1.82806
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-310.542,1.04615
1.04615
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-324.702,1.09726
1.09726
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-352.257,1.18703
1.18703
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-415.386,1.40259
1.40259
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	256
Best kernel execution time: 1.04615
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 79 seconds of which 7.85302 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,-417.629,1.40802
gpu_array,256,8,1,20,2,false,false,true,false,-402.706,1.3591
gpu_array,256,8,1,20,4,false,false,true,false,-385.249,1.30017
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,-429.127,1.44699
gpu_sparse,256,8,1,20,2,false,false,true,false,-413.175,1.3933
gpu_sparse,256,8,1,20,4,false,false,true,false,-386.531,1.30563
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,-496.053,1.67181
gpu_reorg,256,8,1,20,2,false,false,true,false,-442.354,1.49108
gpu_reorg,256,8,1,20,4,false,false,true,false,-412.021,1.38986
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,-224.785,0.763125
gpu_array,256,8,1,50,2,false,false,true,false,-229.428,0.780308
gpu_array,256,8,1,50,4,false,false,true,false,-229.581,0.780312
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,-232.468,0.791635
gpu_sparse,256,8,1,50,2,false,false,true,false,-261.957,0.89168
gpu_sparse,256,8,1,50,4,false,false,true,false,-262.175,0.891547
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,-236.701,0.805569
gpu_reorg,256,8,1,50,2,false,false,true,false,-232.024,0.789152
gpu_reorg,256,8,1,50,4,false,false,true,false,-232.473,0.789991
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,-348.529,1.17725
gpu_array,256,32,1,20,2,false,false,true,false,-322.467,1.08972
gpu_array,256,32,1,20,4,false,false,true,false,-328.01,1.10949
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,-354.504,1.19732
gpu_sparse,256,32,1,20,2,false,false,true,false,-331.579,1.12199
gpu_sparse,256,32,1,20,4,false,false,true,false,-348.07,1.17649
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,-389.198,1.31441
gpu_reorg,256,32,1,20,2,false,false,true,false,-361.287,1.22131
gpu_reorg,256,32,1,20,4,false,false,true,false,-364.41,1.23021
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-213.848,0.727381
0.727381
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-318.799,1.07732
1.07732
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-306.316,1.03828
1.03828
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.727381
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 45 seconds of which 5.15028 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,false,false,false,false,-417.454,1.4075
gpu_array,256,8,1,20,2,false,false,true,false,-403.113,1.35995
gpu_array,256,8,1,20,4,false,false,true,false,-384.867,1.30016
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,false,false,false,false,-428.661,1.44566
gpu_sparse,256,8,1,20,2,false,false,true,false,-413.385,1.39447
gpu_sparse,256,8,1,20,4,false,false,true,false,-387.127,1.30588
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,false,false,false,false,-496.207,1.67074
gpu_reorg,256,8,1,20,2,false,false,true,false,-441.548,1.49008
gpu_reorg,256,8,1,20,4,false,false,true,false,-411.89,1.38933
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,false,false,false,false,-224.45,0.763223
gpu_array,256,8,1,50,2,false,false,true,false,-229.584,0.780481
gpu_array,256,8,1,50,4,false,false,true,false,-229.633,0.781102
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,false,false,false,false,-232.372,0.789538
gpu_sparse,256,8,1,50,2,false,false,true,false,-261.79,0.891242
gpu_sparse,256,8,1,50,4,false,false,true,false,-262.131,0.890905
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,false,false,false,false,-237.143,0.805789
gpu_reorg,256,8,1,50,2,false,false,true,false,-232.414,0.790094
gpu_reorg,256,8,1,50,4,false,false,true,false,-232.58,0.790305
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,false,false,false,false,-348.479,1.17673
gpu_array,256,32,1,20,2,false,false,true,false,-321.651,1.08882
gpu_array,256,32,1,20,4,false,false,true,false,-327.808,1.1091
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,false,false,false,false,-354.952,1.19854
gpu_sparse,256,32,1,20,2,false,false,true,false,-332.321,1.12239
gpu_sparse,256,32,1,20,4,false,false,true,false,-348.422,1.1777
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,false,false,false,false,-390.213,1.31663
gpu_reorg,256,32,1,20,2,false,false,true,false,-361.794,1.22267
gpu_reorg,256,32,1,20,4,false,false,true,false,-363.944,1.22961
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-213.849,0.727753
0.727753
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-318.333,1.07721
1.07721
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,256,8,1,20,4,false,false,true,true,-307.267,1.0383
1.0383
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	256
Best kernel execution time: 0.727753
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 45 seconds of which 5.1505 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-67.7035,0.229538
gpu_array,256,8,1,20,2,true,false,true,false,-64.0207,0.216429
gpu_array,256,8,1,20,4,true,false,true,false,-64.344,0.217373
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-85.2589,0.289113
gpu_sparse,256,8,1,20,2,true,false,true,false,-76.7132,0.259475
gpu_sparse,256,8,1,20,4,true,false,true,false,-76.3237,0.257812
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-74.6763,0.251736
gpu_reorg,256,8,1,20,2,true,false,true,false,-73.2476,0.24789
gpu_reorg,256,8,1,20,4,true,false,true,false,-74.0047,0.250892
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-88.2345,0.296739
gpu_array,256,8,1,50,2,true,false,true,false,-85.5688,0.288306
gpu_array,256,8,1,50,4,true,false,true,false,-85.4431,0.28847
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-105.691,0.356124
gpu_sparse,256,8,1,50,2,true,false,true,false,-98.6264,0.332868
gpu_sparse,256,8,1,50,4,true,false,true,false,-98.878,0.332931
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-95.1289,0.318125
gpu_reorg,256,8,1,50,2,true,false,true,false,-100.995,0.340824
gpu_reorg,256,8,1,50,4,true,false,true,false,-101.072,0.341406
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-71.5933,0.242108
gpu_array,256,32,1,20,2,true,false,true,false,-60.6101,0.205167
gpu_array,256,32,1,20,4,true,false,true,false,-62.0381,0.210239
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-75.7642,0.256425
gpu_sparse,256,32,1,20,2,true,false,true,false,-67.6488,0.22951
gpu_sparse,256,32,1,20,4,true,false,true,false,-69.5438,0.23518
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-101.357,0.341911
gpu_reorg,256,32,1,20,2,true,false,true,false,-89.3625,0.301021
gpu_reorg,256,32,1,20,4,true,false,true,false,-90.3111,0.303854
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-60.1746,0.204284
0.204284
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-76.7948,0.260471
0.260471
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,true,-62.4277,0.211809
0.211809
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,true,-65.3365,0.222108
0.222108
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,true,false,true,true,-66.521,0.22563
0.22563
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,2,false,false,true,true,-71.9334,0.242392
0.242392
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.204284
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 18 seconds of which 1.35293 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-93.9987,0.304291
gpu_array,256,8,1,20,2,true,false,true,false,-63.1074,0.215137
gpu_array,256,8,1,20,4,true,false,true,false,-63.9473,0.2173
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-85.5788,0.288415
gpu_sparse,256,8,1,20,2,true,false,true,false,-76.7666,0.25958
gpu_sparse,256,8,1,20,4,true,false,true,false,-75.9826,0.25732
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-74.6607,0.251688
gpu_reorg,256,8,1,20,2,true,false,true,false,-73.4839,0.248845
gpu_reorg,256,8,1,20,4,true,false,true,false,-74.2219,0.251824
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-88.7451,0.298978
gpu_array,256,8,1,50,2,true,false,true,false,-85.5522,0.288765
gpu_array,256,8,1,50,4,true,false,true,false,-85.5584,0.288661
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-105.91,0.356972
gpu_sparse,256,8,1,50,2,true,false,true,false,-98.5075,0.331743
gpu_sparse,256,8,1,50,4,true,false,true,false,-98.5587,0.332456
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-93.9329,0.316498
gpu_reorg,256,8,1,50,2,true,false,true,false,-100.979,0.340325
gpu_reorg,256,8,1,50,4,true,false,true,false,-100.869,0.340638
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-71.4481,0.242214
gpu_array,256,32,1,20,2,true,false,true,false,-60.2855,0.204447
gpu_array,256,32,1,20,4,true,false,true,false,-61.9702,0.210071
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-75.9535,0.255769
gpu_sparse,256,32,1,20,2,true,false,true,false,-67.7626,0.229075
gpu_sparse,256,32,1,20,4,true,false,true,false,-69.2693,0.234614
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-101.843,0.342972
gpu_reorg,256,32,1,20,2,true,false,true,false,-89.3357,0.299298
gpu_reorg,256,32,1,20,4,true,false,true,false,-89.9788,0.303557
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,true,false,true,true,-60.2648,0.204492
0.204492
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,32,1,20,2,false,false,true,true,-77.1315,0.260829
0.260829
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,true,false,true,true,-62.311,0.211921
0.211921
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,20,2,false,false,true,true,-66.3037,0.223664
0.223664
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,true,false,true,true,-66.7921,0.226293
0.226293
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,256,8,1,50,4,false,false,true,true,-72.3107,0.244004
0.244004
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	256
Best kernel execution time: 0.204447
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 18 seconds of which 1.36438 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-1768.21,71.87
gpu_array,256,8,1,20,2,true,false,true,false,-2015.29,81.2808
gpu_array,256,8,1,20,4,true,false,true,false,-2110,85.2464
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-1735.77,70.2507
gpu_sparse,256,8,1,20,2,true,false,true,false,-2316.43,93.8771
gpu_sparse,256,8,1,20,4,true,false,true,false,-2367.03,96.3916
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-2772.9,113.652
gpu_reorg,256,8,1,20,2,true,false,true,false,-2917.1,118.731
gpu_reorg,256,8,1,20,4,true,false,true,false,-3692.16,150.885
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-3364.77,138.999
gpu_array,256,8,1,50,2,true,false,true,false,-2574.18,104.993
gpu_array,256,8,1,50,4,true,false,true,false,-3820.13,157.041
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-2817.8,115.75
gpu_sparse,256,8,1,50,2,true,false,true,false,-2639.72,107.719
gpu_sparse,256,8,1,50,4,true,false,true,false,-3917.86,161.403
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-4249.01,176.456
gpu_reorg,256,8,1,50,2,true,false,true,false,-10002.6,412.487
gpu_reorg,256,8,1,50,4,true,false,true,false,-9859.69,407.67
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-1949.08,79.1074
gpu_array,256,32,1,20,2,true,false,true,false,-1824.94,73.9671
gpu_array,256,32,1,20,4,true,false,true,false,-1766.21,71.5229
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-1770.64,70.8625
gpu_sparse,256,32,1,20,2,true,false,true,false,-1787.21,72.1331
gpu_sparse,256,32,1,20,4,true,false,true,false,-1785.44,72.3462
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-2156.53,87.5006
gpu_reorg,256,32,1,20,2,true,false,true,false,-4327.22,179.435
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,-1323.07,52.5598
52.5598
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,-1337.48,53.6351
53.6351
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,true,false,true,true,-3150.9,129.497
129.497
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,false,false,true,true,-3495.47,143.231
143.231
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 52.5598
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 595 seconds of which 48.0064 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-1753,71.6059
gpu_array,256,8,1,20,2,true,false,true,false,-2026.95,81.6766
gpu_array,256,8,1,20,4,true,false,true,false,-2083.58,84.6245
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-1743.57,70.5929
gpu_sparse,256,8,1,20,2,true,false,true,false,-2296.91,93.3315
gpu_sparse,256,8,1,20,4,true,false,true,false,-2365.21,96.3933
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-2751.55,113.451
gpu_reorg,256,8,1,20,2,true,false,true,false,-2911.54,118.531
gpu_reorg,256,8,1,20,4,true,false,true,false,-3653.45,150.29
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-3352.19,138.872
gpu_array,256,8,1,50,2,true,false,true,false,-2589.33,105.263
gpu_array,256,8,1,50,4,true,false,true,false,-3796.9,156.444
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-2808.81,115.711
gpu_sparse,256,8,1,50,2,true,false,true,false,-2651.49,108.003
gpu_sparse,256,8,1,50,4,true,false,true,false,-3921.14,161.547
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-4241.73,176.275
gpu_reorg,256,8,1,50,2,true,false,true,false,-9714.57,404.545
gpu_reorg,256,8,1,50,4,true,false,true,false,-9866.59,409.78
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-1958.54,79.4741
gpu_array,256,32,1,20,2,true,false,true,false,-1814.87,73.565
gpu_array,256,32,1,20,4,true,false,true,false,-1776.25,71.9382
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-1766.85,70.8166
gpu_sparse,256,32,1,20,2,true,false,true,false,-1774.99,71.867
gpu_sparse,256,32,1,20,4,true,false,true,false,-1812.89,73.0027
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-2161.52,87.7188
gpu_reorg,256,32,1,20,2,true,false,true,false,-4340.62,179.826
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,256,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,true,false,false,true,-1298.65,52.0589
52.0589
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,20,-1,false,false,false,true,-1345.35,53.8078
53.8078
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,true,false,true,true,-3182.96,130.156
130.156
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,256,8,1,50,2,false,false,true,true,-3470.29,142.567
142.567
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	256
Best kernel execution time: 52.0589
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 595 seconds of which 47.9198 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-63.31,0.215154
gpu_array,256,8,1,20,2,true,false,true,false,-97.3182,0.327474
gpu_array,256,8,1,20,4,true,false,true,false,-97.289,0.325366
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-75.819,0.256889
gpu_sparse,256,8,1,20,2,true,false,true,false,-113.599,0.379543
gpu_sparse,256,8,1,20,4,true,false,true,false,-111.881,0.377454
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-74.8186,0.252306
gpu_reorg,256,8,1,20,2,true,false,true,false,-121.583,0.409449
gpu_reorg,256,8,1,20,4,true,false,true,false,-184.426,0.55315
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-86.8739,0.292348
gpu_array,256,8,1,50,2,true,false,true,false,-185.126,0.6231
gpu_array,256,8,1,50,4,true,false,true,false,-185.779,0.623873
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-96.1872,0.324529
gpu_sparse,256,8,1,50,2,true,false,true,false,-184.399,0.618717
gpu_sparse,256,8,1,50,4,true,false,true,false,-184.154,0.618641
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-95.0243,0.320592
gpu_reorg,256,8,1,50,2,true,false,true,false,-190.166,0.636923
gpu_reorg,256,8,1,50,4,true,false,true,false,-189.592,0.636483
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-65.4641,0.221772
gpu_array,256,32,1,20,2,true,false,true,false,-76.1295,0.257182
gpu_array,256,32,1,20,4,true,false,true,false,-83.5862,0.281017
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-65.4619,0.22393
gpu_sparse,256,32,1,20,2,true,false,true,false,-75.9795,0.25764
gpu_sparse,256,32,1,20,4,true,false,true,false,-79.2644,0.268008
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-86.194,0.291529
gpu_reorg,256,32,1,20,2,true,false,true,false,-95.2336,0.321688
gpu_reorg,256,32,1,20,4,true,false,true,false,-121.588,0.400935
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-59.1743,0.1996
0.1996
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-73.1403,0.245841
0.245841
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,true,false,false,true,-62.9751,0.2141
0.2141
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,false,false,false,true,-81.3396,0.274194
0.274194
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-71.7129,0.242435
0.242435
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-80.5727,0.272141
0.272141
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.1996
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 39 seconds of which 1.80695 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
256 8 1 20 gpu_array
gpu_array,256,8,1,20,-1,true,false,false,false,-106.409,0.293686
gpu_array,256,8,1,20,2,true,false,true,false,-96.9345,0.327189
gpu_array,256,8,1,20,4,true,false,true,false,-95.6955,0.322345
256 8 1 20 gpu_sparse
gpu_sparse,256,8,1,20,-1,true,false,false,false,-75.8926,0.256965
gpu_sparse,256,8,1,20,2,true,false,true,false,-112.13,0.377586
gpu_sparse,256,8,1,20,4,true,false,true,false,-112.41,0.377851
256 8 1 20 gpu_reorg
gpu_reorg,256,8,1,20,-1,true,false,false,false,-75.7192,0.254026
gpu_reorg,256,8,1,20,2,true,false,true,false,-121.686,0.409184
gpu_reorg,256,8,1,20,4,true,false,true,false,-144.731,0.485659
256 8 1 50 gpu_array
gpu_array,256,8,1,50,-1,true,false,false,false,-86.5643,0.292242
gpu_array,256,8,1,50,2,true,false,true,false,-185.962,0.624797
gpu_array,256,8,1,50,4,true,false,true,false,-186.184,0.624572
256 8 1 50 gpu_sparse
gpu_sparse,256,8,1,50,-1,true,false,false,false,-97.2644,0.326596
gpu_sparse,256,8,1,50,2,true,false,true,false,-184.222,0.618588
gpu_sparse,256,8,1,50,4,true,false,true,false,-183.891,0.61805
256 8 1 50 gpu_reorg
gpu_reorg,256,8,1,50,-1,true,false,false,false,-95.1013,0.320584
gpu_reorg,256,8,1,50,2,true,false,true,false,-189.982,0.639275
gpu_reorg,256,8,1,50,4,true,false,true,false,-190.241,0.639743
256 32 1 20 gpu_array
gpu_array,256,32,1,20,-1,true,false,false,false,-65.455,0.221932
gpu_array,256,32,1,20,2,true,false,true,false,-77.0769,0.261253
gpu_array,256,32,1,20,4,true,false,true,false,-84.1422,0.283573
256 32 1 20 gpu_sparse
gpu_sparse,256,32,1,20,-1,true,false,false,false,-66.3585,0.224628
gpu_sparse,256,32,1,20,2,true,false,true,false,-76.6709,0.258798
gpu_sparse,256,32,1,20,4,true,false,true,false,-79.6893,0.268845
256 32 1 20 gpu_reorg
gpu_reorg,256,32,1,20,-1,true,false,false,false,-86.6006,0.295648
gpu_reorg,256,32,1,20,2,true,false,true,false,-96.0099,0.323782
gpu_reorg,256,32,1,20,4,true,false,true,false,-113.27,0.381485
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,true,false,false,true,-63.5045,0.215931
0.215931
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,32,1,20,-1,false,false,false,true,-81.5873,0.275448
0.275448
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,true,false,false,true,-72.293,0.243789
0.243789
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,50,-1,false,false,false,true,-81.1663,0.274516
0.274516
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,true,false,false,true,-58.735,0.200827
0.200827
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,256,8,1,20,-1,false,false,false,true,-73.2419,0.246336
0.246336
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	256
Best kernel execution time: 0.200827
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 38 seconds of which 1.81029 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-349.5,1.17938
gpu_array,512,8,1,20,2,true,false,true,false,-297.529,1.00715
gpu_array,512,8,1,20,4,true,false,true,false,-284.462,0.965149
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-384.651,1.29774
gpu_sparse,512,8,1,20,2,true,false,true,false,-372.543,1.26477
gpu_sparse,512,8,1,20,4,true,false,true,false,-362.174,1.23374
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-428.823,1.44714
gpu_reorg,512,8,1,20,2,true,false,true,false,-295.669,1.00895
gpu_reorg,512,8,1,20,4,true,false,true,false,-286.478,0.96693
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-439.628,1.47737
gpu_array,512,8,1,50,2,true,false,true,false,-334.712,1.13788
gpu_array,512,8,1,50,4,true,false,true,false,-336.618,1.1493
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-461.493,1.55177
gpu_sparse,512,8,1,50,2,true,false,true,false,-428.151,1.44998
gpu_sparse,512,8,1,50,4,true,false,true,false,-427.629,1.45007
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-631.676,2.11428
gpu_reorg,512,8,1,50,2,true,false,true,false,-344.327,1.17478
gpu_reorg,512,8,1,50,4,true,false,true,false,-358.114,1.2125
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-439.47,1.47444
gpu_array,512,32,1,20,2,true,false,true,false,-261.592,0.87718
gpu_array,512,32,1,20,4,true,false,true,false,-245.354,0.822198
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-440.597,1.47481
gpu_sparse,512,32,1,20,2,true,false,true,false,-283.127,0.949569
gpu_sparse,512,32,1,20,4,true,false,true,false,-273.874,0.918313
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-594.875,1.99178
gpu_reorg,512,32,1,20,2,true,false,true,false,-337.914,1.14252
gpu_reorg,512,32,1,20,4,true,false,true,false,-354.129,1.19477
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-244.97,0.820335
0.820335
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-269.257,0.903652
0.903652
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-279.194,0.947429
0.947429
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-310.095,1.05667
1.05667
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-311.629,1.05593
1.05593
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-321.095,1.08903
1.08903
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.820335
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 52 seconds of which 12.2289 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-349.425,1.18042
gpu_array,512,8,1,20,2,true,false,true,false,-298.287,1.00886
gpu_array,512,8,1,20,4,true,false,true,false,-284.272,0.966096
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-385.725,1.30075
gpu_sparse,512,8,1,20,2,true,false,true,false,-373.229,1.2675
gpu_sparse,512,8,1,20,4,true,false,true,false,-362.407,1.2359
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-430.401,1.44778
gpu_reorg,512,8,1,20,2,true,false,true,false,-297.659,1.01149
gpu_reorg,512,8,1,20,4,true,false,true,false,-286.68,0.968962
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-439.73,1.47876
gpu_array,512,8,1,50,2,true,false,true,false,-334.83,1.13812
gpu_array,512,8,1,50,4,true,false,true,false,-338.662,1.15072
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-461.687,1.55348
gpu_sparse,512,8,1,50,2,true,false,true,false,-428.429,1.451
gpu_sparse,512,8,1,50,4,true,false,true,false,-426.807,1.45076
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-632.223,2.11663
gpu_reorg,512,8,1,50,2,true,false,true,false,-344.542,1.17575
gpu_reorg,512,8,1,50,4,true,false,true,false,-358.231,1.21349
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-439.207,1.47406
gpu_array,512,32,1,20,2,true,false,true,false,-262.109,0.880564
gpu_array,512,32,1,20,4,true,false,true,false,-245.156,0.822021
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-440.522,1.47578
gpu_sparse,512,32,1,20,2,true,false,true,false,-283.098,0.950336
gpu_sparse,512,32,1,20,4,true,false,true,false,-273.852,0.918393
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-594.539,1.9914
gpu_reorg,512,32,1,20,2,true,false,true,false,-337.834,1.1434
gpu_reorg,512,32,1,20,4,true,false,true,false,-354.275,1.19475
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-244.92,0.820761
0.820761
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-270.111,0.904818
0.904818
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-279.873,0.946723
0.946723
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-309.988,1.05674
1.05674
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-311.617,1.05613
1.05613
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-320.675,1.09034
1.09034
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	512
Best kernel execution time: 0.820761
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 52 seconds of which 12.2397 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-60.6524,0.20505
gpu_array,512,8,1,20,2,true,false,true,false,-55.7496,0.188513
gpu_array,512,8,1,20,4,true,false,true,false,-55.1372,0.188293
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-72.4693,0.244261
gpu_sparse,512,8,1,20,2,true,false,true,false,-69.7976,0.235588
gpu_sparse,512,8,1,20,4,true,false,true,false,-69.061,0.23328
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-63.0604,0.212383
gpu_reorg,512,8,1,20,2,true,false,true,false,-57.4644,0.19574
gpu_reorg,512,8,1,20,4,true,false,true,false,-58.2508,0.198454
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-80.8482,0.270966
gpu_array,512,8,1,50,2,true,false,true,false,-72.3521,0.243624
gpu_array,512,8,1,50,4,true,false,true,false,-72.4317,0.2434
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-97.8437,0.328815
gpu_sparse,512,8,1,50,2,true,false,true,false,-95.8311,0.32194
gpu_sparse,512,8,1,50,4,true,false,true,false,-95.8648,0.322094
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-78.4045,0.264116
gpu_reorg,512,8,1,50,2,true,false,true,false,-78.809,0.267188
gpu_reorg,512,8,1,50,4,true,false,true,false,-78.6791,0.26489
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-45.4121,0.153698
gpu_array,512,32,1,20,2,true,false,true,false,-35.2808,0.123483
gpu_array,512,32,1,20,4,true,false,true,false,-35.643,0.121305
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-46.3417,0.156974
gpu_sparse,512,32,1,20,2,true,false,true,false,-40.1076,0.135892
gpu_sparse,512,32,1,20,4,true,false,true,false,-40.734,0.137696
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-60.1319,0.202714
gpu_reorg,512,32,1,20,2,true,false,true,false,-48.5805,0.16497
gpu_reorg,512,32,1,20,4,true,false,true,false,-49.2657,0.167263
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-34.8706,0.118362
0.118362
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-44.1829,0.14974
0.14974
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-54.0551,0.183214
0.183214
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-55.3054,0.188703
0.188703
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,-57.2243,0.194347
0.194347
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,-60.0366,0.20363
0.20363
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.118362
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 16 seconds of which 2.09836 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-71.3244,0.242033
gpu_array,512,8,1,20,2,true,false,true,false,-55.6837,0.188659
gpu_array,512,8,1,20,4,true,false,true,false,-55.7211,0.188413
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-72.5271,0.244362
gpu_sparse,512,8,1,20,2,true,false,true,false,-69.9825,0.236229
gpu_sparse,512,8,1,20,4,true,false,true,false,-69.1551,0.234234
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-62.729,0.211066
gpu_reorg,512,8,1,20,2,true,false,true,false,-58.1829,0.196611
gpu_reorg,512,8,1,20,4,true,false,true,false,-58.6415,0.199633
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-80.7234,0.271373
gpu_array,512,8,1,50,2,true,false,true,false,-72.5932,0.243426
gpu_array,512,8,1,50,4,true,false,true,false,-72.0848,0.244622
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-98.0325,0.329474
gpu_sparse,512,8,1,50,2,true,false,true,false,-95.9684,0.323872
gpu_sparse,512,8,1,50,4,true,false,true,false,-96.1451,0.323008
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-78.7724,0.265382
gpu_reorg,512,8,1,50,2,true,false,true,false,-79.4279,0.267395
gpu_reorg,512,8,1,50,4,true,false,true,false,-79.0499,0.265846
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-45.8371,0.155106
gpu_array,512,32,1,20,2,true,false,true,false,-35.2606,0.120928
gpu_array,512,32,1,20,4,true,false,true,false,-35.584,0.121698
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-46.4342,0.157637
gpu_sparse,512,32,1,20,2,true,false,true,false,-40.2915,0.136196
gpu_sparse,512,32,1,20,4,true,false,true,false,-40.8526,0.138271
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-60.2982,0.205065
gpu_reorg,512,32,1,20,2,true,false,true,false,-48.9682,0.165933
gpu_reorg,512,32,1,20,4,true,false,true,false,-49.4499,0.16861
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,true,-35.0084,0.119167
0.119167
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,true,-44.5172,0.151383
0.151383
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-54.4575,0.184393
0.184393
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-55.7693,0.189715
0.189715
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-58.1085,0.196227
0.196227
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-60.4051,0.204881
0.204881
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	512
Best kernel execution time: 0.119167
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 16 seconds of which 2.11687 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-1149.64,3.84828
gpu_array,512,8,1,20,2,true,false,true,false,-629.205,2.10783
gpu_array,512,8,1,20,4,true,false,true,false,-401.528,1.35497
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-1126.78,3.77348
gpu_sparse,512,8,1,20,2,true,false,true,false,-630.859,2.11371
gpu_sparse,512,8,1,20,4,true,false,true,false,-427.256,1.44097
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-1071.85,3.58977
gpu_reorg,512,8,1,20,2,true,false,true,false,-573.894,1.92454
gpu_reorg,512,8,1,20,4,true,false,true,false,-650.545,2.18052
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-547.011,1.8369
gpu_array,512,8,1,50,2,true,false,true,false,-350.174,1.18446
gpu_array,512,8,1,50,4,true,false,true,false,-394.412,1.33107
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-558.549,1.87878
gpu_sparse,512,8,1,50,2,true,false,true,false,-403.368,1.36496
gpu_sparse,512,8,1,50,4,true,false,true,false,-410.188,1.38469
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-611.294,2.04924
gpu_reorg,512,8,1,50,2,true,false,true,false,-296.14,1.00434
gpu_reorg,512,8,1,50,4,true,false,true,false,-373.91,1.26547
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,-417.202,1.17306
1.17306
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,-545.519,1.84482
1.84482
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,true,false,true,true,-534.936,1.79454
1.79454
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,false,false,true,true,-1385.68,4.63992
4.63992
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 1.00434
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 72 seconds of which 13.8505 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-1144.58,3.83118
gpu_array,512,8,1,20,2,true,false,true,false,-626.756,2.10174
gpu_array,512,8,1,20,4,true,false,true,false,-401.93,1.35375
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-1126.61,3.773
gpu_sparse,512,8,1,20,2,true,false,true,false,-630.857,2.11275
gpu_sparse,512,8,1,20,4,true,false,true,false,-427.15,1.43991
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-1072.1,3.59073
gpu_reorg,512,8,1,20,2,true,false,true,false,-573.989,1.92456
gpu_reorg,512,8,1,20,4,true,false,true,false,-650.649,2.18145
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-547.05,1.83617
gpu_array,512,8,1,50,2,true,false,true,false,-350.55,1.18478
gpu_array,512,8,1,50,4,true,false,true,false,-394.683,1.33105
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-558.474,1.87979
gpu_sparse,512,8,1,50,2,true,false,true,false,-402.829,1.36397
gpu_sparse,512,8,1,50,4,true,false,true,false,-410.018,1.38359
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-610.36,2.04715
gpu_reorg,512,8,1,50,2,true,false,true,false,-296.174,1.00416
gpu_reorg,512,8,1,50,4,true,false,true,false,-373.702,1.26509
512 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
512 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,true,false,true,true,-411.964,1.16308
1.16308
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,-544.658,1.84043
1.84043
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,true,false,true,true,-534.806,1.79319
1.79319
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,512,8,1,20,2,false,false,true,true,-1385.11,4.63906
4.63906
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	512
Best kernel execution time: 1.00416
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 71 seconds of which 13.8365 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-335.706,1.13266
gpu_array,512,8,1,20,2,true,false,true,false,-357.443,1.20594
gpu_array,512,8,1,20,4,true,false,true,false,-381.951,1.29177
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-334.617,1.12918
gpu_sparse,512,8,1,20,2,true,false,true,false,-405.138,1.36827
gpu_sparse,512,8,1,20,4,true,false,true,false,-428.378,1.44636
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-439.725,1.48296
gpu_reorg,512,8,1,20,2,true,false,true,false,-338.426,1.14771
gpu_reorg,512,8,1,20,4,true,false,true,false,-367.226,1.24524
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-537.547,1.80692
gpu_array,512,8,1,50,2,true,false,true,false,-449.672,1.51824
gpu_array,512,8,1,50,4,true,false,true,false,-596.167,1.99805
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-534.299,1.79276
gpu_sparse,512,8,1,50,2,true,false,true,false,-535.039,1.80998
gpu_sparse,512,8,1,50,4,true,false,true,false,-625.216,2.09655
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-630.05,2.10849
gpu_reorg,512,8,1,50,2,true,false,true,false,-431.755,1.46341
gpu_reorg,512,8,1,50,4,true,false,true,false,-756.337,2.53046
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-419.819,1.41485
gpu_array,512,32,1,20,2,true,false,true,false,-323.942,1.09775
gpu_array,512,32,1,20,4,true,false,true,false,-264.523,0.886485
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-403.748,1.35836
gpu_sparse,512,32,1,20,2,true,false,true,false,-328.048,1.11037
gpu_sparse,512,32,1,20,4,true,false,true,false,-279.747,0.940299
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-510.185,1.70699
gpu_reorg,512,32,1,20,2,true,false,true,false,-351.733,1.19425
gpu_reorg,512,32,1,20,4,true,false,true,false,-363.098,1.22921
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-276.21,0.926169
0.926169
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-426.127,1.42739
1.42739
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,-291.581,0.979845
0.979845
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,-315.629,1.06679
1.06679
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-334.401,1.13112
1.13112
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-402.169,1.3599
1.3599
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.886485
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 67 seconds of which 14.2555 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-336.087,1.13378
gpu_array,512,8,1,20,2,true,false,true,false,-357.49,1.20609
gpu_array,512,8,1,20,4,true,false,true,false,-381.963,1.2937
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-334.191,1.12877
gpu_sparse,512,8,1,20,2,true,false,true,false,-405.585,1.3681
gpu_sparse,512,8,1,20,4,true,false,true,false,-428.054,1.44613
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-440.156,1.48297
gpu_reorg,512,8,1,20,2,true,false,true,false,-338.618,1.14799
gpu_reorg,512,8,1,20,4,true,false,true,false,-367.489,1.24504
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-537.508,1.80796
gpu_array,512,8,1,50,2,true,false,true,false,-449.724,1.51937
gpu_array,512,8,1,50,4,true,false,true,false,-596.458,2.00067
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-534.218,1.79253
gpu_sparse,512,8,1,50,2,true,false,true,false,-537.162,1.81282
gpu_sparse,512,8,1,50,4,true,false,true,false,-625.72,2.09728
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-629.916,2.10774
gpu_reorg,512,8,1,50,2,true,false,true,false,-431.87,1.46332
gpu_reorg,512,8,1,50,4,true,false,true,false,-756.287,2.5303
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-419.999,1.41534
gpu_array,512,32,1,20,2,true,false,true,false,-324.486,1.098
gpu_array,512,32,1,20,4,true,false,true,false,-264.841,0.88745
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-403.9,1.35886
gpu_sparse,512,32,1,20,2,true,false,true,false,-328.222,1.11048
gpu_sparse,512,32,1,20,4,true,false,true,false,-279.809,0.941508
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-510.014,1.70703
gpu_reorg,512,32,1,20,2,true,false,true,false,-352.069,1.19488
gpu_reorg,512,32,1,20,4,true,false,true,false,-363.704,1.23009
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,true,false,true,true,-276.269,0.926339
0.926339
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,32,1,20,4,false,false,true,true,-426.157,1.42766
1.42766
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,true,false,false,true,-291.828,0.980268
0.980268
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,20,-1,false,false,false,true,-316.065,1.06725
1.06725
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-334.356,1.13137
1.13137
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-401.812,1.35953
1.35953
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	512
Best kernel execution time: 0.88745
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 67 seconds of which 14.2604 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,-415.98,1.40029
gpu_array,512,8,1,20,2,false,false,true,false,-389.04,1.30971
gpu_array,512,8,1,20,4,false,false,true,false,-376.414,1.26764
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,-430.39,1.44812
gpu_sparse,512,8,1,20,2,false,false,true,false,-406.04,1.36624
gpu_sparse,512,8,1,20,4,false,false,true,false,-383.26,1.2897
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,-494.059,1.66127
gpu_reorg,512,8,1,20,2,false,false,true,false,-426.048,1.43405
gpu_reorg,512,8,1,20,4,false,false,true,false,-423.714,1.42492
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,-218.947,0.740514
gpu_array,512,8,1,50,2,false,false,true,false,-219.153,0.74157
gpu_array,512,8,1,50,4,false,false,true,false,-221.154,0.745004
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,-226.868,0.767334
gpu_sparse,512,8,1,50,2,false,false,true,false,-251.445,0.850281
gpu_sparse,512,8,1,50,4,false,false,true,false,-251.081,0.848914
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,-228.853,0.773758
gpu_reorg,512,8,1,50,2,false,false,true,false,-214.835,0.726426
gpu_reorg,512,8,1,50,4,false,false,true,false,-214.888,0.727383
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,-323.519,1.09041
gpu_array,512,32,1,20,2,false,false,true,false,-302.746,1.02084
gpu_array,512,32,1,20,4,false,false,true,false,-308.446,1.04012
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,-328.827,1.10912
gpu_sparse,512,32,1,20,2,false,false,true,false,-310.56,1.04702
gpu_sparse,512,32,1,20,4,false,false,true,false,-326.031,1.09892
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,-359.85,1.21208
gpu_reorg,512,32,1,20,2,false,false,true,false,-336.606,1.13481
gpu_reorg,512,32,1,20,4,false,false,true,false,-340.688,1.14808
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,50,2,false,false,true,true,-185.603,0.629847
0.629847
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,32,1,20,2,false,false,true,true,-332.114,1.11968
1.11968
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,-384.844,1.29499
1.29499
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.629847
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 39 seconds of which 9.97449 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_reorg
epsilon 2000 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,false,false,false,false,-416.405,1.40061
gpu_array,512,8,1,20,2,false,false,true,false,-389.145,1.31039
gpu_array,512,8,1,20,4,false,false,true,false,-376.293,1.26665
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,false,false,false,false,-430.013,1.4477
gpu_sparse,512,8,1,20,2,false,false,true,false,-405.822,1.36592
gpu_sparse,512,8,1,20,4,false,false,true,false,-382.65,1.28863
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,false,false,false,false,-494.342,1.66155
gpu_reorg,512,8,1,20,2,false,false,true,false,-426.316,1.43377
gpu_reorg,512,8,1,20,4,false,false,true,false,-423.416,1.4249
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,false,false,false,false,-218.91,0.740766
gpu_array,512,8,1,50,2,false,false,true,false,-218.876,0.740522
gpu_array,512,8,1,50,4,false,false,true,false,-218.608,0.740145
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,false,false,false,false,-226.995,0.767782
gpu_sparse,512,8,1,50,2,false,false,true,false,-251.466,0.849323
gpu_sparse,512,8,1,50,4,false,false,true,false,-251.005,0.848583
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,false,false,false,false,-228.916,0.773854
gpu_reorg,512,8,1,50,2,false,false,true,false,-214.521,0.728381
gpu_reorg,512,8,1,50,4,false,false,true,false,-215.434,0.727717
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,false,false,false,false,-323.648,1.09109
gpu_array,512,32,1,20,2,false,false,true,false,-302.583,1.02112
gpu_array,512,32,1,20,4,false,false,true,false,-308.309,1.03987
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,false,false,false,false,-329.011,1.10978
gpu_sparse,512,32,1,20,2,false,false,true,false,-310.617,1.04746
gpu_sparse,512,32,1,20,4,false,false,true,false,-326.034,1.09823
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,false,false,false,false,-360.001,1.21222
gpu_reorg,512,32,1,20,2,false,false,true,false,-336.435,1.13423
gpu_reorg,512,32,1,20,4,false,false,true,false,-340.709,1.14878
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,50,4,false,false,true,true,-185.559,0.630076
0.630076
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,32,1,20,2,false,false,true,true,-331.85,1.11815
1.11815
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_reorg
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_reorg,512,8,1,20,4,false,false,true,true,-384.817,1.29597
1.29597
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	512
Best kernel execution time: 0.630076
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 39 seconds of which 9.97299 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_reorg
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-60.2655,0.203908
gpu_array,512,8,1,20,2,true,false,true,false,-54.6236,0.185013
gpu_array,512,8,1,20,4,true,false,true,false,-54.2266,0.18352
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-73.4376,0.247303
gpu_sparse,512,8,1,20,2,true,false,true,false,-68.4716,0.230178
gpu_sparse,512,8,1,20,4,true,false,true,false,-67.9605,0.228955
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-68.296,0.230718
gpu_reorg,512,8,1,20,2,true,false,true,false,-60.8841,0.207025
gpu_reorg,512,8,1,20,4,true,false,true,false,-61.9924,0.210687
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-84.433,0.283109
gpu_array,512,8,1,50,2,true,false,true,false,-72.6506,0.245219
gpu_array,512,8,1,50,4,true,false,true,false,-72.6544,0.244679
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-98.8774,0.331622
gpu_sparse,512,8,1,50,2,true,false,true,false,-83.8229,0.281893
gpu_sparse,512,8,1,50,4,true,false,true,false,-83.7839,0.281892
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-86.3874,0.290371
gpu_reorg,512,8,1,50,2,true,false,true,false,-85.9302,0.289896
gpu_reorg,512,8,1,50,4,true,false,true,false,-85.7096,0.289058
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-50.8032,0.172677
gpu_array,512,32,1,20,2,true,false,true,false,-42.2895,0.142748
gpu_array,512,32,1,20,4,true,false,true,false,-42.5037,0.144761
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-53.6257,0.181611
gpu_sparse,512,32,1,20,2,true,false,true,false,-47.4934,0.160228
gpu_sparse,512,32,1,20,4,true,false,true,false,-48.816,0.164443
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-73.0101,0.245758
gpu_reorg,512,32,1,20,2,true,false,true,false,-63.379,0.214076
gpu_reorg,512,32,1,20,4,true,false,true,false,-63.8047,0.215476
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,true,-41.7113,0.140865
0.140865
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,true,-54.5632,0.183495
0.183495
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-52.812,0.179584
0.179584
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-57.8091,0.195447
0.195447
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,4,true,false,true,true,-54.339,0.184482
0.184482
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,4,false,false,true,true,-60.2589,0.203981
0.203981
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.140865
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 16 seconds of which 2.21021 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-60.5869,0.204767
gpu_array,512,8,1,20,2,true,false,true,false,-54.845,0.1862
gpu_array,512,8,1,20,4,true,false,true,false,-54.3006,0.183152
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-73.2596,0.24693
gpu_sparse,512,8,1,20,2,true,false,true,false,-67.9097,0.229006
gpu_sparse,512,8,1,20,4,true,false,true,false,-67.1786,0.227628
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-68.1064,0.229578
gpu_reorg,512,8,1,20,2,true,false,true,false,-61.2255,0.208094
gpu_reorg,512,8,1,20,4,true,false,true,false,-62.197,0.21059
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-83.9787,0.283009
gpu_array,512,8,1,50,2,true,false,true,false,-72.8481,0.244345
gpu_array,512,8,1,50,4,true,false,true,false,-72.4794,0.244591
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-98.7947,0.332289
gpu_sparse,512,8,1,50,2,true,false,true,false,-83.7515,0.283052
gpu_sparse,512,8,1,50,4,true,false,true,false,-83.8551,0.282312
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-86.0727,0.290605
gpu_reorg,512,8,1,50,2,true,false,true,false,-86.4051,0.290255
gpu_reorg,512,8,1,50,4,true,false,true,false,-85.7,0.288886
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-50.8795,0.172597
gpu_array,512,32,1,20,2,true,false,true,false,-42.1657,0.143563
gpu_array,512,32,1,20,4,true,false,true,false,-42.8599,0.145293
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-53.9449,0.182036
gpu_sparse,512,32,1,20,2,true,false,true,false,-47.5318,0.160859
gpu_sparse,512,32,1,20,4,true,false,true,false,-48.7908,0.165628
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-73.2694,0.24684
gpu_reorg,512,32,1,20,2,true,false,true,false,-63.6318,0.214511
gpu_reorg,512,32,1,20,4,true,false,true,false,-63.8813,0.216372
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,true,false,true,true,-41.4557,0.141316
0.141316
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,32,1,20,2,false,false,true,true,-54.8916,0.184616
0.184616
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,true,false,true,true,-53.3433,0.180745
0.180745
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,20,4,false,false,true,true,-59.6613,0.198726
0.198726
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-55.0743,0.187431
0.187431
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-60.2598,0.204351
0.204351
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	512
Best kernel execution time: 0.141316
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 16 seconds of which 2.21497 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-2501.83,103.233
gpu_array,512,8,1,20,2,true,false,true,false,-1801.71,72.1515
gpu_array,512,8,1,20,4,true,false,true,false,-1993.49,80.3994
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-2339.87,95.8977
gpu_sparse,512,8,1,20,2,true,false,true,false,-1989.61,80.191
gpu_sparse,512,8,1,20,4,true,false,true,false,-2504.63,101.708
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-3257.2,134.616
gpu_reorg,512,8,1,20,2,true,false,true,false,-2595.7,104.128
gpu_reorg,512,8,1,20,4,true,false,true,false,-6938.26,288.986
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-3953.45,163.959
gpu_array,512,8,1,50,2,true,false,true,false,-3636.43,149.126
gpu_array,512,8,1,50,4,true,false,true,false,-4732.61,193.954
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-3237.57,133.571
gpu_sparse,512,8,1,50,2,true,false,true,false,-3601.11,147.515
gpu_sparse,512,8,1,50,4,true,false,true,false,-4540.09,186.825
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-4875.79,202.166
gpu_reorg,512,8,1,50,2,true,false,true,false,-12107.2,505.628
gpu_reorg,512,8,1,50,4,true,false,true,false,-11240.5,466.52
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-1947.64,78.6192
gpu_array,512,32,1,20,2,true,false,true,false,-1808.75,73.3528
gpu_array,512,32,1,20,4,true,false,true,false,-1610.99,64.932
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-1632.59,65.7957
gpu_sparse,512,32,1,20,2,true,false,true,false,-1822.24,73.5676
gpu_sparse,512,32,1,20,4,true,false,true,false,-1658.73,66.8912
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-1878.49,75.8572
gpu_reorg,512,32,1,20,2,true,false,true,false,-4791.24,199.083
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,-2355.11,95.8012
95.8012
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,-2466.12,100.312
100.312
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-2925.5,119.428
119.428
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-3079.03,125.79
125.79
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 64.932
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 603 seconds of which 111.36 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
letters 16 26000 true
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-2501.86,103.06
gpu_array,512,8,1,20,2,true,false,true,false,-1800.04,72.1713
gpu_array,512,8,1,20,4,true,false,true,false,-2023.52,81.1558
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-2327.67,95.5711
gpu_sparse,512,8,1,20,2,true,false,true,false,-2035.27,81.4471
gpu_sparse,512,8,1,20,4,true,false,true,false,-2502.24,101.799
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-3281.14,134.99
gpu_reorg,512,8,1,20,2,true,false,true,false,-2581.74,104.077
gpu_reorg,512,8,1,20,4,true,false,true,false,-6875.13,287.221
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-3962.49,164.272
gpu_array,512,8,1,50,2,true,false,true,false,-3669.93,150.377
gpu_array,512,8,1,50,4,true,false,true,false,-4703.23,193.974
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-3227.46,133.579
gpu_sparse,512,8,1,50,2,true,false,true,false,-3618.03,148.541
gpu_sparse,512,8,1,50,4,true,false,true,false,-4533.1,187.123
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-4842.29,201.423
gpu_reorg,512,8,1,50,2,true,false,true,false,-12041.6,501.839
gpu_reorg,512,8,1,50,4,true,false,true,false,-11288.6,467.397
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-1956.41,79.1295
gpu_array,512,32,1,20,2,true,false,true,false,-1821.07,73.5358
gpu_array,512,32,1,20,4,true,false,true,false,-1611.11,64.8013
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-1646.53,66.1029
gpu_sparse,512,32,1,20,2,true,false,true,false,-1806.26,73.254
gpu_sparse,512,32,1,20,4,true,false,true,false,-1675.36,67.1576
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-1885.12,75.8738
gpu_reorg,512,32,1,20,2,true,false,true,false,-4807.33,199.235
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,512,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,true,false,true,true,-2363.52,95.9571
95.9571
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,20,2,false,false,true,true,-2462.48,100.204
100.204
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,true,false,true,true,-2904.6,118.981
118.981
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_array,512,8,1,50,2,false,false,true,true,-3069.65,125.592
125.592
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	512
Best kernel execution time: 64.8013
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 607 seconds of which 111.356 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-52.4947,0.177137
gpu_array,512,8,1,20,2,true,false,true,false,-91.2269,0.306933
gpu_array,512,8,1,20,4,true,false,true,false,-84.317,0.285224
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-61.4285,0.207612
gpu_sparse,512,8,1,20,2,true,false,true,false,-98.7112,0.331758
gpu_sparse,512,8,1,20,4,true,false,true,false,-98.1164,0.330258
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-65.9244,0.222732
gpu_reorg,512,8,1,20,2,true,false,true,false,-225.477,0.575751
gpu_reorg,512,8,1,20,4,true,false,true,false,-260.666,0.653944
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-80.9212,0.272141
gpu_array,512,8,1,50,2,true,false,true,false,-179.06,0.600522
gpu_array,512,8,1,50,4,true,false,true,false,-177.745,0.596134
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-87.9713,0.296242
gpu_sparse,512,8,1,50,2,true,false,true,false,-176.755,0.592173
gpu_sparse,512,8,1,50,4,true,false,true,false,-178.352,0.598262
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-94.7327,0.318066
gpu_reorg,512,8,1,50,2,true,false,true,false,-179.453,0.601822
gpu_reorg,512,8,1,50,4,true,false,true,false,-179.32,0.600898
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-48.9372,0.16568
gpu_array,512,32,1,20,2,true,false,true,false,-56.9929,0.19266
gpu_array,512,32,1,20,4,true,false,true,false,-58.4988,0.197858
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-46.7317,0.157666
gpu_sparse,512,32,1,20,2,true,false,true,false,-56.542,0.191719
gpu_sparse,512,32,1,20,4,true,false,true,false,-55.9579,0.189195
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-66.6359,0.223504
gpu_reorg,512,32,1,20,2,true,false,true,false,-68.6916,0.231579
gpu_reorg,512,32,1,20,4,true,false,true,false,-170.213,0.453146
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,-1,true,false,false,true,-44.1911,0.149413
0.149413
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,-1,false,false,false,true,-63.5284,0.213806
0.213806
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,-58.5401,0.197521
0.197521
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,-71.1272,0.239993
0.239993
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,-71.8109,0.241228
0.241228
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,-81.0521,0.273373
0.273373
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.149413
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 38 seconds of which 3.34416 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
512 8 1 20 gpu_array
gpu_array,512,8,1,20,-1,true,false,false,false,-51.9937,0.176921
gpu_array,512,8,1,20,2,true,false,true,false,-91.3727,0.30699
gpu_array,512,8,1,20,4,true,false,true,false,-84.6488,0.285404
512 8 1 20 gpu_sparse
gpu_sparse,512,8,1,20,-1,true,false,false,false,-61.5506,0.207912
gpu_sparse,512,8,1,20,2,true,false,true,false,-98.8851,0.332367
gpu_sparse,512,8,1,20,4,true,false,true,false,-98.6231,0.330684
512 8 1 20 gpu_reorg
gpu_reorg,512,8,1,20,-1,true,false,false,false,-66.0935,0.22289
gpu_reorg,512,8,1,20,2,true,false,true,false,-110.623,0.373352
gpu_reorg,512,8,1,20,4,true,false,true,false,-306.215,0.729441
512 8 1 50 gpu_array
gpu_array,512,8,1,50,-1,true,false,false,false,-80.848,0.271822
gpu_array,512,8,1,50,2,true,false,true,false,-179.04,0.600869
gpu_array,512,8,1,50,4,true,false,true,false,-177.269,0.595349
512 8 1 50 gpu_sparse
gpu_sparse,512,8,1,50,-1,true,false,false,false,-87.8777,0.29613
gpu_sparse,512,8,1,50,2,true,false,true,false,-176.922,0.593124
gpu_sparse,512,8,1,50,4,true,false,true,false,-178.161,0.597793
512 8 1 50 gpu_reorg
gpu_reorg,512,8,1,50,-1,true,false,false,false,-95.1328,0.31902
gpu_reorg,512,8,1,50,2,true,false,true,false,-179.823,0.603126
gpu_reorg,512,8,1,50,4,true,false,true,false,-179.531,0.601592
512 32 1 20 gpu_array
gpu_array,512,32,1,20,-1,true,false,false,false,-49.5506,0.166872
gpu_array,512,32,1,20,2,true,false,true,false,-56.9416,0.192477
gpu_array,512,32,1,20,4,true,false,true,false,-58.659,0.197733
512 32 1 20 gpu_sparse
gpu_sparse,512,32,1,20,-1,true,false,false,false,-46.7813,0.157531
gpu_sparse,512,32,1,20,2,true,false,true,false,-56.9747,0.191948
gpu_sparse,512,32,1,20,4,true,false,true,false,-55.8893,0.189462
512 32 1 20 gpu_reorg
gpu_reorg,512,32,1,20,-1,true,false,false,false,-65.7712,0.222254
gpu_reorg,512,32,1,20,2,true,false,true,false,-68.4899,0.230833
gpu_reorg,512,32,1,20,4,true,false,true,false,-130.466,0.364425
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,-1,true,false,false,true,-43.7865,0.149003
0.149003
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,32,1,20,-1,false,false,false,true,-63.5688,0.214441
0.214441
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,true,false,false,true,-58.3097,0.197464
0.197464
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,20,-1,false,false,false,true,-71.8321,0.24151
0.24151
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,true,false,false,true,-71.568,0.240559
0.240559
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,512,8,1,50,-1,false,false,false,true,-81.1264,0.273945
0.273945
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	512
Best kernel execution time: 0.149003
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 37 seconds of which 3.27943 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-350.756,1.17409
gpu_array,1024,8,1,20,2,true,false,true,false,-284.899,0.956707
gpu_array,1024,8,1,20,4,true,false,true,false,-276.557,0.927982
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-394.481,1.32055
gpu_sparse,1024,8,1,20,2,true,false,true,false,-360.829,1.20793
gpu_sparse,1024,8,1,20,4,true,false,true,false,-352.486,1.18313
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-424.923,1.42726
gpu_reorg,1024,8,1,20,2,true,false,true,false,-290.316,0.974961
gpu_reorg,1024,8,1,20,4,true,false,true,false,-279.072,0.936185
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-399.106,1.33795
gpu_array,1024,8,1,50,2,true,false,true,false,-308.483,1.03642
gpu_array,1024,8,1,50,4,true,false,true,false,-308.199,1.03433
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-420.361,1.41118
gpu_sparse,1024,8,1,50,2,true,false,true,false,-390.563,1.30819
gpu_sparse,1024,8,1,50,4,true,false,true,false,-394.563,1.32246
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-573.638,1.92663
gpu_reorg,1024,8,1,50,2,true,false,true,false,-321.025,1.07917
gpu_reorg,1024,8,1,50,4,true,false,true,false,-327.098,1.0945
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-434.529,1.45508
gpu_array,1024,32,1,20,2,true,false,true,false,-256.554,0.858475
gpu_array,1024,32,1,20,4,true,false,true,false,-237.194,0.792979
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-435.982,1.45907
gpu_sparse,1024,32,1,20,2,true,false,true,false,-276.991,0.92756
gpu_sparse,1024,32,1,20,4,true,false,true,false,-253.958,0.850402
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-591.663,1.98007
gpu_reorg,1024,32,1,20,2,true,false,true,false,-333.88,1.11787
gpu_reorg,1024,32,1,20,4,true,false,true,false,-349.556,1.17051
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-237.854,0.795898
0.795898
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-260.76,0.874759
0.874759
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-272.043,0.912376
0.912376
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-309.728,1.04014
1.04014
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-285.134,0.955067
0.955067
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-327.487,1.09862
1.09862
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.792979
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 39 seconds of which 23.3156 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
abalone 8 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-350.635,1.1741
gpu_array,1024,8,1,20,2,true,false,true,false,-284.822,0.95644
gpu_array,1024,8,1,20,4,true,false,true,false,-276.931,0.930986
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-395.006,1.32141
gpu_sparse,1024,8,1,20,2,true,false,true,false,-360.016,1.20938
gpu_sparse,1024,8,1,20,4,true,false,true,false,-353.233,1.18416
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-425.697,1.42941
gpu_reorg,1024,8,1,20,2,true,false,true,false,-291.137,0.976234
gpu_reorg,1024,8,1,20,4,true,false,true,false,-279.054,0.93634
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-399.277,1.33761
gpu_array,1024,8,1,50,2,true,false,true,false,-310.246,1.03915
gpu_array,1024,8,1,50,4,true,false,true,false,-308.386,1.03482
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-420.448,1.4112
gpu_sparse,1024,8,1,50,2,true,false,true,false,-390.228,1.30762
gpu_sparse,1024,8,1,50,4,true,false,true,false,-394.02,1.3223
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-573.518,1.92631
gpu_reorg,1024,8,1,50,2,true,false,true,false,-321.192,1.07798
gpu_reorg,1024,8,1,50,4,true,false,true,false,-326.807,1.09591
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-434.499,1.45489
gpu_array,1024,32,1,20,2,true,false,true,false,-256.032,0.857845
gpu_array,1024,32,1,20,4,true,false,true,false,-237.128,0.793794
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-436.024,1.45881
gpu_sparse,1024,32,1,20,2,true,false,true,false,-276.773,0.927552
gpu_sparse,1024,32,1,20,4,true,false,true,false,-253.555,0.850667
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-591.6,1.98042
gpu_reorg,1024,32,1,20,2,true,false,true,false,-334.117,1.11859
gpu_reorg,1024,32,1,20,4,true,false,true,false,-349.401,1.1701
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-237.895,0.795828
0.795828
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-260.573,0.873786
0.873786
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-272.516,0.913384
0.913384
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-310.332,1.04101
1.04101
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-285.681,0.957791
0.957791
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-327.843,1.09895
1.09895
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	1024
Best kernel execution time: 0.793794
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 39 seconds of which 23.3256 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-54.6588,0.183986
gpu_array,1024,8,1,20,2,true,false,true,false,-49.7224,0.169215
gpu_array,1024,8,1,20,4,true,false,true,false,-49.1951,0.168145
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-67.0489,0.226488
gpu_sparse,1024,8,1,20,2,true,false,true,false,-62.976,0.213477
gpu_sparse,1024,8,1,20,4,true,false,true,false,-62.9293,0.212345
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-59.0902,0.19985
gpu_reorg,1024,8,1,20,2,true,false,true,false,-52.3886,0.179806
gpu_reorg,1024,8,1,20,4,true,false,true,false,-51.8216,0.179396
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-73.3494,0.247257
gpu_array,1024,8,1,50,2,true,false,true,false,-65.6832,0.222064
gpu_array,1024,8,1,50,4,true,false,true,false,-65.9622,0.222342
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-88.4728,0.29672
gpu_sparse,1024,8,1,50,2,true,false,true,false,-83.412,0.280428
gpu_sparse,1024,8,1,50,4,true,false,true,false,-83.5515,0.280534
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-74.9774,0.254004
gpu_reorg,1024,8,1,50,2,true,false,true,false,-72.3198,0.245667
gpu_reorg,1024,8,1,50,4,true,false,true,false,-73.0367,0.247476
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-44.3625,0.149261
gpu_array,1024,32,1,20,2,true,false,true,false,-31.9231,0.110103
gpu_array,1024,32,1,20,4,true,false,true,false,-32.2529,0.109429
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-45.538,0.154334
gpu_sparse,1024,32,1,20,2,true,false,true,false,-36.9031,0.126174
gpu_sparse,1024,32,1,20,4,true,false,true,false,-45.8244,0.154157
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-65.0308,0.218184
gpu_reorg,1024,32,1,20,2,true,false,true,false,-43.9341,0.150812
gpu_reorg,1024,32,1,20,4,true,false,true,false,-45.6232,0.155098
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-30.3715,0.104072
0.104072
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-40.2479,0.135885
0.135885
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-48.0557,0.164053
0.164053
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-48.6918,0.167619
0.167619
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-50.8278,0.173224
0.173224
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-52.9443,0.181707
0.181707
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.104072
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 14 seconds of which 3.86047 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-54.6066,0.184404
gpu_array,1024,8,1,20,2,true,false,true,false,-49.684,0.168581
gpu_array,1024,8,1,20,4,true,false,true,false,-49.3822,0.168581
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-67.5253,0.227594
gpu_sparse,1024,8,1,20,2,true,false,true,false,-62.8643,0.212826
gpu_sparse,1024,8,1,20,4,true,false,true,false,-62.6738,0.210993
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-59.2609,0.200068
gpu_reorg,1024,8,1,20,2,true,false,true,false,-51.5752,0.177749
gpu_reorg,1024,8,1,20,4,true,false,true,false,-52.641,0.181312
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-73.3312,0.246896
gpu_array,1024,8,1,50,2,true,false,true,false,-65.3613,0.220729
gpu_array,1024,8,1,50,4,true,false,true,false,-65.629,0.221619
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-88.3256,0.296444
gpu_sparse,1024,8,1,50,2,true,false,true,false,-83.7151,0.281019
gpu_sparse,1024,8,1,50,4,true,false,true,false,-83.1647,0.279618
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-74.8879,0.253719
gpu_reorg,1024,8,1,50,2,true,false,true,false,-72.4207,0.246252
gpu_reorg,1024,8,1,50,4,true,false,true,false,-72.3864,0.246455
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-44.2822,0.149408
gpu_array,1024,32,1,20,2,true,false,true,false,-32.1843,0.10964
gpu_array,1024,32,1,20,4,true,false,true,false,-32.1181,0.109469
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-45.7089,0.154391
gpu_sparse,1024,32,1,20,2,true,false,true,false,-37.1964,0.149292
gpu_sparse,1024,32,1,20,4,true,false,true,false,-57.8492,0.193783
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-64.9287,0.218796
gpu_reorg,1024,32,1,20,2,true,false,true,false,-48.3212,0.163162
gpu_reorg,1024,32,1,20,4,true,false,true,false,-44.9274,0.153617
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-30.7305,0.104497
0.104497
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-39.7399,0.134128
0.134128
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,true,false,true,true,-47.9105,0.163717
0.163717
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,20,2,false,false,true,true,-48.8582,0.167163
0.167163
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-50.6447,0.173639
0.173639
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-52.6542,0.180768
0.180768
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	1024
Best kernel execution time: 0.104497
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 13 seconds of which 3.90164 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-1045.54,3.50031
gpu_array,1024,8,1,20,2,true,false,true,false,-571.442,1.91492
gpu_array,1024,8,1,20,4,true,false,true,false,-365.797,1.22732
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-1025.55,3.43338
gpu_sparse,1024,8,1,20,2,true,false,true,false,-573.457,1.92178
gpu_sparse,1024,8,1,20,4,true,false,true,false,-395.947,1.32791
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-1032.04,3.45528
gpu_reorg,1024,8,1,20,2,true,false,true,false,-539.035,1.80921
gpu_reorg,1024,8,1,20,4,true,false,true,false,-607.004,2.03556
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-520.569,1.75798
gpu_array,1024,8,1,50,2,true,false,true,false,-330.255,1.10938
gpu_array,1024,8,1,50,4,true,false,true,false,-377.74,1.26634
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-537.874,1.81744
gpu_sparse,1024,8,1,50,2,true,false,true,false,-376.606,1.26557
gpu_sparse,1024,8,1,50,4,true,false,true,false,-394.66,1.32372
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-591.363,1.99016
gpu_reorg,1024,8,1,50,2,true,false,true,false,-274.991,0.924925
gpu_reorg,1024,8,1,50,4,true,false,true,false,-348.933,1.17173
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,true,false,true,true,-447.077,1.18814
1.18814
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,false,false,true,true,-530.707,1.80859
1.80859
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,true,false,true,true,-504.228,1.69135
1.69135
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,false,false,true,true,-1365.82,4.5682
4.5682
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.924925
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 57 seconds of which 26.1176 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-1045.48,3.50035
gpu_array,1024,8,1,20,2,true,false,true,false,-571.768,1.91621
gpu_array,1024,8,1,20,4,true,false,true,false,-366.005,1.22808
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-1025.45,3.43287
gpu_sparse,1024,8,1,20,2,true,false,true,false,-573.568,1.92208
gpu_sparse,1024,8,1,20,4,true,false,true,false,-396.221,1.32783
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-1032.32,3.45603
gpu_reorg,1024,8,1,20,2,true,false,true,false,-539.37,1.80841
gpu_reorg,1024,8,1,20,4,true,false,true,false,-607.267,2.03604
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-520.106,1.75844
gpu_array,1024,8,1,50,2,true,false,true,false,-330.427,1.10989
gpu_array,1024,8,1,50,4,true,false,true,false,-377.782,1.26673
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-538.844,1.82092
gpu_sparse,1024,8,1,50,2,true,false,true,false,-377.433,1.26565
gpu_sparse,1024,8,1,50,4,true,false,true,false,-394.937,1.32466
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-591.746,1.99111
gpu_reorg,1024,8,1,50,2,true,false,true,false,-274.996,0.926517
gpu_reorg,1024,8,1,50,4,true,false,true,false,-349.338,1.1724
1024 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
1024 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,true,false,true,true,-484.138,1.25086
1.25086
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,50,2,false,false,true,true,-530.825,1.80794
1.80794
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,true,false,true,true,-503.479,1.69194
1.69194
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,1024,8,1,20,2,false,false,true,true,-1366.88,4.57079
4.57079
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	1024
Best kernel execution time: 0.926517
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 56 seconds of which 26.1647 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-330.697,1.10845
gpu_array,1024,8,1,20,2,true,false,true,false,-408.626,1.37095
gpu_array,1024,8,1,20,4,true,false,true,false,-397.387,1.33124
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-334.4,1.11999
gpu_sparse,1024,8,1,20,2,true,false,true,false,-433.81,1.46044
gpu_sparse,1024,8,1,20,4,true,false,true,false,-427.732,1.43878
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-460.191,1.54772
gpu_reorg,1024,8,1,20,2,true,false,true,false,-385.446,1.2897
gpu_reorg,1024,8,1,20,4,true,false,true,false,-357.134,1.19696
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-490.334,1.65367
gpu_array,1024,8,1,50,2,true,false,true,false,-454.193,1.54081
gpu_array,1024,8,1,50,4,true,false,true,false,-596.652,2.00171
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-480.049,1.61698
gpu_sparse,1024,8,1,50,2,true,false,true,false,-554.052,1.87355
gpu_sparse,1024,8,1,50,4,true,false,true,false,-620.126,2.08273
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-563.419,1.89844
gpu_reorg,1024,8,1,50,2,true,false,true,false,-411.017,1.38155
gpu_reorg,1024,8,1,50,4,true,false,true,false,-735.329,2.46086
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-395.411,1.32502
gpu_array,1024,32,1,20,2,true,false,true,false,-313.219,1.05052
gpu_array,1024,32,1,20,4,true,false,true,false,-251.416,0.844027
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-381.709,1.27786
gpu_sparse,1024,32,1,20,2,true,false,true,false,-316.562,1.05974
gpu_sparse,1024,32,1,20,4,true,false,true,false,-264.136,0.886475
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-450.225,1.51164
gpu_reorg,1024,32,1,20,2,true,false,true,false,-349.292,1.1696
gpu_reorg,1024,32,1,20,4,true,false,true,false,-352.189,1.17828
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-267.171,0.895254
0.895254
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-410.107,1.37192
1.37192
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-285.371,0.955939
0.955939
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-309.758,1.03757
1.03757
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-307.294,1.03142
1.03142
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-399.525,1.33707
1.33707
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.844027
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 52 seconds of which 27.8365 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-330.45,1.10791
gpu_array,1024,8,1,20,2,true,false,true,false,-408.937,1.36813
gpu_array,1024,8,1,20,4,true,false,true,false,-397.164,1.33173
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-334.797,1.12203
gpu_sparse,1024,8,1,20,2,true,false,true,false,-435.189,1.45994
gpu_sparse,1024,8,1,20,4,true,false,true,false,-427.671,1.43909
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-460.1,1.54788
gpu_reorg,1024,8,1,20,2,true,false,true,false,-383.979,1.28634
gpu_reorg,1024,8,1,20,4,true,false,true,false,-357.284,1.19516
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-490.206,1.65198
gpu_array,1024,8,1,50,2,true,false,true,false,-454.857,1.54029
gpu_array,1024,8,1,50,4,true,false,true,false,-594.747,1.99771
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-479.972,1.61588
gpu_sparse,1024,8,1,50,2,true,false,true,false,-554.546,1.87214
gpu_sparse,1024,8,1,50,4,true,false,true,false,-619.707,2.08189
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-563.468,1.89686
gpu_reorg,1024,8,1,50,2,true,false,true,false,-410.93,1.38306
gpu_reorg,1024,8,1,50,4,true,false,true,false,-735.205,2.46049
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-395.055,1.32463
gpu_array,1024,32,1,20,2,true,false,true,false,-312.622,1.04734
gpu_array,1024,32,1,20,4,true,false,true,false,-250.653,0.843716
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-381.806,1.27822
gpu_sparse,1024,32,1,20,2,true,false,true,false,-316.457,1.0591
gpu_sparse,1024,32,1,20,4,true,false,true,false,-264.573,0.888203
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-449.087,1.51186
gpu_reorg,1024,32,1,20,2,true,false,true,false,-348.913,1.16895
gpu_reorg,1024,32,1,20,4,true,false,true,false,-351.39,1.17702
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,true,false,true,true,-267.642,0.895965
0.895965
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,32,1,20,4,false,false,true,true,-410.043,1.37207
1.37207
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-285.312,0.955682
0.955682
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-309.55,1.03769
1.03769
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-307.572,1.03052
1.03052
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-398.843,1.33667
1.33667
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	1024
Best kernel execution time: 0.843716
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 52 seconds of which 27.8238 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,-443.614,1.48906
gpu_array,1024,8,1,20,2,false,false,true,false,-396.097,1.33326
gpu_array,1024,8,1,20,4,false,false,true,false,-385.934,1.29696
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,-449.195,1.50986
gpu_sparse,1024,8,1,20,2,false,false,true,false,-425.289,1.43007
gpu_sparse,1024,8,1,20,4,false,false,true,false,-388.403,1.30557
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,-528.877,1.77541
gpu_reorg,1024,8,1,20,2,false,false,true,false,-433.474,1.45363
gpu_reorg,1024,8,1,20,4,false,false,true,false,-449.12,1.50979
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,-205.563,0.695197
gpu_array,1024,8,1,50,2,false,false,true,false,-214.271,0.723499
gpu_array,1024,8,1,50,4,false,false,true,false,-214.056,0.722614
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,-212.309,0.716532
gpu_sparse,1024,8,1,50,2,false,false,true,false,-246.138,0.829618
gpu_sparse,1024,8,1,50,4,false,false,true,false,-246.265,0.830122
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,-214.537,0.724012
gpu_reorg,1024,8,1,50,2,false,false,true,false,-208.97,0.707752
gpu_reorg,1024,8,1,50,4,false,false,true,false,-209.249,0.707243
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,-325.924,1.09682
gpu_array,1024,32,1,20,2,false,false,true,false,-307.653,1.03571
gpu_array,1024,32,1,20,4,false,false,true,false,-313.03,1.05373
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,-331.895,1.1175
gpu_sparse,1024,32,1,20,2,false,false,true,false,-315.903,1.06315
gpu_sparse,1024,32,1,20,4,false,false,true,false,-331.098,1.114
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,-365.336,1.2281
gpu_reorg,1024,32,1,20,2,false,false,true,false,-345.417,1.16247
gpu_reorg,1024,32,1,20,4,false,false,true,false,-353.632,1.18987
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-193.44,0.654246
0.654246
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-301.103,1.01302
1.01302
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-296.415,0.998464
0.998464
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.654246
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 29 seconds of which 19.9602 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,false,false,false,false,-443.613,1.48911
gpu_array,1024,8,1,20,2,false,false,true,false,-396.269,1.33285
gpu_array,1024,8,1,20,4,false,false,true,false,-385.407,1.29556
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,false,false,false,false,-449.604,1.50993
gpu_sparse,1024,8,1,20,2,false,false,true,false,-425.352,1.42985
gpu_sparse,1024,8,1,20,4,false,false,true,false,-388.523,1.30577
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,false,false,false,false,-528.775,1.77592
gpu_reorg,1024,8,1,20,2,false,false,true,false,-432.852,1.4539
gpu_reorg,1024,8,1,20,4,false,false,true,false,-449.105,1.50913
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,false,false,false,false,-205.372,0.694813
gpu_array,1024,8,1,50,2,false,false,true,false,-214.03,0.723382
gpu_array,1024,8,1,50,4,false,false,true,false,-214.288,0.723317
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,false,false,false,false,-211.616,0.715428
gpu_sparse,1024,8,1,50,2,false,false,true,false,-246.436,0.830599
gpu_sparse,1024,8,1,50,4,false,false,true,false,-246.377,0.830537
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,false,false,false,false,-214.294,0.724328
gpu_reorg,1024,8,1,50,2,false,false,true,false,-209.031,0.70779
gpu_reorg,1024,8,1,50,4,false,false,true,false,-209.005,0.707316
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,false,false,false,false,-325.906,1.09694
gpu_array,1024,32,1,20,2,false,false,true,false,-308.001,1.03662
gpu_array,1024,32,1,20,4,false,false,true,false,-312.775,1.07943
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,false,false,false,false,-332.056,1.11796
gpu_sparse,1024,32,1,20,2,false,false,true,false,-315.611,1.06245
gpu_sparse,1024,32,1,20,4,false,false,true,false,-331.314,1.11386
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,false,false,false,false,-365.501,1.22885
gpu_reorg,1024,32,1,20,2,false,false,true,false,-345.53,1.16163
gpu_reorg,1024,32,1,20,4,false,false,true,false,-353.527,1.18873
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-193.576,0.654178
0.654178
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-301.057,1.01298
1.01298
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-296.13,0.997747
0.997747
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	1024
Best kernel execution time: 0.654178
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 29 seconds of which 19.9747 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-56.1838,0.189266
gpu_array,1024,8,1,20,2,true,false,true,false,-49.1641,0.166938
gpu_array,1024,8,1,20,4,true,false,true,false,-48.824,0.166268
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-66.7427,0.225026
gpu_sparse,1024,8,1,20,2,true,false,true,false,-70.9437,0.237982
gpu_sparse,1024,8,1,20,4,true,false,true,false,-61.3658,0.206424
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-63.8476,0.215915
gpu_reorg,1024,8,1,20,2,true,false,true,false,-54.4757,0.188345
gpu_reorg,1024,8,1,20,4,true,false,true,false,-54.9859,0.190835
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-74.4652,0.250599
gpu_array,1024,8,1,50,2,true,false,true,false,-63.2912,0.213727
gpu_array,1024,8,1,50,4,true,false,true,false,-63.2721,0.214181
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-86.8677,0.291486
gpu_sparse,1024,8,1,50,2,true,false,true,false,-73.6508,0.248625
gpu_sparse,1024,8,1,50,4,true,false,true,false,-73.7542,0.250654
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-80.3169,0.272961
gpu_reorg,1024,8,1,50,2,true,false,true,false,-77.5913,0.264147
gpu_reorg,1024,8,1,50,4,true,false,true,false,-77.8637,0.264242
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-49.5135,0.166237
gpu_array,1024,32,1,20,2,true,false,true,false,-38.9497,0.131377
gpu_array,1024,32,1,20,4,true,false,true,false,-39.3928,0.133524
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-51.9675,0.176051
gpu_sparse,1024,32,1,20,2,true,false,true,false,-55.4817,0.191134
gpu_sparse,1024,32,1,20,4,true,false,true,false,-60.2234,0.203366
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-69.1814,0.232694
gpu_reorg,1024,32,1,20,2,true,false,true,false,-57.9272,0.195863
gpu_reorg,1024,32,1,20,4,true,false,true,false,-59.062,0.199762
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,-35.8406,0.123306
0.123306
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-49.1847,0.167843
0.167843
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-46.5459,0.159202
0.159202
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-51.6442,0.177078
0.177078
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,2,true,false,true,true,-47.8645,0.164749
0.164749
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,2,false,false,true,true,-53.468,0.183345
0.183345
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.123306
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 13 seconds of which 4.09384 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-56.3523,0.189704
gpu_array,1024,8,1,20,2,true,false,true,false,-49.176,0.16682
gpu_array,1024,8,1,20,4,true,false,true,false,-48.1717,0.165189
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-66.6851,0.225101
gpu_sparse,1024,8,1,20,2,true,false,true,false,-60.5378,0.205316
gpu_sparse,1024,8,1,20,4,true,false,true,false,-60.3226,0.204704
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-64.0151,0.216335
gpu_reorg,1024,8,1,20,2,true,false,true,false,-55.1459,0.189098
gpu_reorg,1024,8,1,20,4,true,false,true,false,-54.7461,0.189401
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-74.2839,0.250303
gpu_array,1024,8,1,50,2,true,false,true,false,-63.0304,0.212756
gpu_array,1024,8,1,50,4,true,false,true,false,-62.7337,0.212601
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-86.4297,0.290954
gpu_sparse,1024,8,1,50,2,true,false,true,false,-74.065,0.249411
gpu_sparse,1024,8,1,50,4,true,false,true,false,-73.7363,0.249098
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-80.6958,0.272946
gpu_reorg,1024,8,1,50,2,true,false,true,false,-77.6314,0.264105
gpu_reorg,1024,8,1,50,4,true,false,true,false,-77.7429,0.264954
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-49.4313,0.165348
gpu_array,1024,32,1,20,2,true,false,true,false,-39.9683,0.132279
gpu_array,1024,32,1,20,4,true,false,true,false,-39.3721,0.132738
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-52.1546,0.17644
gpu_sparse,1024,32,1,20,2,true,false,true,false,-42.5441,0.144334
gpu_sparse,1024,32,1,20,4,true,false,true,false,-44.7292,0.151668
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-69.1598,0.232739
gpu_reorg,1024,32,1,20,2,true,false,true,false,-57.8212,0.195448
gpu_reorg,1024,32,1,20,4,true,false,true,false,-58.9256,0.199352
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,true,false,true,true,-35.9358,0.122793
0.122793
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,32,1,20,2,false,false,true,true,-48.9558,0.16723
0.16723
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,true,false,true,true,-46.9681,0.159795
0.159795
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,20,4,false,false,true,true,-51.4813,0.176864
0.176864
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,4,true,false,true,true,-48.3129,0.165625
0.165625
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,1024,8,1,50,4,false,false,true,true,-53.2942,0.183387
0.183387
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	1024
Best kernel execution time: 0.122793
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 14 seconds of which 4.00886 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-3080.22,126.84
gpu_array,1024,8,1,20,2,true,false,true,false,-1817.05,70.7083
gpu_array,1024,8,1,20,4,true,false,true,false,-2583.63,102.266
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-2793.78,114.931
gpu_sparse,1024,8,1,20,2,true,false,true,false,-2133.2,83.6834
gpu_sparse,1024,8,1,20,4,true,false,true,false,-2936.63,118.556
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-3847.21,159.297
gpu_reorg,1024,8,1,20,2,true,false,true,false,-3513.85,145.068
gpu_reorg,1024,8,1,20,4,true,false,true,false,-9735.22,405.863
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-4235.23,177.77
gpu_array,1024,8,1,50,2,true,false,true,false,-4766.73,193.412
gpu_array,1024,8,1,50,4,true,false,true,false,-5418.77,221.079
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-3360.21,138.4
gpu_sparse,1024,8,1,50,2,true,false,true,false,-4494.12,184.748
gpu_sparse,1024,8,1,50,4,true,false,true,false,-4972.39,205.861
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-5096.81,211.104
gpu_reorg,1024,8,1,50,2,true,false,true,false,-13392.6,558.313
gpu_reorg,1024,8,1,50,4,true,false,true,false,-12234.7,508.94
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-2048.77,81.404
gpu_array,1024,32,1,20,2,true,false,true,false,-2024.19,81.3686
gpu_array,1024,32,1,20,4,true,false,true,false,-1787.23,71.4576
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-1687.49,66.736
gpu_sparse,1024,32,1,20,2,true,false,true,false,-2027.26,81.4975
gpu_sparse,1024,32,1,20,4,true,false,true,false,-1809.61,72.4737
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-2002.68,78.2603
gpu_reorg,1024,32,1,20,2,true,false,true,false,-5630.4,236.104
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,true,false,true,true,-2448.11,97.7332
97.7332
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,false,false,true,true,-2612.94,104.252
104.252
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,-1575.98,61.7278
61.7278
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,-1656.91,64.5321
64.5321
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 61.7278
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 500 seconds of which 247.009 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-3072.5,126.818
gpu_array,1024,8,1,20,2,true,false,true,false,-1840.06,71.1797
gpu_array,1024,8,1,20,4,true,false,true,false,-2561.46,101.871
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-2807.59,115.217
gpu_sparse,1024,8,1,20,2,true,false,true,false,-2118.24,83.8165
gpu_sparse,1024,8,1,20,4,true,false,true,false,-3005.43,119.343
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-3847.49,159.336
gpu_reorg,1024,8,1,20,2,true,false,true,false,-3691.62,147.109
gpu_reorg,1024,8,1,20,4,true,false,true,false,-9846.89,408.111
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-4248.89,176.222
gpu_array,1024,8,1,50,2,true,false,true,false,-4688.39,192.387
gpu_array,1024,8,1,50,4,true,false,true,false,-5393.8,221.644
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-3360.71,138.117
gpu_sparse,1024,8,1,50,2,true,false,true,false,-4526.02,185.072
gpu_sparse,1024,8,1,50,4,true,false,true,false,-5011.27,205.589
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-5083.9,211.02
gpu_reorg,1024,8,1,50,2,true,false,true,false,-13512.1,558.669
gpu_reorg,1024,8,1,50,4,true,false,true,false,-12185.3,510.241
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-2022.09,80.8773
gpu_array,1024,32,1,20,2,true,false,true,false,-1992.98,80.8092
gpu_array,1024,32,1,20,4,true,false,true,false,-1815.52,72.1103
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-1692.71,66.6331
gpu_sparse,1024,32,1,20,2,true,false,true,false,-2019.44,81.3503
gpu_sparse,1024,32,1,20,4,true,false,true,false,-1865.19,73.3057
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-1998.84,78.7721
gpu_reorg,1024,32,1,20,2,true,false,true,false,-5650.56,235.358
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,1024,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,true,false,true,true,-2466.02,98.0988
98.0988
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,20,2,false,false,true,true,-2569.53,103.36
103.36
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,-1565.43,61.4928
61.4928
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,-1620.83,63.7604
63.7604
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	1024
Best kernel execution time: 61.4928
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 501 seconds of which 247.178 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-49.9066,0.168626
gpu_array,1024,8,1,20,2,true,false,true,false,-87.9066,0.295531
gpu_array,1024,8,1,20,4,true,false,true,false,-79.8264,0.268346
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-57.1994,0.193159
gpu_sparse,1024,8,1,20,2,true,false,true,false,-95.0638,0.319014
gpu_sparse,1024,8,1,20,4,true,false,true,false,-85.2944,0.287655
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-62.4532,0.211818
gpu_reorg,1024,8,1,20,2,true,false,true,false,-115.313,0.38741
gpu_reorg,1024,8,1,20,4,true,false,true,false,-302.609,0.758584
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-70.6968,0.238714
gpu_array,1024,8,1,50,2,true,false,true,false,-159.23,0.534155
gpu_array,1024,8,1,50,4,true,false,true,false,-159.407,0.533976
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-78.6861,0.264118
gpu_sparse,1024,8,1,50,2,true,false,true,false,-158.893,0.531748
gpu_sparse,1024,8,1,50,4,true,false,true,false,-157.921,0.529399
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-85.4136,0.287534
gpu_reorg,1024,8,1,50,2,true,false,true,false,-158.624,0.53269
gpu_reorg,1024,8,1,50,4,true,false,true,false,-158.795,0.533267
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-45.1406,0.152401
gpu_array,1024,32,1,20,2,true,false,true,false,-51.8628,0.174276
gpu_array,1024,32,1,20,4,true,false,true,false,-92.6416,0.312484
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-57.8417,0.195389
gpu_sparse,1024,32,1,20,2,true,false,true,false,-52.0722,0.174883
gpu_sparse,1024,32,1,20,4,true,false,true,false,-85.4286,0.270662
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-71.2597,0.24027
gpu_reorg,1024,32,1,20,2,true,false,true,false,-62.8141,0.213252
gpu_reorg,1024,32,1,20,4,true,false,true,false,-73.834,0.248009
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,true,false,false,true,-41.8929,0.142272
0.142272
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,32,1,20,-1,false,false,false,true,-58.5606,0.197223
0.197223
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,true,false,false,true,-45.6689,0.154368
0.154368
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,20,-1,false,false,false,true,-55.8005,0.189736
0.189736
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,true,false,false,true,-55.4553,0.187262
0.187262
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_array,1024,8,1,50,-1,false,false,false,true,-64.1939,0.217188
0.217188
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.142272
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 32 seconds of which 6.11047 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
year_prediction_msd 90 100 false
1024 8 1 20 gpu_array
gpu_array,1024,8,1,20,-1,true,false,false,false,-49.8332,0.167798
gpu_array,1024,8,1,20,2,true,false,true,false,-87.5351,0.294038
gpu_array,1024,8,1,20,4,true,false,true,false,-79.4907,0.267108
1024 8 1 20 gpu_sparse
gpu_sparse,1024,8,1,20,-1,true,false,false,false,-56.7825,0.192127
gpu_sparse,1024,8,1,20,2,true,false,true,false,-94.8681,0.317467
gpu_sparse,1024,8,1,20,4,true,false,true,false,-85.2058,0.287375
1024 8 1 20 gpu_reorg
gpu_reorg,1024,8,1,20,-1,true,false,false,false,-62.1087,0.211632
gpu_reorg,1024,8,1,20,2,true,false,true,false,-114.362,0.385597
gpu_reorg,1024,8,1,20,4,true,false,true,false,-142.656,0.488927
1024 8 1 50 gpu_array
gpu_array,1024,8,1,50,-1,true,false,false,false,-70.1878,0.235994
gpu_array,1024,8,1,50,2,true,false,true,false,-158.533,0.530835
gpu_array,1024,8,1,50,4,true,false,true,false,-158.948,0.531875
1024 8 1 50 gpu_sparse
gpu_sparse,1024,8,1,50,-1,true,false,false,false,-78.0727,0.262218
gpu_sparse,1024,8,1,50,2,true,false,true,false,-157.739,0.528838
gpu_sparse,1024,8,1,50,4,true,false,true,false,-157.847,0.528862
1024 8 1 50 gpu_reorg
gpu_reorg,1024,8,1,50,-1,true,false,false,false,-85.4071,0.287267
gpu_reorg,1024,8,1,50,2,true,false,true,false,-158.595,0.532153
gpu_reorg,1024,8,1,50,4,true,false,true,false,-159.196,0.533301
1024 32 1 20 gpu_array
gpu_array,1024,32,1,20,-1,true,false,false,false,-45.0184,0.152487
gpu_array,1024,32,1,20,2,true,false,true,false,-51.7898,0.174025
gpu_array,1024,32,1,20,4,true,false,true,false,-53.6264,0.18021
1024 32 1 20 gpu_sparse
gpu_sparse,1024,32,1,20,-1,true,false,false,false,-44.8697,0.151771
gpu_sparse,1024,32,1,20,2,true,false,true,false,-51.9955,0.177347
gpu_sparse,1024,32,1,20,4,true,false,true,false,-51.362,0.173166
1024 32 1 20 gpu_reorg
gpu_reorg,1024,32,1,20,-1,true,false,false,false,-63.129,0.213747
gpu_reorg,1024,32,1,20,2,true,false,true,false,-152.68,0.42757
gpu_reorg,1024,32,1,20,4,true,false,true,false,-82.9594,0.278857
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,true,false,false,true,-42.0121,0.142178
0.142178
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,32,1,20,-1,false,false,false,true,-59.6414,0.200446
0.200446
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,true,false,false,true,-53.0787,0.179124
0.179124
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,20,-1,false,false,false,true,-66.0261,0.223949
0.223949
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,true,false,false,true,-63.9594,0.215446
0.215446
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,1024,8,1,50,-1,false,false,false,true,-72.5746,0.244771
0.244771
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	1024
Best kernel execution time: 0.142178
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 32 seconds of which 5.97105 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-348.712,1.17188
gpu_array,2048,8,1,20,2,true,false,true,false,-277.615,0.943563
gpu_array,2048,8,1,20,4,true,false,true,false,-276.59,0.939377
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-390.39,1.31006
gpu_sparse,2048,8,1,20,2,true,false,true,false,-351.908,1.19332
gpu_sparse,2048,8,1,20,4,true,false,true,false,-349.163,1.18092
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-423.904,1.42228
gpu_reorg,2048,8,1,20,2,true,false,true,false,-290.919,0.992469
gpu_reorg,2048,8,1,20,4,true,false,true,false,-281.799,0.960075
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-395.46,1.33213
gpu_array,2048,8,1,50,2,true,false,true,false,-309.12,1.05
gpu_array,2048,8,1,50,4,true,false,true,false,-305.541,1.04126
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-416.016,1.39986
gpu_sparse,2048,8,1,50,2,true,false,true,false,-383.557,1.29837
gpu_sparse,2048,8,1,50,4,true,false,true,false,-383.57,1.29867
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-572.938,1.91711
gpu_reorg,2048,8,1,50,2,true,false,true,false,-316.713,1.07846
gpu_reorg,2048,8,1,50,4,true,false,true,false,-324.768,1.10305
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-395.397,1.32758
gpu_array,2048,32,1,20,2,true,false,true,false,-234.672,0.795242
gpu_array,2048,32,1,20,4,true,false,true,false,-219.381,0.7421
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-396.478,1.32883
gpu_sparse,2048,32,1,20,2,true,false,true,false,-258.359,0.865639
gpu_sparse,2048,32,1,20,4,true,false,true,false,-244.148,0.826782
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-537.253,1.7974
gpu_reorg,2048,32,1,20,2,true,false,true,false,-305.378,1.03175
gpu_reorg,2048,32,1,20,4,true,false,true,false,-318.251,1.07683
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-218.703,0.740026
0.740026
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-242.385,0.823656
0.823656
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-268.001,0.911478
0.911478
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-304.041,1.03495
1.03495
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,true,-280.96,0.951329
0.951329
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,true,-321.616,1.09004
1.09004
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.740026
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 61 seconds of which 45.4367 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
abalone 8 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-348.659,1.17332
gpu_array,2048,8,1,20,2,true,false,true,false,-278.108,0.946069
gpu_array,2048,8,1,20,4,true,false,true,false,-278.009,0.94301
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-390.864,1.31211
gpu_sparse,2048,8,1,20,2,true,false,true,false,-352.457,1.19649
gpu_sparse,2048,8,1,20,4,true,false,true,false,-349.227,1.18414
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-424.177,1.42356
gpu_reorg,2048,8,1,20,2,true,false,true,false,-290.39,0.993657
gpu_reorg,2048,8,1,20,4,true,false,true,false,-282.294,0.962358
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-395.859,1.33437
gpu_array,2048,8,1,50,2,true,false,true,false,-309.324,1.05269
gpu_array,2048,8,1,50,4,true,false,true,false,-305.686,1.04366
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-417.337,1.40187
gpu_sparse,2048,8,1,50,2,true,false,true,false,-385.242,1.30022
gpu_sparse,2048,8,1,50,4,true,false,true,false,-384.783,1.29976
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-573.76,1.91942
gpu_reorg,2048,8,1,50,2,true,false,true,false,-317.052,1.08005
gpu_reorg,2048,8,1,50,4,true,false,true,false,-326.151,1.10209
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-395.701,1.32872
gpu_array,2048,32,1,20,2,true,false,true,false,-235.108,0.795926
gpu_array,2048,32,1,20,4,true,false,true,false,-219.4,0.742288
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-396.655,1.32966
gpu_sparse,2048,32,1,20,2,true,false,true,false,-252.827,0.858691
gpu_sparse,2048,32,1,20,4,true,false,true,false,-244.223,0.827742
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-537.491,1.79827
gpu_reorg,2048,32,1,20,2,true,false,true,false,-305.4,1.03377
gpu_reorg,2048,32,1,20,4,true,false,true,false,-318.223,1.07781
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-219.068,0.740897
0.740897
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-243.245,0.823521
0.823521
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-267.767,0.911615
0.911615
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-304.118,1.03601
1.03601
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,true,-281.118,0.952443
0.952443
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,true,-321.822,1.09071
1.09071
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json	2048
Best kernel execution time: 0.740897
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json 61 seconds of which 45.4864 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/abalone_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-53.252,0.179194
gpu_array,2048,8,1,20,2,true,false,true,false,-47.4469,0.160542
gpu_array,2048,8,1,20,4,true,false,true,false,-47.1733,0.160199
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-65.3297,0.219146
gpu_sparse,2048,8,1,20,2,true,false,true,false,-60.4175,0.203105
gpu_sparse,2048,8,1,20,4,true,false,true,false,-60.5704,0.203067
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-57.4814,0.192896
gpu_reorg,2048,8,1,20,2,true,false,true,false,-50.8052,0.172874
gpu_reorg,2048,8,1,20,4,true,false,true,false,-51.2436,0.174333
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-70.7401,0.237961
gpu_array,2048,8,1,50,2,true,false,true,false,-61.0812,0.205921
gpu_array,2048,8,1,50,4,true,false,true,false,-61.0053,0.20566
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-84.8299,0.284342
gpu_sparse,2048,8,1,50,2,true,false,true,false,-79.2502,0.26688
gpu_sparse,2048,8,1,50,4,true,false,true,false,-79.6214,0.26723
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-73.8929,0.248741
gpu_reorg,2048,8,1,50,2,true,false,true,false,-70.4359,0.23648
gpu_reorg,2048,8,1,50,4,true,false,true,false,-70.2688,0.236615
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-40.5589,0.137854
gpu_array,2048,32,1,20,2,true,false,true,false,-29.3573,0.10026
gpu_array,2048,32,1,20,4,true,false,true,false,-29.0342,0.0991235
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-41.121,0.138806
gpu_sparse,2048,32,1,20,2,true,false,true,false,-33.4429,0.113285
gpu_sparse,2048,32,1,20,4,true,false,true,false,-33.5659,0.114266
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-52.5296,0.177443
gpu_reorg,2048,32,1,20,2,true,false,true,false,-41.0752,0.139115
gpu_reorg,2048,32,1,20,4,true,false,true,false,-41.5233,0.140793
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-27.2553,0.0928792
0.0928792
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-36.0845,0.122056
0.122056
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-46.0659,0.156281
0.156281
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-47.5871,0.161936
0.161936
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,true,-49.7715,0.168481
0.168481
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,true,-51.9681,0.175977
0.175977
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0928792
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 17 seconds of which 7.24223 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline 13 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-53.1571,0.178796
gpu_array,2048,8,1,20,2,true,false,true,false,-47.185,0.159701
gpu_array,2048,8,1,20,4,true,false,true,false,-46.81,0.159195
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-65.32,0.219014
gpu_sparse,2048,8,1,20,2,true,false,true,false,-60.3873,0.202592
gpu_sparse,2048,8,1,20,4,true,false,true,false,-60.4908,0.203037
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-57.3639,0.192265
gpu_reorg,2048,8,1,20,2,true,false,true,false,-50.5072,0.171969
gpu_reorg,2048,8,1,20,4,true,false,true,false,-51.375,0.174325
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-70.5276,0.236569
gpu_array,2048,8,1,50,2,true,false,true,false,-61.1244,0.206141
gpu_array,2048,8,1,50,4,true,false,true,false,-61.3933,0.206265
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-84.8856,0.284368
gpu_sparse,2048,8,1,50,2,true,false,true,false,-79.2182,0.265215
gpu_sparse,2048,8,1,50,4,true,false,true,false,-79.1026,0.265601
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-73.7496,0.248904
gpu_reorg,2048,8,1,50,2,true,false,true,false,-70.0023,0.235487
gpu_reorg,2048,8,1,50,4,true,false,true,false,-70.1408,0.235646
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-40.612,0.136993
gpu_array,2048,32,1,20,2,true,false,true,false,-29.2739,0.0996737
gpu_array,2048,32,1,20,4,true,false,true,false,-29.0299,0.0990055
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-40.9576,0.13813
gpu_sparse,2048,32,1,20,2,true,false,true,false,-33.4453,0.113782
gpu_sparse,2048,32,1,20,4,true,false,true,false,-33.6716,0.114037
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-52.2666,0.176305
gpu_reorg,2048,32,1,20,2,true,false,true,false,-41.0253,0.139224
gpu_reorg,2048,32,1,20,4,true,false,true,false,-41.2966,0.139925
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-27.2158,0.0933195
0.0933195
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-35.687,0.121591
0.121591
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-45.9152,0.156133
0.156133
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-47.7889,0.162263
0.162263
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-49.6634,0.168149
0.168149
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-51.5701,0.174559
0.174559
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json	2048
Best kernel execution time: 0.0933195
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json 17 seconds of which 7.22311 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: true
	Representation: gpu_array
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-1041.7,3.48616
gpu_array,2048,8,1,20,2,true,false,true,false,-567.736,1.90116
gpu_array,2048,8,1,20,4,true,false,true,false,-362.911,1.22712
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-1021.91,3.41982
gpu_sparse,2048,8,1,20,2,true,false,true,false,-569.719,1.90786
gpu_sparse,2048,8,1,20,4,true,false,true,false,-409.217,1.37693
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-1042.9,3.49029
gpu_reorg,2048,8,1,20,2,true,false,true,false,-534.694,1.79135
gpu_reorg,2048,8,1,20,4,true,false,true,false,-601.715,2.01596
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-524.493,1.75941
gpu_array,2048,8,1,50,2,true,false,true,false,-334.65,1.13361
gpu_array,2048,8,1,50,4,true,false,true,false,-366.891,1.22216
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-546.764,1.83171
gpu_sparse,2048,8,1,50,2,true,false,true,false,-372.576,1.25948
gpu_sparse,2048,8,1,50,4,true,false,true,false,-379.16,1.27992
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-592.723,1.98546
gpu_reorg,2048,8,1,50,2,true,false,true,false,-271.754,0.921777
gpu_reorg,2048,8,1,50,4,true,false,true,false,-345.039,1.16584
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,-358.4,1.03681
1.03681
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,-535.107,1.79328
1.79328
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,true,false,true,true,-500.316,1.67639
1.67639
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,false,false,true,true,-1387.96,4.64687
4.64687
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.921777
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 82 seconds of which 52.0143 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
airline-ohe 692 1000 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-1041.42,3.48551
gpu_array,2048,8,1,20,2,true,false,true,false,-567.676,1.90092
gpu_array,2048,8,1,20,4,true,false,true,false,-362.788,1.22403
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-1021.72,3.41955
gpu_sparse,2048,8,1,20,2,true,false,true,false,-569.599,1.90754
gpu_sparse,2048,8,1,20,4,true,false,true,false,-408.179,1.37417
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-1042.71,3.49013
gpu_reorg,2048,8,1,20,2,true,false,true,false,-534.322,1.79043
gpu_reorg,2048,8,1,20,4,true,false,true,false,-601.617,2.01527
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-524.698,1.75805
gpu_array,2048,8,1,50,2,true,false,true,false,-333.845,1.13312
gpu_array,2048,8,1,50,4,true,false,true,false,-359.267,1.21004
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-546.895,1.83128
gpu_sparse,2048,8,1,50,2,true,false,true,false,-372.784,1.25982
gpu_sparse,2048,8,1,50,4,true,false,true,false,-379.462,1.2792
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-592.496,1.98527
gpu_reorg,2048,8,1,50,2,true,false,true,false,-271.767,0.921557
gpu_reorg,2048,8,1,50,4,true,false,true,false,-344.969,1.16528
2048 32 1 20 gpu_array
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_sparse
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
2048 32 1 20 gpu_reorg
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,true,false,true,true,-348.991,1.02179
1.02179
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,50,2,false,false,true,true,-534.941,1.79243
1.79243
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_reorg
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,true,false,true,true,-500.266,1.67643
1.67643
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json,gpu_reorg,2048,8,1,20,2,false,false,true,true,-1387.59,4.64785
4.64785
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json	2048
Best kernel execution time: 0.921557
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json 82 seconds of which 51.9656 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/airline-ohe_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_reorg
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-334.311,1.12717
gpu_array,2048,8,1,20,2,true,false,true,false,-454.22,1.5198
gpu_array,2048,8,1,20,4,true,false,true,false,-444.261,1.4876
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-330.143,1.11639
gpu_sparse,2048,8,1,20,2,true,false,true,false,-461.863,1.53964
gpu_sparse,2048,8,1,20,4,true,false,true,false,-451.823,1.51362
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-483.36,1.61886
gpu_reorg,2048,8,1,20,2,true,false,true,false,-422.784,1.41726
gpu_reorg,2048,8,1,20,4,true,false,true,false,-357.201,1.2017
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-490.546,1.64225
gpu_array,2048,8,1,50,2,true,false,true,false,-514.437,1.72191
gpu_array,2048,8,1,50,4,true,false,true,false,-617.13,2.06685
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-477.063,1.59708
gpu_sparse,2048,8,1,50,2,true,false,true,false,-616.268,2.06583
gpu_sparse,2048,8,1,50,4,true,false,true,false,-636.877,2.13219
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-557.142,1.86474
gpu_reorg,2048,8,1,50,2,true,false,true,false,-416.878,1.4034
gpu_reorg,2048,8,1,50,4,true,false,true,false,-717.796,2.41293
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-382.931,1.29185
gpu_array,2048,32,1,20,2,true,false,true,false,-292.921,0.989285
gpu_array,2048,32,1,20,4,true,false,true,false,-236.11,0.80131
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-353.816,1.19291
gpu_sparse,2048,32,1,20,2,true,false,true,false,-294.457,0.995006
gpu_sparse,2048,32,1,20,4,true,false,true,false,-249.111,0.848396
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-435.468,1.4594
gpu_reorg,2048,32,1,20,2,true,false,true,false,-324.642,1.09666
gpu_reorg,2048,32,1,20,4,true,false,true,false,-334.102,1.12864
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-244.726,0.828841
0.828841
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-385.231,1.29145
1.29145
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,-286.515,0.967304
0.967304
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,-306.113,1.03434
1.03434
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,-393.883,1.32087
1.32087
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-422.257,1.4184
1.4184
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.80131
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 80 seconds of which 56.6648 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
covtype 54 800 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-334.362,1.12763
gpu_array,2048,8,1,20,2,true,false,true,false,-455.887,1.52216
gpu_array,2048,8,1,20,4,true,false,true,false,-444.233,1.48649
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-329.831,1.11588
gpu_sparse,2048,8,1,20,2,true,false,true,false,-458.939,1.53659
gpu_sparse,2048,8,1,20,4,true,false,true,false,-453.118,1.51822
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-483.671,1.61879
gpu_reorg,2048,8,1,20,2,true,false,true,false,-423.466,1.41731
gpu_reorg,2048,8,1,20,4,true,false,true,false,-355.049,1.19725
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-490.467,1.64139
gpu_array,2048,8,1,50,2,true,false,true,false,-513.279,1.71815
gpu_array,2048,8,1,50,4,true,false,true,false,-617.257,2.06573
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-476.945,1.59721
gpu_sparse,2048,8,1,50,2,true,false,true,false,-620.344,2.07174
gpu_sparse,2048,8,1,50,4,true,false,true,false,-637.123,2.13314
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-557.483,1.8651
gpu_reorg,2048,8,1,50,2,true,false,true,false,-417.913,1.40731
gpu_reorg,2048,8,1,50,4,true,false,true,false,-718.003,2.40236
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-383.647,1.29125
gpu_array,2048,32,1,20,2,true,false,true,false,-292.863,0.989586
gpu_array,2048,32,1,20,4,true,false,true,false,-236.042,0.801622
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-353.762,1.1928
gpu_sparse,2048,32,1,20,2,true,false,true,false,-294.692,0.995003
gpu_sparse,2048,32,1,20,4,true,false,true,false,-249.126,0.84928
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-435.244,1.45992
gpu_reorg,2048,32,1,20,2,true,false,true,false,-324.809,1.09725
gpu_reorg,2048,32,1,20,4,true,false,true,false,-334.179,1.1282
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,true,false,true,true,-244.692,0.828251
0.828251
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,32,1,20,4,false,false,true,true,-384.848,1.29231
1.29231
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,true,false,false,true,-286.447,0.966822
0.966822
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,20,-1,false,false,false,true,-305.733,1.0344
1.0344
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,true,false,false,true,-393.967,1.32093
1.32093
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-422.351,1.41861
1.41861
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json	2048
Best kernel execution time: 0.801622
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json 80 seconds of which 56.6583 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/covtype_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 4
	sharedMemoryReduce: false
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,-473.687,1.58925
gpu_array,2048,8,1,20,2,false,false,true,false,-427.229,1.43265
gpu_array,2048,8,1,20,4,false,false,true,false,-388.973,1.30707
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,-483.275,1.62378
gpu_sparse,2048,8,1,20,2,false,false,true,false,-455.786,1.52931
gpu_sparse,2048,8,1,20,4,false,false,true,false,-390.466,1.31193
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,-556.95,1.86813
gpu_reorg,2048,8,1,20,2,false,false,true,false,-439.558,1.47528
gpu_reorg,2048,8,1,20,4,false,false,true,false,-457.368,1.53605
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,-203.258,0.686249
gpu_array,2048,8,1,50,2,false,false,true,false,-208.048,0.701873
gpu_array,2048,8,1,50,4,false,false,true,false,-208.206,0.701856
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,-208.864,0.704502
gpu_sparse,2048,8,1,50,2,false,false,true,false,-236.071,0.796484
gpu_sparse,2048,8,1,50,4,false,false,true,false,-235.681,0.795904
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,-214.022,0.723241
gpu_reorg,2048,8,1,50,2,false,false,true,false,-204.839,0.691536
gpu_reorg,2048,8,1,50,4,false,false,true,false,-205.747,0.695117
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,-319.56,1.0748
gpu_array,2048,32,1,20,2,false,false,true,false,-302.859,1.0183
gpu_array,2048,32,1,20,4,false,false,true,false,-307.785,1.03575
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,-325.016,1.09406
gpu_sparse,2048,32,1,20,2,false,false,true,false,-309.897,1.0421
gpu_sparse,2048,32,1,20,4,false,false,true,false,-325.913,1.09578
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,-364.931,1.2264
gpu_reorg,2048,32,1,20,2,false,false,true,false,-347.635,1.16801
gpu_reorg,2048,32,1,20,4,false,false,true,false,-361.987,1.21171
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-193.573,0.653156
0.653156
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-296.189,0.995973
0.995973
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-297.994,1.00244
1.00244
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.653156
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 50 seconds of which 40.2907 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
epsilon 2000 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,false,false,false,false,-473.632,1.58814
gpu_array,2048,8,1,20,2,false,false,true,false,-427.007,1.43209
gpu_array,2048,8,1,20,4,false,false,true,false,-387.807,1.30438
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,false,false,false,false,-483.497,1.62349
gpu_sparse,2048,8,1,20,2,false,false,true,false,-455.264,1.52765
gpu_sparse,2048,8,1,20,4,false,false,true,false,-390.573,1.31278
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,false,false,false,false,-557.664,1.86987
gpu_reorg,2048,8,1,20,2,false,false,true,false,-439.022,1.47412
gpu_reorg,2048,8,1,20,4,false,false,true,false,-457.304,1.5361
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,false,false,false,false,-203.177,0.686096
gpu_array,2048,8,1,50,2,false,false,true,false,-208.019,0.701409
gpu_array,2048,8,1,50,4,false,false,true,false,-208.314,0.702336
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,false,false,false,false,-208.699,0.705286
gpu_sparse,2048,8,1,50,2,false,false,true,false,-236.078,0.796511
gpu_sparse,2048,8,1,50,4,false,false,true,false,-235.886,0.796497
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,false,false,false,false,-214.078,0.723652
gpu_reorg,2048,8,1,50,2,false,false,true,false,-204.861,0.691299
gpu_reorg,2048,8,1,50,4,false,false,true,false,-207.371,0.698209
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,false,false,false,false,-319.562,1.07458
gpu_array,2048,32,1,20,2,false,false,true,false,-302.831,1.01875
gpu_array,2048,32,1,20,4,false,false,true,false,-307.873,1.0359
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,false,false,false,false,-325.101,1.09417
gpu_sparse,2048,32,1,20,2,false,false,true,false,-309.913,1.04254
gpu_sparse,2048,32,1,20,4,false,false,true,false,-325.858,1.09527
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,false,false,false,false,-365.441,1.22791
gpu_reorg,2048,32,1,20,2,false,false,true,false,-347.981,1.16933
gpu_reorg,2048,32,1,20,4,false,false,true,false,-359.991,1.21078
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: false
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,50,-1,false,false,false,true,-193.546,0.65319
0.65319
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-296.12,0.995887
0.995887
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: false
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-297.779,1.00182
1.00182
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json	2048
Best kernel execution time: 0.65319
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json 50 seconds of which 40.2924 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/epsilon_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: false
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-53.6983,0.181046
gpu_array,2048,8,1,20,2,true,false,true,false,-46.8541,0.158592
gpu_array,2048,8,1,20,4,true,false,true,false,-46.1855,0.156769
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-65.2957,0.218925
gpu_sparse,2048,8,1,20,2,true,false,true,false,-58.1361,0.195477
gpu_sparse,2048,8,1,20,4,true,false,true,false,-58.1391,0.196333
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-61.7266,0.208412
gpu_reorg,2048,8,1,20,2,true,false,true,false,-54.8285,0.186121
gpu_reorg,2048,8,1,20,4,true,false,true,false,-55.1936,0.187275
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-74.184,0.247684
gpu_array,2048,8,1,50,2,true,false,true,false,-59.0625,0.198704
gpu_array,2048,8,1,50,4,true,false,true,false,-58.8082,0.198598
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-85.3251,0.285777
gpu_sparse,2048,8,1,50,2,true,false,true,false,-69.9789,0.23445
gpu_sparse,2048,8,1,50,4,true,false,true,false,-69.7321,0.234258
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-78.4042,0.263286
gpu_reorg,2048,8,1,50,2,true,false,true,false,-75.0689,0.251882
gpu_reorg,2048,8,1,50,4,true,false,true,false,-74.9426,0.251694
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-44.0573,0.148222
gpu_array,2048,32,1,20,2,true,false,true,false,-34.0086,0.1164
gpu_array,2048,32,1,20,4,true,false,true,false,-35.1761,0.118791
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-46.6231,0.155697
gpu_sparse,2048,32,1,20,2,true,false,true,false,-38.9862,0.131948
gpu_sparse,2048,32,1,20,4,true,false,true,false,-39.9149,0.13495
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-63.6215,0.214896
gpu_reorg,2048,32,1,20,2,true,false,true,false,-54.8884,0.184863
gpu_reorg,2048,32,1,20,4,true,false,true,false,-54.4559,0.183262
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,-33.3956,0.113634
0.113634
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-45.1443,0.15261
0.15261
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-45.2167,0.152942
0.152942
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-50.6853,0.171645
0.171645
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,4,true,false,true,true,-46.4697,0.157303
0.157303
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,4,false,false,true,true,-52.9271,0.179335
0.179335
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.113634
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 17 seconds of which 7.58388 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
higgs 28 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-53.7116,0.180537
gpu_array,2048,8,1,20,2,true,false,true,false,-46.9239,0.158658
gpu_array,2048,8,1,20,4,true,false,true,false,-45.9812,0.156
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-65.2487,0.21955
gpu_sparse,2048,8,1,20,2,true,false,true,false,-58.1569,0.195187
gpu_sparse,2048,8,1,20,4,true,false,true,false,-58.1859,0.195986
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-61.6633,0.208285
gpu_reorg,2048,8,1,20,2,true,false,true,false,-54.439,0.184028
gpu_reorg,2048,8,1,20,4,true,false,true,false,-54.8657,0.186025
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-71.7554,0.241694
gpu_array,2048,8,1,50,2,true,false,true,false,-58.9406,0.19808
gpu_array,2048,8,1,50,4,true,false,true,false,-58.965,0.198584
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-85.174,0.285477
gpu_sparse,2048,8,1,50,2,true,false,true,false,-69.8063,0.234224
gpu_sparse,2048,8,1,50,4,true,false,true,false,-69.529,0.233722
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-78.4744,0.26335
gpu_reorg,2048,8,1,50,2,true,false,true,false,-74.9831,0.251777
gpu_reorg,2048,8,1,50,4,true,false,true,false,-74.8889,0.251265
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-43.825,0.147664
gpu_array,2048,32,1,20,2,true,false,true,false,-34.6882,0.116943
gpu_array,2048,32,1,20,4,true,false,true,false,-34.8795,0.118075
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-45.8218,0.154736
gpu_sparse,2048,32,1,20,2,true,false,true,false,-38.5836,0.130226
gpu_sparse,2048,32,1,20,4,true,false,true,false,-39.7061,0.134259
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-63.5961,0.214915
gpu_reorg,2048,32,1,20,2,true,false,true,false,-54.6128,0.184578
gpu_reorg,2048,32,1,20,4,true,false,true,false,-54.6394,0.183881
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: false
	Representation: gpu_array
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,true,false,true,true,-33.3341,0.113677
0.113677
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,32,1,20,2,false,false,true,true,-45.2707,0.152635
0.152635
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 4
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,true,false,true,true,-44.9877,0.152469
0.152469
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,20,4,false,false,true,true,-50.7292,0.172144
0.172144
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_array
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,true,false,true,true,-46.0308,0.156721
0.156721
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json,gpu_array,2048,8,1,50,2,false,false,true,true,-52.9054,0.179548
0.179548
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json	2048
Best kernel execution time: 0.113677
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json 17 seconds of which 7.56314 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/higgs_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: true
	interleaveDepth: 2
	sharedMemoryReduce: true
	Representation: gpu_array
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-3210.36,133.979
gpu_array,2048,8,1,20,2,true,false,true,false,-1818.36,72.4555
gpu_array,2048,8,1,20,4,true,false,true,false,-2888.8,118.571
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-2853.97,118.267
gpu_sparse,2048,8,1,20,2,true,false,true,false,-2280.17,91.9983
gpu_sparse,2048,8,1,20,4,true,false,true,false,-3306.26,136.76
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-4309.68,178.908
gpu_reorg,2048,8,1,20,2,true,false,true,false,-5518.42,224.163
gpu_reorg,2048,8,1,20,4,true,false,true,false,-11314.9,469.879
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-4361.51,180.958
gpu_array,2048,8,1,50,2,true,false,true,false,-5096.64,210.071
gpu_array,2048,8,1,50,4,true,false,true,false,-5627.57,231.012
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-3397.44,140.685
gpu_sparse,2048,8,1,50,2,true,false,true,false,-4993.87,206.78
gpu_sparse,2048,8,1,50,4,true,false,true,false,-5085.43,211.116
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-5172.53,215.007
gpu_reorg,2048,8,1,50,2,true,false,true,false,-14389.3,596.369
gpu_reorg,2048,8,1,50,4,true,false,true,false,-12637.6,526.003
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-1982.43,81.0657
gpu_array,2048,32,1,20,2,true,false,true,false,-1923.41,78.9106
gpu_array,2048,32,1,20,4,true,false,true,false,-1701.74,69.4068
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-1675.53,67.9488
gpu_sparse,2048,32,1,20,2,true,false,true,false,-1920.63,78.8322
gpu_sparse,2048,32,1,20,4,true,false,true,false,-1744.34,70.9543
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-1987.83,82.4869
gpu_reorg,2048,32,1,20,2,true,false,true,false,-5736.11,238.66
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,-2238.96,90.6142
90.6142
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,-2348.31,95.7794
95.7794
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,-1444.41,58.4022
58.4022
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,-1508.2,60.8563
60.8563
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 58.4022
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 780 seconds of which 526.018 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
letters 16 26000 true
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-3200.19,133.749
gpu_array,2048,8,1,20,2,true,false,true,false,-1792.17,71.5427
gpu_array,2048,8,1,20,4,true,false,true,false,-2770.04,115.504
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-2866.59,118.512
gpu_sparse,2048,8,1,20,2,true,false,true,false,-2289.63,92.3233
gpu_sparse,2048,8,1,20,4,true,false,true,false,-3343.72,137.699
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-4315.67,179.543
gpu_reorg,2048,8,1,20,2,true,false,true,false,-5232.09,219.604
gpu_reorg,2048,8,1,20,4,true,false,true,false,-11272.6,472.054
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-4360.31,180.737
gpu_array,2048,8,1,50,2,true,false,true,false,-5109.74,209.834
gpu_array,2048,8,1,50,4,true,false,true,false,-5443.41,226.989
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-3403.52,140.667
gpu_sparse,2048,8,1,50,2,true,false,true,false,-4979.97,206.034
gpu_sparse,2048,8,1,50,4,true,false,true,false,-5096.36,209.478
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-5166.71,215.054
gpu_reorg,2048,8,1,50,2,true,false,true,false,-14506.6,605.354
gpu_reorg,2048,8,1,50,4,true,false,true,false,-12621.4,525.647
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-1982.37,81.0741
gpu_array,2048,32,1,20,2,true,false,true,false,-1921.89,79.1081
gpu_array,2048,32,1,20,4,true,false,true,false,-1704.02,69.6156
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-1673.09,68.3824
gpu_sparse,2048,32,1,20,2,true,false,true,false,-1929.15,79.0572
gpu_sparse,2048,32,1,20,4,true,false,true,false,-1724.66,70.6601
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-2003.23,82.6741
gpu_reorg,2048,32,1,20,2,true,false,true,false,-5707.02,238.582
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, smem, stream, params, extra)' failed with 'CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES'
gpu_reorg,2048,32,1,20,4,true,false,true,false,-1,-1
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Shared memory size exceeds maximum allowed size.
Lowering to LLVM failed.
-1
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: true
interleaveDepth: 2
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,true,false,true,true,-2227.48,90.4053
90.4053
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,20,2,false,false,true,true,-2360.85,96.046
96.046
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,-1450.32,58.5472
58.5472
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,-1501.8,60.7236
60.7236
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json	2048
Best kernel execution time: 58.5472
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json 779 seconds of which 525.845 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/letters_xgb_model_save.json is: 
	numRowsPerTB: 8
	numRowsPerThread: 1
	numTreeThreads: 50
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-45.8604,0.154731
gpu_array,2048,8,1,20,2,true,false,true,false,-84.3655,0.282937
gpu_array,2048,8,1,20,4,true,false,true,false,-75.1804,0.252708
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-54.5887,0.183778
gpu_sparse,2048,8,1,20,2,true,false,true,false,-86.677,0.291726
gpu_sparse,2048,8,1,20,4,true,false,true,false,-83.31,0.279858
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-58.124,0.196772
gpu_reorg,2048,8,1,20,2,true,false,true,false,-116.802,0.390663
gpu_reorg,2048,8,1,20,4,true,false,true,false,-218.272,0.581423
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-67.3992,0.226742
gpu_array,2048,8,1,50,2,true,false,true,false,-160.28,0.53705
gpu_array,2048,8,1,50,4,true,false,true,false,-156.993,0.526456
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-75.2997,0.253003
gpu_sparse,2048,8,1,50,2,true,false,true,false,-157.808,0.528984
gpu_sparse,2048,8,1,50,4,true,false,true,false,-155.634,0.521539
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-82.7201,0.278407
gpu_reorg,2048,8,1,50,2,true,false,true,false,-156.71,0.525194
gpu_reorg,2048,8,1,50,4,true,false,true,false,-156.888,0.525645
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-40.7884,0.137362
gpu_array,2048,32,1,20,2,true,false,true,false,-46.2086,0.155155
gpu_array,2048,32,1,20,4,true,false,true,false,-47.9551,0.161083
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-39.9696,0.134875
gpu_sparse,2048,32,1,20,2,true,false,true,false,-46.21,0.155196
gpu_sparse,2048,32,1,20,4,true,false,true,false,-45.7056,0.153801
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-57.1686,0.192712
gpu_reorg,2048,32,1,20,2,true,false,true,false,-58.1425,0.195343
gpu_reorg,2048,32,1,20,4,true,false,true,false,-65.6312,0.220406
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,-37.2324,0.125557
0.125557
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,-54.6711,0.183884
0.183884
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,-50.6788,0.171282
0.171282
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,-65.2616,0.2198
0.2198
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,-62.4127,0.209831
0.209831
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,-71.124,0.238833
0.238833
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.125557
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 37 seconds of which 11.296 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
year_prediction_msd 90 100 false
2048 8 1 20 gpu_array
gpu_array,2048,8,1,20,-1,true,false,false,false,-45.912,0.154937
gpu_array,2048,8,1,20,2,true,false,true,false,-84.1153,0.282122
gpu_array,2048,8,1,20,4,true,false,true,false,-74.8283,0.251737
2048 8 1 20 gpu_sparse
gpu_sparse,2048,8,1,20,-1,true,false,false,false,-54.4336,0.183118
gpu_sparse,2048,8,1,20,2,true,false,true,false,-86.8852,0.291546
gpu_sparse,2048,8,1,20,4,true,false,true,false,-83.0427,0.278624
2048 8 1 20 gpu_reorg
gpu_reorg,2048,8,1,20,-1,true,false,false,false,-58.1452,0.196634
gpu_reorg,2048,8,1,20,2,true,false,true,false,-116.233,0.388893
gpu_reorg,2048,8,1,20,4,true,false,true,false,-128.526,0.430155
2048 8 1 50 gpu_array
gpu_array,2048,8,1,50,-1,true,false,false,false,-66.9905,0.225346
gpu_array,2048,8,1,50,2,true,false,true,false,-159.475,0.534488
gpu_array,2048,8,1,50,4,true,false,true,false,-156.25,0.523667
2048 8 1 50 gpu_sparse
gpu_sparse,2048,8,1,50,-1,true,false,false,false,-75.209,0.251964
gpu_sparse,2048,8,1,50,2,true,false,true,false,-157.06,0.526292
gpu_sparse,2048,8,1,50,4,true,false,true,false,-154.905,0.518983
2048 8 1 50 gpu_reorg
gpu_reorg,2048,8,1,50,-1,true,false,false,false,-82.4061,0.277009
gpu_reorg,2048,8,1,50,2,true,false,true,false,-155.865,0.522276
gpu_reorg,2048,8,1,50,4,true,false,true,false,-155.835,0.522042
2048 32 1 20 gpu_array
gpu_array,2048,32,1,20,-1,true,false,false,false,-40.4366,0.136659
gpu_array,2048,32,1,20,2,true,false,true,false,-45.8966,0.154167
gpu_array,2048,32,1,20,4,true,false,true,false,-47.8506,0.160621
2048 32 1 20 gpu_sparse
gpu_sparse,2048,32,1,20,-1,true,false,false,false,-39.459,0.133287
gpu_sparse,2048,32,1,20,2,true,false,true,false,-45.8242,0.15429
gpu_sparse,2048,32,1,20,4,true,false,true,false,-45.5194,0.152992
2048 32 1 20 gpu_reorg
gpu_reorg,2048,32,1,20,-1,true,false,false,false,-57.0294,0.192328
gpu_reorg,2048,32,1,20,2,true,false,true,false,-57.6737,0.194491
gpu_reorg,2048,32,1,20,4,true,false,true,false,-65.3269,0.219473
Checking shared reduce
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: false
	Representation: gpu_sparse
*************
Trying shared reduce for config
numRowsPerTB: 32
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,true,false,false,true,-36.9176,0.124903
0.124903
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,32,1,20,-1,false,false,false,true,-54.144,0.182175
0.182175
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 20
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,true,false,false,true,-50.5022,0.170623
0.170623
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,20,-1,false,false,false,true,-65.0795,0.219373
0.219373
Trying shared reduce for config
numRowsPerTB: 8
numRowsPerThread: 1
numTreeThreads: 50
cacheRows: true
cacheTrees: false
unrollTreeWalks: false
interleaveDepth: -1
sharedMemoryReduce: false
Rep: gpu_sparse
*************
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,true,false,false,true,-61.8479,0.207792
0.207792
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json,gpu_sparse,2048,8,1,50,-1,false,false,false,true,-70.6314,0.237207
0.237207
/home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json	2048
Best kernel execution time: 0.124903
Time taken for auto-tuning /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json 37 seconds of which 11.0595 is kernel execution
Best schedule for /home/ashwin/mlir-build/llvm-project/mlir/examples/treebeard/xgb_models/year_prediction_msd_xgb_model_save.json is: 
	numRowsPerTB: 32
	numRowsPerThread: 1
	numTreeThreads: 20
	cacheRows: true
	cacheTrees: false
	unrollTreeWalks: false
	interleaveDepth: -1
	sharedMemoryReduce: true
	Representation: gpu_sparse
